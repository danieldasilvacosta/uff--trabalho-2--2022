{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/', force_remount=True)\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5CispoBeMZp",
        "outputId": "37850edf-cdac-468c-8a83-1ce5f281a929"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "id": "D5CispoBeMZp"
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWsthLm6e8ny",
        "outputId": "35c6b674-3e07-4de7-a15c-260aa03047c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "id": "GWsthLm6e8ny"
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llemgM4yeMca",
        "outputId": "06431999-1def-4413-d79b-448579647415"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ],
      "id": "llemgM4yeMca"
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu8ejWihdQUz",
        "outputId": "174f07eb-cb42-41f2-8965-d92f66a37940"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ],
      "id": "Wu8ejWihdQUz"
    },
    {
      "cell_type": "markdown",
      "id": "9ca39af7-84d8-469f-aaf6-f5764501dbdb",
      "metadata": {
        "id": "9ca39af7-84d8-469f-aaf6-f5764501dbdb"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a53f45d-33b3-4a40-b0e2-674577ca0149",
      "metadata": {
        "id": "3a53f45d-33b3-4a40-b0e2-674577ca0149"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4beefaac-3b23-4d8a-b2d1-a337eb0e8c33",
      "metadata": {
        "id": "4beefaac-3b23-4d8a-b2d1-a337eb0e8c33"
      },
      "source": [
        "# Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de8dbcfa-a7fe-4393-95c6-ee59e7c0da6a",
      "metadata": {
        "id": "de8dbcfa-a7fe-4393-95c6-ee59e7c0da6a"
      },
      "outputs": [],
      "source": [
        "class Vocab(object):\n",
        "    def __init__(self, iter, max_size=None, sos_token=None, eos_token=None, unk_token=None):\n",
        "        \"\"\"Initialize the vocabulary.\n",
        "        Args:\n",
        "            iter: An iterable which produces sequences of tokens used to update\n",
        "                the vocabulary.\n",
        "            max_size: (Optional) Maximum number of tokens in the vocabulary.\n",
        "            sos_token: (Optional) Token denoting the start of a sequence.\n",
        "            eos_token: (Optional) Token denoting the end of a sequence.\n",
        "            unk_token: (Optional) Token denoting an unknown element in a\n",
        "                sequence.\n",
        "        \"\"\"\n",
        "        self.max_size = max_size\n",
        "        self.pad_token = '<pad>'\n",
        "        self.sos_token = sos_token\n",
        "        self.eos_token = eos_token\n",
        "        self.unk_token = unk_token\n",
        "\n",
        "        # Add special tokens.\n",
        "        id2word = [self.pad_token]\n",
        "        if sos_token is not None:\n",
        "            id2word.append(self.sos_token)\n",
        "        if eos_token is not None:\n",
        "            id2word.append(self.eos_token)\n",
        "        if unk_token is not None:\n",
        "            id2word.append(self.unk_token)\n",
        "\n",
        "        # Update counter with token counts.\n",
        "        counter = Counter()\n",
        "        for x in iter:\n",
        "            counter.update(x)\n",
        "\n",
        "        # Extract lookup tables.\n",
        "        if max_size is not None:\n",
        "            counts = counter.most_common(max_size)\n",
        "        else:\n",
        "            counts = counter.items()\n",
        "            counts = sorted(counts, key=lambda x: x[1], reverse=True)\n",
        "        words = [x[0] for x in counts]\n",
        "        id2word.extend(words)\n",
        "        word2id = {x: i for i, x in enumerate(id2word)}\n",
        "\n",
        "        self._id2word = id2word\n",
        "        self._word2id = word2id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._id2word)\n",
        "\n",
        "    def word2id(self, word):\n",
        "        \"\"\"Map a word in the vocabulary to its unique integer id.\n",
        "        Args:\n",
        "            word: Word to lookup.\n",
        "        Returns:\n",
        "            id: The integer id of the word being looked up.\n",
        "        \"\"\"\n",
        "        if word in self._word2id:\n",
        "            return self._word2id[word]\n",
        "        elif self.unk_token is not None:\n",
        "            return self._word2id[self.unk_token]\n",
        "        else:\n",
        "            raise KeyError('Word \"%s\" not in vocabulary.' % word)\n",
        "\n",
        "    def id2word(self, id):\n",
        "        \"\"\"Map an integer id to its corresponding word in the vocabulary.\n",
        "        Args:\n",
        "            id: Integer id of the word being looked up.\n",
        "        Returns:\n",
        "            word: The corresponding word.\n",
        "        \"\"\"\n",
        "        return self._id2word[id]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e94ad8b-ff9e-4d97-be37-2fad7f172072",
      "metadata": {
        "id": "0e94ad8b-ff9e-4d97-be37-2fad7f172072"
      },
      "source": [
        "# CoNLLDataset e Annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef8512e-d6b2-4e96-a9c8-7fcb464af35c",
      "metadata": {
        "id": "5ef8512e-d6b2-4e96-a9c8-7fcb464af35c"
      },
      "outputs": [],
      "source": [
        "class Annotation(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"A helper object for storing annotation data.\"\"\"\n",
        "        self.tokens = []\n",
        "        self.pos_tags = []\n",
        "\n",
        "\n",
        "class CoNLLDataset(Dataset):\n",
        "    def __init__(self, fname, max_exs=None):\n",
        "        \"\"\"Initializes the CoNLLDataset.\n",
        "        Args:\n",
        "            fname: The .conllu file to load data from.\n",
        "        \"\"\"\n",
        "        self.fname = fname\n",
        "        self.annotations = self.process_conll_file(fname, max_exs)\n",
        "        self.token_vocab = Vocab([x.tokens for x in self.annotations],\n",
        "                                 unk_token='<unk>')\n",
        "        self.pos_vocab = Vocab([x.pos_tags for x in self.annotations])\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        annotation = self.annotations[idx]\n",
        "        input = [self.token_vocab.word2id(x) for x in annotation.tokens]\n",
        "        target = [self.pos_vocab.word2id(x) for x in annotation.pos_tags]\n",
        "        return input, target\n",
        "\n",
        "    def process_conll_file(self, fname, max_exs):\n",
        "        # Read the entire file.\n",
        "        with open(fname, 'r') as f:\n",
        "            raw_text = f.read()\n",
        "        # Split into chunks on blank lines.\n",
        "        chunks = re.split(r'^\\n', raw_text, flags=re.MULTILINE)\n",
        "        #print(chunks)\n",
        "        # Process each chunk into an annotation.\n",
        "        annotations = []\n",
        "        exs = 0\n",
        "        for chunk in chunks:\n",
        "            if not max_exs or exs < max_exs:\n",
        "                annotation = Annotation()\n",
        "                lines = chunk.split('\\n')\n",
        "                # Iterate over all lines in the chunk.\n",
        "                for line in lines:\n",
        "                    # If line is empty ignore it.\n",
        "                    if len(line)==0:\n",
        "                        continue\n",
        "                    # If line is a commend ignore it.\n",
        "                    if line[0] == '#':\n",
        "                        continue\n",
        "                    # Otherwise split on tabs and retrieve the token and the\n",
        "                    # POS tag fields.\n",
        "                    fields = line.split('\\t')\n",
        "                    annotation.tokens.append(fields[1])\n",
        "                    annotation.pos_tags.append(fields[3])\n",
        "                if (len(annotation.tokens) > 0) and (len(annotation.pos_tags) > 0):\n",
        "                    annotations.append(annotation)\n",
        "            exs += 1\n",
        "        return annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5907be-6c34-4e65-b922-9e814b771922",
      "metadata": {
        "id": "1e5907be-6c34-4e65-b922-9e814b771922"
      },
      "source": [
        "# Funções: pad() e collate_annotations()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22bfb3a3-52e1-4c2c-8563-723e15182391",
      "metadata": {
        "id": "22bfb3a3-52e1-4c2c-8563-723e15182391"
      },
      "outputs": [],
      "source": [
        "def pad(sequences, max_length, pad_value=0):\n",
        "    \"\"\"Pads a list of sequences.\n",
        "    Args:\n",
        "        sequences: A list of sequences to be padded.\n",
        "        max_length: The length to pad to.\n",
        "        pad_value: The value used for padding.\n",
        "    Returns:\n",
        "        A list of padded sequences.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for sequence in sequences:\n",
        "        padded = sequence + [0]*(max_length - len(sequence))\n",
        "        out.append(padded)\n",
        "    return out\n",
        "\n",
        "\n",
        "def collate_annotations(batch):\n",
        "    \"\"\"Function used to collate data returned by CoNLLDataset.\"\"\"\n",
        "    # Get inputs, targets, and lengths.\n",
        "    inputs, targets = zip(*batch)\n",
        "    lengths = [len(x) for x in inputs]\n",
        "    # Sort by length.\n",
        "    sort = sorted(zip(inputs, targets, lengths),\n",
        "                  key=lambda x: x[2],\n",
        "                  reverse=True)\n",
        "    inputs, targets, lengths = zip(*sort)\n",
        "    # Pad.\n",
        "    max_length = max(lengths)\n",
        "    inputs = pad(inputs, max_length)\n",
        "    targets = pad(targets, max_length)\n",
        "    # Transpose.\n",
        "    inputs = list(map(list, zip(*inputs)))\n",
        "    targets = list(map(list, zip(*targets)))\n",
        "    # Convert to PyTorch variables.\n",
        "    inputs = Variable(torch.LongTensor(inputs))\n",
        "    targets = Variable(torch.LongTensor(targets))\n",
        "    lengths = Variable(torch.LongTensor(lengths))\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "        lengths = lengths.cuda()\n",
        "    return inputs, targets, lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdecfc14-2652-47be-895b-3a89b6e65db9",
      "metadata": {
        "id": "cdecfc14-2652-47be-895b-3a89b6e65db9"
      },
      "source": [
        "# Tagger - LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e09b9f91-6d8c-40b7-b21b-e8838c66e419",
      "metadata": {
        "id": "e09b9f91-6d8c-40b7-b21b-e8838c66e419"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class Tagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 embedding_dim=64,\n",
        "                 hidden_dim=64,\n",
        "                 dropout=0.5,\n",
        "                 bidirectional=True,\n",
        "                 pad_idx=0):\n",
        "        \"\"\"Initializes the tagger.\n",
        "        \n",
        "        Args:\n",
        "            input_dim: Size of the input vocabulary, projection\n",
        "            output_dim: Size of the output vocabulary.\n",
        "            embedding_dim: Dimension of the word embeddings.\n",
        "            hidden_dim: Number of units in each LSTM hidden layer.\n",
        "            bidirectional: Whether or not to use a bidirectional rnn.\n",
        "        \"\"\"\n",
        "        super(Tagger, self).__init__()\n",
        "\n",
        "        # Store parameters\n",
        "        self.input_dim = input_dim \n",
        "        self.output_dim = output_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bidirectional = bidirectional\n",
        "          \n",
        "        # Define layers\n",
        "        self.word_embeddings = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers = n_layers, \n",
        "                          bidirectional=bidirectional,\n",
        "                          dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.activation = nn.LogSoftmax(dim=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, lengths=None, hidden=None):\n",
        "        \"\"\"Computes a forward pass of the language model.\n",
        "        \n",
        "        Args:\n",
        "            x: A LongTensor w/ dimension [seq_len, batch_size].\n",
        "            lengths: The lengths of the sequences in x.\n",
        "            hidden: Hidden state to be fed into the lstm.\n",
        "            \n",
        "        Returns:\n",
        "            net: Probability of the next word in the sequence.\n",
        "            hidden: Hidden state of the lstm.\n",
        "        \"\"\"\n",
        "        seq_len, batch_size = x.size()\n",
        "        \n",
        "        # If no hidden state is provided, then default to zeros.\n",
        "        if hidden is None:\n",
        "            if self.bidirectional:\n",
        "                num_directions = 2\n",
        "            else:\n",
        "                num_directions = 1\n",
        "            hidden = Variable(torch.zeros(num_directions, batch_size, self.hidden_dim))\n",
        "            if torch.cuda.is_available():\n",
        "                hidden = hidden.cuda()\n",
        "\n",
        "        net = self.word_embeddings(x)\n",
        "        # Pack before feeding into the RNN.\n",
        "        if lengths is not None:\n",
        "            lengths = lengths.data.view(-1).tolist()\n",
        "            net = pack_padded_sequence(net, lengths)\n",
        "        # net, hidden = self.rnn(net, hidden) # Daniel\n",
        "        net, hidden = self.rnn(net, (hidden, hidden)) # Daniel\n",
        "        # Unpack after\n",
        "        if lengths is not None:\n",
        "            net, _ = pad_packed_sequence(net)\n",
        "        net = self.fc(net)\n",
        "        net = self.activation(net)\n",
        "\n",
        "        return net, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d0c518-c0a6-42bb-bf88-c37e55c0fbd9",
      "metadata": {
        "id": "66d0c518-c0a6-42bb-bf88-c37e55c0fbd9"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020c10db-51d4-4bec-8ba7-829d3bf554af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "020c10db-51d4-4bec-8ba7-829d3bf554af",
        "outputId": "446f7187-7362-4208-efdb-afd4a099e437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Iteration 0 - Train Loss: 2.968833 - Dev Loss: 2.944645\n",
            "Epoch 0 Iteration 10 - Train Loss: 2.868050 - Dev Loss: 2.754698\n",
            "Epoch 0 Iteration 20 - Train Loss: 2.665470 - Dev Loss: 2.501058\n",
            "Epoch 0 Iteration 30 - Train Loss: 2.334254 - Dev Loss: 2.158570\n",
            "Epoch 0 Iteration 40 - Train Loss: 2.120098 - Dev Loss: 1.973297\n",
            "Epoch 0 Iteration 50 - Train Loss: 1.944630 - Dev Loss: 1.809096\n",
            "Epoch 0 Iteration 60 - Train Loss: 1.749651 - Dev Loss: 1.645241\n",
            "Epoch 0 Iteration 70 - Train Loss: 1.542222 - Dev Loss: 1.504398\n",
            "Epoch 0 Iteration 80 - Train Loss: 1.472404 - Dev Loss: 1.394716\n",
            "Epoch 0 Iteration 90 - Train Loss: 1.366670 - Dev Loss: 1.303365\n",
            "Epoch 0 Iteration 100 - Train Loss: 1.227721 - Dev Loss: 1.226141\n",
            "Epoch 0 Iteration 110 - Train Loss: 1.201088 - Dev Loss: 1.171135\n",
            "Epoch 0 Iteration 120 - Train Loss: 1.140807 - Dev Loss: 1.121336\n",
            "Epoch 0 Iteration 130 - Train Loss: 1.069339 - Dev Loss: 1.083197\n",
            "Epoch 0 Iteration 140 - Train Loss: 1.073905 - Dev Loss: 1.051408\n",
            "Epoch 0 Iteration 150 - Train Loss: 1.024022 - Dev Loss: 1.023247\n",
            "Epoch 0 Iteration 160 - Train Loss: 1.022693 - Dev Loss: 0.998973\n",
            "Epoch 0 Iteration 170 - Train Loss: 0.999312 - Dev Loss: 0.970760\n",
            "Epoch 0 Iteration 180 - Train Loss: 0.973372 - Dev Loss: 0.951194\n",
            "Epoch 0 Iteration 190 - Train Loss: 0.959322 - Dev Loss: 0.937651\n",
            "Epoch 0 Iteration 200 - Train Loss: 0.923873 - Dev Loss: 0.927306\n",
            "Epoch 0 Iteration 210 - Train Loss: 0.858596 - Dev Loss: 0.899772\n",
            "Epoch 0 Iteration 220 - Train Loss: 0.916277 - Dev Loss: 0.886338\n",
            "Epoch 0 Iteration 230 - Train Loss: 0.893279 - Dev Loss: 0.876995\n",
            "Epoch 0 Iteration 240 - Train Loss: 0.891036 - Dev Loss: 0.863240\n",
            "Epoch 0 Iteration 250 - Train Loss: 0.818600 - Dev Loss: 0.849738\n",
            "Epoch 1 Iteration 260 - Train Loss: 0.792991 - Dev Loss: 0.841538\n",
            "Epoch 1 Iteration 270 - Train Loss: 0.818090 - Dev Loss: 0.829405\n",
            "Epoch 1 Iteration 280 - Train Loss: 0.823189 - Dev Loss: 0.815906\n",
            "Epoch 1 Iteration 290 - Train Loss: 0.781111 - Dev Loss: 0.807544\n",
            "Epoch 1 Iteration 300 - Train Loss: 0.826214 - Dev Loss: 0.797266\n",
            "Epoch 1 Iteration 310 - Train Loss: 0.803533 - Dev Loss: 0.781026\n",
            "Epoch 1 Iteration 320 - Train Loss: 0.749816 - Dev Loss: 0.768655\n",
            "Epoch 1 Iteration 330 - Train Loss: 0.724862 - Dev Loss: 0.763687\n",
            "Epoch 1 Iteration 340 - Train Loss: 0.739058 - Dev Loss: 0.751266\n",
            "Epoch 1 Iteration 350 - Train Loss: 0.732544 - Dev Loss: 0.744368\n",
            "Epoch 1 Iteration 360 - Train Loss: 0.709043 - Dev Loss: 0.733557\n",
            "Epoch 1 Iteration 370 - Train Loss: 0.680755 - Dev Loss: 0.725823\n",
            "Epoch 1 Iteration 380 - Train Loss: 0.688186 - Dev Loss: 0.720800\n",
            "Epoch 1 Iteration 390 - Train Loss: 0.700059 - Dev Loss: 0.720581\n",
            "Epoch 1 Iteration 400 - Train Loss: 0.675480 - Dev Loss: 0.706465\n",
            "Epoch 1 Iteration 410 - Train Loss: 0.685099 - Dev Loss: 0.695347\n",
            "Epoch 1 Iteration 420 - Train Loss: 0.673390 - Dev Loss: 0.691213\n",
            "Epoch 1 Iteration 430 - Train Loss: 0.642290 - Dev Loss: 0.683761\n",
            "Epoch 1 Iteration 440 - Train Loss: 0.679102 - Dev Loss: 0.678952\n",
            "Epoch 1 Iteration 450 - Train Loss: 0.672658 - Dev Loss: 0.673518\n",
            "Epoch 1 Iteration 460 - Train Loss: 0.682837 - Dev Loss: 0.663733\n",
            "Epoch 1 Iteration 470 - Train Loss: 0.674838 - Dev Loss: 0.660701\n",
            "Epoch 1 Iteration 480 - Train Loss: 0.650989 - Dev Loss: 0.653433\n",
            "Epoch 1 Iteration 490 - Train Loss: 0.631112 - Dev Loss: 0.653248\n",
            "Epoch 1 Iteration 500 - Train Loss: 0.618144 - Dev Loss: 0.648720\n",
            "Epoch 1 Iteration 510 - Train Loss: 0.638399 - Dev Loss: 0.640619\n",
            "Epoch 2 Iteration 520 - Train Loss: 0.603740 - Dev Loss: 0.634022\n",
            "Epoch 2 Iteration 530 - Train Loss: 0.616708 - Dev Loss: 0.629328\n",
            "Epoch 2 Iteration 540 - Train Loss: 0.596755 - Dev Loss: 0.625955\n",
            "Epoch 2 Iteration 550 - Train Loss: 0.596201 - Dev Loss: 0.625387\n",
            "Epoch 2 Iteration 560 - Train Loss: 0.554239 - Dev Loss: 0.615236\n",
            "Epoch 2 Iteration 570 - Train Loss: 0.561417 - Dev Loss: 0.607344\n",
            "Epoch 2 Iteration 580 - Train Loss: 0.580484 - Dev Loss: 0.603999\n",
            "Epoch 2 Iteration 590 - Train Loss: 0.554511 - Dev Loss: 0.598441\n",
            "Epoch 2 Iteration 600 - Train Loss: 0.524944 - Dev Loss: 0.596472\n",
            "Epoch 2 Iteration 610 - Train Loss: 0.576389 - Dev Loss: 0.591652\n",
            "Epoch 2 Iteration 620 - Train Loss: 0.562346 - Dev Loss: 0.589132\n",
            "Epoch 2 Iteration 630 - Train Loss: 0.584340 - Dev Loss: 0.584283\n",
            "Epoch 2 Iteration 640 - Train Loss: 0.558889 - Dev Loss: 0.578706\n",
            "Epoch 2 Iteration 650 - Train Loss: 0.516868 - Dev Loss: 0.574685\n",
            "Epoch 2 Iteration 660 - Train Loss: 0.543244 - Dev Loss: 0.572688\n",
            "Epoch 2 Iteration 670 - Train Loss: 0.541667 - Dev Loss: 0.571351\n",
            "Epoch 2 Iteration 680 - Train Loss: 0.561244 - Dev Loss: 0.562278\n",
            "Epoch 2 Iteration 690 - Train Loss: 0.503741 - Dev Loss: 0.559255\n",
            "Epoch 2 Iteration 700 - Train Loss: 0.545957 - Dev Loss: 0.556667\n",
            "Epoch 2 Iteration 710 - Train Loss: 0.496207 - Dev Loss: 0.551439\n",
            "Epoch 2 Iteration 720 - Train Loss: 0.505896 - Dev Loss: 0.545609\n",
            "Epoch 2 Iteration 730 - Train Loss: 0.498396 - Dev Loss: 0.545559\n",
            "Epoch 2 Iteration 740 - Train Loss: 0.506029 - Dev Loss: 0.544344\n",
            "Epoch 2 Iteration 750 - Train Loss: 0.492119 - Dev Loss: 0.538402\n",
            "Epoch 2 Iteration 760 - Train Loss: 0.486293 - Dev Loss: 0.533755\n",
            "Epoch 3 Iteration 770 - Train Loss: 0.504059 - Dev Loss: 0.529163\n",
            "Epoch 3 Iteration 780 - Train Loss: 0.457390 - Dev Loss: 0.526501\n",
            "Epoch 3 Iteration 790 - Train Loss: 0.451214 - Dev Loss: 0.523493\n",
            "Epoch 3 Iteration 800 - Train Loss: 0.456923 - Dev Loss: 0.521015\n",
            "Epoch 3 Iteration 810 - Train Loss: 0.464098 - Dev Loss: 0.518343\n",
            "Epoch 3 Iteration 820 - Train Loss: 0.483373 - Dev Loss: 0.517959\n",
            "Epoch 3 Iteration 830 - Train Loss: 0.475873 - Dev Loss: 0.510882\n",
            "Epoch 3 Iteration 840 - Train Loss: 0.452030 - Dev Loss: 0.509567\n",
            "Epoch 3 Iteration 850 - Train Loss: 0.437834 - Dev Loss: 0.507768\n",
            "Epoch 3 Iteration 860 - Train Loss: 0.402382 - Dev Loss: 0.506636\n",
            "Epoch 3 Iteration 870 - Train Loss: 0.467330 - Dev Loss: 0.505102\n",
            "Epoch 3 Iteration 880 - Train Loss: 0.455374 - Dev Loss: 0.497741\n",
            "Epoch 3 Iteration 890 - Train Loss: 0.480980 - Dev Loss: 0.494191\n",
            "Epoch 3 Iteration 900 - Train Loss: 0.420249 - Dev Loss: 0.491793\n",
            "Epoch 3 Iteration 910 - Train Loss: 0.441051 - Dev Loss: 0.497046\n",
            "Epoch 3 Iteration 920 - Train Loss: 0.444067 - Dev Loss: 0.489006\n",
            "Epoch 3 Iteration 930 - Train Loss: 0.381102 - Dev Loss: 0.488877\n",
            "Epoch 3 Iteration 940 - Train Loss: 0.420151 - Dev Loss: 0.484038\n",
            "Epoch 3 Iteration 950 - Train Loss: 0.416610 - Dev Loss: 0.481580\n",
            "Epoch 3 Iteration 960 - Train Loss: 0.418196 - Dev Loss: 0.477965\n",
            "Epoch 3 Iteration 970 - Train Loss: 0.459908 - Dev Loss: 0.476837\n",
            "Epoch 3 Iteration 980 - Train Loss: 0.427019 - Dev Loss: 0.477342\n",
            "Epoch 3 Iteration 990 - Train Loss: 0.405339 - Dev Loss: 0.474759\n",
            "Epoch 3 Iteration 1000 - Train Loss: 0.400229 - Dev Loss: 0.472083\n",
            "Epoch 3 Iteration 1010 - Train Loss: 0.402067 - Dev Loss: 0.471157\n",
            "Epoch 3 Iteration 1020 - Train Loss: 0.447744 - Dev Loss: 0.471143\n",
            "Epoch 4 Iteration 1030 - Train Loss: 0.381038 - Dev Loss: 0.467518\n",
            "Epoch 4 Iteration 1040 - Train Loss: 0.349807 - Dev Loss: 0.466821\n",
            "Epoch 4 Iteration 1050 - Train Loss: 0.361084 - Dev Loss: 0.466064\n",
            "Epoch 4 Iteration 1060 - Train Loss: 0.353124 - Dev Loss: 0.461169\n",
            "Epoch 4 Iteration 1070 - Train Loss: 0.387841 - Dev Loss: 0.460422\n",
            "Epoch 4 Iteration 1080 - Train Loss: 0.350688 - Dev Loss: 0.457438\n",
            "Epoch 4 Iteration 1090 - Train Loss: 0.364501 - Dev Loss: 0.457214\n",
            "Epoch 4 Iteration 1100 - Train Loss: 0.364124 - Dev Loss: 0.450750\n",
            "Epoch 4 Iteration 1110 - Train Loss: 0.367305 - Dev Loss: 0.450480\n",
            "Epoch 4 Iteration 1120 - Train Loss: 0.353138 - Dev Loss: 0.449748\n",
            "Epoch 4 Iteration 1130 - Train Loss: 0.364069 - Dev Loss: 0.448515\n",
            "Epoch 4 Iteration 1140 - Train Loss: 0.370757 - Dev Loss: 0.446866\n",
            "Epoch 4 Iteration 1150 - Train Loss: 0.354979 - Dev Loss: 0.444204\n",
            "Epoch 4 Iteration 1160 - Train Loss: 0.345117 - Dev Loss: 0.442914\n",
            "Epoch 4 Iteration 1170 - Train Loss: 0.352346 - Dev Loss: 0.440693\n",
            "Epoch 4 Iteration 1180 - Train Loss: 0.349974 - Dev Loss: 0.443472\n",
            "Epoch 4 Iteration 1190 - Train Loss: 0.373525 - Dev Loss: 0.439692\n",
            "Epoch 4 Iteration 1200 - Train Loss: 0.345456 - Dev Loss: 0.437275\n",
            "Epoch 4 Iteration 1210 - Train Loss: 0.379651 - Dev Loss: 0.433311\n",
            "Epoch 4 Iteration 1220 - Train Loss: 0.347115 - Dev Loss: 0.433636\n",
            "Epoch 4 Iteration 1230 - Train Loss: 0.334669 - Dev Loss: 0.432308\n",
            "Epoch 4 Iteration 1240 - Train Loss: 0.372931 - Dev Loss: 0.428755\n",
            "Epoch 4 Iteration 1250 - Train Loss: 0.347956 - Dev Loss: 0.426618\n",
            "Epoch 4 Iteration 1260 - Train Loss: 0.350186 - Dev Loss: 0.427271\n",
            "Epoch 4 Iteration 1270 - Train Loss: 0.356543 - Dev Loss: 0.425105\n",
            "Epoch 5 Iteration 1280 - Train Loss: 0.342550 - Dev Loss: 0.423901\n",
            "Epoch 5 Iteration 1290 - Train Loss: 0.287083 - Dev Loss: 0.419582\n",
            "Epoch 5 Iteration 1300 - Train Loss: 0.292832 - Dev Loss: 0.419429\n",
            "Epoch 5 Iteration 1310 - Train Loss: 0.283077 - Dev Loss: 0.418695\n",
            "Epoch 5 Iteration 1320 - Train Loss: 0.317538 - Dev Loss: 0.418062\n",
            "Epoch 5 Iteration 1330 - Train Loss: 0.286422 - Dev Loss: 0.417568\n",
            "Epoch 5 Iteration 1340 - Train Loss: 0.289648 - Dev Loss: 0.419061\n",
            "Epoch 5 Iteration 1350 - Train Loss: 0.309338 - Dev Loss: 0.419181\n",
            "Epoch 5 Iteration 1360 - Train Loss: 0.322444 - Dev Loss: 0.419150\n",
            "Epoch 5 Iteration 1370 - Train Loss: 0.308279 - Dev Loss: 0.416361\n",
            "Epoch 5 Iteration 1380 - Train Loss: 0.306496 - Dev Loss: 0.413848\n",
            "Epoch 5 Iteration 1390 - Train Loss: 0.301983 - Dev Loss: 0.411926\n",
            "Epoch 5 Iteration 1400 - Train Loss: 0.279145 - Dev Loss: 0.412324\n",
            "Epoch 5 Iteration 1410 - Train Loss: 0.274851 - Dev Loss: 0.410887\n",
            "Epoch 5 Iteration 1420 - Train Loss: 0.281298 - Dev Loss: 0.410246\n",
            "Epoch 5 Iteration 1430 - Train Loss: 0.314020 - Dev Loss: 0.406301\n",
            "Epoch 5 Iteration 1440 - Train Loss: 0.312693 - Dev Loss: 0.404642\n",
            "Epoch 5 Iteration 1450 - Train Loss: 0.297978 - Dev Loss: 0.404006\n",
            "Epoch 5 Iteration 1460 - Train Loss: 0.283901 - Dev Loss: 0.407265\n",
            "Epoch 5 Iteration 1470 - Train Loss: 0.281267 - Dev Loss: 0.401715\n",
            "Epoch 5 Iteration 1480 - Train Loss: 0.292388 - Dev Loss: 0.399952\n",
            "Epoch 5 Iteration 1490 - Train Loss: 0.277445 - Dev Loss: 0.401305\n",
            "Epoch 5 Iteration 1500 - Train Loss: 0.277175 - Dev Loss: 0.400289\n",
            "Epoch 5 Iteration 1510 - Train Loss: 0.251774 - Dev Loss: 0.399857\n",
            "Epoch 5 Iteration 1520 - Train Loss: 0.304669 - Dev Loss: 0.399331\n",
            "Epoch 5 Iteration 1530 - Train Loss: 0.298650 - Dev Loss: 0.393799\n",
            "Epoch 6 Iteration 1540 - Train Loss: 0.243286 - Dev Loss: 0.392393\n",
            "Epoch 6 Iteration 1550 - Train Loss: 0.225157 - Dev Loss: 0.390852\n",
            "Epoch 6 Iteration 1560 - Train Loss: 0.248315 - Dev Loss: 0.387143\n",
            "Epoch 6 Iteration 1570 - Train Loss: 0.231034 - Dev Loss: 0.386018\n",
            "Epoch 6 Iteration 1580 - Train Loss: 0.241670 - Dev Loss: 0.387820\n",
            "Epoch 6 Iteration 1590 - Train Loss: 0.243620 - Dev Loss: 0.388267\n",
            "Epoch 6 Iteration 1600 - Train Loss: 0.247036 - Dev Loss: 0.388975\n",
            "Epoch 6 Iteration 1610 - Train Loss: 0.253485 - Dev Loss: 0.387799\n",
            "Epoch 6 Iteration 1620 - Train Loss: 0.257744 - Dev Loss: 0.385901\n",
            "Epoch 6 Iteration 1630 - Train Loss: 0.273131 - Dev Loss: 0.387017\n",
            "Epoch 6 Iteration 1640 - Train Loss: 0.265866 - Dev Loss: 0.386907\n",
            "Epoch 6 Iteration 1650 - Train Loss: 0.240496 - Dev Loss: 0.388941\n",
            "Epoch 6 Iteration 1660 - Train Loss: 0.248400 - Dev Loss: 0.386692\n",
            "Epoch 6 Iteration 1670 - Train Loss: 0.255689 - Dev Loss: 0.386357\n",
            "Epoch 6 Iteration 1680 - Train Loss: 0.219375 - Dev Loss: 0.383257\n",
            "Epoch 6 Iteration 1690 - Train Loss: 0.244728 - Dev Loss: 0.382798\n",
            "Epoch 6 Iteration 1700 - Train Loss: 0.235632 - Dev Loss: 0.387447\n",
            "Epoch 6 Iteration 1710 - Train Loss: 0.229495 - Dev Loss: 0.384364\n",
            "Epoch 6 Iteration 1720 - Train Loss: 0.224270 - Dev Loss: 0.382491\n",
            "Epoch 6 Iteration 1730 - Train Loss: 0.244692 - Dev Loss: 0.380585\n",
            "Epoch 6 Iteration 1740 - Train Loss: 0.232725 - Dev Loss: 0.380701\n",
            "Epoch 6 Iteration 1750 - Train Loss: 0.220037 - Dev Loss: 0.380699\n",
            "Epoch 6 Iteration 1760 - Train Loss: 0.219869 - Dev Loss: 0.381640\n",
            "Epoch 6 Iteration 1770 - Train Loss: 0.237022 - Dev Loss: 0.381739\n",
            "Epoch 6 Iteration 1780 - Train Loss: 0.205525 - Dev Loss: 0.377988\n",
            "Epoch 6 Iteration 1790 - Train Loss: 0.259573 - Dev Loss: 0.377053\n",
            "Epoch 7 Iteration 1800 - Train Loss: 0.182432 - Dev Loss: 0.376303\n",
            "Epoch 7 Iteration 1810 - Train Loss: 0.188527 - Dev Loss: 0.375075\n",
            "Epoch 7 Iteration 1820 - Train Loss: 0.211336 - Dev Loss: 0.377271\n",
            "Epoch 7 Iteration 1830 - Train Loss: 0.196869 - Dev Loss: 0.377605\n",
            "Epoch 7 Iteration 1840 - Train Loss: 0.179927 - Dev Loss: 0.374759\n",
            "Epoch 7 Iteration 1850 - Train Loss: 0.184639 - Dev Loss: 0.374700\n",
            "Epoch 7 Iteration 1860 - Train Loss: 0.200294 - Dev Loss: 0.374026\n",
            "Epoch 7 Iteration 1870 - Train Loss: 0.196431 - Dev Loss: 0.373005\n",
            "Epoch 7 Iteration 1880 - Train Loss: 0.193119 - Dev Loss: 0.374259\n",
            "Epoch 7 Iteration 1890 - Train Loss: 0.189013 - Dev Loss: 0.372011\n",
            "Epoch 7 Iteration 1900 - Train Loss: 0.185873 - Dev Loss: 0.373205\n",
            "Epoch 7 Iteration 1910 - Train Loss: 0.181974 - Dev Loss: 0.370545\n",
            "Epoch 7 Iteration 1920 - Train Loss: 0.188483 - Dev Loss: 0.372935\n",
            "Epoch 7 Iteration 1930 - Train Loss: 0.213339 - Dev Loss: 0.370983\n",
            "Epoch 7 Iteration 1940 - Train Loss: 0.196664 - Dev Loss: 0.367773\n",
            "Epoch 7 Iteration 1950 - Train Loss: 0.193843 - Dev Loss: 0.368877\n",
            "Epoch 7 Iteration 1960 - Train Loss: 0.196049 - Dev Loss: 0.370261\n",
            "Epoch 7 Iteration 1970 - Train Loss: 0.177175 - Dev Loss: 0.369211\n",
            "Epoch 7 Iteration 1980 - Train Loss: 0.202226 - Dev Loss: 0.374875\n",
            "Epoch 7 Iteration 1990 - Train Loss: 0.180768 - Dev Loss: 0.375161\n",
            "Epoch 7 Iteration 2000 - Train Loss: 0.204494 - Dev Loss: 0.370593\n",
            "Epoch 7 Iteration 2010 - Train Loss: 0.213488 - Dev Loss: 0.370914\n",
            "Epoch 7 Iteration 2020 - Train Loss: 0.210521 - Dev Loss: 0.370798\n",
            "Epoch 7 Iteration 2030 - Train Loss: 0.191942 - Dev Loss: 0.370449\n",
            "Epoch 7 Iteration 2040 - Train Loss: 0.201274 - Dev Loss: 0.366524\n",
            "Epoch 8 Iteration 2050 - Train Loss: 0.176805 - Dev Loss: 0.364411\n",
            "Epoch 8 Iteration 2060 - Train Loss: 0.143480 - Dev Loss: 0.363903\n",
            "Epoch 8 Iteration 2070 - Train Loss: 0.156706 - Dev Loss: 0.366844\n",
            "Epoch 8 Iteration 2080 - Train Loss: 0.151402 - Dev Loss: 0.365243\n",
            "Epoch 8 Iteration 2090 - Train Loss: 0.156086 - Dev Loss: 0.366033\n",
            "Epoch 8 Iteration 2100 - Train Loss: 0.158673 - Dev Loss: 0.366755\n",
            "Epoch 8 Iteration 2110 - Train Loss: 0.146839 - Dev Loss: 0.369661\n",
            "Epoch 8 Iteration 2120 - Train Loss: 0.162256 - Dev Loss: 0.366520\n",
            "Epoch 8 Iteration 2130 - Train Loss: 0.169139 - Dev Loss: 0.366062\n",
            "Epoch 8 Iteration 2140 - Train Loss: 0.155282 - Dev Loss: 0.363797\n",
            "Epoch 8 Iteration 2150 - Train Loss: 0.148892 - Dev Loss: 0.364083\n",
            "Epoch 8 Iteration 2160 - Train Loss: 0.147834 - Dev Loss: 0.365757\n",
            "Epoch 8 Iteration 2170 - Train Loss: 0.172271 - Dev Loss: 0.363856\n",
            "Epoch 8 Iteration 2180 - Train Loss: 0.163932 - Dev Loss: 0.364080\n",
            "Epoch 8 Iteration 2190 - Train Loss: 0.145207 - Dev Loss: 0.368419\n",
            "Epoch 8 Iteration 2200 - Train Loss: 0.162372 - Dev Loss: 0.366986\n",
            "Epoch 8 Iteration 2210 - Train Loss: 0.149670 - Dev Loss: 0.367633\n",
            "Epoch 8 Iteration 2220 - Train Loss: 0.153634 - Dev Loss: 0.362757\n",
            "Epoch 8 Iteration 2230 - Train Loss: 0.159686 - Dev Loss: 0.361085\n",
            "Epoch 8 Iteration 2240 - Train Loss: 0.177979 - Dev Loss: 0.364139\n",
            "Epoch 8 Iteration 2250 - Train Loss: 0.162657 - Dev Loss: 0.370560\n",
            "Epoch 8 Iteration 2260 - Train Loss: 0.152798 - Dev Loss: 0.365248\n",
            "Epoch 8 Iteration 2270 - Train Loss: 0.159900 - Dev Loss: 0.362826\n",
            "Epoch 8 Iteration 2280 - Train Loss: 0.176766 - Dev Loss: 0.363721\n",
            "Epoch 8 Iteration 2290 - Train Loss: 0.158208 - Dev Loss: 0.363857\n",
            "Epoch 8 Iteration 2300 - Train Loss: 0.136428 - Dev Loss: 0.361498\n",
            "Epoch 9 Iteration 2310 - Train Loss: 0.144428 - Dev Loss: 0.364200\n",
            "Epoch 9 Iteration 2320 - Train Loss: 0.122400 - Dev Loss: 0.357821\n",
            "Epoch 9 Iteration 2330 - Train Loss: 0.127528 - Dev Loss: 0.359618\n",
            "Epoch 9 Iteration 2340 - Train Loss: 0.121291 - Dev Loss: 0.363938\n",
            "Epoch 9 Iteration 2350 - Train Loss: 0.119010 - Dev Loss: 0.361730\n",
            "Epoch 9 Iteration 2360 - Train Loss: 0.132247 - Dev Loss: 0.359140\n",
            "Epoch 9 Iteration 2370 - Train Loss: 0.128175 - Dev Loss: 0.358446\n",
            "Epoch 9 Iteration 2380 - Train Loss: 0.121808 - Dev Loss: 0.358615\n",
            "Epoch 9 Iteration 2390 - Train Loss: 0.120298 - Dev Loss: 0.360894\n",
            "Epoch 9 Iteration 2400 - Train Loss: 0.137452 - Dev Loss: 0.361598\n",
            "Epoch 9 Iteration 2410 - Train Loss: 0.146736 - Dev Loss: 0.360739\n",
            "Epoch 9 Iteration 2420 - Train Loss: 0.118237 - Dev Loss: 0.364332\n",
            "Epoch 9 Iteration 2430 - Train Loss: 0.122824 - Dev Loss: 0.365371\n",
            "Epoch 9 Iteration 2440 - Train Loss: 0.138106 - Dev Loss: 0.361231\n",
            "Epoch 9 Iteration 2450 - Train Loss: 0.137460 - Dev Loss: 0.363278\n",
            "Epoch 9 Iteration 2460 - Train Loss: 0.125797 - Dev Loss: 0.361506\n",
            "Epoch 9 Iteration 2470 - Train Loss: 0.125522 - Dev Loss: 0.361751\n",
            "Epoch 9 Iteration 2480 - Train Loss: 0.117137 - Dev Loss: 0.362419\n",
            "Epoch 9 Iteration 2490 - Train Loss: 0.128795 - Dev Loss: 0.364488\n",
            "Epoch 9 Iteration 2500 - Train Loss: 0.142116 - Dev Loss: 0.360297\n",
            "Epoch 9 Iteration 2510 - Train Loss: 0.112509 - Dev Loss: 0.365958\n",
            "Epoch 9 Iteration 2520 - Train Loss: 0.120979 - Dev Loss: 0.362877\n",
            "Epoch 9 Iteration 2530 - Train Loss: 0.125347 - Dev Loss: 0.359646\n",
            "Epoch 9 Iteration 2540 - Train Loss: 0.132309 - Dev Loss: 0.364441\n",
            "Epoch 9 Iteration 2550 - Train Loss: 0.134650 - Dev Loss: 0.360181\n",
            "Epoch 10 Iteration 2560 - Train Loss: 0.108460 - Dev Loss: 0.366341\n",
            "Epoch 10 Iteration 2570 - Train Loss: 0.093279 - Dev Loss: 0.363517\n",
            "Epoch 10 Iteration 2580 - Train Loss: 0.103866 - Dev Loss: 0.359991\n",
            "Epoch 10 Iteration 2590 - Train Loss: 0.096560 - Dev Loss: 0.361402\n",
            "Epoch 10 Iteration 2600 - Train Loss: 0.097090 - Dev Loss: 0.362711\n",
            "Epoch 10 Iteration 2610 - Train Loss: 0.106043 - Dev Loss: 0.363439\n",
            "Epoch 10 Iteration 2620 - Train Loss: 0.096117 - Dev Loss: 0.363301\n",
            "Epoch 10 Iteration 2630 - Train Loss: 0.108777 - Dev Loss: 0.366149\n",
            "Epoch 10 Iteration 2640 - Train Loss: 0.103509 - Dev Loss: 0.362353\n",
            "Epoch 10 Iteration 2650 - Train Loss: 0.106815 - Dev Loss: 0.365049\n",
            "Epoch 10 Iteration 2660 - Train Loss: 0.093648 - Dev Loss: 0.362493\n",
            "Epoch 10 Iteration 2670 - Train Loss: 0.092412 - Dev Loss: 0.363970\n",
            "Epoch 10 Iteration 2680 - Train Loss: 0.106377 - Dev Loss: 0.364239\n",
            "Epoch 10 Iteration 2690 - Train Loss: 0.100644 - Dev Loss: 0.362619\n",
            "Epoch 10 Iteration 2700 - Train Loss: 0.099388 - Dev Loss: 0.366943\n",
            "Epoch 10 Iteration 2710 - Train Loss: 0.089969 - Dev Loss: 0.365373\n",
            "Epoch 10 Iteration 2720 - Train Loss: 0.090871 - Dev Loss: 0.368495\n",
            "Epoch 10 Iteration 2730 - Train Loss: 0.104742 - Dev Loss: 0.365941\n",
            "Epoch 10 Iteration 2740 - Train Loss: 0.099943 - Dev Loss: 0.369757\n",
            "Epoch 10 Iteration 2750 - Train Loss: 0.105093 - Dev Loss: 0.365487\n",
            "Epoch 10 Iteration 2760 - Train Loss: 0.105425 - Dev Loss: 0.365515\n",
            "Epoch 10 Iteration 2770 - Train Loss: 0.100262 - Dev Loss: 0.359006\n",
            "Epoch 10 Iteration 2780 - Train Loss: 0.103151 - Dev Loss: 0.358346\n",
            "Epoch 10 Iteration 2790 - Train Loss: 0.112121 - Dev Loss: 0.364970\n",
            "Epoch 10 Iteration 2800 - Train Loss: 0.105981 - Dev Loss: 0.367359\n",
            "Epoch 10 Iteration 2810 - Train Loss: 0.103266 - Dev Loss: 0.364876\n",
            "Epoch 11 Iteration 2820 - Train Loss: 0.093567 - Dev Loss: 0.368985\n",
            "Epoch 11 Iteration 2830 - Train Loss: 0.069712 - Dev Loss: 0.366005\n",
            "Epoch 11 Iteration 2840 - Train Loss: 0.070720 - Dev Loss: 0.369064\n",
            "Epoch 11 Iteration 2850 - Train Loss: 0.074174 - Dev Loss: 0.368020\n",
            "Epoch 11 Iteration 2860 - Train Loss: 0.082145 - Dev Loss: 0.369099\n",
            "Epoch 11 Iteration 2870 - Train Loss: 0.075329 - Dev Loss: 0.367582\n",
            "Epoch 11 Iteration 2880 - Train Loss: 0.074428 - Dev Loss: 0.366077\n",
            "Epoch 11 Iteration 2890 - Train Loss: 0.071381 - Dev Loss: 0.368796\n",
            "Epoch 11 Iteration 2900 - Train Loss: 0.070135 - Dev Loss: 0.371361\n",
            "Epoch 11 Iteration 2910 - Train Loss: 0.076677 - Dev Loss: 0.371052\n",
            "Epoch 11 Iteration 2920 - Train Loss: 0.082966 - Dev Loss: 0.370191\n",
            "Epoch 11 Iteration 2930 - Train Loss: 0.083909 - Dev Loss: 0.368114\n",
            "Epoch 11 Iteration 2940 - Train Loss: 0.082610 - Dev Loss: 0.365530\n",
            "Epoch 11 Iteration 2950 - Train Loss: 0.079444 - Dev Loss: 0.367562\n",
            "Epoch 11 Iteration 2960 - Train Loss: 0.080702 - Dev Loss: 0.364218\n",
            "Epoch 11 Iteration 2970 - Train Loss: 0.083946 - Dev Loss: 0.366182\n",
            "Epoch 11 Iteration 2980 - Train Loss: 0.085959 - Dev Loss: 0.366037\n",
            "Epoch 11 Iteration 2990 - Train Loss: 0.076770 - Dev Loss: 0.365598\n",
            "Epoch 11 Iteration 3000 - Train Loss: 0.085644 - Dev Loss: 0.370780\n",
            "Epoch 11 Iteration 3010 - Train Loss: 0.082023 - Dev Loss: 0.372400\n",
            "Epoch 11 Iteration 3020 - Train Loss: 0.096292 - Dev Loss: 0.363959\n",
            "Epoch 11 Iteration 3030 - Train Loss: 0.080117 - Dev Loss: 0.370673\n",
            "Epoch 11 Iteration 3040 - Train Loss: 0.094016 - Dev Loss: 0.366518\n",
            "Epoch 11 Iteration 3050 - Train Loss: 0.077874 - Dev Loss: 0.369202\n",
            "Epoch 11 Iteration 3060 - Train Loss: 0.076024 - Dev Loss: 0.367507\n",
            "Epoch 11 Iteration 3070 - Train Loss: 0.071707 - Dev Loss: 0.368205\n",
            "Epoch 12 Iteration 3080 - Train Loss: 0.067150 - Dev Loss: 0.371951\n",
            "Epoch 12 Iteration 3090 - Train Loss: 0.058141 - Dev Loss: 0.369415\n",
            "Epoch 12 Iteration 3100 - Train Loss: 0.060476 - Dev Loss: 0.369811\n",
            "Epoch 12 Iteration 3110 - Train Loss: 0.059203 - Dev Loss: 0.369822\n",
            "Epoch 12 Iteration 3120 - Train Loss: 0.065999 - Dev Loss: 0.369784\n",
            "Epoch 12 Iteration 3130 - Train Loss: 0.067337 - Dev Loss: 0.373415\n",
            "Epoch 12 Iteration 3140 - Train Loss: 0.052402 - Dev Loss: 0.370902\n",
            "Epoch 12 Iteration 3150 - Train Loss: 0.065208 - Dev Loss: 0.370441\n",
            "Epoch 12 Iteration 3160 - Train Loss: 0.058172 - Dev Loss: 0.373204\n",
            "Epoch 12 Iteration 3170 - Train Loss: 0.056155 - Dev Loss: 0.378444\n",
            "Epoch 12 Iteration 3180 - Train Loss: 0.065863 - Dev Loss: 0.375500\n",
            "Epoch 12 Iteration 3190 - Train Loss: 0.068605 - Dev Loss: 0.375158\n",
            "Epoch 12 Iteration 3200 - Train Loss: 0.075452 - Dev Loss: 0.374488\n",
            "Epoch 12 Iteration 3210 - Train Loss: 0.055160 - Dev Loss: 0.372806\n",
            "Epoch 12 Iteration 3220 - Train Loss: 0.061708 - Dev Loss: 0.375360\n",
            "Epoch 12 Iteration 3230 - Train Loss: 0.059501 - Dev Loss: 0.373202\n",
            "Epoch 12 Iteration 3240 - Train Loss: 0.062804 - Dev Loss: 0.373091\n",
            "Epoch 12 Iteration 3250 - Train Loss: 0.066678 - Dev Loss: 0.379661\n",
            "Epoch 12 Iteration 3260 - Train Loss: 0.060335 - Dev Loss: 0.378012\n",
            "Epoch 12 Iteration 3270 - Train Loss: 0.056615 - Dev Loss: 0.378308\n",
            "Epoch 12 Iteration 3280 - Train Loss: 0.062158 - Dev Loss: 0.383743\n",
            "Epoch 12 Iteration 3290 - Train Loss: 0.057400 - Dev Loss: 0.380059\n",
            "Epoch 12 Iteration 3300 - Train Loss: 0.061373 - Dev Loss: 0.384622\n",
            "Epoch 12 Iteration 3310 - Train Loss: 0.064622 - Dev Loss: 0.376254\n",
            "Epoch 12 Iteration 3320 - Train Loss: 0.070571 - Dev Loss: 0.376399\n",
            "Epoch 13 Iteration 3330 - Train Loss: 0.060800 - Dev Loss: 0.375791\n",
            "Epoch 13 Iteration 3340 - Train Loss: 0.044136 - Dev Loss: 0.374706\n",
            "Epoch 13 Iteration 3350 - Train Loss: 0.049437 - Dev Loss: 0.376268\n",
            "Epoch 13 Iteration 3360 - Train Loss: 0.050895 - Dev Loss: 0.377418\n",
            "Epoch 13 Iteration 3370 - Train Loss: 0.043357 - Dev Loss: 0.378955\n",
            "Epoch 13 Iteration 3380 - Train Loss: 0.047339 - Dev Loss: 0.378813\n",
            "Epoch 13 Iteration 3390 - Train Loss: 0.052583 - Dev Loss: 0.378800\n",
            "Epoch 13 Iteration 3400 - Train Loss: 0.051051 - Dev Loss: 0.377894\n",
            "Epoch 13 Iteration 3410 - Train Loss: 0.051024 - Dev Loss: 0.379799\n",
            "Epoch 13 Iteration 3420 - Train Loss: 0.042163 - Dev Loss: 0.382964\n",
            "Epoch 13 Iteration 3430 - Train Loss: 0.047352 - Dev Loss: 0.385459\n",
            "Epoch 13 Iteration 3440 - Train Loss: 0.047084 - Dev Loss: 0.392040\n",
            "Epoch 13 Iteration 3450 - Train Loss: 0.050895 - Dev Loss: 0.383055\n",
            "Epoch 13 Iteration 3460 - Train Loss: 0.051203 - Dev Loss: 0.378924\n",
            "Epoch 13 Iteration 3470 - Train Loss: 0.046704 - Dev Loss: 0.382715\n",
            "Epoch 13 Iteration 3480 - Train Loss: 0.041976 - Dev Loss: 0.379641\n",
            "Epoch 13 Iteration 3490 - Train Loss: 0.049813 - Dev Loss: 0.379844\n",
            "Epoch 13 Iteration 3500 - Train Loss: 0.050255 - Dev Loss: 0.380522\n",
            "Epoch 13 Iteration 3510 - Train Loss: 0.050603 - Dev Loss: 0.380233\n",
            "Epoch 13 Iteration 3520 - Train Loss: 0.038866 - Dev Loss: 0.379097\n",
            "Epoch 13 Iteration 3530 - Train Loss: 0.053667 - Dev Loss: 0.381960\n",
            "Epoch 13 Iteration 3540 - Train Loss: 0.052553 - Dev Loss: 0.385103\n",
            "Epoch 13 Iteration 3550 - Train Loss: 0.047801 - Dev Loss: 0.380818\n",
            "Epoch 13 Iteration 3560 - Train Loss: 0.042174 - Dev Loss: 0.386752\n",
            "Epoch 13 Iteration 3570 - Train Loss: 0.061093 - Dev Loss: 0.390736\n",
            "Epoch 13 Iteration 3580 - Train Loss: 0.049460 - Dev Loss: 0.385548\n",
            "Epoch 14 Iteration 3590 - Train Loss: 0.036363 - Dev Loss: 0.386774\n",
            "Epoch 14 Iteration 3600 - Train Loss: 0.035578 - Dev Loss: 0.388775\n",
            "Epoch 14 Iteration 3610 - Train Loss: 0.044533 - Dev Loss: 0.389382\n",
            "Epoch 14 Iteration 3620 - Train Loss: 0.031737 - Dev Loss: 0.388432\n",
            "Epoch 14 Iteration 3630 - Train Loss: 0.038584 - Dev Loss: 0.389552\n",
            "Epoch 14 Iteration 3640 - Train Loss: 0.042472 - Dev Loss: 0.386298\n",
            "Epoch 14 Iteration 3650 - Train Loss: 0.036398 - Dev Loss: 0.387401\n",
            "Epoch 14 Iteration 3660 - Train Loss: 0.036031 - Dev Loss: 0.384596\n",
            "Epoch 14 Iteration 3670 - Train Loss: 0.035950 - Dev Loss: 0.387433\n",
            "Epoch 14 Iteration 3680 - Train Loss: 0.041107 - Dev Loss: 0.388583\n",
            "Epoch 14 Iteration 3690 - Train Loss: 0.035656 - Dev Loss: 0.388996\n",
            "Epoch 14 Iteration 3700 - Train Loss: 0.029773 - Dev Loss: 0.388742\n",
            "Epoch 14 Iteration 3710 - Train Loss: 0.035799 - Dev Loss: 0.389101\n",
            "Epoch 14 Iteration 3720 - Train Loss: 0.036316 - Dev Loss: 0.392442\n",
            "Epoch 14 Iteration 3730 - Train Loss: 0.045457 - Dev Loss: 0.387493\n",
            "Epoch 14 Iteration 3740 - Train Loss: 0.033703 - Dev Loss: 0.388702\n",
            "Epoch 14 Iteration 3750 - Train Loss: 0.036761 - Dev Loss: 0.393908\n",
            "Epoch 14 Iteration 3760 - Train Loss: 0.041988 - Dev Loss: 0.389691\n",
            "Epoch 14 Iteration 3770 - Train Loss: 0.035823 - Dev Loss: 0.390785\n",
            "Epoch 14 Iteration 3780 - Train Loss: 0.040999 - Dev Loss: 0.392503\n",
            "Epoch 14 Iteration 3790 - Train Loss: 0.037094 - Dev Loss: 0.388660\n",
            "Epoch 14 Iteration 3800 - Train Loss: 0.034807 - Dev Loss: 0.394932\n",
            "Epoch 14 Iteration 3810 - Train Loss: 0.031530 - Dev Loss: 0.392550\n",
            "Epoch 14 Iteration 3820 - Train Loss: 0.040663 - Dev Loss: 0.393501\n",
            "Epoch 14 Iteration 3830 - Train Loss: 0.034325 - Dev Loss: 0.389881\n",
            "Epoch 15 Iteration 3840 - Train Loss: 0.041361 - Dev Loss: 0.392493\n",
            "Epoch 15 Iteration 3850 - Train Loss: 0.022017 - Dev Loss: 0.392166\n",
            "Epoch 15 Iteration 3860 - Train Loss: 0.029944 - Dev Loss: 0.391856\n",
            "Epoch 15 Iteration 3870 - Train Loss: 0.032079 - Dev Loss: 0.389674\n",
            "Epoch 15 Iteration 3880 - Train Loss: 0.024750 - Dev Loss: 0.391042\n",
            "Epoch 15 Iteration 3890 - Train Loss: 0.023706 - Dev Loss: 0.391408\n",
            "Epoch 15 Iteration 3900 - Train Loss: 0.033317 - Dev Loss: 0.391478\n",
            "Epoch 15 Iteration 3910 - Train Loss: 0.029273 - Dev Loss: 0.396053\n",
            "Epoch 15 Iteration 3920 - Train Loss: 0.032223 - Dev Loss: 0.394140\n",
            "Epoch 15 Iteration 3930 - Train Loss: 0.026118 - Dev Loss: 0.394615\n",
            "Epoch 15 Iteration 3940 - Train Loss: 0.031289 - Dev Loss: 0.399103\n",
            "Epoch 15 Iteration 3950 - Train Loss: 0.028457 - Dev Loss: 0.396039\n",
            "Epoch 15 Iteration 3960 - Train Loss: 0.029363 - Dev Loss: 0.399097\n",
            "Epoch 15 Iteration 3970 - Train Loss: 0.032557 - Dev Loss: 0.404717\n",
            "Epoch 15 Iteration 3980 - Train Loss: 0.023044 - Dev Loss: 0.394828\n",
            "Epoch 15 Iteration 3990 - Train Loss: 0.030468 - Dev Loss: 0.401891\n",
            "Epoch 15 Iteration 4000 - Train Loss: 0.031500 - Dev Loss: 0.401866\n",
            "Epoch 15 Iteration 4010 - Train Loss: 0.026464 - Dev Loss: 0.400094\n",
            "Epoch 15 Iteration 4020 - Train Loss: 0.025519 - Dev Loss: 0.403914\n",
            "Epoch 15 Iteration 4030 - Train Loss: 0.029630 - Dev Loss: 0.402071\n",
            "Epoch 15 Iteration 4040 - Train Loss: 0.029822 - Dev Loss: 0.402279\n",
            "Epoch 15 Iteration 4050 - Train Loss: 0.035128 - Dev Loss: 0.403511\n",
            "Epoch 15 Iteration 4060 - Train Loss: 0.029330 - Dev Loss: 0.401166\n",
            "Epoch 15 Iteration 4070 - Train Loss: 0.036833 - Dev Loss: 0.400027\n",
            "Epoch 15 Iteration 4080 - Train Loss: 0.025225 - Dev Loss: 0.398909\n",
            "Epoch 15 Iteration 4090 - Train Loss: 0.029544 - Dev Loss: 0.404503\n",
            "Epoch 16 Iteration 4100 - Train Loss: 0.023621 - Dev Loss: 0.406497\n",
            "Epoch 16 Iteration 4110 - Train Loss: 0.020641 - Dev Loss: 0.407161\n",
            "Epoch 16 Iteration 4120 - Train Loss: 0.018117 - Dev Loss: 0.404106\n",
            "Epoch 16 Iteration 4130 - Train Loss: 0.022302 - Dev Loss: 0.407737\n",
            "Epoch 16 Iteration 4140 - Train Loss: 0.023283 - Dev Loss: 0.407311\n",
            "Epoch 16 Iteration 4150 - Train Loss: 0.019773 - Dev Loss: 0.408155\n",
            "Epoch 16 Iteration 4160 - Train Loss: 0.023536 - Dev Loss: 0.412747\n",
            "Epoch 16 Iteration 4170 - Train Loss: 0.023891 - Dev Loss: 0.407171\n",
            "Epoch 16 Iteration 4180 - Train Loss: 0.019914 - Dev Loss: 0.404678\n",
            "Epoch 16 Iteration 4190 - Train Loss: 0.024205 - Dev Loss: 0.407450\n",
            "Epoch 16 Iteration 4200 - Train Loss: 0.018768 - Dev Loss: 0.403418\n",
            "Epoch 16 Iteration 4210 - Train Loss: 0.018854 - Dev Loss: 0.407935\n",
            "Epoch 16 Iteration 4220 - Train Loss: 0.025455 - Dev Loss: 0.408085\n",
            "Epoch 16 Iteration 4230 - Train Loss: 0.021501 - Dev Loss: 0.409755\n",
            "Epoch 16 Iteration 4240 - Train Loss: 0.024175 - Dev Loss: 0.406588\n",
            "Epoch 16 Iteration 4250 - Train Loss: 0.021227 - Dev Loss: 0.405995\n",
            "Epoch 16 Iteration 4260 - Train Loss: 0.019238 - Dev Loss: 0.408436\n",
            "Epoch 16 Iteration 4270 - Train Loss: 0.026061 - Dev Loss: 0.409734\n",
            "Epoch 16 Iteration 4280 - Train Loss: 0.024998 - Dev Loss: 0.410166\n",
            "Epoch 16 Iteration 4290 - Train Loss: 0.022519 - Dev Loss: 0.415245\n",
            "Epoch 16 Iteration 4300 - Train Loss: 0.024333 - Dev Loss: 0.409970\n",
            "Epoch 16 Iteration 4310 - Train Loss: 0.024111 - Dev Loss: 0.413485\n",
            "Epoch 16 Iteration 4320 - Train Loss: 0.022969 - Dev Loss: 0.410945\n",
            "Epoch 16 Iteration 4330 - Train Loss: 0.020993 - Dev Loss: 0.413326\n",
            "Epoch 16 Iteration 4340 - Train Loss: 0.023331 - Dev Loss: 0.408990\n",
            "Epoch 16 Iteration 4350 - Train Loss: 0.016475 - Dev Loss: 0.412054\n",
            "Epoch 17 Iteration 4360 - Train Loss: 0.018931 - Dev Loss: 0.411372\n",
            "Epoch 17 Iteration 4370 - Train Loss: 0.021837 - Dev Loss: 0.411601\n",
            "Epoch 17 Iteration 4380 - Train Loss: 0.017532 - Dev Loss: 0.413186\n",
            "Epoch 17 Iteration 4390 - Train Loss: 0.016396 - Dev Loss: 0.414135\n",
            "Epoch 17 Iteration 4400 - Train Loss: 0.014571 - Dev Loss: 0.412079\n",
            "Epoch 17 Iteration 4410 - Train Loss: 0.017296 - Dev Loss: 0.412244\n",
            "Epoch 17 Iteration 4420 - Train Loss: 0.016628 - Dev Loss: 0.413433\n",
            "Epoch 17 Iteration 4430 - Train Loss: 0.012592 - Dev Loss: 0.413960\n",
            "Epoch 17 Iteration 4440 - Train Loss: 0.017282 - Dev Loss: 0.417889\n",
            "Epoch 17 Iteration 4450 - Train Loss: 0.013230 - Dev Loss: 0.419049\n",
            "Epoch 17 Iteration 4460 - Train Loss: 0.021293 - Dev Loss: 0.419799\n",
            "Epoch 17 Iteration 4470 - Train Loss: 0.015865 - Dev Loss: 0.423053\n",
            "Epoch 17 Iteration 4480 - Train Loss: 0.016192 - Dev Loss: 0.418885\n",
            "Epoch 17 Iteration 4490 - Train Loss: 0.018390 - Dev Loss: 0.418084\n",
            "Epoch 17 Iteration 4500 - Train Loss: 0.018944 - Dev Loss: 0.417117\n",
            "Epoch 17 Iteration 4510 - Train Loss: 0.017881 - Dev Loss: 0.418428\n",
            "Epoch 17 Iteration 4520 - Train Loss: 0.015957 - Dev Loss: 0.420684\n",
            "Epoch 17 Iteration 4530 - Train Loss: 0.016150 - Dev Loss: 0.417447\n",
            "Epoch 17 Iteration 4540 - Train Loss: 0.014781 - Dev Loss: 0.417185\n",
            "Epoch 17 Iteration 4550 - Train Loss: 0.015298 - Dev Loss: 0.422147\n",
            "Epoch 17 Iteration 4560 - Train Loss: 0.016653 - Dev Loss: 0.418554\n",
            "Epoch 17 Iteration 4570 - Train Loss: 0.018795 - Dev Loss: 0.418727\n",
            "Epoch 17 Iteration 4580 - Train Loss: 0.017578 - Dev Loss: 0.416808\n",
            "Epoch 17 Iteration 4590 - Train Loss: 0.018370 - Dev Loss: 0.417710\n",
            "Epoch 17 Iteration 4600 - Train Loss: 0.017258 - Dev Loss: 0.415549\n",
            "Epoch 18 Iteration 4610 - Train Loss: 0.018560 - Dev Loss: 0.423387\n",
            "Epoch 18 Iteration 4620 - Train Loss: 0.009320 - Dev Loss: 0.429232\n",
            "Epoch 18 Iteration 4630 - Train Loss: 0.015667 - Dev Loss: 0.423390\n",
            "Epoch 18 Iteration 4640 - Train Loss: 0.011843 - Dev Loss: 0.423475\n",
            "Epoch 18 Iteration 4650 - Train Loss: 0.013616 - Dev Loss: 0.424121\n",
            "Epoch 18 Iteration 4660 - Train Loss: 0.012024 - Dev Loss: 0.425672\n",
            "Epoch 18 Iteration 4670 - Train Loss: 0.011030 - Dev Loss: 0.422778\n",
            "Epoch 18 Iteration 4680 - Train Loss: 0.011034 - Dev Loss: 0.426302\n",
            "Epoch 18 Iteration 4690 - Train Loss: 0.010696 - Dev Loss: 0.430732\n",
            "Epoch 18 Iteration 4700 - Train Loss: 0.011764 - Dev Loss: 0.420283\n",
            "Epoch 18 Iteration 4710 - Train Loss: 0.012818 - Dev Loss: 0.422524\n",
            "Epoch 18 Iteration 4720 - Train Loss: 0.013472 - Dev Loss: 0.424704\n",
            "Epoch 18 Iteration 4730 - Train Loss: 0.012014 - Dev Loss: 0.423637\n",
            "Epoch 18 Iteration 4740 - Train Loss: 0.010807 - Dev Loss: 0.429590\n",
            "Epoch 18 Iteration 4750 - Train Loss: 0.013155 - Dev Loss: 0.428212\n",
            "Epoch 18 Iteration 4760 - Train Loss: 0.011339 - Dev Loss: 0.423424\n",
            "Epoch 18 Iteration 4770 - Train Loss: 0.013199 - Dev Loss: 0.425280\n",
            "Epoch 18 Iteration 4780 - Train Loss: 0.014187 - Dev Loss: 0.429149\n",
            "Epoch 18 Iteration 4790 - Train Loss: 0.013783 - Dev Loss: 0.428297\n",
            "Epoch 18 Iteration 4800 - Train Loss: 0.012932 - Dev Loss: 0.424155\n",
            "Epoch 18 Iteration 4810 - Train Loss: 0.012615 - Dev Loss: 0.424857\n",
            "Epoch 18 Iteration 4820 - Train Loss: 0.014867 - Dev Loss: 0.426108\n",
            "Epoch 18 Iteration 4830 - Train Loss: 0.011852 - Dev Loss: 0.424756\n",
            "Epoch 18 Iteration 4840 - Train Loss: 0.010294 - Dev Loss: 0.426017\n",
            "Epoch 18 Iteration 4850 - Train Loss: 0.015222 - Dev Loss: 0.425119\n",
            "Epoch 18 Iteration 4860 - Train Loss: 0.015752 - Dev Loss: 0.430004\n",
            "Epoch 19 Iteration 4870 - Train Loss: 0.011492 - Dev Loss: 0.427492\n",
            "Epoch 19 Iteration 4880 - Train Loss: 0.010745 - Dev Loss: 0.429271\n",
            "Epoch 19 Iteration 4890 - Train Loss: 0.007997 - Dev Loss: 0.429648\n",
            "Epoch 19 Iteration 4900 - Train Loss: 0.009233 - Dev Loss: 0.432034\n",
            "Epoch 19 Iteration 4910 - Train Loss: 0.009319 - Dev Loss: 0.430523\n",
            "Epoch 19 Iteration 4920 - Train Loss: 0.008755 - Dev Loss: 0.432964\n",
            "Epoch 19 Iteration 4930 - Train Loss: 0.010208 - Dev Loss: 0.429230\n",
            "Epoch 19 Iteration 4940 - Train Loss: 0.007676 - Dev Loss: 0.430300\n",
            "Epoch 19 Iteration 4950 - Train Loss: 0.009841 - Dev Loss: 0.441246\n",
            "Epoch 19 Iteration 4960 - Train Loss: 0.009042 - Dev Loss: 0.435124\n",
            "Epoch 19 Iteration 4970 - Train Loss: 0.011900 - Dev Loss: 0.431664\n",
            "Epoch 19 Iteration 4980 - Train Loss: 0.011358 - Dev Loss: 0.440768\n",
            "Epoch 19 Iteration 4990 - Train Loss: 0.011729 - Dev Loss: 0.443281\n",
            "Epoch 19 Iteration 5000 - Train Loss: 0.010543 - Dev Loss: 0.433630\n",
            "Epoch 19 Iteration 5010 - Train Loss: 0.010281 - Dev Loss: 0.434193\n",
            "Epoch 19 Iteration 5020 - Train Loss: 0.009067 - Dev Loss: 0.437059\n",
            "Epoch 19 Iteration 5030 - Train Loss: 0.008701 - Dev Loss: 0.434227\n",
            "Epoch 19 Iteration 5040 - Train Loss: 0.010619 - Dev Loss: 0.437485\n",
            "Epoch 19 Iteration 5050 - Train Loss: 0.010143 - Dev Loss: 0.436869\n",
            "Epoch 19 Iteration 5060 - Train Loss: 0.009708 - Dev Loss: 0.436378\n",
            "Epoch 19 Iteration 5070 - Train Loss: 0.009390 - Dev Loss: 0.434051\n",
            "Epoch 19 Iteration 5080 - Train Loss: 0.008537 - Dev Loss: 0.442775\n",
            "Epoch 19 Iteration 5090 - Train Loss: 0.013693 - Dev Loss: 0.436818\n",
            "Epoch 19 Iteration 5100 - Train Loss: 0.010301 - Dev Loss: 0.437374\n",
            "Epoch 19 Iteration 5110 - Train Loss: 0.009931 - Dev Loss: 0.439141\n",
            "Epoch 20 Iteration 5120 - Train Loss: 0.012394 - Dev Loss: 0.441281\n",
            "Epoch 20 Iteration 5130 - Train Loss: 0.006381 - Dev Loss: 0.437818\n",
            "Epoch 20 Iteration 5140 - Train Loss: 0.006677 - Dev Loss: 0.440541\n",
            "Epoch 20 Iteration 5150 - Train Loss: 0.007065 - Dev Loss: 0.442717\n",
            "Epoch 20 Iteration 5160 - Train Loss: 0.007489 - Dev Loss: 0.442785\n",
            "Epoch 20 Iteration 5170 - Train Loss: 0.007264 - Dev Loss: 0.441453\n",
            "Epoch 20 Iteration 5180 - Train Loss: 0.007884 - Dev Loss: 0.443208\n",
            "Epoch 20 Iteration 5190 - Train Loss: 0.006029 - Dev Loss: 0.444431\n",
            "Epoch 20 Iteration 5200 - Train Loss: 0.007603 - Dev Loss: 0.444148\n",
            "Epoch 20 Iteration 5210 - Train Loss: 0.008450 - Dev Loss: 0.444183\n",
            "Epoch 20 Iteration 5220 - Train Loss: 0.007538 - Dev Loss: 0.440936\n",
            "Epoch 20 Iteration 5230 - Train Loss: 0.008381 - Dev Loss: 0.459059\n",
            "Epoch 20 Iteration 5240 - Train Loss: 0.008183 - Dev Loss: 0.445859\n",
            "Epoch 20 Iteration 5250 - Train Loss: 0.007389 - Dev Loss: 0.439649\n",
            "Epoch 20 Iteration 5260 - Train Loss: 0.007158 - Dev Loss: 0.447476\n",
            "Epoch 20 Iteration 5270 - Train Loss: 0.007123 - Dev Loss: 0.441516\n",
            "Epoch 20 Iteration 5280 - Train Loss: 0.007604 - Dev Loss: 0.442551\n",
            "Epoch 20 Iteration 5290 - Train Loss: 0.007104 - Dev Loss: 0.443523\n",
            "Epoch 20 Iteration 5300 - Train Loss: 0.008448 - Dev Loss: 0.444065\n",
            "Epoch 20 Iteration 5310 - Train Loss: 0.006722 - Dev Loss: 0.441169\n",
            "Epoch 20 Iteration 5320 - Train Loss: 0.009594 - Dev Loss: 0.445148\n",
            "Epoch 20 Iteration 5330 - Train Loss: 0.008650 - Dev Loss: 0.446053\n",
            "Epoch 20 Iteration 5340 - Train Loss: 0.006990 - Dev Loss: 0.443624\n",
            "Epoch 20 Iteration 5350 - Train Loss: 0.008043 - Dev Loss: 0.441956\n",
            "Epoch 20 Iteration 5360 - Train Loss: 0.007858 - Dev Loss: 0.443835\n",
            "Epoch 20 Iteration 5370 - Train Loss: 0.008988 - Dev Loss: 0.445124\n",
            "Epoch 21 Iteration 5380 - Train Loss: 0.007394 - Dev Loss: 0.447814\n",
            "Epoch 21 Iteration 5390 - Train Loss: 0.005324 - Dev Loss: 0.448993\n",
            "Epoch 21 Iteration 5400 - Train Loss: 0.005456 - Dev Loss: 0.446384\n",
            "Epoch 21 Iteration 5410 - Train Loss: 0.005528 - Dev Loss: 0.445312\n",
            "Epoch 21 Iteration 5420 - Train Loss: 0.004945 - Dev Loss: 0.447967\n",
            "Epoch 21 Iteration 5430 - Train Loss: 0.006370 - Dev Loss: 0.446480\n",
            "Epoch 21 Iteration 5440 - Train Loss: 0.005620 - Dev Loss: 0.447452\n",
            "Epoch 21 Iteration 5450 - Train Loss: 0.005989 - Dev Loss: 0.450408\n",
            "Epoch 21 Iteration 5460 - Train Loss: 0.005109 - Dev Loss: 0.451282\n",
            "Epoch 21 Iteration 5470 - Train Loss: 0.006262 - Dev Loss: 0.449767\n",
            "Epoch 21 Iteration 5480 - Train Loss: 0.004608 - Dev Loss: 0.449115\n",
            "Epoch 21 Iteration 5490 - Train Loss: 0.005691 - Dev Loss: 0.450608\n",
            "Epoch 21 Iteration 5500 - Train Loss: 0.006916 - Dev Loss: 0.451370\n",
            "Epoch 21 Iteration 5510 - Train Loss: 0.005435 - Dev Loss: 0.450933\n",
            "Epoch 21 Iteration 5520 - Train Loss: 0.005110 - Dev Loss: 0.455345\n",
            "Epoch 21 Iteration 5530 - Train Loss: 0.006251 - Dev Loss: 0.450842\n",
            "Epoch 21 Iteration 5540 - Train Loss: 0.006891 - Dev Loss: 0.451785\n",
            "Epoch 21 Iteration 5550 - Train Loss: 0.006364 - Dev Loss: 0.454432\n",
            "Epoch 21 Iteration 5560 - Train Loss: 0.005538 - Dev Loss: 0.454226\n",
            "Epoch 21 Iteration 5570 - Train Loss: 0.006520 - Dev Loss: 0.454250\n",
            "Epoch 21 Iteration 5580 - Train Loss: 0.005893 - Dev Loss: 0.454574\n",
            "Epoch 21 Iteration 5590 - Train Loss: 0.006438 - Dev Loss: 0.458022\n",
            "Epoch 21 Iteration 5600 - Train Loss: 0.006744 - Dev Loss: 0.460599\n",
            "Epoch 21 Iteration 5610 - Train Loss: 0.006129 - Dev Loss: 0.460972\n",
            "Epoch 21 Iteration 5620 - Train Loss: 0.006773 - Dev Loss: 0.460433\n",
            "Epoch 21 Iteration 5630 - Train Loss: 0.005860 - Dev Loss: 0.459505\n",
            "Epoch 22 Iteration 5640 - Train Loss: 0.004759 - Dev Loss: 0.457584\n",
            "Epoch 22 Iteration 5650 - Train Loss: 0.004144 - Dev Loss: 0.458203\n",
            "Epoch 22 Iteration 5660 - Train Loss: 0.005611 - Dev Loss: 0.456390\n",
            "Epoch 22 Iteration 5670 - Train Loss: 0.004800 - Dev Loss: 0.459421\n",
            "Epoch 22 Iteration 5680 - Train Loss: 0.004934 - Dev Loss: 0.462800\n",
            "Epoch 22 Iteration 5690 - Train Loss: 0.004678 - Dev Loss: 0.459356\n",
            "Epoch 22 Iteration 5700 - Train Loss: 0.004647 - Dev Loss: 0.459879\n",
            "Epoch 22 Iteration 5710 - Train Loss: 0.005233 - Dev Loss: 0.459717\n",
            "Epoch 22 Iteration 5720 - Train Loss: 0.004199 - Dev Loss: 0.460411\n",
            "Epoch 22 Iteration 5730 - Train Loss: 0.005623 - Dev Loss: 0.459739\n",
            "Epoch 22 Iteration 5740 - Train Loss: 0.004366 - Dev Loss: 0.458812\n",
            "Epoch 22 Iteration 5750 - Train Loss: 0.004992 - Dev Loss: 0.461214\n",
            "Epoch 22 Iteration 5760 - Train Loss: 0.004808 - Dev Loss: 0.461740\n",
            "Epoch 22 Iteration 5770 - Train Loss: 0.004615 - Dev Loss: 0.461251\n",
            "Epoch 22 Iteration 5780 - Train Loss: 0.004363 - Dev Loss: 0.460302\n",
            "Epoch 22 Iteration 5790 - Train Loss: 0.004524 - Dev Loss: 0.459095\n",
            "Epoch 22 Iteration 5800 - Train Loss: 0.004113 - Dev Loss: 0.460668\n",
            "Epoch 22 Iteration 5810 - Train Loss: 0.003923 - Dev Loss: 0.466714\n",
            "Epoch 22 Iteration 5820 - Train Loss: 0.004829 - Dev Loss: 0.467388\n",
            "Epoch 22 Iteration 5830 - Train Loss: 0.004813 - Dev Loss: 0.464238\n",
            "Epoch 22 Iteration 5840 - Train Loss: 0.004545 - Dev Loss: 0.460884\n",
            "Epoch 22 Iteration 5850 - Train Loss: 0.004362 - Dev Loss: 0.464271\n",
            "Epoch 22 Iteration 5860 - Train Loss: 0.003891 - Dev Loss: 0.465646\n",
            "Epoch 22 Iteration 5870 - Train Loss: 0.003757 - Dev Loss: 0.463706\n",
            "Epoch 22 Iteration 5880 - Train Loss: 0.005365 - Dev Loss: 0.465078\n",
            "Epoch 23 Iteration 5890 - Train Loss: 0.004100 - Dev Loss: 0.467239\n",
            "Epoch 23 Iteration 5900 - Train Loss: 0.003568 - Dev Loss: 0.468027\n",
            "Epoch 23 Iteration 5910 - Train Loss: 0.003210 - Dev Loss: 0.468066\n",
            "Epoch 23 Iteration 5920 - Train Loss: 0.003633 - Dev Loss: 0.468832\n",
            "Epoch 23 Iteration 5930 - Train Loss: 0.003704 - Dev Loss: 0.468213\n",
            "Epoch 23 Iteration 5940 - Train Loss: 0.003212 - Dev Loss: 0.469011\n",
            "Epoch 23 Iteration 5950 - Train Loss: 0.003333 - Dev Loss: 0.469151\n",
            "Epoch 23 Iteration 5960 - Train Loss: 0.004171 - Dev Loss: 0.471497\n",
            "Epoch 23 Iteration 5970 - Train Loss: 0.004153 - Dev Loss: 0.473184\n",
            "Epoch 23 Iteration 5980 - Train Loss: 0.003162 - Dev Loss: 0.468601\n",
            "Epoch 23 Iteration 5990 - Train Loss: 0.003539 - Dev Loss: 0.468426\n",
            "Epoch 23 Iteration 6000 - Train Loss: 0.003348 - Dev Loss: 0.471798\n",
            "Epoch 23 Iteration 6010 - Train Loss: 0.003223 - Dev Loss: 0.475009\n",
            "Epoch 23 Iteration 6020 - Train Loss: 0.004268 - Dev Loss: 0.472014\n",
            "Epoch 23 Iteration 6030 - Train Loss: 0.003765 - Dev Loss: 0.476358\n",
            "Epoch 23 Iteration 6040 - Train Loss: 0.003557 - Dev Loss: 0.476117\n",
            "Epoch 23 Iteration 6050 - Train Loss: 0.004049 - Dev Loss: 0.477338\n",
            "Epoch 23 Iteration 6060 - Train Loss: 0.003919 - Dev Loss: 0.478032\n",
            "Epoch 23 Iteration 6070 - Train Loss: 0.003669 - Dev Loss: 0.478344\n",
            "Epoch 23 Iteration 6080 - Train Loss: 0.003787 - Dev Loss: 0.473644\n",
            "Epoch 23 Iteration 6090 - Train Loss: 0.004016 - Dev Loss: 0.474434\n",
            "Epoch 23 Iteration 6100 - Train Loss: 0.003773 - Dev Loss: 0.479034\n",
            "Epoch 23 Iteration 6110 - Train Loss: 0.003273 - Dev Loss: 0.477154\n",
            "Epoch 23 Iteration 6120 - Train Loss: 0.003742 - Dev Loss: 0.472067\n",
            "Epoch 23 Iteration 6130 - Train Loss: 0.003339 - Dev Loss: 0.473163\n",
            "Epoch 23 Iteration 6140 - Train Loss: 0.003440 - Dev Loss: 0.473343\n",
            "Epoch 24 Iteration 6150 - Train Loss: 0.002816 - Dev Loss: 0.473804\n",
            "Epoch 24 Iteration 6160 - Train Loss: 0.002706 - Dev Loss: 0.472836\n",
            "Epoch 24 Iteration 6170 - Train Loss: 0.003314 - Dev Loss: 0.475390\n",
            "Epoch 24 Iteration 6180 - Train Loss: 0.002764 - Dev Loss: 0.476709\n",
            "Epoch 24 Iteration 6190 - Train Loss: 0.002833 - Dev Loss: 0.474563\n",
            "Epoch 24 Iteration 6200 - Train Loss: 0.002750 - Dev Loss: 0.476325\n",
            "Epoch 24 Iteration 6210 - Train Loss: 0.002928 - Dev Loss: 0.477382\n",
            "Epoch 24 Iteration 6220 - Train Loss: 0.002869 - Dev Loss: 0.478159\n",
            "Epoch 24 Iteration 6230 - Train Loss: 0.002832 - Dev Loss: 0.476400\n",
            "Epoch 24 Iteration 6240 - Train Loss: 0.002771 - Dev Loss: 0.476238\n",
            "Epoch 24 Iteration 6250 - Train Loss: 0.003565 - Dev Loss: 0.478171\n",
            "Epoch 24 Iteration 6260 - Train Loss: 0.002298 - Dev Loss: 0.477554\n",
            "Epoch 24 Iteration 6270 - Train Loss: 0.002699 - Dev Loss: 0.479041\n",
            "Epoch 24 Iteration 6280 - Train Loss: 0.002954 - Dev Loss: 0.478693\n",
            "Epoch 24 Iteration 6290 - Train Loss: 0.002836 - Dev Loss: 0.480478\n",
            "Epoch 24 Iteration 6300 - Train Loss: 0.002803 - Dev Loss: 0.480704\n",
            "Epoch 24 Iteration 6310 - Train Loss: 0.003014 - Dev Loss: 0.475660\n",
            "Epoch 24 Iteration 6320 - Train Loss: 0.003504 - Dev Loss: 0.481776\n",
            "Epoch 24 Iteration 6330 - Train Loss: 0.002699 - Dev Loss: 0.483928\n",
            "Epoch 24 Iteration 6340 - Train Loss: 0.003102 - Dev Loss: 0.479949\n",
            "Epoch 24 Iteration 6350 - Train Loss: 0.003120 - Dev Loss: 0.482540\n",
            "Epoch 24 Iteration 6360 - Train Loss: 0.002760 - Dev Loss: 0.485583\n",
            "Epoch 24 Iteration 6370 - Train Loss: 0.002464 - Dev Loss: 0.485730\n",
            "Epoch 24 Iteration 6380 - Train Loss: 0.003065 - Dev Loss: 0.483889\n",
            "Epoch 24 Iteration 6390 - Train Loss: 0.002321 - Dev Loss: 0.485020\n",
            "Epoch 25 Iteration 6400 - Train Loss: 0.003355 - Dev Loss: 0.482655\n",
            "Epoch 25 Iteration 6410 - Train Loss: 0.002196 - Dev Loss: 0.481912\n",
            "Epoch 25 Iteration 6420 - Train Loss: 0.002404 - Dev Loss: 0.486525\n",
            "Epoch 25 Iteration 6430 - Train Loss: 0.002380 - Dev Loss: 0.488027\n",
            "Epoch 25 Iteration 6440 - Train Loss: 0.002221 - Dev Loss: 0.484706\n",
            "Epoch 25 Iteration 6450 - Train Loss: 0.002241 - Dev Loss: 0.482830\n",
            "Epoch 25 Iteration 6460 - Train Loss: 0.002086 - Dev Loss: 0.485959\n",
            "Epoch 25 Iteration 6470 - Train Loss: 0.002258 - Dev Loss: 0.484882\n",
            "Epoch 25 Iteration 6480 - Train Loss: 0.001938 - Dev Loss: 0.485591\n",
            "Epoch 25 Iteration 6490 - Train Loss: 0.002118 - Dev Loss: 0.485766\n",
            "Epoch 25 Iteration 6500 - Train Loss: 0.002575 - Dev Loss: 0.487009\n",
            "Epoch 25 Iteration 6510 - Train Loss: 0.002235 - Dev Loss: 0.488118\n",
            "Epoch 25 Iteration 6520 - Train Loss: 0.002244 - Dev Loss: 0.487111\n",
            "Epoch 25 Iteration 6530 - Train Loss: 0.002289 - Dev Loss: 0.485675\n",
            "Epoch 25 Iteration 6540 - Train Loss: 0.002427 - Dev Loss: 0.485371\n",
            "Epoch 25 Iteration 6550 - Train Loss: 0.002558 - Dev Loss: 0.487588\n",
            "Epoch 25 Iteration 6560 - Train Loss: 0.002846 - Dev Loss: 0.486283\n",
            "Epoch 25 Iteration 6570 - Train Loss: 0.002745 - Dev Loss: 0.486245\n",
            "Epoch 25 Iteration 6580 - Train Loss: 0.002473 - Dev Loss: 0.488841\n",
            "Epoch 25 Iteration 6590 - Train Loss: 0.002046 - Dev Loss: 0.490936\n",
            "Epoch 25 Iteration 6600 - Train Loss: 0.002479 - Dev Loss: 0.491876\n",
            "Epoch 25 Iteration 6610 - Train Loss: 0.002157 - Dev Loss: 0.490619\n",
            "Epoch 25 Iteration 6620 - Train Loss: 0.002163 - Dev Loss: 0.492015\n",
            "Epoch 25 Iteration 6630 - Train Loss: 0.002297 - Dev Loss: 0.492387\n",
            "Epoch 25 Iteration 6640 - Train Loss: 0.002563 - Dev Loss: 0.490161\n",
            "Epoch 25 Iteration 6650 - Train Loss: 0.002540 - Dev Loss: 0.490706\n",
            "Epoch 26 Iteration 6660 - Train Loss: 0.002058 - Dev Loss: 0.488732\n",
            "Epoch 26 Iteration 6670 - Train Loss: 0.002010 - Dev Loss: 0.487881\n",
            "Epoch 26 Iteration 6680 - Train Loss: 0.002105 - Dev Loss: 0.490748\n",
            "Epoch 26 Iteration 6690 - Train Loss: 0.001954 - Dev Loss: 0.491642\n",
            "Epoch 26 Iteration 6700 - Train Loss: 0.001853 - Dev Loss: 0.491421\n",
            "Epoch 26 Iteration 6710 - Train Loss: 0.001934 - Dev Loss: 0.491468\n",
            "Epoch 26 Iteration 6720 - Train Loss: 0.001857 - Dev Loss: 0.491645\n",
            "Epoch 26 Iteration 6730 - Train Loss: 0.001686 - Dev Loss: 0.491737\n",
            "Epoch 26 Iteration 6740 - Train Loss: 0.002148 - Dev Loss: 0.490548\n",
            "Epoch 26 Iteration 6750 - Train Loss: 0.001999 - Dev Loss: 0.492531\n",
            "Epoch 26 Iteration 6760 - Train Loss: 0.001599 - Dev Loss: 0.491346\n",
            "Epoch 26 Iteration 6770 - Train Loss: 0.001882 - Dev Loss: 0.490064\n",
            "Epoch 26 Iteration 6780 - Train Loss: 0.001769 - Dev Loss: 0.493933\n",
            "Epoch 26 Iteration 6790 - Train Loss: 0.001752 - Dev Loss: 0.495370\n",
            "Epoch 26 Iteration 6800 - Train Loss: 0.002168 - Dev Loss: 0.494738\n",
            "Epoch 26 Iteration 6810 - Train Loss: 0.001988 - Dev Loss: 0.493340\n",
            "Epoch 26 Iteration 6820 - Train Loss: 0.001948 - Dev Loss: 0.497109\n",
            "Epoch 26 Iteration 6830 - Train Loss: 0.001961 - Dev Loss: 0.495892\n",
            "Epoch 26 Iteration 6840 - Train Loss: 0.001618 - Dev Loss: 0.497392\n",
            "Epoch 26 Iteration 6850 - Train Loss: 0.002221 - Dev Loss: 0.497610\n",
            "Epoch 26 Iteration 6860 - Train Loss: 0.001557 - Dev Loss: 0.496608\n",
            "Epoch 26 Iteration 6870 - Train Loss: 0.002056 - Dev Loss: 0.497298\n",
            "Epoch 26 Iteration 6880 - Train Loss: 0.002021 - Dev Loss: 0.499331\n",
            "Epoch 26 Iteration 6890 - Train Loss: 0.001829 - Dev Loss: 0.496972\n",
            "Epoch 26 Iteration 6900 - Train Loss: 0.002214 - Dev Loss: 0.496734\n",
            "Epoch 26 Iteration 6910 - Train Loss: 0.001906 - Dev Loss: 0.497363\n",
            "Epoch 27 Iteration 6920 - Train Loss: 0.001761 - Dev Loss: 0.499435\n",
            "Epoch 27 Iteration 6930 - Train Loss: 0.001411 - Dev Loss: 0.500035\n",
            "Epoch 27 Iteration 6940 - Train Loss: 0.001668 - Dev Loss: 0.500099\n",
            "Epoch 27 Iteration 6950 - Train Loss: 0.001700 - Dev Loss: 0.500781\n",
            "Epoch 27 Iteration 6960 - Train Loss: 0.001488 - Dev Loss: 0.501870\n",
            "Epoch 27 Iteration 6970 - Train Loss: 0.001854 - Dev Loss: 0.502656\n",
            "Epoch 27 Iteration 6980 - Train Loss: 0.001629 - Dev Loss: 0.504744\n",
            "Epoch 27 Iteration 6990 - Train Loss: 0.001674 - Dev Loss: 0.506541\n",
            "Epoch 27 Iteration 7000 - Train Loss: 0.001456 - Dev Loss: 0.502159\n",
            "Epoch 27 Iteration 7010 - Train Loss: 0.001641 - Dev Loss: 0.501443\n",
            "Epoch 27 Iteration 7020 - Train Loss: 0.001522 - Dev Loss: 0.504431\n",
            "Epoch 27 Iteration 7030 - Train Loss: 0.001295 - Dev Loss: 0.505807\n",
            "Epoch 27 Iteration 7040 - Train Loss: 0.001517 - Dev Loss: 0.504704\n",
            "Epoch 27 Iteration 7050 - Train Loss: 0.001583 - Dev Loss: 0.504568\n",
            "Epoch 27 Iteration 7060 - Train Loss: 0.001512 - Dev Loss: 0.504709\n",
            "Epoch 27 Iteration 7070 - Train Loss: 0.001560 - Dev Loss: 0.506144\n",
            "Epoch 27 Iteration 7080 - Train Loss: 0.001650 - Dev Loss: 0.503432\n",
            "Epoch 27 Iteration 7090 - Train Loss: 0.001419 - Dev Loss: 0.504737\n",
            "Epoch 27 Iteration 7100 - Train Loss: 0.001552 - Dev Loss: 0.505928\n",
            "Epoch 27 Iteration 7110 - Train Loss: 0.001634 - Dev Loss: 0.505665\n",
            "Epoch 27 Iteration 7120 - Train Loss: 0.001525 - Dev Loss: 0.504083\n",
            "Epoch 27 Iteration 7130 - Train Loss: 0.001429 - Dev Loss: 0.503366\n",
            "Epoch 27 Iteration 7140 - Train Loss: 0.001464 - Dev Loss: 0.504860\n",
            "Epoch 27 Iteration 7150 - Train Loss: 0.001501 - Dev Loss: 0.504992\n",
            "Epoch 27 Iteration 7160 - Train Loss: 0.001727 - Dev Loss: 0.506490\n",
            "Epoch 28 Iteration 7170 - Train Loss: 0.001541 - Dev Loss: 0.506812\n",
            "Epoch 28 Iteration 7180 - Train Loss: 0.001555 - Dev Loss: 0.507530\n",
            "Epoch 28 Iteration 7190 - Train Loss: 0.001317 - Dev Loss: 0.509334\n",
            "Epoch 28 Iteration 7200 - Train Loss: 0.001232 - Dev Loss: 0.509626\n",
            "Epoch 28 Iteration 7210 - Train Loss: 0.001357 - Dev Loss: 0.506721\n",
            "Epoch 28 Iteration 7220 - Train Loss: 0.001244 - Dev Loss: 0.506696\n",
            "Epoch 28 Iteration 7230 - Train Loss: 0.001310 - Dev Loss: 0.508138\n",
            "Epoch 28 Iteration 7240 - Train Loss: 0.001318 - Dev Loss: 0.510017\n",
            "Epoch 28 Iteration 7250 - Train Loss: 0.001183 - Dev Loss: 0.509315\n",
            "Epoch 28 Iteration 7260 - Train Loss: 0.001228 - Dev Loss: 0.508411\n",
            "Epoch 28 Iteration 7270 - Train Loss: 0.001429 - Dev Loss: 0.506543\n",
            "Epoch 28 Iteration 7280 - Train Loss: 0.001277 - Dev Loss: 0.508266\n",
            "Epoch 28 Iteration 7290 - Train Loss: 0.001336 - Dev Loss: 0.510701\n",
            "Epoch 28 Iteration 7300 - Train Loss: 0.001231 - Dev Loss: 0.509901\n",
            "Epoch 28 Iteration 7310 - Train Loss: 0.001080 - Dev Loss: 0.510405\n",
            "Epoch 28 Iteration 7320 - Train Loss: 0.001324 - Dev Loss: 0.510361\n",
            "Epoch 28 Iteration 7330 - Train Loss: 0.001320 - Dev Loss: 0.509399\n",
            "Epoch 28 Iteration 7340 - Train Loss: 0.001330 - Dev Loss: 0.509754\n",
            "Epoch 28 Iteration 7350 - Train Loss: 0.001239 - Dev Loss: 0.510908\n",
            "Epoch 28 Iteration 7360 - Train Loss: 0.001255 - Dev Loss: 0.511873\n",
            "Epoch 28 Iteration 7370 - Train Loss: 0.001364 - Dev Loss: 0.512821\n",
            "Epoch 28 Iteration 7380 - Train Loss: 0.001334 - Dev Loss: 0.512118\n",
            "Epoch 28 Iteration 7390 - Train Loss: 0.001408 - Dev Loss: 0.511003\n",
            "Epoch 28 Iteration 7400 - Train Loss: 0.001526 - Dev Loss: 0.512612\n",
            "Epoch 28 Iteration 7410 - Train Loss: 0.001276 - Dev Loss: 0.511866\n",
            "Epoch 28 Iteration 7420 - Train Loss: 0.001445 - Dev Loss: 0.512823\n",
            "Epoch 29 Iteration 7430 - Train Loss: 0.001305 - Dev Loss: 0.514576\n",
            "Epoch 29 Iteration 7440 - Train Loss: 0.001148 - Dev Loss: 0.515382\n",
            "Epoch 29 Iteration 7450 - Train Loss: 0.000899 - Dev Loss: 0.513990\n",
            "Epoch 29 Iteration 7460 - Train Loss: 0.001096 - Dev Loss: 0.513163\n",
            "Epoch 29 Iteration 7470 - Train Loss: 0.000907 - Dev Loss: 0.514858\n",
            "Epoch 29 Iteration 7480 - Train Loss: 0.001099 - Dev Loss: 0.516981\n",
            "Epoch 29 Iteration 7490 - Train Loss: 0.001228 - Dev Loss: 0.515924\n",
            "Epoch 29 Iteration 7500 - Train Loss: 0.001045 - Dev Loss: 0.515571\n",
            "Epoch 29 Iteration 7510 - Train Loss: 0.001198 - Dev Loss: 0.517880\n",
            "Epoch 29 Iteration 7520 - Train Loss: 0.001265 - Dev Loss: 0.515659\n",
            "Epoch 29 Iteration 7530 - Train Loss: 0.001126 - Dev Loss: 0.514430\n",
            "Epoch 29 Iteration 7540 - Train Loss: 0.000980 - Dev Loss: 0.515734\n",
            "Epoch 29 Iteration 7550 - Train Loss: 0.001069 - Dev Loss: 0.518167\n",
            "Epoch 29 Iteration 7560 - Train Loss: 0.001094 - Dev Loss: 0.519026\n",
            "Epoch 29 Iteration 7570 - Train Loss: 0.001132 - Dev Loss: 0.518111\n",
            "Epoch 29 Iteration 7580 - Train Loss: 0.001278 - Dev Loss: 0.522085\n",
            "Epoch 29 Iteration 7590 - Train Loss: 0.001230 - Dev Loss: 0.524988\n",
            "Epoch 29 Iteration 7600 - Train Loss: 0.001046 - Dev Loss: 0.519059\n",
            "Epoch 29 Iteration 7610 - Train Loss: 0.001044 - Dev Loss: 0.517634\n",
            "Epoch 29 Iteration 7620 - Train Loss: 0.001051 - Dev Loss: 0.520020\n",
            "Epoch 29 Iteration 7630 - Train Loss: 0.001062 - Dev Loss: 0.519934\n",
            "Epoch 29 Iteration 7640 - Train Loss: 0.001115 - Dev Loss: 0.517675\n",
            "Epoch 29 Iteration 7650 - Train Loss: 0.001072 - Dev Loss: 0.522564\n",
            "Epoch 29 Iteration 7660 - Train Loss: 0.000926 - Dev Loss: 0.524352\n",
            "Epoch 29 Iteration 7670 - Train Loss: 0.001175 - Dev Loss: 0.521238\n",
            "Epoch 30 Iteration 7680 - Train Loss: 0.000997 - Dev Loss: 0.518919\n",
            "Epoch 30 Iteration 7690 - Train Loss: 0.000822 - Dev Loss: 0.519384\n",
            "Epoch 30 Iteration 7700 - Train Loss: 0.001100 - Dev Loss: 0.521395\n",
            "Epoch 30 Iteration 7710 - Train Loss: 0.000804 - Dev Loss: 0.521587\n",
            "Epoch 30 Iteration 7720 - Train Loss: 0.000862 - Dev Loss: 0.523056\n",
            "Epoch 30 Iteration 7730 - Train Loss: 0.000823 - Dev Loss: 0.523973\n",
            "Epoch 30 Iteration 7740 - Train Loss: 0.000886 - Dev Loss: 0.524202\n",
            "Epoch 30 Iteration 7750 - Train Loss: 0.000992 - Dev Loss: 0.523809\n",
            "Epoch 30 Iteration 7760 - Train Loss: 0.000936 - Dev Loss: 0.523900\n",
            "Epoch 30 Iteration 7770 - Train Loss: 0.000954 - Dev Loss: 0.523628\n",
            "Epoch 30 Iteration 7780 - Train Loss: 0.000866 - Dev Loss: 0.524025\n",
            "Epoch 30 Iteration 7790 - Train Loss: 0.000821 - Dev Loss: 0.525163\n",
            "Epoch 30 Iteration 7800 - Train Loss: 0.000888 - Dev Loss: 0.522832\n",
            "Epoch 30 Iteration 7810 - Train Loss: 0.000807 - Dev Loss: 0.524168\n",
            "Epoch 30 Iteration 7820 - Train Loss: 0.000992 - Dev Loss: 0.524321\n",
            "Epoch 30 Iteration 7830 - Train Loss: 0.000860 - Dev Loss: 0.522475\n",
            "Epoch 30 Iteration 7840 - Train Loss: 0.001138 - Dev Loss: 0.525676\n",
            "Epoch 30 Iteration 7850 - Train Loss: 0.000779 - Dev Loss: 0.528652\n",
            "Epoch 30 Iteration 7860 - Train Loss: 0.000810 - Dev Loss: 0.526743\n",
            "Epoch 30 Iteration 7870 - Train Loss: 0.000865 - Dev Loss: 0.524917\n",
            "Epoch 30 Iteration 7880 - Train Loss: 0.000946 - Dev Loss: 0.527726\n",
            "Epoch 30 Iteration 7890 - Train Loss: 0.000964 - Dev Loss: 0.527034\n",
            "Epoch 30 Iteration 7900 - Train Loss: 0.000881 - Dev Loss: 0.526578\n",
            "Epoch 30 Iteration 7910 - Train Loss: 0.001028 - Dev Loss: 0.528604\n",
            "Epoch 30 Iteration 7920 - Train Loss: 0.001051 - Dev Loss: 0.529569\n",
            "Epoch 30 Iteration 7930 - Train Loss: 0.000865 - Dev Loss: 0.527339\n",
            "Epoch 31 Iteration 7940 - Train Loss: 0.000803 - Dev Loss: 0.528011\n",
            "Epoch 31 Iteration 7950 - Train Loss: 0.000752 - Dev Loss: 0.529346\n",
            "Epoch 31 Iteration 7960 - Train Loss: 0.000705 - Dev Loss: 0.528848\n",
            "Epoch 31 Iteration 7970 - Train Loss: 0.000717 - Dev Loss: 0.529475\n",
            "Epoch 31 Iteration 7980 - Train Loss: 0.000732 - Dev Loss: 0.530137\n",
            "Epoch 31 Iteration 7990 - Train Loss: 0.000848 - Dev Loss: 0.529777\n",
            "Epoch 31 Iteration 8000 - Train Loss: 0.000968 - Dev Loss: 0.531279\n",
            "Epoch 31 Iteration 8010 - Train Loss: 0.000730 - Dev Loss: 0.532755\n",
            "Epoch 31 Iteration 8020 - Train Loss: 0.000797 - Dev Loss: 0.533282\n",
            "Epoch 31 Iteration 8030 - Train Loss: 0.000730 - Dev Loss: 0.532289\n",
            "Epoch 31 Iteration 8040 - Train Loss: 0.000784 - Dev Loss: 0.532500\n",
            "Epoch 31 Iteration 8050 - Train Loss: 0.000824 - Dev Loss: 0.533461\n",
            "Epoch 31 Iteration 8060 - Train Loss: 0.000789 - Dev Loss: 0.531190\n",
            "Epoch 31 Iteration 8070 - Train Loss: 0.000764 - Dev Loss: 0.532020\n",
            "Epoch 31 Iteration 8080 - Train Loss: 0.000768 - Dev Loss: 0.533082\n",
            "Epoch 31 Iteration 8090 - Train Loss: 0.000807 - Dev Loss: 0.535743\n",
            "Epoch 31 Iteration 8100 - Train Loss: 0.000716 - Dev Loss: 0.535569\n",
            "Epoch 31 Iteration 8110 - Train Loss: 0.000672 - Dev Loss: 0.534838\n",
            "Epoch 31 Iteration 8120 - Train Loss: 0.000788 - Dev Loss: 0.535963\n",
            "Epoch 31 Iteration 8130 - Train Loss: 0.000768 - Dev Loss: 0.536015\n",
            "Epoch 31 Iteration 8140 - Train Loss: 0.000698 - Dev Loss: 0.533639\n",
            "Epoch 31 Iteration 8150 - Train Loss: 0.000787 - Dev Loss: 0.536749\n",
            "Epoch 31 Iteration 8160 - Train Loss: 0.000712 - Dev Loss: 0.535238\n",
            "Epoch 31 Iteration 8170 - Train Loss: 0.000781 - Dev Loss: 0.535295\n",
            "Epoch 31 Iteration 8180 - Train Loss: 0.000760 - Dev Loss: 0.537219\n",
            "Epoch 31 Iteration 8190 - Train Loss: 0.000787 - Dev Loss: 0.537016\n",
            "Epoch 32 Iteration 8200 - Train Loss: 0.000660 - Dev Loss: 0.538071\n",
            "Epoch 32 Iteration 8210 - Train Loss: 0.000643 - Dev Loss: 0.536177\n",
            "Epoch 32 Iteration 8220 - Train Loss: 0.000719 - Dev Loss: 0.535372\n",
            "Epoch 32 Iteration 8230 - Train Loss: 0.000683 - Dev Loss: 0.536510\n",
            "Epoch 32 Iteration 8240 - Train Loss: 0.000585 - Dev Loss: 0.536085\n",
            "Epoch 32 Iteration 8250 - Train Loss: 0.000612 - Dev Loss: 0.537816\n",
            "Epoch 32 Iteration 8260 - Train Loss: 0.000632 - Dev Loss: 0.538630\n",
            "Epoch 32 Iteration 8270 - Train Loss: 0.000700 - Dev Loss: 0.538584\n",
            "Epoch 32 Iteration 8280 - Train Loss: 0.000599 - Dev Loss: 0.539181\n",
            "Epoch 32 Iteration 8290 - Train Loss: 0.000693 - Dev Loss: 0.540029\n",
            "Epoch 32 Iteration 8300 - Train Loss: 0.000602 - Dev Loss: 0.540794\n",
            "Epoch 32 Iteration 8310 - Train Loss: 0.000663 - Dev Loss: 0.539944\n",
            "Epoch 32 Iteration 8320 - Train Loss: 0.000710 - Dev Loss: 0.538365\n",
            "Epoch 32 Iteration 8330 - Train Loss: 0.000770 - Dev Loss: 0.542814\n",
            "Epoch 32 Iteration 8340 - Train Loss: 0.000596 - Dev Loss: 0.543890\n",
            "Epoch 32 Iteration 8350 - Train Loss: 0.000652 - Dev Loss: 0.542066\n",
            "Epoch 32 Iteration 8360 - Train Loss: 0.000652 - Dev Loss: 0.540697\n",
            "Epoch 32 Iteration 8370 - Train Loss: 0.000612 - Dev Loss: 0.541400\n",
            "Epoch 32 Iteration 8380 - Train Loss: 0.000631 - Dev Loss: 0.546100\n",
            "Epoch 32 Iteration 8390 - Train Loss: 0.000597 - Dev Loss: 0.545400\n",
            "Epoch 32 Iteration 8400 - Train Loss: 0.000623 - Dev Loss: 0.541267\n",
            "Epoch 32 Iteration 8410 - Train Loss: 0.000687 - Dev Loss: 0.540370\n",
            "Epoch 32 Iteration 8420 - Train Loss: 0.000694 - Dev Loss: 0.542173\n",
            "Epoch 32 Iteration 8430 - Train Loss: 0.000629 - Dev Loss: 0.542618\n",
            "Epoch 32 Iteration 8440 - Train Loss: 0.000617 - Dev Loss: 0.541423\n",
            "Epoch 33 Iteration 8450 - Train Loss: 0.000608 - Dev Loss: 0.540475\n",
            "Epoch 33 Iteration 8460 - Train Loss: 0.000618 - Dev Loss: 0.541905\n",
            "Epoch 33 Iteration 8470 - Train Loss: 0.000591 - Dev Loss: 0.542449\n",
            "Epoch 33 Iteration 8480 - Train Loss: 0.000539 - Dev Loss: 0.542584\n",
            "Epoch 33 Iteration 8490 - Train Loss: 0.000566 - Dev Loss: 0.545349\n",
            "Epoch 33 Iteration 8500 - Train Loss: 0.000508 - Dev Loss: 0.545166\n",
            "Epoch 33 Iteration 8510 - Train Loss: 0.000524 - Dev Loss: 0.543920\n",
            "Epoch 33 Iteration 8520 - Train Loss: 0.000634 - Dev Loss: 0.543841\n",
            "Epoch 33 Iteration 8530 - Train Loss: 0.000457 - Dev Loss: 0.545077\n",
            "Epoch 33 Iteration 8540 - Train Loss: 0.000548 - Dev Loss: 0.544899\n",
            "Epoch 33 Iteration 8550 - Train Loss: 0.000567 - Dev Loss: 0.542630\n",
            "Epoch 33 Iteration 8560 - Train Loss: 0.000666 - Dev Loss: 0.545791\n",
            "Epoch 33 Iteration 8570 - Train Loss: 0.000542 - Dev Loss: 0.546911\n",
            "Epoch 33 Iteration 8580 - Train Loss: 0.000514 - Dev Loss: 0.548024\n",
            "Epoch 33 Iteration 8590 - Train Loss: 0.000633 - Dev Loss: 0.548237\n",
            "Epoch 33 Iteration 8600 - Train Loss: 0.000478 - Dev Loss: 0.549395\n",
            "Epoch 33 Iteration 8610 - Train Loss: 0.000569 - Dev Loss: 0.547089\n",
            "Epoch 33 Iteration 8620 - Train Loss: 0.000509 - Dev Loss: 0.546903\n",
            "Epoch 33 Iteration 8630 - Train Loss: 0.000606 - Dev Loss: 0.549048\n",
            "Epoch 33 Iteration 8640 - Train Loss: 0.000581 - Dev Loss: 0.550706\n",
            "Epoch 33 Iteration 8650 - Train Loss: 0.000524 - Dev Loss: 0.548987\n",
            "Epoch 33 Iteration 8660 - Train Loss: 0.000613 - Dev Loss: 0.548455\n",
            "Epoch 33 Iteration 8670 - Train Loss: 0.000490 - Dev Loss: 0.550693\n",
            "Epoch 33 Iteration 8680 - Train Loss: 0.000504 - Dev Loss: 0.550127\n",
            "Epoch 33 Iteration 8690 - Train Loss: 0.000496 - Dev Loss: 0.550571\n",
            "Epoch 33 Iteration 8700 - Train Loss: 0.000513 - Dev Loss: 0.551880\n",
            "Epoch 34 Iteration 8710 - Train Loss: 0.000461 - Dev Loss: 0.551860\n",
            "Epoch 34 Iteration 8720 - Train Loss: 0.000454 - Dev Loss: 0.551259\n",
            "Epoch 34 Iteration 8730 - Train Loss: 0.000439 - Dev Loss: 0.550564\n",
            "Epoch 34 Iteration 8740 - Train Loss: 0.000455 - Dev Loss: 0.550737\n",
            "Epoch 34 Iteration 8750 - Train Loss: 0.000486 - Dev Loss: 0.551109\n",
            "Epoch 34 Iteration 8760 - Train Loss: 0.000456 - Dev Loss: 0.551307\n",
            "Epoch 34 Iteration 8770 - Train Loss: 0.000506 - Dev Loss: 0.551567\n",
            "Epoch 34 Iteration 8780 - Train Loss: 0.000425 - Dev Loss: 0.552132\n",
            "Epoch 34 Iteration 8790 - Train Loss: 0.000461 - Dev Loss: 0.553084\n",
            "Epoch 34 Iteration 8800 - Train Loss: 0.000484 - Dev Loss: 0.553043\n",
            "Epoch 34 Iteration 8810 - Train Loss: 0.000478 - Dev Loss: 0.554204\n",
            "Epoch 34 Iteration 8820 - Train Loss: 0.000420 - Dev Loss: 0.558079\n",
            "Epoch 34 Iteration 8830 - Train Loss: 0.000479 - Dev Loss: 0.554809\n",
            "Epoch 34 Iteration 8840 - Train Loss: 0.000566 - Dev Loss: 0.553521\n",
            "Epoch 34 Iteration 8850 - Train Loss: 0.000488 - Dev Loss: 0.556374\n",
            "Epoch 34 Iteration 8860 - Train Loss: 0.000531 - Dev Loss: 0.555961\n",
            "Epoch 34 Iteration 8870 - Train Loss: 0.000446 - Dev Loss: 0.555854\n",
            "Epoch 34 Iteration 8880 - Train Loss: 0.000420 - Dev Loss: 0.555728\n",
            "Epoch 34 Iteration 8890 - Train Loss: 0.000490 - Dev Loss: 0.556090\n",
            "Epoch 34 Iteration 8900 - Train Loss: 0.000401 - Dev Loss: 0.557313\n",
            "Epoch 34 Iteration 8910 - Train Loss: 0.000505 - Dev Loss: 0.554831\n",
            "Epoch 34 Iteration 8920 - Train Loss: 0.000505 - Dev Loss: 0.554848\n",
            "Epoch 34 Iteration 8930 - Train Loss: 0.000488 - Dev Loss: 0.556351\n",
            "Epoch 34 Iteration 8940 - Train Loss: 0.000376 - Dev Loss: 0.556997\n",
            "Epoch 34 Iteration 8950 - Train Loss: 0.000482 - Dev Loss: 0.556091\n",
            "Epoch 35 Iteration 8960 - Train Loss: 0.000473 - Dev Loss: 0.557963\n",
            "Epoch 35 Iteration 8970 - Train Loss: 0.000348 - Dev Loss: 0.558537\n",
            "Epoch 35 Iteration 8980 - Train Loss: 0.000406 - Dev Loss: 0.558707\n",
            "Epoch 35 Iteration 8990 - Train Loss: 0.000346 - Dev Loss: 0.556811\n",
            "Epoch 35 Iteration 9000 - Train Loss: 0.000460 - Dev Loss: 0.555954\n",
            "Epoch 35 Iteration 9010 - Train Loss: 0.000400 - Dev Loss: 0.557456\n",
            "Epoch 35 Iteration 9020 - Train Loss: 0.000362 - Dev Loss: 0.558538\n",
            "Epoch 35 Iteration 9030 - Train Loss: 0.000319 - Dev Loss: 0.557600\n",
            "Epoch 35 Iteration 9040 - Train Loss: 0.000379 - Dev Loss: 0.558409\n",
            "Epoch 35 Iteration 9050 - Train Loss: 0.000382 - Dev Loss: 0.558403\n",
            "Epoch 35 Iteration 9060 - Train Loss: 0.000440 - Dev Loss: 0.557473\n",
            "Epoch 35 Iteration 9070 - Train Loss: 0.000356 - Dev Loss: 0.559641\n",
            "Epoch 35 Iteration 9080 - Train Loss: 0.000396 - Dev Loss: 0.562584\n",
            "Epoch 35 Iteration 9090 - Train Loss: 0.000384 - Dev Loss: 0.561604\n",
            "Epoch 35 Iteration 9100 - Train Loss: 0.000425 - Dev Loss: 0.559558\n",
            "Epoch 35 Iteration 9110 - Train Loss: 0.000416 - Dev Loss: 0.559067\n",
            "Epoch 35 Iteration 9120 - Train Loss: 0.000391 - Dev Loss: 0.561158\n",
            "Epoch 35 Iteration 9130 - Train Loss: 0.000409 - Dev Loss: 0.561964\n",
            "Epoch 35 Iteration 9140 - Train Loss: 0.000409 - Dev Loss: 0.563962\n",
            "Epoch 35 Iteration 9150 - Train Loss: 0.000419 - Dev Loss: 0.564098\n",
            "Epoch 35 Iteration 9160 - Train Loss: 0.000400 - Dev Loss: 0.563078\n",
            "Epoch 35 Iteration 9170 - Train Loss: 0.000490 - Dev Loss: 0.565495\n",
            "Epoch 35 Iteration 9180 - Train Loss: 0.000425 - Dev Loss: 0.566242\n",
            "Epoch 35 Iteration 9190 - Train Loss: 0.000408 - Dev Loss: 0.565834\n",
            "Epoch 35 Iteration 9200 - Train Loss: 0.000367 - Dev Loss: 0.566431\n",
            "Epoch 35 Iteration 9210 - Train Loss: 0.000411 - Dev Loss: 0.565761\n",
            "Epoch 36 Iteration 9220 - Train Loss: 0.000335 - Dev Loss: 0.566532\n",
            "Epoch 36 Iteration 9230 - Train Loss: 0.000404 - Dev Loss: 0.568260\n",
            "Epoch 36 Iteration 9240 - Train Loss: 0.000330 - Dev Loss: 0.567266\n",
            "Epoch 36 Iteration 9250 - Train Loss: 0.000326 - Dev Loss: 0.566511\n",
            "Epoch 36 Iteration 9260 - Train Loss: 0.000315 - Dev Loss: 0.566252\n",
            "Epoch 36 Iteration 9270 - Train Loss: 0.000330 - Dev Loss: 0.567353\n",
            "Epoch 36 Iteration 9280 - Train Loss: 0.000326 - Dev Loss: 0.570592\n",
            "Epoch 36 Iteration 9290 - Train Loss: 0.000292 - Dev Loss: 0.570600\n",
            "Epoch 36 Iteration 9300 - Train Loss: 0.000386 - Dev Loss: 0.569812\n",
            "Epoch 36 Iteration 9310 - Train Loss: 0.000306 - Dev Loss: 0.570089\n",
            "Epoch 36 Iteration 9320 - Train Loss: 0.000311 - Dev Loss: 0.571137\n",
            "Epoch 36 Iteration 9330 - Train Loss: 0.000344 - Dev Loss: 0.570681\n",
            "Epoch 36 Iteration 9340 - Train Loss: 0.000299 - Dev Loss: 0.570949\n",
            "Epoch 36 Iteration 9350 - Train Loss: 0.000361 - Dev Loss: 0.569877\n",
            "Epoch 36 Iteration 9360 - Train Loss: 0.000323 - Dev Loss: 0.570192\n",
            "Epoch 36 Iteration 9370 - Train Loss: 0.000334 - Dev Loss: 0.570930\n",
            "Epoch 36 Iteration 9380 - Train Loss: 0.000363 - Dev Loss: 0.569159\n",
            "Epoch 36 Iteration 9390 - Train Loss: 0.000334 - Dev Loss: 0.569646\n",
            "Epoch 36 Iteration 9400 - Train Loss: 0.000289 - Dev Loss: 0.567987\n",
            "Epoch 36 Iteration 9410 - Train Loss: 0.000336 - Dev Loss: 0.567742\n",
            "Epoch 36 Iteration 9420 - Train Loss: 0.000367 - Dev Loss: 0.568695\n",
            "Epoch 36 Iteration 9430 - Train Loss: 0.000353 - Dev Loss: 0.569094\n",
            "Epoch 36 Iteration 9440 - Train Loss: 0.000344 - Dev Loss: 0.570627\n",
            "Epoch 36 Iteration 9450 - Train Loss: 0.000306 - Dev Loss: 0.571614\n",
            "Epoch 36 Iteration 9460 - Train Loss: 0.000411 - Dev Loss: 0.570691\n",
            "Epoch 36 Iteration 9470 - Train Loss: 0.000367 - Dev Loss: 0.569934\n",
            "Epoch 37 Iteration 9480 - Train Loss: 0.000264 - Dev Loss: 0.570363\n",
            "Epoch 37 Iteration 9490 - Train Loss: 0.000320 - Dev Loss: 0.570133\n",
            "Epoch 37 Iteration 9500 - Train Loss: 0.000328 - Dev Loss: 0.568976\n",
            "Epoch 37 Iteration 9510 - Train Loss: 0.000303 - Dev Loss: 0.571181\n",
            "Epoch 37 Iteration 9520 - Train Loss: 0.000271 - Dev Loss: 0.571770\n",
            "Epoch 37 Iteration 9530 - Train Loss: 0.000295 - Dev Loss: 0.572001\n",
            "Epoch 37 Iteration 9540 - Train Loss: 0.000289 - Dev Loss: 0.571981\n",
            "Epoch 37 Iteration 9550 - Train Loss: 0.000283 - Dev Loss: 0.573216\n",
            "Epoch 37 Iteration 9560 - Train Loss: 0.000280 - Dev Loss: 0.574001\n",
            "Epoch 37 Iteration 9570 - Train Loss: 0.000300 - Dev Loss: 0.574545\n",
            "Epoch 37 Iteration 9580 - Train Loss: 0.000246 - Dev Loss: 0.576081\n",
            "Epoch 37 Iteration 9590 - Train Loss: 0.000285 - Dev Loss: 0.575525\n",
            "Epoch 37 Iteration 9600 - Train Loss: 0.000306 - Dev Loss: 0.575066\n",
            "Epoch 37 Iteration 9610 - Train Loss: 0.000293 - Dev Loss: 0.576777\n",
            "Epoch 37 Iteration 9620 - Train Loss: 0.000256 - Dev Loss: 0.578512\n",
            "Epoch 37 Iteration 9630 - Train Loss: 0.000290 - Dev Loss: 0.577737\n",
            "Epoch 37 Iteration 9640 - Train Loss: 0.000310 - Dev Loss: 0.576655\n",
            "Epoch 37 Iteration 9650 - Train Loss: 0.000315 - Dev Loss: 0.578562\n",
            "Epoch 37 Iteration 9660 - Train Loss: 0.000238 - Dev Loss: 0.577108\n",
            "Epoch 37 Iteration 9670 - Train Loss: 0.000293 - Dev Loss: 0.578306\n",
            "Epoch 37 Iteration 9680 - Train Loss: 0.000273 - Dev Loss: 0.579377\n",
            "Epoch 37 Iteration 9690 - Train Loss: 0.000280 - Dev Loss: 0.578357\n",
            "Epoch 37 Iteration 9700 - Train Loss: 0.000290 - Dev Loss: 0.579135\n",
            "Epoch 37 Iteration 9710 - Train Loss: 0.000303 - Dev Loss: 0.578419\n",
            "Epoch 37 Iteration 9720 - Train Loss: 0.000334 - Dev Loss: 0.578431\n",
            "Epoch 38 Iteration 9730 - Train Loss: 0.000271 - Dev Loss: 0.579331\n",
            "Epoch 38 Iteration 9740 - Train Loss: 0.000251 - Dev Loss: 0.580715\n",
            "Epoch 38 Iteration 9750 - Train Loss: 0.000259 - Dev Loss: 0.581933\n",
            "Epoch 38 Iteration 9760 - Train Loss: 0.000239 - Dev Loss: 0.580677\n",
            "Epoch 38 Iteration 9770 - Train Loss: 0.000316 - Dev Loss: 0.579323\n",
            "Epoch 38 Iteration 9780 - Train Loss: 0.000223 - Dev Loss: 0.579229\n",
            "Epoch 38 Iteration 9790 - Train Loss: 0.000236 - Dev Loss: 0.580226\n",
            "Epoch 38 Iteration 9800 - Train Loss: 0.000229 - Dev Loss: 0.581816\n",
            "Epoch 38 Iteration 9810 - Train Loss: 0.000237 - Dev Loss: 0.582509\n",
            "Epoch 38 Iteration 9820 - Train Loss: 0.000266 - Dev Loss: 0.582448\n",
            "Epoch 38 Iteration 9830 - Train Loss: 0.000249 - Dev Loss: 0.582157\n",
            "Epoch 38 Iteration 9840 - Train Loss: 0.000208 - Dev Loss: 0.582778\n",
            "Epoch 38 Iteration 9850 - Train Loss: 0.000277 - Dev Loss: 0.581344\n",
            "Epoch 38 Iteration 9860 - Train Loss: 0.000263 - Dev Loss: 0.580223\n",
            "Epoch 38 Iteration 9870 - Train Loss: 0.000242 - Dev Loss: 0.582152\n",
            "Epoch 38 Iteration 9880 - Train Loss: 0.000249 - Dev Loss: 0.582039\n",
            "Epoch 38 Iteration 9890 - Train Loss: 0.000287 - Dev Loss: 0.581622\n",
            "Epoch 38 Iteration 9900 - Train Loss: 0.000231 - Dev Loss: 0.583192\n",
            "Epoch 38 Iteration 9910 - Train Loss: 0.000257 - Dev Loss: 0.583205\n",
            "Epoch 38 Iteration 9920 - Train Loss: 0.000220 - Dev Loss: 0.583156\n",
            "Epoch 38 Iteration 9930 - Train Loss: 0.000236 - Dev Loss: 0.583504\n",
            "Epoch 38 Iteration 9940 - Train Loss: 0.000232 - Dev Loss: 0.584121\n",
            "Epoch 38 Iteration 9950 - Train Loss: 0.000234 - Dev Loss: 0.584964\n",
            "Epoch 38 Iteration 9960 - Train Loss: 0.000249 - Dev Loss: 0.586497\n",
            "Epoch 38 Iteration 9970 - Train Loss: 0.000275 - Dev Loss: 0.587818\n",
            "Epoch 38 Iteration 9980 - Train Loss: 0.000254 - Dev Loss: 0.587043\n",
            "Epoch 39 Iteration 9990 - Train Loss: 0.000200 - Dev Loss: 0.588045\n",
            "Epoch 39 Iteration 10000 - Train Loss: 0.000224 - Dev Loss: 0.586505\n",
            "Epoch 39 Iteration 10010 - Train Loss: 0.000215 - Dev Loss: 0.586189\n",
            "Epoch 39 Iteration 10020 - Train Loss: 0.000234 - Dev Loss: 0.587657\n",
            "Epoch 39 Iteration 10030 - Train Loss: 0.000192 - Dev Loss: 0.587920\n",
            "Epoch 39 Iteration 10040 - Train Loss: 0.000199 - Dev Loss: 0.587421\n",
            "Epoch 39 Iteration 10050 - Train Loss: 0.000211 - Dev Loss: 0.586450\n",
            "Epoch 39 Iteration 10060 - Train Loss: 0.000232 - Dev Loss: 0.587702\n",
            "Epoch 39 Iteration 10070 - Train Loss: 0.000240 - Dev Loss: 0.587011\n",
            "Epoch 39 Iteration 10080 - Train Loss: 0.000223 - Dev Loss: 0.586284\n",
            "Epoch 39 Iteration 10090 - Train Loss: 0.000223 - Dev Loss: 0.586688\n",
            "Epoch 39 Iteration 10100 - Train Loss: 0.000238 - Dev Loss: 0.588618\n",
            "Epoch 39 Iteration 10110 - Train Loss: 0.000195 - Dev Loss: 0.588753\n",
            "Epoch 39 Iteration 10120 - Train Loss: 0.000217 - Dev Loss: 0.586809\n",
            "Epoch 39 Iteration 10130 - Train Loss: 0.000205 - Dev Loss: 0.587267\n",
            "Epoch 39 Iteration 10140 - Train Loss: 0.000227 - Dev Loss: 0.589236\n",
            "Epoch 39 Iteration 10150 - Train Loss: 0.000197 - Dev Loss: 0.590179\n",
            "Epoch 39 Iteration 10160 - Train Loss: 0.000185 - Dev Loss: 0.590498\n",
            "Epoch 39 Iteration 10170 - Train Loss: 0.000183 - Dev Loss: 0.589502\n",
            "Epoch 39 Iteration 10180 - Train Loss: 0.000236 - Dev Loss: 0.589165\n",
            "Epoch 39 Iteration 10190 - Train Loss: 0.000219 - Dev Loss: 0.590256\n",
            "Epoch 39 Iteration 10200 - Train Loss: 0.000191 - Dev Loss: 0.591469\n",
            "Epoch 39 Iteration 10210 - Train Loss: 0.000211 - Dev Loss: 0.591670\n",
            "Epoch 39 Iteration 10220 - Train Loss: 0.000214 - Dev Loss: 0.594054\n",
            "Epoch 39 Iteration 10230 - Train Loss: 0.000196 - Dev Loss: 0.592146\n",
            "Epoch 40 Iteration 10240 - Train Loss: 0.000224 - Dev Loss: 0.591700\n",
            "Epoch 40 Iteration 10250 - Train Loss: 0.000180 - Dev Loss: 0.592300\n",
            "Epoch 40 Iteration 10260 - Train Loss: 0.000193 - Dev Loss: 0.592935\n",
            "Epoch 40 Iteration 10270 - Train Loss: 0.000167 - Dev Loss: 0.593830\n",
            "Epoch 40 Iteration 10280 - Train Loss: 0.000198 - Dev Loss: 0.592529\n",
            "Epoch 40 Iteration 10290 - Train Loss: 0.000178 - Dev Loss: 0.592462\n",
            "Epoch 40 Iteration 10300 - Train Loss: 0.000187 - Dev Loss: 0.592566\n",
            "Epoch 40 Iteration 10310 - Train Loss: 0.000153 - Dev Loss: 0.594125\n",
            "Epoch 40 Iteration 10320 - Train Loss: 0.000188 - Dev Loss: 0.595109\n",
            "Epoch 40 Iteration 10330 - Train Loss: 0.000194 - Dev Loss: 0.595013\n",
            "Epoch 40 Iteration 10340 - Train Loss: 0.000175 - Dev Loss: 0.595366\n",
            "Epoch 40 Iteration 10350 - Train Loss: 0.000186 - Dev Loss: 0.596066\n",
            "Epoch 40 Iteration 10360 - Train Loss: 0.000198 - Dev Loss: 0.596090\n",
            "Epoch 40 Iteration 10370 - Train Loss: 0.000196 - Dev Loss: 0.597867\n",
            "Epoch 40 Iteration 10380 - Train Loss: 0.000179 - Dev Loss: 0.599607\n",
            "Epoch 40 Iteration 10390 - Train Loss: 0.000164 - Dev Loss: 0.599145\n",
            "Epoch 40 Iteration 10400 - Train Loss: 0.000207 - Dev Loss: 0.598740\n",
            "Epoch 40 Iteration 10410 - Train Loss: 0.000197 - Dev Loss: 0.597794\n",
            "Epoch 40 Iteration 10420 - Train Loss: 0.000189 - Dev Loss: 0.597438\n",
            "Epoch 40 Iteration 10430 - Train Loss: 0.000180 - Dev Loss: 0.597288\n",
            "Epoch 40 Iteration 10440 - Train Loss: 0.000151 - Dev Loss: 0.598735\n",
            "Epoch 40 Iteration 10450 - Train Loss: 0.000191 - Dev Loss: 0.598675\n",
            "Epoch 40 Iteration 10460 - Train Loss: 0.000203 - Dev Loss: 0.595949\n",
            "Epoch 40 Iteration 10470 - Train Loss: 0.000190 - Dev Loss: 0.597775\n",
            "Epoch 40 Iteration 10480 - Train Loss: 0.000170 - Dev Loss: 0.599469\n",
            "Epoch 40 Iteration 10490 - Train Loss: 0.000161 - Dev Loss: 0.597807\n",
            "Epoch 41 Iteration 10500 - Train Loss: 0.000181 - Dev Loss: 0.597191\n",
            "Epoch 41 Iteration 10510 - Train Loss: 0.000138 - Dev Loss: 0.599172\n",
            "Epoch 41 Iteration 10520 - Train Loss: 0.000171 - Dev Loss: 0.597946\n",
            "Epoch 41 Iteration 10530 - Train Loss: 0.000155 - Dev Loss: 0.598006\n",
            "Epoch 41 Iteration 10540 - Train Loss: 0.000166 - Dev Loss: 0.598430\n",
            "Epoch 41 Iteration 10550 - Train Loss: 0.000164 - Dev Loss: 0.598730\n",
            "Epoch 41 Iteration 10560 - Train Loss: 0.000159 - Dev Loss: 0.597794\n",
            "Epoch 41 Iteration 10570 - Train Loss: 0.000162 - Dev Loss: 0.597911\n",
            "Epoch 41 Iteration 10580 - Train Loss: 0.000157 - Dev Loss: 0.600084\n",
            "Epoch 41 Iteration 10590 - Train Loss: 0.000174 - Dev Loss: 0.602011\n",
            "Epoch 41 Iteration 10600 - Train Loss: 0.000174 - Dev Loss: 0.602041\n",
            "Epoch 41 Iteration 10610 - Train Loss: 0.000156 - Dev Loss: 0.600893\n",
            "Epoch 41 Iteration 10620 - Train Loss: 0.000144 - Dev Loss: 0.599077\n",
            "Epoch 41 Iteration 10630 - Train Loss: 0.000150 - Dev Loss: 0.601120\n",
            "Epoch 41 Iteration 10640 - Train Loss: 0.000157 - Dev Loss: 0.603903\n",
            "Epoch 41 Iteration 10650 - Train Loss: 0.000163 - Dev Loss: 0.602640\n",
            "Epoch 41 Iteration 10660 - Train Loss: 0.000136 - Dev Loss: 0.601444\n",
            "Epoch 41 Iteration 10670 - Train Loss: 0.000151 - Dev Loss: 0.601618\n",
            "Epoch 41 Iteration 10680 - Train Loss: 0.000166 - Dev Loss: 0.603286\n",
            "Epoch 41 Iteration 10690 - Train Loss: 0.000144 - Dev Loss: 0.604510\n",
            "Epoch 41 Iteration 10700 - Train Loss: 0.000163 - Dev Loss: 0.604477\n",
            "Epoch 41 Iteration 10710 - Train Loss: 0.000161 - Dev Loss: 0.604866\n",
            "Epoch 41 Iteration 10720 - Train Loss: 0.000166 - Dev Loss: 0.607551\n",
            "Epoch 41 Iteration 10730 - Train Loss: 0.000153 - Dev Loss: 0.604726\n",
            "Epoch 41 Iteration 10740 - Train Loss: 0.000137 - Dev Loss: 0.602126\n",
            "Epoch 41 Iteration 10750 - Train Loss: 0.000149 - Dev Loss: 0.603063\n",
            "Epoch 42 Iteration 10760 - Train Loss: 0.000141 - Dev Loss: 0.605910\n",
            "Epoch 42 Iteration 10770 - Train Loss: 0.000132 - Dev Loss: 0.607448\n",
            "Epoch 42 Iteration 10780 - Train Loss: 0.000130 - Dev Loss: 0.607476\n",
            "Epoch 42 Iteration 10790 - Train Loss: 0.000151 - Dev Loss: 0.606525\n",
            "Epoch 42 Iteration 10800 - Train Loss: 0.000136 - Dev Loss: 0.606933\n",
            "Epoch 42 Iteration 10810 - Train Loss: 0.000135 - Dev Loss: 0.607613\n",
            "Epoch 42 Iteration 10820 - Train Loss: 0.000128 - Dev Loss: 0.607508\n",
            "Epoch 42 Iteration 10830 - Train Loss: 0.000150 - Dev Loss: 0.607097\n",
            "Epoch 42 Iteration 10840 - Train Loss: 0.000140 - Dev Loss: 0.607307\n",
            "Epoch 42 Iteration 10850 - Train Loss: 0.000127 - Dev Loss: 0.607260\n",
            "Epoch 42 Iteration 10860 - Train Loss: 0.000150 - Dev Loss: 0.608066\n",
            "Epoch 42 Iteration 10870 - Train Loss: 0.000161 - Dev Loss: 0.610104\n",
            "Epoch 42 Iteration 10880 - Train Loss: 0.000135 - Dev Loss: 0.611637\n",
            "Epoch 42 Iteration 10890 - Train Loss: 0.000124 - Dev Loss: 0.611982\n",
            "Epoch 42 Iteration 10900 - Train Loss: 0.000128 - Dev Loss: 0.610329\n",
            "Epoch 42 Iteration 10910 - Train Loss: 0.000130 - Dev Loss: 0.609263\n",
            "Epoch 42 Iteration 10920 - Train Loss: 0.000114 - Dev Loss: 0.609277\n",
            "Epoch 42 Iteration 10930 - Train Loss: 0.000128 - Dev Loss: 0.610221\n",
            "Epoch 42 Iteration 10940 - Train Loss: 0.000126 - Dev Loss: 0.611956\n",
            "Epoch 42 Iteration 10950 - Train Loss: 0.000136 - Dev Loss: 0.612565\n",
            "Epoch 42 Iteration 10960 - Train Loss: 0.000162 - Dev Loss: 0.611066\n",
            "Epoch 42 Iteration 10970 - Train Loss: 0.000138 - Dev Loss: 0.610716\n",
            "Epoch 42 Iteration 10980 - Train Loss: 0.000121 - Dev Loss: 0.611012\n",
            "Epoch 42 Iteration 10990 - Train Loss: 0.000121 - Dev Loss: 0.610458\n",
            "Epoch 42 Iteration 11000 - Train Loss: 0.000138 - Dev Loss: 0.610213\n",
            "Epoch 43 Iteration 11010 - Train Loss: 0.000121 - Dev Loss: 0.610979\n",
            "Epoch 43 Iteration 11020 - Train Loss: 0.000100 - Dev Loss: 0.611696\n",
            "Epoch 43 Iteration 11030 - Train Loss: 0.000132 - Dev Loss: 0.612839\n",
            "Epoch 43 Iteration 11040 - Train Loss: 0.000117 - Dev Loss: 0.612636\n",
            "Epoch 43 Iteration 11050 - Train Loss: 0.000125 - Dev Loss: 0.611796\n",
            "Epoch 43 Iteration 11060 - Train Loss: 0.000120 - Dev Loss: 0.614928\n",
            "Epoch 43 Iteration 11070 - Train Loss: 0.000130 - Dev Loss: 0.615970\n",
            "Epoch 43 Iteration 11080 - Train Loss: 0.000126 - Dev Loss: 0.615230\n",
            "Epoch 43 Iteration 11090 - Train Loss: 0.000106 - Dev Loss: 0.615053\n",
            "Epoch 43 Iteration 11100 - Train Loss: 0.000108 - Dev Loss: 0.614684\n",
            "Epoch 43 Iteration 11110 - Train Loss: 0.000110 - Dev Loss: 0.615828\n",
            "Epoch 43 Iteration 11120 - Train Loss: 0.000121 - Dev Loss: 0.616412\n",
            "Epoch 43 Iteration 11130 - Train Loss: 0.000116 - Dev Loss: 0.613807\n",
            "Epoch 43 Iteration 11140 - Train Loss: 0.000113 - Dev Loss: 0.613794\n",
            "Epoch 43 Iteration 11150 - Train Loss: 0.000108 - Dev Loss: 0.616481\n",
            "Epoch 43 Iteration 11160 - Train Loss: 0.000126 - Dev Loss: 0.616323\n",
            "Epoch 43 Iteration 11170 - Train Loss: 0.000119 - Dev Loss: 0.616538\n",
            "Epoch 43 Iteration 11180 - Train Loss: 0.000119 - Dev Loss: 0.617734\n",
            "Epoch 43 Iteration 11190 - Train Loss: 0.000109 - Dev Loss: 0.618425\n",
            "Epoch 43 Iteration 11200 - Train Loss: 0.000119 - Dev Loss: 0.619506\n",
            "Epoch 43 Iteration 11210 - Train Loss: 0.000116 - Dev Loss: 0.618270\n",
            "Epoch 43 Iteration 11220 - Train Loss: 0.000112 - Dev Loss: 0.618108\n",
            "Epoch 43 Iteration 11230 - Train Loss: 0.000108 - Dev Loss: 0.617802\n",
            "Epoch 43 Iteration 11240 - Train Loss: 0.000115 - Dev Loss: 0.619787\n",
            "Epoch 43 Iteration 11250 - Train Loss: 0.000108 - Dev Loss: 0.620087\n",
            "Epoch 43 Iteration 11260 - Train Loss: 0.000139 - Dev Loss: 0.618875\n",
            "Epoch 44 Iteration 11270 - Train Loss: 0.000111 - Dev Loss: 0.618857\n",
            "Epoch 44 Iteration 11280 - Train Loss: 0.000092 - Dev Loss: 0.620537\n",
            "Epoch 44 Iteration 11290 - Train Loss: 0.000106 - Dev Loss: 0.621387\n",
            "Epoch 44 Iteration 11300 - Train Loss: 0.000088 - Dev Loss: 0.619471\n",
            "Epoch 44 Iteration 11310 - Train Loss: 0.000098 - Dev Loss: 0.619313\n",
            "Epoch 44 Iteration 11320 - Train Loss: 0.000095 - Dev Loss: 0.620080\n",
            "Epoch 44 Iteration 11330 - Train Loss: 0.000108 - Dev Loss: 0.622740\n",
            "Epoch 44 Iteration 11340 - Train Loss: 0.000104 - Dev Loss: 0.624223\n",
            "Epoch 44 Iteration 11350 - Train Loss: 0.000104 - Dev Loss: 0.626310\n",
            "Epoch 44 Iteration 11360 - Train Loss: 0.000099 - Dev Loss: 0.625109\n",
            "Epoch 44 Iteration 11370 - Train Loss: 0.000103 - Dev Loss: 0.621348\n",
            "Epoch 44 Iteration 11380 - Train Loss: 0.000091 - Dev Loss: 0.620776\n",
            "Epoch 44 Iteration 11390 - Train Loss: 0.000098 - Dev Loss: 0.622451\n",
            "Epoch 44 Iteration 11400 - Train Loss: 0.000093 - Dev Loss: 0.623617\n",
            "Epoch 44 Iteration 11410 - Train Loss: 0.000104 - Dev Loss: 0.622693\n",
            "Epoch 44 Iteration 11420 - Train Loss: 0.000087 - Dev Loss: 0.619932\n",
            "Epoch 44 Iteration 11430 - Train Loss: 0.000119 - Dev Loss: 0.620206\n",
            "Epoch 44 Iteration 11440 - Train Loss: 0.000103 - Dev Loss: 0.620982\n",
            "Epoch 44 Iteration 11450 - Train Loss: 0.000097 - Dev Loss: 0.621034\n",
            "Epoch 44 Iteration 11460 - Train Loss: 0.000106 - Dev Loss: 0.623330\n",
            "Epoch 44 Iteration 11470 - Train Loss: 0.000091 - Dev Loss: 0.623591\n",
            "Epoch 44 Iteration 11480 - Train Loss: 0.000100 - Dev Loss: 0.624227\n",
            "Epoch 44 Iteration 11490 - Train Loss: 0.000092 - Dev Loss: 0.624791\n",
            "Epoch 44 Iteration 11500 - Train Loss: 0.000103 - Dev Loss: 0.625836\n",
            "Epoch 44 Iteration 11510 - Train Loss: 0.000100 - Dev Loss: 0.627036\n",
            "Epoch 45 Iteration 11520 - Train Loss: 0.000137 - Dev Loss: 0.627867\n",
            "Epoch 45 Iteration 11530 - Train Loss: 0.000077 - Dev Loss: 0.628716\n",
            "Epoch 45 Iteration 11540 - Train Loss: 0.000090 - Dev Loss: 0.628933\n",
            "Epoch 45 Iteration 11550 - Train Loss: 0.000081 - Dev Loss: 0.627854\n",
            "Epoch 45 Iteration 11560 - Train Loss: 0.000090 - Dev Loss: 0.627657\n",
            "Epoch 45 Iteration 11570 - Train Loss: 0.000083 - Dev Loss: 0.627802\n",
            "Epoch 45 Iteration 11580 - Train Loss: 0.000083 - Dev Loss: 0.628508\n",
            "Epoch 45 Iteration 11590 - Train Loss: 0.000086 - Dev Loss: 0.627946\n",
            "Epoch 45 Iteration 11600 - Train Loss: 0.000082 - Dev Loss: 0.627773\n",
            "Epoch 45 Iteration 11610 - Train Loss: 0.000087 - Dev Loss: 0.627876\n",
            "Epoch 45 Iteration 11620 - Train Loss: 0.000092 - Dev Loss: 0.627690\n",
            "Epoch 45 Iteration 11630 - Train Loss: 0.000086 - Dev Loss: 0.627708\n",
            "Epoch 45 Iteration 11640 - Train Loss: 0.000081 - Dev Loss: 0.628019\n",
            "Epoch 45 Iteration 11650 - Train Loss: 0.000090 - Dev Loss: 0.627595\n",
            "Epoch 45 Iteration 11660 - Train Loss: 0.000093 - Dev Loss: 0.627285\n",
            "Epoch 45 Iteration 11670 - Train Loss: 0.000084 - Dev Loss: 0.627210\n",
            "Epoch 45 Iteration 11680 - Train Loss: 0.000095 - Dev Loss: 0.627087\n",
            "Epoch 45 Iteration 11690 - Train Loss: 0.000082 - Dev Loss: 0.630850\n",
            "Epoch 45 Iteration 11700 - Train Loss: 0.000098 - Dev Loss: 0.632566\n",
            "Epoch 45 Iteration 11710 - Train Loss: 0.000080 - Dev Loss: 0.630233\n",
            "Epoch 45 Iteration 11720 - Train Loss: 0.000086 - Dev Loss: 0.630330\n",
            "Epoch 45 Iteration 11730 - Train Loss: 0.000100 - Dev Loss: 0.631610\n",
            "Epoch 45 Iteration 11740 - Train Loss: 0.000088 - Dev Loss: 0.631645\n",
            "Epoch 45 Iteration 11750 - Train Loss: 0.000078 - Dev Loss: 0.633287\n",
            "Epoch 45 Iteration 11760 - Train Loss: 0.000094 - Dev Loss: 0.631924\n",
            "Epoch 45 Iteration 11770 - Train Loss: 0.000083 - Dev Loss: 0.631664\n",
            "Epoch 46 Iteration 11780 - Train Loss: 0.000082 - Dev Loss: 0.632253\n",
            "Epoch 46 Iteration 11790 - Train Loss: 0.000093 - Dev Loss: 0.632997\n",
            "Epoch 46 Iteration 11800 - Train Loss: 0.000068 - Dev Loss: 0.632489\n",
            "Epoch 46 Iteration 11810 - Train Loss: 0.000068 - Dev Loss: 0.632984\n",
            "Epoch 46 Iteration 11820 - Train Loss: 0.000081 - Dev Loss: 0.632077\n",
            "Epoch 46 Iteration 11830 - Train Loss: 0.000073 - Dev Loss: 0.632545\n",
            "Epoch 46 Iteration 11840 - Train Loss: 0.000072 - Dev Loss: 0.633648\n",
            "Epoch 46 Iteration 11850 - Train Loss: 0.000066 - Dev Loss: 0.633735\n",
            "Epoch 46 Iteration 11860 - Train Loss: 0.000084 - Dev Loss: 0.634278\n",
            "Epoch 46 Iteration 11870 - Train Loss: 0.000076 - Dev Loss: 0.634936\n",
            "Epoch 46 Iteration 11880 - Train Loss: 0.000072 - Dev Loss: 0.633553\n",
            "Epoch 46 Iteration 11890 - Train Loss: 0.000076 - Dev Loss: 0.633274\n",
            "Epoch 46 Iteration 11900 - Train Loss: 0.000086 - Dev Loss: 0.634152\n",
            "Epoch 46 Iteration 11910 - Train Loss: 0.000077 - Dev Loss: 0.637347\n",
            "Epoch 46 Iteration 11920 - Train Loss: 0.000066 - Dev Loss: 0.637121\n",
            "Epoch 46 Iteration 11930 - Train Loss: 0.000077 - Dev Loss: 0.637810\n",
            "Epoch 46 Iteration 11940 - Train Loss: 0.000071 - Dev Loss: 0.637717\n",
            "Epoch 46 Iteration 11950 - Train Loss: 0.000070 - Dev Loss: 0.637848\n",
            "Epoch 46 Iteration 11960 - Train Loss: 0.000071 - Dev Loss: 0.636606\n",
            "Epoch 46 Iteration 11970 - Train Loss: 0.000071 - Dev Loss: 0.636271\n",
            "Epoch 46 Iteration 11980 - Train Loss: 0.000074 - Dev Loss: 0.636531\n",
            "Epoch 46 Iteration 11990 - Train Loss: 0.000084 - Dev Loss: 0.638646\n",
            "Epoch 46 Iteration 12000 - Train Loss: 0.000074 - Dev Loss: 0.639931\n",
            "Epoch 46 Iteration 12010 - Train Loss: 0.000072 - Dev Loss: 0.639324\n",
            "Epoch 46 Iteration 12020 - Train Loss: 0.000081 - Dev Loss: 0.639700\n",
            "Epoch 46 Iteration 12030 - Train Loss: 0.000077 - Dev Loss: 0.638650\n",
            "Epoch 47 Iteration 12040 - Train Loss: 0.000064 - Dev Loss: 0.639136\n",
            "Epoch 47 Iteration 12050 - Train Loss: 0.000058 - Dev Loss: 0.639653\n",
            "Epoch 47 Iteration 12060 - Train Loss: 0.000072 - Dev Loss: 0.639733\n",
            "Epoch 47 Iteration 12070 - Train Loss: 0.000051 - Dev Loss: 0.640528\n",
            "Epoch 47 Iteration 12080 - Train Loss: 0.000061 - Dev Loss: 0.641395\n",
            "Epoch 47 Iteration 12090 - Train Loss: 0.000068 - Dev Loss: 0.640990\n",
            "Epoch 47 Iteration 12100 - Train Loss: 0.000055 - Dev Loss: 0.641034\n",
            "Epoch 47 Iteration 12110 - Train Loss: 0.000064 - Dev Loss: 0.640882\n",
            "Epoch 47 Iteration 12120 - Train Loss: 0.000068 - Dev Loss: 0.642232\n",
            "Epoch 47 Iteration 12130 - Train Loss: 0.000057 - Dev Loss: 0.642867\n",
            "Epoch 47 Iteration 12140 - Train Loss: 0.000066 - Dev Loss: 0.641991\n",
            "Epoch 47 Iteration 12150 - Train Loss: 0.000065 - Dev Loss: 0.639336\n",
            "Epoch 47 Iteration 12160 - Train Loss: 0.000077 - Dev Loss: 0.640512\n",
            "Epoch 47 Iteration 12170 - Train Loss: 0.000057 - Dev Loss: 0.641407\n",
            "Epoch 47 Iteration 12180 - Train Loss: 0.000060 - Dev Loss: 0.642403\n",
            "Epoch 47 Iteration 12190 - Train Loss: 0.000070 - Dev Loss: 0.641794\n",
            "Epoch 47 Iteration 12200 - Train Loss: 0.000069 - Dev Loss: 0.641901\n",
            "Epoch 47 Iteration 12210 - Train Loss: 0.000066 - Dev Loss: 0.642977\n",
            "Epoch 47 Iteration 12220 - Train Loss: 0.000065 - Dev Loss: 0.642059\n",
            "Epoch 47 Iteration 12230 - Train Loss: 0.000059 - Dev Loss: 0.641434\n",
            "Epoch 47 Iteration 12240 - Train Loss: 0.000060 - Dev Loss: 0.641866\n",
            "Epoch 47 Iteration 12250 - Train Loss: 0.000072 - Dev Loss: 0.642778\n",
            "Epoch 47 Iteration 12260 - Train Loss: 0.000076 - Dev Loss: 0.644889\n",
            "Epoch 47 Iteration 12270 - Train Loss: 0.000067 - Dev Loss: 0.644634\n",
            "Epoch 47 Iteration 12280 - Train Loss: 0.000072 - Dev Loss: 0.642641\n",
            "Epoch 48 Iteration 12290 - Train Loss: 0.000062 - Dev Loss: 0.644748\n",
            "Epoch 48 Iteration 12300 - Train Loss: 0.000058 - Dev Loss: 0.645159\n",
            "Epoch 48 Iteration 12310 - Train Loss: 0.000061 - Dev Loss: 0.644342\n",
            "Epoch 48 Iteration 12320 - Train Loss: 0.000055 - Dev Loss: 0.644710\n",
            "Epoch 48 Iteration 12330 - Train Loss: 0.000059 - Dev Loss: 0.644747\n",
            "Epoch 48 Iteration 12340 - Train Loss: 0.000052 - Dev Loss: 0.646281\n",
            "Epoch 48 Iteration 12350 - Train Loss: 0.000049 - Dev Loss: 0.647370\n",
            "Epoch 48 Iteration 12360 - Train Loss: 0.000056 - Dev Loss: 0.647115\n",
            "Epoch 48 Iteration 12370 - Train Loss: 0.000058 - Dev Loss: 0.647223\n",
            "Epoch 48 Iteration 12380 - Train Loss: 0.000050 - Dev Loss: 0.647113\n",
            "Epoch 48 Iteration 12390 - Train Loss: 0.000061 - Dev Loss: 0.647316\n",
            "Epoch 48 Iteration 12400 - Train Loss: 0.000054 - Dev Loss: 0.647204\n",
            "Epoch 48 Iteration 12410 - Train Loss: 0.000050 - Dev Loss: 0.648028\n",
            "Epoch 48 Iteration 12420 - Train Loss: 0.000055 - Dev Loss: 0.649080\n",
            "Epoch 48 Iteration 12430 - Train Loss: 0.000055 - Dev Loss: 0.650672\n",
            "Epoch 48 Iteration 12440 - Train Loss: 0.000055 - Dev Loss: 0.649705\n",
            "Epoch 48 Iteration 12450 - Train Loss: 0.000060 - Dev Loss: 0.650154\n",
            "Epoch 48 Iteration 12460 - Train Loss: 0.000057 - Dev Loss: 0.648799\n",
            "Epoch 48 Iteration 12470 - Train Loss: 0.000053 - Dev Loss: 0.647379\n",
            "Epoch 48 Iteration 12480 - Train Loss: 0.000056 - Dev Loss: 0.649050\n",
            "Epoch 48 Iteration 12490 - Train Loss: 0.000051 - Dev Loss: 0.651356\n",
            "Epoch 48 Iteration 12500 - Train Loss: 0.000059 - Dev Loss: 0.648089\n",
            "Epoch 48 Iteration 12510 - Train Loss: 0.000053 - Dev Loss: 0.649931\n",
            "Epoch 48 Iteration 12520 - Train Loss: 0.000057 - Dev Loss: 0.653527\n",
            "Epoch 48 Iteration 12530 - Train Loss: 0.000054 - Dev Loss: 0.652521\n",
            "Epoch 48 Iteration 12540 - Train Loss: 0.000059 - Dev Loss: 0.652501\n",
            "Epoch 49 Iteration 12550 - Train Loss: 0.000044 - Dev Loss: 0.653388\n",
            "Epoch 49 Iteration 12560 - Train Loss: 0.000047 - Dev Loss: 0.651746\n",
            "Epoch 49 Iteration 12570 - Train Loss: 0.000041 - Dev Loss: 0.651689\n",
            "Epoch 49 Iteration 12580 - Train Loss: 0.000052 - Dev Loss: 0.652905\n",
            "Epoch 49 Iteration 12590 - Train Loss: 0.000052 - Dev Loss: 0.655847\n",
            "Epoch 49 Iteration 12600 - Train Loss: 0.000048 - Dev Loss: 0.657059\n",
            "Epoch 49 Iteration 12610 - Train Loss: 0.000052 - Dev Loss: 0.656422\n",
            "Epoch 49 Iteration 12620 - Train Loss: 0.000047 - Dev Loss: 0.655889\n",
            "Epoch 49 Iteration 12630 - Train Loss: 0.000051 - Dev Loss: 0.655457\n",
            "Epoch 49 Iteration 12640 - Train Loss: 0.000050 - Dev Loss: 0.655358\n",
            "Epoch 49 Iteration 12650 - Train Loss: 0.000043 - Dev Loss: 0.653877\n",
            "Epoch 49 Iteration 12660 - Train Loss: 0.000042 - Dev Loss: 0.653891\n",
            "Epoch 49 Iteration 12670 - Train Loss: 0.000047 - Dev Loss: 0.654655\n",
            "Epoch 49 Iteration 12680 - Train Loss: 0.000052 - Dev Loss: 0.655180\n",
            "Epoch 49 Iteration 12690 - Train Loss: 0.000047 - Dev Loss: 0.655993\n",
            "Epoch 49 Iteration 12700 - Train Loss: 0.000047 - Dev Loss: 0.655859\n",
            "Epoch 49 Iteration 12710 - Train Loss: 0.000048 - Dev Loss: 0.656121\n",
            "Epoch 49 Iteration 12720 - Train Loss: 0.000044 - Dev Loss: 0.657948\n",
            "Epoch 49 Iteration 12730 - Train Loss: 0.000043 - Dev Loss: 0.657881\n",
            "Epoch 49 Iteration 12740 - Train Loss: 0.000050 - Dev Loss: 0.657766\n",
            "Epoch 49 Iteration 12750 - Train Loss: 0.000050 - Dev Loss: 0.657551\n",
            "Epoch 49 Iteration 12760 - Train Loss: 0.000055 - Dev Loss: 0.658490\n",
            "Epoch 49 Iteration 12770 - Train Loss: 0.000049 - Dev Loss: 0.657601\n",
            "Epoch 49 Iteration 12780 - Train Loss: 0.000050 - Dev Loss: 0.657223\n",
            "Epoch 49 Iteration 12790 - Train Loss: 0.000049 - Dev Loss: 0.657181\n",
            "Epoch 50 Iteration 12800 - Train Loss: 0.000050 - Dev Loss: 0.660169\n",
            "Epoch 50 Iteration 12810 - Train Loss: 0.000041 - Dev Loss: 0.660358\n",
            "Epoch 50 Iteration 12820 - Train Loss: 0.000042 - Dev Loss: 0.659654\n",
            "Epoch 50 Iteration 12830 - Train Loss: 0.000041 - Dev Loss: 0.662933\n",
            "Epoch 50 Iteration 12840 - Train Loss: 0.000041 - Dev Loss: 0.663151\n",
            "Epoch 50 Iteration 12850 - Train Loss: 0.000042 - Dev Loss: 0.660532\n",
            "Epoch 50 Iteration 12860 - Train Loss: 0.000038 - Dev Loss: 0.659734\n",
            "Epoch 50 Iteration 12870 - Train Loss: 0.000036 - Dev Loss: 0.660747\n",
            "Epoch 50 Iteration 12880 - Train Loss: 0.000041 - Dev Loss: 0.662148\n",
            "Epoch 50 Iteration 12890 - Train Loss: 0.000043 - Dev Loss: 0.662422\n",
            "Epoch 50 Iteration 12900 - Train Loss: 0.000048 - Dev Loss: 0.664285\n",
            "Epoch 50 Iteration 12910 - Train Loss: 0.000047 - Dev Loss: 0.662588\n",
            "Epoch 50 Iteration 12920 - Train Loss: 0.000044 - Dev Loss: 0.661660\n",
            "Epoch 50 Iteration 12930 - Train Loss: 0.000039 - Dev Loss: 0.661211\n",
            "Epoch 50 Iteration 12940 - Train Loss: 0.000047 - Dev Loss: 0.661346\n",
            "Epoch 50 Iteration 12950 - Train Loss: 0.000041 - Dev Loss: 0.661216\n",
            "Epoch 50 Iteration 12960 - Train Loss: 0.000041 - Dev Loss: 0.662474\n",
            "Epoch 50 Iteration 12970 - Train Loss: 0.000043 - Dev Loss: 0.664279\n",
            "Epoch 50 Iteration 12980 - Train Loss: 0.000038 - Dev Loss: 0.664984\n",
            "Epoch 50 Iteration 12990 - Train Loss: 0.000035 - Dev Loss: 0.665685\n",
            "Epoch 50 Iteration 13000 - Train Loss: 0.000043 - Dev Loss: 0.665467\n",
            "Epoch 50 Iteration 13010 - Train Loss: 0.000038 - Dev Loss: 0.663684\n",
            "Epoch 50 Iteration 13020 - Train Loss: 0.000037 - Dev Loss: 0.663213\n",
            "Epoch 50 Iteration 13030 - Train Loss: 0.000046 - Dev Loss: 0.663474\n",
            "Epoch 50 Iteration 13040 - Train Loss: 0.000046 - Dev Loss: 0.663494\n",
            "Epoch 50 Iteration 13050 - Train Loss: 0.000050 - Dev Loss: 0.663621\n",
            "Epoch 51 Iteration 13060 - Train Loss: 0.000035 - Dev Loss: 0.664168\n",
            "Epoch 51 Iteration 13070 - Train Loss: 0.000037 - Dev Loss: 0.665405\n",
            "Epoch 51 Iteration 13080 - Train Loss: 0.000037 - Dev Loss: 0.664825\n",
            "Epoch 51 Iteration 13090 - Train Loss: 0.000035 - Dev Loss: 0.664035\n",
            "Epoch 51 Iteration 13100 - Train Loss: 0.000034 - Dev Loss: 0.666571\n",
            "Epoch 51 Iteration 13110 - Train Loss: 0.000036 - Dev Loss: 0.670215\n",
            "Epoch 51 Iteration 13120 - Train Loss: 0.000039 - Dev Loss: 0.669548\n",
            "Epoch 51 Iteration 13130 - Train Loss: 0.000034 - Dev Loss: 0.667902\n",
            "Epoch 51 Iteration 13140 - Train Loss: 0.000032 - Dev Loss: 0.668429\n",
            "Epoch 51 Iteration 13150 - Train Loss: 0.000034 - Dev Loss: 0.668899\n",
            "Epoch 51 Iteration 13160 - Train Loss: 0.000037 - Dev Loss: 0.668358\n",
            "Epoch 51 Iteration 13170 - Train Loss: 0.000033 - Dev Loss: 0.668842\n",
            "Epoch 51 Iteration 13180 - Train Loss: 0.000037 - Dev Loss: 0.669056\n",
            "Epoch 51 Iteration 13190 - Train Loss: 0.000033 - Dev Loss: 0.668365\n",
            "Epoch 51 Iteration 13200 - Train Loss: 0.000041 - Dev Loss: 0.666574\n",
            "Epoch 51 Iteration 13210 - Train Loss: 0.000037 - Dev Loss: 0.665971\n",
            "Epoch 51 Iteration 13220 - Train Loss: 0.000035 - Dev Loss: 0.667791\n",
            "Epoch 51 Iteration 13230 - Train Loss: 0.000038 - Dev Loss: 0.668557\n",
            "Epoch 51 Iteration 13240 - Train Loss: 0.000041 - Dev Loss: 0.668386\n",
            "Epoch 51 Iteration 13250 - Train Loss: 0.000036 - Dev Loss: 0.668564\n",
            "Epoch 51 Iteration 13260 - Train Loss: 0.000037 - Dev Loss: 0.670571\n",
            "Epoch 51 Iteration 13270 - Train Loss: 0.000036 - Dev Loss: 0.672254\n",
            "Epoch 51 Iteration 13280 - Train Loss: 0.000042 - Dev Loss: 0.671550\n",
            "Epoch 51 Iteration 13290 - Train Loss: 0.000033 - Dev Loss: 0.670924\n",
            "Epoch 51 Iteration 13300 - Train Loss: 0.000037 - Dev Loss: 0.671962\n",
            "Epoch 51 Iteration 13310 - Train Loss: 0.000030 - Dev Loss: 0.671162\n",
            "Epoch 52 Iteration 13320 - Train Loss: 0.000034 - Dev Loss: 0.670719\n",
            "Epoch 52 Iteration 13330 - Train Loss: 0.000031 - Dev Loss: 0.671363\n",
            "Epoch 52 Iteration 13340 - Train Loss: 0.000031 - Dev Loss: 0.672338\n",
            "Epoch 52 Iteration 13350 - Train Loss: 0.000033 - Dev Loss: 0.672023\n",
            "Epoch 52 Iteration 13360 - Train Loss: 0.000031 - Dev Loss: 0.671460\n",
            "Epoch 52 Iteration 13370 - Train Loss: 0.000032 - Dev Loss: 0.671391\n",
            "Epoch 52 Iteration 13380 - Train Loss: 0.000032 - Dev Loss: 0.672052\n",
            "Epoch 52 Iteration 13390 - Train Loss: 0.000036 - Dev Loss: 0.674066\n",
            "Epoch 52 Iteration 13400 - Train Loss: 0.000030 - Dev Loss: 0.673968\n",
            "Epoch 52 Iteration 13410 - Train Loss: 0.000034 - Dev Loss: 0.672601\n",
            "Epoch 52 Iteration 13420 - Train Loss: 0.000032 - Dev Loss: 0.674448\n",
            "Epoch 52 Iteration 13430 - Train Loss: 0.000033 - Dev Loss: 0.674778\n",
            "Epoch 52 Iteration 13440 - Train Loss: 0.000030 - Dev Loss: 0.673564\n",
            "Epoch 52 Iteration 13450 - Train Loss: 0.000030 - Dev Loss: 0.673197\n",
            "Epoch 52 Iteration 13460 - Train Loss: 0.000027 - Dev Loss: 0.673924\n",
            "Epoch 52 Iteration 13470 - Train Loss: 0.000028 - Dev Loss: 0.675003\n",
            "Epoch 52 Iteration 13480 - Train Loss: 0.000032 - Dev Loss: 0.673482\n",
            "Epoch 52 Iteration 13490 - Train Loss: 0.000029 - Dev Loss: 0.674069\n",
            "Epoch 52 Iteration 13500 - Train Loss: 0.000028 - Dev Loss: 0.675603\n",
            "Epoch 52 Iteration 13510 - Train Loss: 0.000032 - Dev Loss: 0.675008\n",
            "Epoch 52 Iteration 13520 - Train Loss: 0.000032 - Dev Loss: 0.675648\n",
            "Epoch 52 Iteration 13530 - Train Loss: 0.000034 - Dev Loss: 0.677760\n",
            "Epoch 52 Iteration 13540 - Train Loss: 0.000031 - Dev Loss: 0.678376\n",
            "Epoch 52 Iteration 13550 - Train Loss: 0.000032 - Dev Loss: 0.675518\n",
            "Epoch 52 Iteration 13560 - Train Loss: 0.000027 - Dev Loss: 0.676882\n",
            "Epoch 53 Iteration 13570 - Train Loss: 0.000034 - Dev Loss: 0.679624\n",
            "Epoch 53 Iteration 13580 - Train Loss: 0.000027 - Dev Loss: 0.681532\n",
            "Epoch 53 Iteration 13590 - Train Loss: 0.000027 - Dev Loss: 0.680218\n",
            "Epoch 53 Iteration 13600 - Train Loss: 0.000027 - Dev Loss: 0.679990\n",
            "Epoch 53 Iteration 13610 - Train Loss: 0.000026 - Dev Loss: 0.680733\n",
            "Epoch 53 Iteration 13620 - Train Loss: 0.000029 - Dev Loss: 0.680790\n",
            "Epoch 53 Iteration 13630 - Train Loss: 0.000030 - Dev Loss: 0.679335\n",
            "Epoch 53 Iteration 13640 - Train Loss: 0.000028 - Dev Loss: 0.679744\n",
            "Epoch 53 Iteration 13650 - Train Loss: 0.000028 - Dev Loss: 0.680083\n",
            "Epoch 53 Iteration 13660 - Train Loss: 0.000030 - Dev Loss: 0.682569\n",
            "Epoch 53 Iteration 13670 - Train Loss: 0.000029 - Dev Loss: 0.682609\n",
            "Epoch 53 Iteration 13680 - Train Loss: 0.000026 - Dev Loss: 0.680701\n",
            "Epoch 53 Iteration 13690 - Train Loss: 0.000026 - Dev Loss: 0.680325\n",
            "Epoch 53 Iteration 13700 - Train Loss: 0.000026 - Dev Loss: 0.681764\n",
            "Epoch 53 Iteration 13710 - Train Loss: 0.000029 - Dev Loss: 0.682747\n",
            "Epoch 53 Iteration 13720 - Train Loss: 0.000022 - Dev Loss: 0.681606\n",
            "Epoch 53 Iteration 13730 - Train Loss: 0.000025 - Dev Loss: 0.681983\n",
            "Epoch 53 Iteration 13740 - Train Loss: 0.000030 - Dev Loss: 0.684172\n",
            "Epoch 53 Iteration 13750 - Train Loss: 0.000029 - Dev Loss: 0.682890\n",
            "Epoch 53 Iteration 13760 - Train Loss: 0.000024 - Dev Loss: 0.682153\n",
            "Epoch 53 Iteration 13770 - Train Loss: 0.000026 - Dev Loss: 0.685078\n",
            "Epoch 53 Iteration 13780 - Train Loss: 0.000030 - Dev Loss: 0.686367\n",
            "Epoch 53 Iteration 13790 - Train Loss: 0.000028 - Dev Loss: 0.682728\n",
            "Epoch 53 Iteration 13800 - Train Loss: 0.000027 - Dev Loss: 0.683885\n",
            "Epoch 53 Iteration 13810 - Train Loss: 0.000027 - Dev Loss: 0.687600\n",
            "Epoch 53 Iteration 13820 - Train Loss: 0.000029 - Dev Loss: 0.686038\n",
            "Epoch 54 Iteration 13830 - Train Loss: 0.000024 - Dev Loss: 0.683202\n",
            "Epoch 54 Iteration 13840 - Train Loss: 0.000024 - Dev Loss: 0.685898\n",
            "Epoch 54 Iteration 13850 - Train Loss: 0.000024 - Dev Loss: 0.685408\n",
            "Epoch 54 Iteration 13860 - Train Loss: 0.000025 - Dev Loss: 0.684530\n",
            "Epoch 54 Iteration 13870 - Train Loss: 0.000024 - Dev Loss: 0.684546\n",
            "Epoch 54 Iteration 13880 - Train Loss: 0.000021 - Dev Loss: 0.684895\n",
            "Epoch 54 Iteration 13890 - Train Loss: 0.000023 - Dev Loss: 0.685240\n",
            "Epoch 54 Iteration 13900 - Train Loss: 0.000023 - Dev Loss: 0.684307\n",
            "Epoch 54 Iteration 13910 - Train Loss: 0.000029 - Dev Loss: 0.684706\n",
            "Epoch 54 Iteration 13920 - Train Loss: 0.000029 - Dev Loss: 0.685735\n",
            "Epoch 54 Iteration 13930 - Train Loss: 0.000023 - Dev Loss: 0.688024\n",
            "Epoch 54 Iteration 13940 - Train Loss: 0.000023 - Dev Loss: 0.688141\n",
            "Epoch 54 Iteration 13950 - Train Loss: 0.000024 - Dev Loss: 0.687778\n",
            "Epoch 54 Iteration 13960 - Train Loss: 0.000024 - Dev Loss: 0.688973\n",
            "Epoch 54 Iteration 13970 - Train Loss: 0.000023 - Dev Loss: 0.687200\n",
            "Epoch 54 Iteration 13980 - Train Loss: 0.000023 - Dev Loss: 0.687157\n",
            "Epoch 54 Iteration 13990 - Train Loss: 0.000025 - Dev Loss: 0.689203\n",
            "Epoch 54 Iteration 14000 - Train Loss: 0.000021 - Dev Loss: 0.690195\n",
            "Epoch 54 Iteration 14010 - Train Loss: 0.000024 - Dev Loss: 0.691166\n",
            "Epoch 54 Iteration 14020 - Train Loss: 0.000025 - Dev Loss: 0.689511\n",
            "Epoch 54 Iteration 14030 - Train Loss: 0.000023 - Dev Loss: 0.690526\n",
            "Epoch 54 Iteration 14040 - Train Loss: 0.000026 - Dev Loss: 0.691727\n",
            "Epoch 54 Iteration 14050 - Train Loss: 0.000021 - Dev Loss: 0.691562\n",
            "Epoch 54 Iteration 14060 - Train Loss: 0.000023 - Dev Loss: 0.689939\n",
            "Epoch 54 Iteration 14070 - Train Loss: 0.000023 - Dev Loss: 0.691817\n",
            "Epoch 55 Iteration 14080 - Train Loss: 0.000025 - Dev Loss: 0.691052\n",
            "Epoch 55 Iteration 14090 - Train Loss: 0.000019 - Dev Loss: 0.688958\n",
            "Epoch 55 Iteration 14100 - Train Loss: 0.000023 - Dev Loss: 0.693197\n",
            "Epoch 55 Iteration 14110 - Train Loss: 0.000021 - Dev Loss: 0.694966\n",
            "Epoch 55 Iteration 14120 - Train Loss: 0.000020 - Dev Loss: 0.691738\n",
            "Epoch 55 Iteration 14130 - Train Loss: 0.000019 - Dev Loss: 0.690782\n",
            "Epoch 55 Iteration 14140 - Train Loss: 0.000022 - Dev Loss: 0.691614\n",
            "Epoch 55 Iteration 14150 - Train Loss: 0.000019 - Dev Loss: 0.693129\n",
            "Epoch 55 Iteration 14160 - Train Loss: 0.000018 - Dev Loss: 0.693444\n",
            "Epoch 55 Iteration 14170 - Train Loss: 0.000019 - Dev Loss: 0.691507\n",
            "Epoch 55 Iteration 14180 - Train Loss: 0.000018 - Dev Loss: 0.691202\n",
            "Epoch 55 Iteration 14190 - Train Loss: 0.000016 - Dev Loss: 0.694663\n",
            "Epoch 55 Iteration 14200 - Train Loss: 0.000019 - Dev Loss: 0.695302\n",
            "Epoch 55 Iteration 14210 - Train Loss: 0.000020 - Dev Loss: 0.693531\n",
            "Epoch 55 Iteration 14220 - Train Loss: 0.000022 - Dev Loss: 0.694360\n",
            "Epoch 55 Iteration 14230 - Train Loss: 0.000021 - Dev Loss: 0.695962\n",
            "Epoch 55 Iteration 14240 - Train Loss: 0.000021 - Dev Loss: 0.697438\n",
            "Epoch 55 Iteration 14250 - Train Loss: 0.000020 - Dev Loss: 0.696585\n",
            "Epoch 55 Iteration 14260 - Train Loss: 0.000023 - Dev Loss: 0.696705\n",
            "Epoch 55 Iteration 14270 - Train Loss: 0.000020 - Dev Loss: 0.697300\n",
            "Epoch 55 Iteration 14280 - Train Loss: 0.000025 - Dev Loss: 0.697485\n",
            "Epoch 55 Iteration 14290 - Train Loss: 0.000022 - Dev Loss: 0.696816\n",
            "Epoch 55 Iteration 14300 - Train Loss: 0.000024 - Dev Loss: 0.696252\n",
            "Epoch 55 Iteration 14310 - Train Loss: 0.000021 - Dev Loss: 0.696416\n",
            "Epoch 55 Iteration 14320 - Train Loss: 0.000018 - Dev Loss: 0.696772\n",
            "Epoch 55 Iteration 14330 - Train Loss: 0.000022 - Dev Loss: 0.698476\n",
            "Epoch 56 Iteration 14340 - Train Loss: 0.000020 - Dev Loss: 0.696319\n",
            "Epoch 56 Iteration 14350 - Train Loss: 0.000016 - Dev Loss: 0.695395\n",
            "Epoch 56 Iteration 14360 - Train Loss: 0.000020 - Dev Loss: 0.694459\n",
            "Epoch 56 Iteration 14370 - Train Loss: 0.000018 - Dev Loss: 0.695393\n",
            "Epoch 56 Iteration 14380 - Train Loss: 0.000016 - Dev Loss: 0.697458\n",
            "Epoch 56 Iteration 14390 - Train Loss: 0.000019 - Dev Loss: 0.696397\n",
            "Epoch 56 Iteration 14400 - Train Loss: 0.000015 - Dev Loss: 0.696347\n",
            "Epoch 56 Iteration 14410 - Train Loss: 0.000019 - Dev Loss: 0.697247\n",
            "Epoch 56 Iteration 14420 - Train Loss: 0.000018 - Dev Loss: 0.698838\n",
            "Epoch 56 Iteration 14430 - Train Loss: 0.000016 - Dev Loss: 0.699710\n",
            "Epoch 56 Iteration 14440 - Train Loss: 0.000018 - Dev Loss: 0.701013\n",
            "Epoch 56 Iteration 14450 - Train Loss: 0.000020 - Dev Loss: 0.700917\n",
            "Epoch 56 Iteration 14460 - Train Loss: 0.000020 - Dev Loss: 0.715522\n",
            "Epoch 56 Iteration 14470 - Train Loss: 0.000346 - Dev Loss: 0.700385\n",
            "Epoch 56 Iteration 14480 - Train Loss: 0.008376 - Dev Loss: 0.712541\n",
            "Epoch 56 Iteration 14490 - Train Loss: 0.034733 - Dev Loss: 0.694859\n",
            "Epoch 56 Iteration 14500 - Train Loss: 0.023860 - Dev Loss: 0.744603\n",
            "Epoch 56 Iteration 14510 - Train Loss: 0.015763 - Dev Loss: 0.701962\n",
            "Epoch 56 Iteration 14520 - Train Loss: 0.014704 - Dev Loss: 0.733918\n",
            "Epoch 56 Iteration 14530 - Train Loss: 0.016526 - Dev Loss: 0.698761\n",
            "Epoch 56 Iteration 14540 - Train Loss: 0.016760 - Dev Loss: 0.702582\n",
            "Epoch 56 Iteration 14550 - Train Loss: 0.010385 - Dev Loss: 0.669472\n",
            "Epoch 56 Iteration 14560 - Train Loss: 0.010956 - Dev Loss: 0.660440\n",
            "Epoch 56 Iteration 14570 - Train Loss: 0.013905 - Dev Loss: 0.665186\n",
            "Epoch 56 Iteration 14580 - Train Loss: 0.013322 - Dev Loss: 0.639107\n",
            "Epoch 56 Iteration 14590 - Train Loss: 0.007876 - Dev Loss: 0.691157\n",
            "Epoch 57 Iteration 14600 - Train Loss: 0.009402 - Dev Loss: 0.652081\n",
            "Epoch 57 Iteration 14610 - Train Loss: 0.007593 - Dev Loss: 0.652756\n",
            "Epoch 57 Iteration 14620 - Train Loss: 0.008573 - Dev Loss: 0.640240\n",
            "Epoch 57 Iteration 14630 - Train Loss: 0.004251 - Dev Loss: 0.632672\n",
            "Epoch 57 Iteration 14640 - Train Loss: 0.004906 - Dev Loss: 0.638907\n",
            "Epoch 57 Iteration 14650 - Train Loss: 0.003836 - Dev Loss: 0.644909\n",
            "Epoch 57 Iteration 14660 - Train Loss: 0.005936 - Dev Loss: 0.638435\n",
            "Epoch 57 Iteration 14670 - Train Loss: 0.002765 - Dev Loss: 0.642167\n",
            "Epoch 57 Iteration 14680 - Train Loss: 0.004849 - Dev Loss: 0.640224\n",
            "Epoch 57 Iteration 14690 - Train Loss: 0.002097 - Dev Loss: 0.636397\n",
            "Epoch 57 Iteration 14700 - Train Loss: 0.004965 - Dev Loss: 0.634107\n",
            "Epoch 57 Iteration 14710 - Train Loss: 0.007945 - Dev Loss: 0.642903\n",
            "Epoch 57 Iteration 14720 - Train Loss: 0.006033 - Dev Loss: 0.644478\n",
            "Epoch 57 Iteration 14730 - Train Loss: 0.006417 - Dev Loss: 0.651356\n",
            "Epoch 57 Iteration 14740 - Train Loss: 0.007059 - Dev Loss: 0.666051\n",
            "Epoch 57 Iteration 14750 - Train Loss: 0.005321 - Dev Loss: 0.655153\n",
            "Epoch 57 Iteration 14760 - Train Loss: 0.006984 - Dev Loss: 0.645987\n",
            "Epoch 57 Iteration 14770 - Train Loss: 0.005737 - Dev Loss: 0.640378\n",
            "Epoch 57 Iteration 14780 - Train Loss: 0.003475 - Dev Loss: 0.644836\n",
            "Epoch 57 Iteration 14790 - Train Loss: 0.004690 - Dev Loss: 0.633838\n",
            "Epoch 57 Iteration 14800 - Train Loss: 0.002800 - Dev Loss: 0.638351\n",
            "Epoch 57 Iteration 14810 - Train Loss: 0.001668 - Dev Loss: 0.639917\n",
            "Epoch 57 Iteration 14820 - Train Loss: 0.002925 - Dev Loss: 0.633301\n",
            "Epoch 57 Iteration 14830 - Train Loss: 0.002899 - Dev Loss: 0.634582\n",
            "Epoch 57 Iteration 14840 - Train Loss: 0.002349 - Dev Loss: 0.640150\n",
            "Epoch 58 Iteration 14850 - Train Loss: 0.002047 - Dev Loss: 0.643404\n",
            "Epoch 58 Iteration 14860 - Train Loss: 0.001597 - Dev Loss: 0.645034\n",
            "Epoch 58 Iteration 14870 - Train Loss: 0.000770 - Dev Loss: 0.646530\n",
            "Epoch 58 Iteration 14880 - Train Loss: 0.000940 - Dev Loss: 0.639395\n",
            "Epoch 58 Iteration 14890 - Train Loss: 0.000521 - Dev Loss: 0.638182\n",
            "Epoch 58 Iteration 14900 - Train Loss: 0.000377 - Dev Loss: 0.636921\n",
            "Epoch 58 Iteration 14910 - Train Loss: 0.002086 - Dev Loss: 0.643388\n",
            "Epoch 58 Iteration 14920 - Train Loss: 0.001515 - Dev Loss: 0.640387\n",
            "Epoch 58 Iteration 14930 - Train Loss: 0.000603 - Dev Loss: 0.635661\n",
            "Epoch 58 Iteration 14940 - Train Loss: 0.000381 - Dev Loss: 0.635262\n",
            "Epoch 58 Iteration 14950 - Train Loss: 0.000608 - Dev Loss: 0.635017\n",
            "Epoch 58 Iteration 14960 - Train Loss: 0.000755 - Dev Loss: 0.633600\n",
            "Epoch 58 Iteration 14970 - Train Loss: 0.000746 - Dev Loss: 0.631809\n",
            "Epoch 58 Iteration 14980 - Train Loss: 0.000608 - Dev Loss: 0.632146\n",
            "Epoch 58 Iteration 14990 - Train Loss: 0.000386 - Dev Loss: 0.633095\n",
            "Epoch 58 Iteration 15000 - Train Loss: 0.000609 - Dev Loss: 0.635292\n",
            "Epoch 58 Iteration 15010 - Train Loss: 0.000587 - Dev Loss: 0.634801\n",
            "Epoch 58 Iteration 15020 - Train Loss: 0.000389 - Dev Loss: 0.633499\n",
            "Epoch 58 Iteration 15030 - Train Loss: 0.000838 - Dev Loss: 0.630471\n",
            "Epoch 58 Iteration 15040 - Train Loss: 0.001051 - Dev Loss: 0.630098\n",
            "Epoch 58 Iteration 15050 - Train Loss: 0.000479 - Dev Loss: 0.632075\n",
            "Epoch 58 Iteration 15060 - Train Loss: 0.000374 - Dev Loss: 0.632059\n",
            "Epoch 58 Iteration 15070 - Train Loss: 0.000484 - Dev Loss: 0.631592\n",
            "Epoch 58 Iteration 15080 - Train Loss: 0.000549 - Dev Loss: 0.634203\n",
            "Epoch 58 Iteration 15090 - Train Loss: 0.000764 - Dev Loss: 0.636512\n",
            "Epoch 58 Iteration 15100 - Train Loss: 0.000279 - Dev Loss: 0.638560\n",
            "Epoch 59 Iteration 15110 - Train Loss: 0.000221 - Dev Loss: 0.638651\n",
            "Epoch 59 Iteration 15120 - Train Loss: 0.000205 - Dev Loss: 0.638442\n",
            "Epoch 59 Iteration 15130 - Train Loss: 0.000168 - Dev Loss: 0.637985\n",
            "Epoch 59 Iteration 15140 - Train Loss: 0.000178 - Dev Loss: 0.637598\n",
            "Epoch 59 Iteration 15150 - Train Loss: 0.003502 - Dev Loss: 0.639193\n",
            "Epoch 59 Iteration 15160 - Train Loss: 0.000235 - Dev Loss: 0.640678\n",
            "Epoch 59 Iteration 15170 - Train Loss: 0.000570 - Dev Loss: 0.640290\n",
            "Epoch 59 Iteration 15180 - Train Loss: 0.000163 - Dev Loss: 0.638277\n",
            "Epoch 59 Iteration 15190 - Train Loss: 0.000269 - Dev Loss: 0.637580\n",
            "Epoch 59 Iteration 15200 - Train Loss: 0.000154 - Dev Loss: 0.637121\n",
            "Epoch 59 Iteration 15210 - Train Loss: 0.000371 - Dev Loss: 0.636928\n",
            "Epoch 59 Iteration 15220 - Train Loss: 0.000175 - Dev Loss: 0.636973\n",
            "Epoch 59 Iteration 15230 - Train Loss: 0.000163 - Dev Loss: 0.637239\n",
            "Epoch 59 Iteration 15240 - Train Loss: 0.000184 - Dev Loss: 0.637556\n",
            "Epoch 59 Iteration 15250 - Train Loss: 0.000189 - Dev Loss: 0.637583\n",
            "Epoch 59 Iteration 15260 - Train Loss: 0.000180 - Dev Loss: 0.637225\n",
            "Epoch 59 Iteration 15270 - Train Loss: 0.000200 - Dev Loss: 0.637137\n",
            "Epoch 59 Iteration 15280 - Train Loss: 0.000182 - Dev Loss: 0.636821\n",
            "Epoch 59 Iteration 15290 - Train Loss: 0.000175 - Dev Loss: 0.636895\n",
            "Epoch 59 Iteration 15300 - Train Loss: 0.000121 - Dev Loss: 0.637080\n",
            "Epoch 59 Iteration 15310 - Train Loss: 0.000135 - Dev Loss: 0.637258\n",
            "Epoch 59 Iteration 15320 - Train Loss: 0.000126 - Dev Loss: 0.637223\n",
            "Epoch 59 Iteration 15330 - Train Loss: 0.000330 - Dev Loss: 0.637450\n",
            "Epoch 59 Iteration 15340 - Train Loss: 0.000128 - Dev Loss: 0.637963\n",
            "Epoch 59 Iteration 15350 - Train Loss: 0.000135 - Dev Loss: 0.637917\n",
            "Epoch 60 Iteration 15360 - Train Loss: 0.000142 - Dev Loss: 0.637582\n",
            "Epoch 60 Iteration 15370 - Train Loss: 0.000097 - Dev Loss: 0.637335\n",
            "Epoch 60 Iteration 15380 - Train Loss: 0.000117 - Dev Loss: 0.637317\n",
            "Epoch 60 Iteration 15390 - Train Loss: 0.000119 - Dev Loss: 0.637329\n",
            "Epoch 60 Iteration 15400 - Train Loss: 0.000122 - Dev Loss: 0.637365\n",
            "Epoch 60 Iteration 15410 - Train Loss: 0.000084 - Dev Loss: 0.637413\n",
            "Epoch 60 Iteration 15420 - Train Loss: 0.000133 - Dev Loss: 0.637336\n",
            "Epoch 60 Iteration 15430 - Train Loss: 0.000116 - Dev Loss: 0.637373\n",
            "Epoch 60 Iteration 15440 - Train Loss: 0.000131 - Dev Loss: 0.637382\n",
            "Epoch 60 Iteration 15450 - Train Loss: 0.000110 - Dev Loss: 0.637453\n",
            "Epoch 60 Iteration 15460 - Train Loss: 0.000105 - Dev Loss: 0.637485\n",
            "Epoch 60 Iteration 15470 - Train Loss: 0.000092 - Dev Loss: 0.637435\n",
            "Epoch 60 Iteration 15480 - Train Loss: 0.000115 - Dev Loss: 0.637600\n",
            "Epoch 60 Iteration 15490 - Train Loss: 0.000115 - Dev Loss: 0.637532\n",
            "Epoch 60 Iteration 15500 - Train Loss: 0.000093 - Dev Loss: 0.637391\n",
            "Epoch 60 Iteration 15510 - Train Loss: 0.000104 - Dev Loss: 0.637325\n",
            "Epoch 60 Iteration 15520 - Train Loss: 0.000110 - Dev Loss: 0.637332\n",
            "Epoch 60 Iteration 15530 - Train Loss: 0.000124 - Dev Loss: 0.637386\n",
            "Epoch 60 Iteration 15540 - Train Loss: 0.000101 - Dev Loss: 0.637512\n",
            "Epoch 60 Iteration 15550 - Train Loss: 0.000123 - Dev Loss: 0.637279\n",
            "Epoch 60 Iteration 15560 - Train Loss: 0.000082 - Dev Loss: 0.637058\n",
            "Epoch 60 Iteration 15570 - Train Loss: 0.000093 - Dev Loss: 0.636951\n",
            "Epoch 60 Iteration 15580 - Train Loss: 0.000091 - Dev Loss: 0.636940\n",
            "Epoch 60 Iteration 15590 - Train Loss: 0.000104 - Dev Loss: 0.636912\n",
            "Epoch 60 Iteration 15600 - Train Loss: 0.000103 - Dev Loss: 0.637126\n",
            "Epoch 60 Iteration 15610 - Train Loss: 0.000095 - Dev Loss: 0.637195\n",
            "Epoch 61 Iteration 15620 - Train Loss: 0.000108 - Dev Loss: 0.637087\n",
            "Epoch 61 Iteration 15630 - Train Loss: 0.000077 - Dev Loss: 0.637107\n",
            "Epoch 61 Iteration 15640 - Train Loss: 0.000084 - Dev Loss: 0.637080\n",
            "Epoch 61 Iteration 15650 - Train Loss: 0.000090 - Dev Loss: 0.637136\n",
            "Epoch 61 Iteration 15660 - Train Loss: 0.000082 - Dev Loss: 0.637187\n",
            "Epoch 61 Iteration 15670 - Train Loss: 0.000088 - Dev Loss: 0.637292\n",
            "Epoch 61 Iteration 15680 - Train Loss: 0.000077 - Dev Loss: 0.637218\n",
            "Epoch 61 Iteration 15690 - Train Loss: 0.000089 - Dev Loss: 0.637259\n",
            "Epoch 61 Iteration 15700 - Train Loss: 0.000085 - Dev Loss: 0.637294\n",
            "Epoch 61 Iteration 15710 - Train Loss: 0.000083 - Dev Loss: 0.637305\n",
            "Epoch 61 Iteration 15720 - Train Loss: 0.000089 - Dev Loss: 0.637389\n",
            "Epoch 61 Iteration 15730 - Train Loss: 0.000097 - Dev Loss: 0.637601\n",
            "Epoch 61 Iteration 15740 - Train Loss: 0.000084 - Dev Loss: 0.637795\n",
            "Epoch 61 Iteration 15750 - Train Loss: 0.000081 - Dev Loss: 0.637866\n",
            "Epoch 61 Iteration 15760 - Train Loss: 0.000099 - Dev Loss: 0.637872\n",
            "Epoch 61 Iteration 15770 - Train Loss: 0.000082 - Dev Loss: 0.637903\n",
            "Epoch 61 Iteration 15780 - Train Loss: 0.000104 - Dev Loss: 0.638013\n",
            "Epoch 61 Iteration 15790 - Train Loss: 0.000101 - Dev Loss: 0.638004\n",
            "Epoch 61 Iteration 15800 - Train Loss: 0.000089 - Dev Loss: 0.637891\n",
            "Epoch 61 Iteration 15810 - Train Loss: 0.000083 - Dev Loss: 0.637990\n",
            "Epoch 61 Iteration 15820 - Train Loss: 0.000085 - Dev Loss: 0.638058\n",
            "Epoch 61 Iteration 15830 - Train Loss: 0.000094 - Dev Loss: 0.638049\n",
            "Epoch 61 Iteration 15840 - Train Loss: 0.000072 - Dev Loss: 0.638056\n",
            "Epoch 61 Iteration 15850 - Train Loss: 0.000086 - Dev Loss: 0.638110\n",
            "Epoch 61 Iteration 15860 - Train Loss: 0.000091 - Dev Loss: 0.638052\n",
            "Epoch 61 Iteration 15870 - Train Loss: 0.000088 - Dev Loss: 0.637896\n",
            "Epoch 62 Iteration 15880 - Train Loss: 0.000082 - Dev Loss: 0.637877\n",
            "Epoch 62 Iteration 15890 - Train Loss: 0.000075 - Dev Loss: 0.637893\n",
            "Epoch 62 Iteration 15900 - Train Loss: 0.000084 - Dev Loss: 0.637910\n",
            "Epoch 62 Iteration 15910 - Train Loss: 0.000078 - Dev Loss: 0.638017\n",
            "Epoch 62 Iteration 15920 - Train Loss: 0.000069 - Dev Loss: 0.638074\n",
            "Epoch 62 Iteration 15930 - Train Loss: 0.000080 - Dev Loss: 0.638255\n",
            "Epoch 62 Iteration 15940 - Train Loss: 0.000065 - Dev Loss: 0.638360\n",
            "Epoch 62 Iteration 15950 - Train Loss: 0.000083 - Dev Loss: 0.638467\n",
            "Epoch 62 Iteration 15960 - Train Loss: 0.000080 - Dev Loss: 0.638597\n",
            "Epoch 62 Iteration 15970 - Train Loss: 0.000069 - Dev Loss: 0.638597\n",
            "Epoch 62 Iteration 15980 - Train Loss: 0.000080 - Dev Loss: 0.638610\n",
            "Epoch 62 Iteration 15990 - Train Loss: 0.000071 - Dev Loss: 0.638701\n",
            "Epoch 62 Iteration 16000 - Train Loss: 0.000076 - Dev Loss: 0.638755\n",
            "Epoch 62 Iteration 16010 - Train Loss: 0.000087 - Dev Loss: 0.638670\n",
            "Epoch 62 Iteration 16020 - Train Loss: 0.000082 - Dev Loss: 0.638553\n",
            "Epoch 62 Iteration 16030 - Train Loss: 0.000076 - Dev Loss: 0.638489\n",
            "Epoch 62 Iteration 16040 - Train Loss: 0.000080 - Dev Loss: 0.638593\n",
            "Epoch 62 Iteration 16050 - Train Loss: 0.000075 - Dev Loss: 0.638665\n",
            "Epoch 62 Iteration 16060 - Train Loss: 0.000062 - Dev Loss: 0.638633\n",
            "Epoch 62 Iteration 16070 - Train Loss: 0.000066 - Dev Loss: 0.638742\n",
            "Epoch 62 Iteration 16080 - Train Loss: 0.000074 - Dev Loss: 0.638904\n",
            "Epoch 62 Iteration 16090 - Train Loss: 0.000067 - Dev Loss: 0.638915\n",
            "Epoch 62 Iteration 16100 - Train Loss: 0.000074 - Dev Loss: 0.638907\n",
            "Epoch 62 Iteration 16110 - Train Loss: 0.000076 - Dev Loss: 0.638887\n",
            "Epoch 62 Iteration 16120 - Train Loss: 0.000077 - Dev Loss: 0.638960\n",
            "Epoch 63 Iteration 16130 - Train Loss: 0.000067 - Dev Loss: 0.638968\n",
            "Epoch 63 Iteration 16140 - Train Loss: 0.000070 - Dev Loss: 0.638921\n",
            "Epoch 63 Iteration 16150 - Train Loss: 0.000064 - Dev Loss: 0.638966\n",
            "Epoch 63 Iteration 16160 - Train Loss: 0.000065 - Dev Loss: 0.639077\n",
            "Epoch 63 Iteration 16170 - Train Loss: 0.000077 - Dev Loss: 0.639145\n",
            "Epoch 63 Iteration 16180 - Train Loss: 0.000065 - Dev Loss: 0.639198\n",
            "Epoch 63 Iteration 16190 - Train Loss: 0.000079 - Dev Loss: 0.639233\n",
            "Epoch 63 Iteration 16200 - Train Loss: 0.000067 - Dev Loss: 0.639206\n",
            "Epoch 63 Iteration 16210 - Train Loss: 0.000069 - Dev Loss: 0.639092\n",
            "Epoch 63 Iteration 16220 - Train Loss: 0.000077 - Dev Loss: 0.639081\n",
            "Epoch 63 Iteration 16230 - Train Loss: 0.000065 - Dev Loss: 0.639108\n",
            "Epoch 63 Iteration 16240 - Train Loss: 0.000060 - Dev Loss: 0.639179\n",
            "Epoch 63 Iteration 16250 - Train Loss: 0.000056 - Dev Loss: 0.639304\n",
            "Epoch 63 Iteration 16260 - Train Loss: 0.000066 - Dev Loss: 0.639290\n",
            "Epoch 63 Iteration 16270 - Train Loss: 0.000058 - Dev Loss: 0.639246\n",
            "Epoch 63 Iteration 16280 - Train Loss: 0.000067 - Dev Loss: 0.639272\n",
            "Epoch 63 Iteration 16290 - Train Loss: 0.000061 - Dev Loss: 0.639361\n",
            "Epoch 63 Iteration 16300 - Train Loss: 0.000086 - Dev Loss: 0.639462\n",
            "Epoch 63 Iteration 16310 - Train Loss: 0.000069 - Dev Loss: 0.639595\n",
            "Epoch 63 Iteration 16320 - Train Loss: 0.000064 - Dev Loss: 0.639654\n",
            "Epoch 63 Iteration 16330 - Train Loss: 0.000059 - Dev Loss: 0.639650\n",
            "Epoch 63 Iteration 16340 - Train Loss: 0.000055 - Dev Loss: 0.639566\n",
            "Epoch 63 Iteration 16350 - Train Loss: 0.000069 - Dev Loss: 0.639697\n",
            "Epoch 63 Iteration 16360 - Train Loss: 0.000049 - Dev Loss: 0.639746\n",
            "Epoch 63 Iteration 16370 - Train Loss: 0.000070 - Dev Loss: 0.639825\n",
            "Epoch 63 Iteration 16380 - Train Loss: 0.000061 - Dev Loss: 0.639956\n",
            "Epoch 64 Iteration 16390 - Train Loss: 0.000064 - Dev Loss: 0.640097\n",
            "Epoch 64 Iteration 16400 - Train Loss: 0.000059 - Dev Loss: 0.640221\n",
            "Epoch 64 Iteration 16410 - Train Loss: 0.000058 - Dev Loss: 0.640398\n",
            "Epoch 64 Iteration 16420 - Train Loss: 0.000054 - Dev Loss: 0.640580\n",
            "Epoch 64 Iteration 16430 - Train Loss: 0.000060 - Dev Loss: 0.640687\n",
            "Epoch 64 Iteration 16440 - Train Loss: 0.000070 - Dev Loss: 0.640722\n",
            "Epoch 64 Iteration 16450 - Train Loss: 0.000062 - Dev Loss: 0.640749\n",
            "Epoch 64 Iteration 16460 - Train Loss: 0.000058 - Dev Loss: 0.640698\n",
            "Epoch 64 Iteration 16470 - Train Loss: 0.000050 - Dev Loss: 0.640883\n",
            "Epoch 64 Iteration 16480 - Train Loss: 0.000067 - Dev Loss: 0.641178\n",
            "Epoch 64 Iteration 16490 - Train Loss: 0.000056 - Dev Loss: 0.641226\n",
            "Epoch 64 Iteration 16500 - Train Loss: 0.000048 - Dev Loss: 0.641179\n",
            "Epoch 64 Iteration 16510 - Train Loss: 0.000061 - Dev Loss: 0.641131\n",
            "Epoch 64 Iteration 16520 - Train Loss: 0.000058 - Dev Loss: 0.641072\n",
            "Epoch 64 Iteration 16530 - Train Loss: 0.000053 - Dev Loss: 0.641071\n",
            "Epoch 64 Iteration 16540 - Train Loss: 0.000055 - Dev Loss: 0.641148\n",
            "Epoch 64 Iteration 16550 - Train Loss: 0.000053 - Dev Loss: 0.641156\n",
            "Epoch 64 Iteration 16560 - Train Loss: 0.000063 - Dev Loss: 0.641028\n",
            "Epoch 64 Iteration 16570 - Train Loss: 0.000060 - Dev Loss: 0.640968\n",
            "Epoch 64 Iteration 16580 - Train Loss: 0.000054 - Dev Loss: 0.640871\n",
            "Epoch 64 Iteration 16590 - Train Loss: 0.000057 - Dev Loss: 0.640840\n",
            "Epoch 64 Iteration 16600 - Train Loss: 0.000057 - Dev Loss: 0.640797\n",
            "Epoch 64 Iteration 16610 - Train Loss: 0.000055 - Dev Loss: 0.640752\n",
            "Epoch 64 Iteration 16620 - Train Loss: 0.000058 - Dev Loss: 0.640878\n",
            "Epoch 64 Iteration 16630 - Train Loss: 0.000063 - Dev Loss: 0.640958\n",
            "Epoch 65 Iteration 16640 - Train Loss: 0.000054 - Dev Loss: 0.640985\n",
            "Epoch 65 Iteration 16650 - Train Loss: 0.000053 - Dev Loss: 0.640969\n",
            "Epoch 65 Iteration 16660 - Train Loss: 0.000068 - Dev Loss: 0.640980\n",
            "Epoch 65 Iteration 16670 - Train Loss: 0.000039 - Dev Loss: 0.640963\n",
            "Epoch 65 Iteration 16680 - Train Loss: 0.000050 - Dev Loss: 0.641020\n",
            "Epoch 65 Iteration 16690 - Train Loss: 0.000052 - Dev Loss: 0.641036\n",
            "Epoch 65 Iteration 16700 - Train Loss: 0.000052 - Dev Loss: 0.641043\n",
            "Epoch 65 Iteration 16710 - Train Loss: 0.000052 - Dev Loss: 0.641174\n",
            "Epoch 65 Iteration 16720 - Train Loss: 0.000050 - Dev Loss: 0.641339\n",
            "Epoch 65 Iteration 16730 - Train Loss: 0.000046 - Dev Loss: 0.641512\n",
            "Epoch 65 Iteration 16740 - Train Loss: 0.000051 - Dev Loss: 0.641640\n",
            "Epoch 65 Iteration 16750 - Train Loss: 0.000051 - Dev Loss: 0.641966\n",
            "Epoch 65 Iteration 16760 - Train Loss: 0.000061 - Dev Loss: 0.642189\n",
            "Epoch 65 Iteration 16770 - Train Loss: 0.000057 - Dev Loss: 0.642226\n",
            "Epoch 65 Iteration 16780 - Train Loss: 0.000052 - Dev Loss: 0.642197\n",
            "Epoch 65 Iteration 16790 - Train Loss: 0.000047 - Dev Loss: 0.642225\n",
            "Epoch 65 Iteration 16800 - Train Loss: 0.000048 - Dev Loss: 0.642316\n",
            "Epoch 65 Iteration 16810 - Train Loss: 0.000053 - Dev Loss: 0.642334\n",
            "Epoch 65 Iteration 16820 - Train Loss: 0.000060 - Dev Loss: 0.642412\n",
            "Epoch 65 Iteration 16830 - Train Loss: 0.000046 - Dev Loss: 0.642433\n",
            "Epoch 65 Iteration 16840 - Train Loss: 0.000052 - Dev Loss: 0.642439\n",
            "Epoch 65 Iteration 16850 - Train Loss: 0.000059 - Dev Loss: 0.642499\n",
            "Epoch 65 Iteration 16860 - Train Loss: 0.000050 - Dev Loss: 0.642545\n",
            "Epoch 65 Iteration 16870 - Train Loss: 0.000043 - Dev Loss: 0.642540\n",
            "Epoch 65 Iteration 16880 - Train Loss: 0.000057 - Dev Loss: 0.642447\n",
            "Epoch 65 Iteration 16890 - Train Loss: 0.000057 - Dev Loss: 0.642411\n",
            "Epoch 66 Iteration 16900 - Train Loss: 0.000058 - Dev Loss: 0.642383\n",
            "Epoch 66 Iteration 16910 - Train Loss: 0.000044 - Dev Loss: 0.642326\n",
            "Epoch 66 Iteration 16920 - Train Loss: 0.000043 - Dev Loss: 0.642273\n",
            "Epoch 66 Iteration 16930 - Train Loss: 0.000047 - Dev Loss: 0.642254\n",
            "Epoch 66 Iteration 16940 - Train Loss: 0.000052 - Dev Loss: 0.642266\n",
            "Epoch 66 Iteration 16950 - Train Loss: 0.000051 - Dev Loss: 0.642263\n",
            "Epoch 66 Iteration 16960 - Train Loss: 0.000044 - Dev Loss: 0.642255\n",
            "Epoch 66 Iteration 16970 - Train Loss: 0.000041 - Dev Loss: 0.642261\n",
            "Epoch 66 Iteration 16980 - Train Loss: 0.000047 - Dev Loss: 0.642397\n",
            "Epoch 66 Iteration 16990 - Train Loss: 0.000052 - Dev Loss: 0.642365\n",
            "Epoch 66 Iteration 17000 - Train Loss: 0.000039 - Dev Loss: 0.642308\n",
            "Epoch 66 Iteration 17010 - Train Loss: 0.000048 - Dev Loss: 0.642413\n",
            "Epoch 66 Iteration 17020 - Train Loss: 0.000042 - Dev Loss: 0.642548\n",
            "Epoch 66 Iteration 17030 - Train Loss: 0.000050 - Dev Loss: 0.642758\n",
            "Epoch 66 Iteration 17040 - Train Loss: 0.000052 - Dev Loss: 0.642915\n",
            "Epoch 66 Iteration 17050 - Train Loss: 0.000044 - Dev Loss: 0.643064\n",
            "Epoch 66 Iteration 17060 - Train Loss: 0.000047 - Dev Loss: 0.643143\n",
            "Epoch 66 Iteration 17070 - Train Loss: 0.000057 - Dev Loss: 0.643272\n",
            "Epoch 66 Iteration 17080 - Train Loss: 0.000044 - Dev Loss: 0.643374\n",
            "Epoch 66 Iteration 17090 - Train Loss: 0.000052 - Dev Loss: 0.643570\n",
            "Epoch 66 Iteration 17100 - Train Loss: 0.000051 - Dev Loss: 0.643765\n",
            "Epoch 66 Iteration 17110 - Train Loss: 0.000052 - Dev Loss: 0.643943\n",
            "Epoch 66 Iteration 17120 - Train Loss: 0.000044 - Dev Loss: 0.643972\n",
            "Epoch 66 Iteration 17130 - Train Loss: 0.000046 - Dev Loss: 0.644082\n",
            "Epoch 66 Iteration 17140 - Train Loss: 0.000045 - Dev Loss: 0.644196\n",
            "Epoch 66 Iteration 17150 - Train Loss: 0.000040 - Dev Loss: 0.644326\n",
            "Epoch 67 Iteration 17160 - Train Loss: 0.000035 - Dev Loss: 0.644380\n",
            "Epoch 67 Iteration 17170 - Train Loss: 0.000047 - Dev Loss: 0.644375\n",
            "Epoch 67 Iteration 17180 - Train Loss: 0.000047 - Dev Loss: 0.644467\n",
            "Epoch 67 Iteration 17190 - Train Loss: 0.000035 - Dev Loss: 0.644543\n",
            "Epoch 67 Iteration 17200 - Train Loss: 0.000038 - Dev Loss: 0.644500\n",
            "Epoch 67 Iteration 17210 - Train Loss: 0.000043 - Dev Loss: 0.644421\n",
            "Epoch 67 Iteration 17220 - Train Loss: 0.000038 - Dev Loss: 0.644423\n",
            "Epoch 67 Iteration 17230 - Train Loss: 0.000044 - Dev Loss: 0.644463\n",
            "Epoch 67 Iteration 17240 - Train Loss: 0.000047 - Dev Loss: 0.644585\n",
            "Epoch 67 Iteration 17250 - Train Loss: 0.000053 - Dev Loss: 0.644672\n",
            "Epoch 67 Iteration 17260 - Train Loss: 0.000037 - Dev Loss: 0.644746\n",
            "Epoch 67 Iteration 17270 - Train Loss: 0.000040 - Dev Loss: 0.644836\n",
            "Epoch 67 Iteration 17280 - Train Loss: 0.000041 - Dev Loss: 0.644876\n",
            "Epoch 67 Iteration 17290 - Train Loss: 0.000045 - Dev Loss: 0.644860\n",
            "Epoch 67 Iteration 17300 - Train Loss: 0.000042 - Dev Loss: 0.644854\n",
            "Epoch 67 Iteration 17310 - Train Loss: 0.000049 - Dev Loss: 0.644869\n",
            "Epoch 67 Iteration 17320 - Train Loss: 0.000040 - Dev Loss: 0.645072\n",
            "Epoch 67 Iteration 17330 - Train Loss: 0.000046 - Dev Loss: 0.645129\n",
            "Epoch 67 Iteration 17340 - Train Loss: 0.000041 - Dev Loss: 0.645008\n",
            "Epoch 67 Iteration 17350 - Train Loss: 0.000044 - Dev Loss: 0.644928\n",
            "Epoch 67 Iteration 17360 - Train Loss: 0.000041 - Dev Loss: 0.644970\n",
            "Epoch 67 Iteration 17370 - Train Loss: 0.000040 - Dev Loss: 0.645053\n",
            "Epoch 67 Iteration 17380 - Train Loss: 0.000041 - Dev Loss: 0.645152\n",
            "Epoch 67 Iteration 17390 - Train Loss: 0.000041 - Dev Loss: 0.645301\n",
            "Epoch 67 Iteration 17400 - Train Loss: 0.000043 - Dev Loss: 0.645522\n",
            "Epoch 68 Iteration 17410 - Train Loss: 0.000037 - Dev Loss: 0.645691\n",
            "Epoch 68 Iteration 17420 - Train Loss: 0.000042 - Dev Loss: 0.645770\n",
            "Epoch 68 Iteration 17430 - Train Loss: 0.000038 - Dev Loss: 0.645851\n",
            "Epoch 68 Iteration 17440 - Train Loss: 0.000040 - Dev Loss: 0.645823\n",
            "Epoch 68 Iteration 17450 - Train Loss: 0.000046 - Dev Loss: 0.645840\n",
            "Epoch 68 Iteration 17460 - Train Loss: 0.000043 - Dev Loss: 0.645939\n",
            "Epoch 68 Iteration 17470 - Train Loss: 0.000040 - Dev Loss: 0.646066\n",
            "Epoch 68 Iteration 17480 - Train Loss: 0.000038 - Dev Loss: 0.646187\n",
            "Epoch 68 Iteration 17490 - Train Loss: 0.000038 - Dev Loss: 0.646396\n",
            "Epoch 68 Iteration 17500 - Train Loss: 0.000033 - Dev Loss: 0.646525\n",
            "Epoch 68 Iteration 17510 - Train Loss: 0.000043 - Dev Loss: 0.646548\n",
            "Epoch 68 Iteration 17520 - Train Loss: 0.000044 - Dev Loss: 0.646486\n",
            "Epoch 68 Iteration 17530 - Train Loss: 0.000032 - Dev Loss: 0.646517\n",
            "Epoch 68 Iteration 17540 - Train Loss: 0.000034 - Dev Loss: 0.646439\n",
            "Epoch 68 Iteration 17550 - Train Loss: 0.000032 - Dev Loss: 0.646383\n",
            "Epoch 68 Iteration 17560 - Train Loss: 0.000034 - Dev Loss: 0.646466\n",
            "Epoch 68 Iteration 17570 - Train Loss: 0.000037 - Dev Loss: 0.646504\n",
            "Epoch 68 Iteration 17580 - Train Loss: 0.000039 - Dev Loss: 0.646308\n",
            "Epoch 68 Iteration 17590 - Train Loss: 0.000037 - Dev Loss: 0.646186\n",
            "Epoch 68 Iteration 17600 - Train Loss: 0.000045 - Dev Loss: 0.646207\n",
            "Epoch 68 Iteration 17610 - Train Loss: 0.000030 - Dev Loss: 0.646416\n",
            "Epoch 68 Iteration 17620 - Train Loss: 0.000042 - Dev Loss: 0.646564\n",
            "Epoch 68 Iteration 17630 - Train Loss: 0.000038 - Dev Loss: 0.646567\n",
            "Epoch 68 Iteration 17640 - Train Loss: 0.000038 - Dev Loss: 0.646635\n",
            "Epoch 68 Iteration 17650 - Train Loss: 0.000038 - Dev Loss: 0.646849\n",
            "Epoch 68 Iteration 17660 - Train Loss: 0.000036 - Dev Loss: 0.647029\n",
            "Epoch 69 Iteration 17670 - Train Loss: 0.000042 - Dev Loss: 0.646926\n",
            "Epoch 69 Iteration 17680 - Train Loss: 0.000041 - Dev Loss: 0.647006\n",
            "Epoch 69 Iteration 17690 - Train Loss: 0.000034 - Dev Loss: 0.647187\n",
            "Epoch 69 Iteration 17700 - Train Loss: 0.000033 - Dev Loss: 0.647352\n",
            "Epoch 69 Iteration 17710 - Train Loss: 0.000032 - Dev Loss: 0.647398\n",
            "Epoch 69 Iteration 17720 - Train Loss: 0.000032 - Dev Loss: 0.647408\n",
            "Epoch 69 Iteration 17730 - Train Loss: 0.000035 - Dev Loss: 0.647484\n",
            "Epoch 69 Iteration 17740 - Train Loss: 0.000036 - Dev Loss: 0.647720\n",
            "Epoch 69 Iteration 17750 - Train Loss: 0.000035 - Dev Loss: 0.647782\n",
            "Epoch 69 Iteration 17760 - Train Loss: 0.000036 - Dev Loss: 0.647863\n",
            "Epoch 69 Iteration 17770 - Train Loss: 0.000032 - Dev Loss: 0.648062\n",
            "Epoch 69 Iteration 17780 - Train Loss: 0.000035 - Dev Loss: 0.648066\n",
            "Epoch 69 Iteration 17790 - Train Loss: 0.000032 - Dev Loss: 0.648101\n",
            "Epoch 69 Iteration 17800 - Train Loss: 0.000034 - Dev Loss: 0.648239\n",
            "Epoch 69 Iteration 17810 - Train Loss: 0.000039 - Dev Loss: 0.648314\n",
            "Epoch 69 Iteration 17820 - Train Loss: 0.000041 - Dev Loss: 0.648407\n",
            "Epoch 69 Iteration 17830 - Train Loss: 0.000036 - Dev Loss: 0.648389\n",
            "Epoch 69 Iteration 17840 - Train Loss: 0.000031 - Dev Loss: 0.648389\n",
            "Epoch 69 Iteration 17850 - Train Loss: 0.000031 - Dev Loss: 0.648324\n",
            "Epoch 69 Iteration 17860 - Train Loss: 0.000032 - Dev Loss: 0.648311\n",
            "Epoch 69 Iteration 17870 - Train Loss: 0.000034 - Dev Loss: 0.648261\n",
            "Epoch 69 Iteration 17880 - Train Loss: 0.000038 - Dev Loss: 0.648279\n",
            "Epoch 69 Iteration 17890 - Train Loss: 0.000034 - Dev Loss: 0.648387\n",
            "Epoch 69 Iteration 17900 - Train Loss: 0.000029 - Dev Loss: 0.648431\n",
            "Epoch 69 Iteration 17910 - Train Loss: 0.000037 - Dev Loss: 0.648524\n",
            "Epoch 70 Iteration 17920 - Train Loss: 0.000036 - Dev Loss: 0.648556\n",
            "Epoch 70 Iteration 17930 - Train Loss: 0.000033 - Dev Loss: 0.648603\n",
            "Epoch 70 Iteration 17940 - Train Loss: 0.000036 - Dev Loss: 0.648822\n",
            "Epoch 70 Iteration 17950 - Train Loss: 0.000026 - Dev Loss: 0.648927\n",
            "Epoch 70 Iteration 17960 - Train Loss: 0.000037 - Dev Loss: 0.649178\n",
            "Epoch 70 Iteration 17970 - Train Loss: 0.000032 - Dev Loss: 0.649266\n",
            "Epoch 70 Iteration 17980 - Train Loss: 0.000033 - Dev Loss: 0.649098\n",
            "Epoch 70 Iteration 17990 - Train Loss: 0.000026 - Dev Loss: 0.649187\n",
            "Epoch 70 Iteration 18000 - Train Loss: 0.000029 - Dev Loss: 0.649357\n",
            "Epoch 70 Iteration 18010 - Train Loss: 0.000031 - Dev Loss: 0.649409\n",
            "Epoch 70 Iteration 18020 - Train Loss: 0.000033 - Dev Loss: 0.649347\n",
            "Epoch 70 Iteration 18030 - Train Loss: 0.000025 - Dev Loss: 0.649336\n",
            "Epoch 70 Iteration 18040 - Train Loss: 0.000032 - Dev Loss: 0.649337\n",
            "Epoch 70 Iteration 18050 - Train Loss: 0.000031 - Dev Loss: 0.649430\n",
            "Epoch 70 Iteration 18060 - Train Loss: 0.000028 - Dev Loss: 0.649606\n",
            "Epoch 70 Iteration 18070 - Train Loss: 0.000033 - Dev Loss: 0.649763\n",
            "Epoch 70 Iteration 18080 - Train Loss: 0.000034 - Dev Loss: 0.649731\n",
            "Epoch 70 Iteration 18090 - Train Loss: 0.000033 - Dev Loss: 0.649782\n",
            "Epoch 70 Iteration 18100 - Train Loss: 0.000033 - Dev Loss: 0.649908\n",
            "Epoch 70 Iteration 18110 - Train Loss: 0.000032 - Dev Loss: 0.650061\n",
            "Epoch 70 Iteration 18120 - Train Loss: 0.000026 - Dev Loss: 0.650207\n",
            "Epoch 70 Iteration 18130 - Train Loss: 0.000034 - Dev Loss: 0.650259\n",
            "Epoch 70 Iteration 18140 - Train Loss: 0.000035 - Dev Loss: 0.650316\n",
            "Epoch 70 Iteration 18150 - Train Loss: 0.000033 - Dev Loss: 0.650331\n",
            "Epoch 70 Iteration 18160 - Train Loss: 0.000030 - Dev Loss: 0.650439\n",
            "Epoch 70 Iteration 18170 - Train Loss: 0.000030 - Dev Loss: 0.650506\n",
            "Epoch 71 Iteration 18180 - Train Loss: 0.000029 - Dev Loss: 0.650468\n",
            "Epoch 71 Iteration 18190 - Train Loss: 0.000028 - Dev Loss: 0.650611\n",
            "Epoch 71 Iteration 18200 - Train Loss: 0.000026 - Dev Loss: 0.650830\n",
            "Epoch 71 Iteration 18210 - Train Loss: 0.000026 - Dev Loss: 0.651057\n",
            "Epoch 71 Iteration 18220 - Train Loss: 0.000032 - Dev Loss: 0.651156\n",
            "Epoch 71 Iteration 18230 - Train Loss: 0.000027 - Dev Loss: 0.651059\n",
            "Epoch 71 Iteration 18240 - Train Loss: 0.000028 - Dev Loss: 0.650894\n",
            "Epoch 71 Iteration 18250 - Train Loss: 0.000030 - Dev Loss: 0.650854\n",
            "Epoch 71 Iteration 18260 - Train Loss: 0.000030 - Dev Loss: 0.650917\n",
            "Epoch 71 Iteration 18270 - Train Loss: 0.000030 - Dev Loss: 0.650851\n",
            "Epoch 71 Iteration 18280 - Train Loss: 0.000026 - Dev Loss: 0.650916\n",
            "Epoch 71 Iteration 18290 - Train Loss: 0.000029 - Dev Loss: 0.651163\n",
            "Epoch 71 Iteration 18300 - Train Loss: 0.000026 - Dev Loss: 0.651201\n",
            "Epoch 71 Iteration 18310 - Train Loss: 0.000029 - Dev Loss: 0.651114\n",
            "Epoch 71 Iteration 18320 - Train Loss: 0.000025 - Dev Loss: 0.651031\n",
            "Epoch 71 Iteration 18330 - Train Loss: 0.000035 - Dev Loss: 0.651185\n",
            "Epoch 71 Iteration 18340 - Train Loss: 0.000025 - Dev Loss: 0.651254\n",
            "Epoch 71 Iteration 18350 - Train Loss: 0.000034 - Dev Loss: 0.651302\n",
            "Epoch 71 Iteration 18360 - Train Loss: 0.000029 - Dev Loss: 0.651467\n",
            "Epoch 71 Iteration 18370 - Train Loss: 0.000031 - Dev Loss: 0.651604\n",
            "Epoch 71 Iteration 18380 - Train Loss: 0.000027 - Dev Loss: 0.651794\n",
            "Epoch 71 Iteration 18390 - Train Loss: 0.000028 - Dev Loss: 0.652055\n",
            "Epoch 71 Iteration 18400 - Train Loss: 0.000025 - Dev Loss: 0.652181\n",
            "Epoch 71 Iteration 18410 - Train Loss: 0.000027 - Dev Loss: 0.652231\n",
            "Epoch 71 Iteration 18420 - Train Loss: 0.000025 - Dev Loss: 0.652235\n",
            "Epoch 71 Iteration 18430 - Train Loss: 0.000033 - Dev Loss: 0.652416\n",
            "Epoch 72 Iteration 18440 - Train Loss: 0.000026 - Dev Loss: 0.652545\n",
            "Epoch 72 Iteration 18450 - Train Loss: 0.000022 - Dev Loss: 0.652626\n",
            "Epoch 72 Iteration 18460 - Train Loss: 0.000027 - Dev Loss: 0.652571\n",
            "Epoch 72 Iteration 18470 - Train Loss: 0.000023 - Dev Loss: 0.652559\n",
            "Epoch 72 Iteration 18480 - Train Loss: 0.000030 - Dev Loss: 0.652637\n",
            "Epoch 72 Iteration 18490 - Train Loss: 0.000027 - Dev Loss: 0.652608\n",
            "Epoch 72 Iteration 18500 - Train Loss: 0.000026 - Dev Loss: 0.652593\n",
            "Epoch 72 Iteration 18510 - Train Loss: 0.000027 - Dev Loss: 0.652638\n",
            "Epoch 72 Iteration 18520 - Train Loss: 0.000027 - Dev Loss: 0.652639\n",
            "Epoch 72 Iteration 18530 - Train Loss: 0.000022 - Dev Loss: 0.652720\n",
            "Epoch 72 Iteration 18540 - Train Loss: 0.000027 - Dev Loss: 0.652852\n",
            "Epoch 72 Iteration 18550 - Train Loss: 0.000030 - Dev Loss: 0.652949\n",
            "Epoch 72 Iteration 18560 - Train Loss: 0.000021 - Dev Loss: 0.653170\n",
            "Epoch 72 Iteration 18570 - Train Loss: 0.000029 - Dev Loss: 0.653400\n",
            "Epoch 72 Iteration 18580 - Train Loss: 0.000027 - Dev Loss: 0.653517\n",
            "Epoch 72 Iteration 18590 - Train Loss: 0.000027 - Dev Loss: 0.653596\n",
            "Epoch 72 Iteration 18600 - Train Loss: 0.000027 - Dev Loss: 0.653668\n",
            "Epoch 72 Iteration 18610 - Train Loss: 0.000023 - Dev Loss: 0.653559\n",
            "Epoch 72 Iteration 18620 - Train Loss: 0.000026 - Dev Loss: 0.653614\n",
            "Epoch 72 Iteration 18630 - Train Loss: 0.000025 - Dev Loss: 0.653743\n",
            "Epoch 72 Iteration 18640 - Train Loss: 0.000028 - Dev Loss: 0.653831\n",
            "Epoch 72 Iteration 18650 - Train Loss: 0.000024 - Dev Loss: 0.653739\n",
            "Epoch 72 Iteration 18660 - Train Loss: 0.000028 - Dev Loss: 0.653797\n",
            "Epoch 72 Iteration 18670 - Train Loss: 0.000030 - Dev Loss: 0.654094\n",
            "Epoch 72 Iteration 18680 - Train Loss: 0.000026 - Dev Loss: 0.654249\n",
            "Epoch 73 Iteration 18690 - Train Loss: 0.000026 - Dev Loss: 0.654335\n",
            "Epoch 73 Iteration 18700 - Train Loss: 0.000029 - Dev Loss: 0.654625\n",
            "Epoch 73 Iteration 18710 - Train Loss: 0.000021 - Dev Loss: 0.654773\n",
            "Epoch 73 Iteration 18720 - Train Loss: 0.000026 - Dev Loss: 0.654906\n",
            "Epoch 73 Iteration 18730 - Train Loss: 0.000023 - Dev Loss: 0.655195\n",
            "Epoch 73 Iteration 18740 - Train Loss: 0.000024 - Dev Loss: 0.655241\n",
            "Epoch 73 Iteration 18750 - Train Loss: 0.000021 - Dev Loss: 0.655223\n",
            "Epoch 73 Iteration 18760 - Train Loss: 0.000020 - Dev Loss: 0.655256\n",
            "Epoch 73 Iteration 18770 - Train Loss: 0.000024 - Dev Loss: 0.655320\n",
            "Epoch 73 Iteration 18780 - Train Loss: 0.000019 - Dev Loss: 0.655398\n",
            "Epoch 73 Iteration 18790 - Train Loss: 0.000022 - Dev Loss: 0.655454\n",
            "Epoch 73 Iteration 18800 - Train Loss: 0.000024 - Dev Loss: 0.655718\n",
            "Epoch 73 Iteration 18810 - Train Loss: 0.000024 - Dev Loss: 0.655924\n",
            "Epoch 73 Iteration 18820 - Train Loss: 0.000025 - Dev Loss: 0.655870\n",
            "Epoch 73 Iteration 18830 - Train Loss: 0.000025 - Dev Loss: 0.655836\n",
            "Epoch 73 Iteration 18840 - Train Loss: 0.000025 - Dev Loss: 0.655918\n",
            "Epoch 73 Iteration 18850 - Train Loss: 0.000023 - Dev Loss: 0.656037\n",
            "Epoch 73 Iteration 18860 - Train Loss: 0.000020 - Dev Loss: 0.656044\n",
            "Epoch 73 Iteration 18870 - Train Loss: 0.000025 - Dev Loss: 0.655960\n",
            "Epoch 73 Iteration 18880 - Train Loss: 0.000023 - Dev Loss: 0.655944\n",
            "Epoch 73 Iteration 18890 - Train Loss: 0.000027 - Dev Loss: 0.655834\n",
            "Epoch 73 Iteration 18900 - Train Loss: 0.000022 - Dev Loss: 0.655857\n",
            "Epoch 73 Iteration 18910 - Train Loss: 0.000024 - Dev Loss: 0.655885\n",
            "Epoch 73 Iteration 18920 - Train Loss: 0.000026 - Dev Loss: 0.655977\n",
            "Epoch 73 Iteration 18930 - Train Loss: 0.000023 - Dev Loss: 0.656129\n",
            "Epoch 73 Iteration 18940 - Train Loss: 0.000023 - Dev Loss: 0.656254\n",
            "Epoch 74 Iteration 18950 - Train Loss: 0.000020 - Dev Loss: 0.656233\n",
            "Epoch 74 Iteration 18960 - Train Loss: 0.000021 - Dev Loss: 0.656195\n",
            "Epoch 74 Iteration 18970 - Train Loss: 0.000023 - Dev Loss: 0.655999\n",
            "Epoch 74 Iteration 18980 - Train Loss: 0.000023 - Dev Loss: 0.655979\n",
            "Epoch 74 Iteration 18990 - Train Loss: 0.000020 - Dev Loss: 0.656025\n",
            "Epoch 74 Iteration 19000 - Train Loss: 0.000019 - Dev Loss: 0.656136\n",
            "Epoch 74 Iteration 19010 - Train Loss: 0.000021 - Dev Loss: 0.656379\n",
            "Epoch 74 Iteration 19020 - Train Loss: 0.000018 - Dev Loss: 0.656617\n",
            "Epoch 74 Iteration 19030 - Train Loss: 0.000025 - Dev Loss: 0.656770\n",
            "Epoch 74 Iteration 19040 - Train Loss: 0.000024 - Dev Loss: 0.656893\n",
            "Epoch 74 Iteration 19050 - Train Loss: 0.000026 - Dev Loss: 0.657007\n",
            "Epoch 74 Iteration 19060 - Train Loss: 0.000025 - Dev Loss: 0.657148\n",
            "Epoch 74 Iteration 19070 - Train Loss: 0.000018 - Dev Loss: 0.657323\n",
            "Epoch 74 Iteration 19080 - Train Loss: 0.000021 - Dev Loss: 0.657392\n",
            "Epoch 74 Iteration 19090 - Train Loss: 0.000021 - Dev Loss: 0.657496\n",
            "Epoch 74 Iteration 19100 - Train Loss: 0.000022 - Dev Loss: 0.657635\n",
            "Epoch 74 Iteration 19110 - Train Loss: 0.000023 - Dev Loss: 0.657690\n",
            "Epoch 74 Iteration 19120 - Train Loss: 0.000019 - Dev Loss: 0.657790\n",
            "Epoch 74 Iteration 19130 - Train Loss: 0.000021 - Dev Loss: 0.657841\n",
            "Epoch 74 Iteration 19140 - Train Loss: 0.000016 - Dev Loss: 0.657802\n",
            "Epoch 74 Iteration 19150 - Train Loss: 0.000022 - Dev Loss: 0.657829\n",
            "Epoch 74 Iteration 19160 - Train Loss: 0.000024 - Dev Loss: 0.658085\n",
            "Epoch 74 Iteration 19170 - Train Loss: 0.000021 - Dev Loss: 0.658286\n",
            "Epoch 74 Iteration 19180 - Train Loss: 0.000023 - Dev Loss: 0.658373\n",
            "Epoch 74 Iteration 19190 - Train Loss: 0.000021 - Dev Loss: 0.658510\n",
            "Epoch 75 Iteration 19200 - Train Loss: 0.000020 - Dev Loss: 0.658690\n",
            "Epoch 75 Iteration 19210 - Train Loss: 0.000018 - Dev Loss: 0.658713\n",
            "Epoch 75 Iteration 19220 - Train Loss: 0.000020 - Dev Loss: 0.658743\n",
            "Epoch 75 Iteration 19230 - Train Loss: 0.000018 - Dev Loss: 0.658716\n",
            "Epoch 75 Iteration 19240 - Train Loss: 0.000019 - Dev Loss: 0.658738\n",
            "Epoch 75 Iteration 19250 - Train Loss: 0.000017 - Dev Loss: 0.658779\n",
            "Epoch 75 Iteration 19260 - Train Loss: 0.000019 - Dev Loss: 0.658831\n",
            "Epoch 75 Iteration 19270 - Train Loss: 0.000019 - Dev Loss: 0.658782\n",
            "Epoch 75 Iteration 19280 - Train Loss: 0.000021 - Dev Loss: 0.658866\n",
            "Epoch 75 Iteration 19290 - Train Loss: 0.000019 - Dev Loss: 0.659046\n",
            "Epoch 75 Iteration 19300 - Train Loss: 0.000020 - Dev Loss: 0.659113\n",
            "Epoch 75 Iteration 19310 - Train Loss: 0.000016 - Dev Loss: 0.659202\n",
            "Epoch 75 Iteration 19320 - Train Loss: 0.000021 - Dev Loss: 0.659243\n",
            "Epoch 75 Iteration 19330 - Train Loss: 0.000016 - Dev Loss: 0.659261\n",
            "Epoch 75 Iteration 19340 - Train Loss: 0.000022 - Dev Loss: 0.659323\n",
            "Epoch 75 Iteration 19350 - Train Loss: 0.000021 - Dev Loss: 0.659447\n",
            "Epoch 75 Iteration 19360 - Train Loss: 0.000022 - Dev Loss: 0.659712\n",
            "Epoch 75 Iteration 19370 - Train Loss: 0.000018 - Dev Loss: 0.659817\n",
            "Epoch 75 Iteration 19380 - Train Loss: 0.000019 - Dev Loss: 0.659863\n",
            "Epoch 75 Iteration 19390 - Train Loss: 0.000025 - Dev Loss: 0.659866\n",
            "Epoch 75 Iteration 19400 - Train Loss: 0.000020 - Dev Loss: 0.660144\n",
            "Epoch 75 Iteration 19410 - Train Loss: 0.000022 - Dev Loss: 0.660396\n",
            "Epoch 75 Iteration 19420 - Train Loss: 0.000018 - Dev Loss: 0.660457\n",
            "Epoch 75 Iteration 19430 - Train Loss: 0.000021 - Dev Loss: 0.660595\n",
            "Epoch 75 Iteration 19440 - Train Loss: 0.000020 - Dev Loss: 0.660707\n",
            "Epoch 75 Iteration 19450 - Train Loss: 0.000020 - Dev Loss: 0.660760\n",
            "Epoch 76 Iteration 19460 - Train Loss: 0.000016 - Dev Loss: 0.660834\n",
            "Epoch 76 Iteration 19470 - Train Loss: 0.000016 - Dev Loss: 0.660835\n",
            "Epoch 76 Iteration 19480 - Train Loss: 0.000016 - Dev Loss: 0.660900\n",
            "Epoch 76 Iteration 19490 - Train Loss: 0.000020 - Dev Loss: 0.661022\n",
            "Epoch 76 Iteration 19500 - Train Loss: 0.000017 - Dev Loss: 0.661185\n",
            "Epoch 76 Iteration 19510 - Train Loss: 0.000017 - Dev Loss: 0.661303\n",
            "Epoch 76 Iteration 19520 - Train Loss: 0.000016 - Dev Loss: 0.661312\n",
            "Epoch 76 Iteration 19530 - Train Loss: 0.000016 - Dev Loss: 0.661409\n",
            "Epoch 76 Iteration 19540 - Train Loss: 0.000018 - Dev Loss: 0.661434\n",
            "Epoch 76 Iteration 19550 - Train Loss: 0.000019 - Dev Loss: 0.661339\n",
            "Epoch 76 Iteration 19560 - Train Loss: 0.000015 - Dev Loss: 0.661332\n",
            "Epoch 76 Iteration 19570 - Train Loss: 0.000019 - Dev Loss: 0.661332\n",
            "Epoch 76 Iteration 19580 - Train Loss: 0.000020 - Dev Loss: 0.661320\n",
            "Epoch 76 Iteration 19590 - Train Loss: 0.000019 - Dev Loss: 0.661371\n",
            "Epoch 76 Iteration 19600 - Train Loss: 0.000021 - Dev Loss: 0.661526\n",
            "Epoch 76 Iteration 19610 - Train Loss: 0.000017 - Dev Loss: 0.661736\n",
            "Epoch 76 Iteration 19620 - Train Loss: 0.000017 - Dev Loss: 0.662090\n",
            "Epoch 76 Iteration 19630 - Train Loss: 0.000022 - Dev Loss: 0.662293\n",
            "Epoch 76 Iteration 19640 - Train Loss: 0.000018 - Dev Loss: 0.662361\n",
            "Epoch 76 Iteration 19650 - Train Loss: 0.000019 - Dev Loss: 0.662625\n",
            "Epoch 76 Iteration 19660 - Train Loss: 0.000016 - Dev Loss: 0.662819\n",
            "Epoch 76 Iteration 19670 - Train Loss: 0.000018 - Dev Loss: 0.662828\n",
            "Epoch 76 Iteration 19680 - Train Loss: 0.000020 - Dev Loss: 0.663002\n",
            "Epoch 76 Iteration 19690 - Train Loss: 0.000017 - Dev Loss: 0.663110\n",
            "Epoch 76 Iteration 19700 - Train Loss: 0.000018 - Dev Loss: 0.663147\n",
            "Epoch 76 Iteration 19710 - Train Loss: 0.000018 - Dev Loss: 0.663291\n",
            "Epoch 77 Iteration 19720 - Train Loss: 0.000016 - Dev Loss: 0.663317\n",
            "Epoch 77 Iteration 19730 - Train Loss: 0.000017 - Dev Loss: 0.663376\n",
            "Epoch 77 Iteration 19740 - Train Loss: 0.000015 - Dev Loss: 0.663339\n",
            "Epoch 77 Iteration 19750 - Train Loss: 0.000018 - Dev Loss: 0.663332\n",
            "Epoch 77 Iteration 19760 - Train Loss: 0.000013 - Dev Loss: 0.663486\n",
            "Epoch 77 Iteration 19770 - Train Loss: 0.000017 - Dev Loss: 0.663572\n",
            "Epoch 77 Iteration 19780 - Train Loss: 0.000016 - Dev Loss: 0.663645\n",
            "Epoch 77 Iteration 19790 - Train Loss: 0.000016 - Dev Loss: 0.663687\n",
            "Epoch 77 Iteration 19800 - Train Loss: 0.000015 - Dev Loss: 0.663671\n",
            "Epoch 77 Iteration 19810 - Train Loss: 0.000018 - Dev Loss: 0.663834\n",
            "Epoch 77 Iteration 19820 - Train Loss: 0.000015 - Dev Loss: 0.664014\n",
            "Epoch 77 Iteration 19830 - Train Loss: 0.000019 - Dev Loss: 0.664221\n",
            "Epoch 77 Iteration 19840 - Train Loss: 0.000015 - Dev Loss: 0.664413\n",
            "Epoch 77 Iteration 19850 - Train Loss: 0.000017 - Dev Loss: 0.664519\n",
            "Epoch 77 Iteration 19860 - Train Loss: 0.000015 - Dev Loss: 0.664602\n",
            "Epoch 77 Iteration 19870 - Train Loss: 0.000019 - Dev Loss: 0.664502\n",
            "Epoch 77 Iteration 19880 - Train Loss: 0.000013 - Dev Loss: 0.664598\n",
            "Epoch 77 Iteration 19890 - Train Loss: 0.000019 - Dev Loss: 0.664730\n",
            "Epoch 77 Iteration 19900 - Train Loss: 0.000017 - Dev Loss: 0.664804\n",
            "Epoch 77 Iteration 19910 - Train Loss: 0.000015 - Dev Loss: 0.665133\n",
            "Epoch 77 Iteration 19920 - Train Loss: 0.000014 - Dev Loss: 0.665497\n",
            "Epoch 77 Iteration 19930 - Train Loss: 0.000017 - Dev Loss: 0.665512\n",
            "Epoch 77 Iteration 19940 - Train Loss: 0.000016 - Dev Loss: 0.665579\n",
            "Epoch 77 Iteration 19950 - Train Loss: 0.000016 - Dev Loss: 0.665468\n",
            "Epoch 77 Iteration 19960 - Train Loss: 0.000016 - Dev Loss: 0.665392\n",
            "Epoch 78 Iteration 19970 - Train Loss: 0.000017 - Dev Loss: 0.665368\n",
            "Epoch 78 Iteration 19980 - Train Loss: 0.000015 - Dev Loss: 0.665566\n",
            "Epoch 78 Iteration 19990 - Train Loss: 0.000015 - Dev Loss: 0.665716\n",
            "Epoch 78 Iteration 20000 - Train Loss: 0.000014 - Dev Loss: 0.665768\n",
            "Epoch 78 Iteration 20010 - Train Loss: 0.000017 - Dev Loss: 0.665819\n",
            "Epoch 78 Iteration 20020 - Train Loss: 0.000015 - Dev Loss: 0.666095\n",
            "Epoch 78 Iteration 20030 - Train Loss: 0.000015 - Dev Loss: 0.666324\n",
            "Epoch 78 Iteration 20040 - Train Loss: 0.000013 - Dev Loss: 0.666451\n",
            "Epoch 78 Iteration 20050 - Train Loss: 0.000014 - Dev Loss: 0.666481\n",
            "Epoch 78 Iteration 20060 - Train Loss: 0.000017 - Dev Loss: 0.666454\n",
            "Epoch 78 Iteration 20070 - Train Loss: 0.000014 - Dev Loss: 0.666552\n",
            "Epoch 78 Iteration 20080 - Train Loss: 0.000014 - Dev Loss: 0.666540\n",
            "Epoch 78 Iteration 20090 - Train Loss: 0.000014 - Dev Loss: 0.666550\n",
            "Epoch 78 Iteration 20100 - Train Loss: 0.000014 - Dev Loss: 0.666522\n",
            "Epoch 78 Iteration 20110 - Train Loss: 0.000015 - Dev Loss: 0.666527\n",
            "Epoch 78 Iteration 20120 - Train Loss: 0.000017 - Dev Loss: 0.666511\n",
            "Epoch 78 Iteration 20130 - Train Loss: 0.000013 - Dev Loss: 0.666537\n",
            "Epoch 78 Iteration 20140 - Train Loss: 0.000015 - Dev Loss: 0.666879\n",
            "Epoch 78 Iteration 20150 - Train Loss: 0.000012 - Dev Loss: 0.667020\n",
            "Epoch 78 Iteration 20160 - Train Loss: 0.000018 - Dev Loss: 0.667043\n",
            "Epoch 78 Iteration 20170 - Train Loss: 0.000012 - Dev Loss: 0.667090\n",
            "Epoch 78 Iteration 20180 - Train Loss: 0.000017 - Dev Loss: 0.667098\n",
            "Epoch 78 Iteration 20190 - Train Loss: 0.000014 - Dev Loss: 0.667178\n",
            "Epoch 78 Iteration 20200 - Train Loss: 0.000015 - Dev Loss: 0.667352\n",
            "Epoch 78 Iteration 20210 - Train Loss: 0.000013 - Dev Loss: 0.667701\n",
            "Epoch 78 Iteration 20220 - Train Loss: 0.000014 - Dev Loss: 0.667788\n",
            "Epoch 79 Iteration 20230 - Train Loss: 0.000017 - Dev Loss: 0.667952\n",
            "Epoch 79 Iteration 20240 - Train Loss: 0.000015 - Dev Loss: 0.668023\n",
            "Epoch 79 Iteration 20250 - Train Loss: 0.000014 - Dev Loss: 0.668142\n",
            "Epoch 79 Iteration 20260 - Train Loss: 0.000013 - Dev Loss: 0.668480\n",
            "Epoch 79 Iteration 20270 - Train Loss: 0.000013 - Dev Loss: 0.668607\n",
            "Epoch 79 Iteration 20280 - Train Loss: 0.000011 - Dev Loss: 0.668656\n",
            "Epoch 79 Iteration 20290 - Train Loss: 0.000013 - Dev Loss: 0.668702\n",
            "Epoch 79 Iteration 20300 - Train Loss: 0.000012 - Dev Loss: 0.668894\n",
            "Epoch 79 Iteration 20310 - Train Loss: 0.000011 - Dev Loss: 0.669049\n",
            "Epoch 79 Iteration 20320 - Train Loss: 0.000014 - Dev Loss: 0.669051\n",
            "Epoch 79 Iteration 20330 - Train Loss: 0.000013 - Dev Loss: 0.669133\n",
            "Epoch 79 Iteration 20340 - Train Loss: 0.000013 - Dev Loss: 0.669148\n",
            "Epoch 79 Iteration 20350 - Train Loss: 0.000014 - Dev Loss: 0.669242\n",
            "Epoch 79 Iteration 20360 - Train Loss: 0.000015 - Dev Loss: 0.669340\n",
            "Epoch 79 Iteration 20370 - Train Loss: 0.000013 - Dev Loss: 0.669342\n",
            "Epoch 79 Iteration 20380 - Train Loss: 0.000014 - Dev Loss: 0.669455\n",
            "Epoch 79 Iteration 20390 - Train Loss: 0.000011 - Dev Loss: 0.669630\n",
            "Epoch 79 Iteration 20400 - Train Loss: 0.000011 - Dev Loss: 0.669597\n",
            "Epoch 79 Iteration 20410 - Train Loss: 0.000013 - Dev Loss: 0.669612\n",
            "Epoch 79 Iteration 20420 - Train Loss: 0.000018 - Dev Loss: 0.669987\n",
            "Epoch 79 Iteration 20430 - Train Loss: 0.000014 - Dev Loss: 0.670326\n",
            "Epoch 79 Iteration 20440 - Train Loss: 0.000014 - Dev Loss: 0.670363\n",
            "Epoch 79 Iteration 20450 - Train Loss: 0.000013 - Dev Loss: 0.670348\n",
            "Epoch 79 Iteration 20460 - Train Loss: 0.000014 - Dev Loss: 0.670404\n",
            "Epoch 79 Iteration 20470 - Train Loss: 0.000012 - Dev Loss: 0.670449\n",
            "Epoch 80 Iteration 20480 - Train Loss: 0.000015 - Dev Loss: 0.670421\n",
            "Epoch 80 Iteration 20490 - Train Loss: 0.000012 - Dev Loss: 0.670345\n",
            "Epoch 80 Iteration 20500 - Train Loss: 0.000011 - Dev Loss: 0.670518\n",
            "Epoch 80 Iteration 20510 - Train Loss: 0.000012 - Dev Loss: 0.670594\n",
            "Epoch 80 Iteration 20520 - Train Loss: 0.000012 - Dev Loss: 0.670526\n",
            "Epoch 80 Iteration 20530 - Train Loss: 0.000012 - Dev Loss: 0.670565\n",
            "Epoch 80 Iteration 20540 - Train Loss: 0.000012 - Dev Loss: 0.670665\n",
            "Epoch 80 Iteration 20550 - Train Loss: 0.000013 - Dev Loss: 0.670775\n",
            "Epoch 80 Iteration 20560 - Train Loss: 0.000012 - Dev Loss: 0.671115\n",
            "Epoch 80 Iteration 20570 - Train Loss: 0.000013 - Dev Loss: 0.671383\n",
            "Epoch 80 Iteration 20580 - Train Loss: 0.000015 - Dev Loss: 0.671633\n",
            "Epoch 80 Iteration 20590 - Train Loss: 0.000012 - Dev Loss: 0.671821\n",
            "Epoch 80 Iteration 20600 - Train Loss: 0.000012 - Dev Loss: 0.671873\n",
            "Epoch 80 Iteration 20610 - Train Loss: 0.000013 - Dev Loss: 0.671789\n",
            "Epoch 80 Iteration 20620 - Train Loss: 0.000010 - Dev Loss: 0.671790\n",
            "Epoch 80 Iteration 20630 - Train Loss: 0.000011 - Dev Loss: 0.671748\n",
            "Epoch 80 Iteration 20640 - Train Loss: 0.000012 - Dev Loss: 0.671855\n",
            "Epoch 80 Iteration 20650 - Train Loss: 0.000012 - Dev Loss: 0.671917\n",
            "Epoch 80 Iteration 20660 - Train Loss: 0.000011 - Dev Loss: 0.671947\n",
            "Epoch 80 Iteration 20670 - Train Loss: 0.000012 - Dev Loss: 0.672125\n",
            "Epoch 80 Iteration 20680 - Train Loss: 0.000015 - Dev Loss: 0.671944\n",
            "Epoch 80 Iteration 20690 - Train Loss: 0.000013 - Dev Loss: 0.672094\n",
            "Epoch 80 Iteration 20700 - Train Loss: 0.000011 - Dev Loss: 0.672364\n",
            "Epoch 80 Iteration 20710 - Train Loss: 0.000012 - Dev Loss: 0.672548\n",
            "Epoch 80 Iteration 20720 - Train Loss: 0.000012 - Dev Loss: 0.672869\n",
            "Epoch 80 Iteration 20730 - Train Loss: 0.000011 - Dev Loss: 0.673217\n",
            "Epoch 81 Iteration 20740 - Train Loss: 0.000011 - Dev Loss: 0.673538\n",
            "Epoch 81 Iteration 20750 - Train Loss: 0.000010 - Dev Loss: 0.673503\n",
            "Epoch 81 Iteration 20760 - Train Loss: 0.000011 - Dev Loss: 0.673539\n",
            "Epoch 81 Iteration 20770 - Train Loss: 0.000010 - Dev Loss: 0.673587\n",
            "Epoch 81 Iteration 20780 - Train Loss: 0.000014 - Dev Loss: 0.673616\n",
            "Epoch 81 Iteration 20790 - Train Loss: 0.000010 - Dev Loss: 0.673801\n",
            "Epoch 81 Iteration 20800 - Train Loss: 0.000012 - Dev Loss: 0.673963\n",
            "Epoch 81 Iteration 20810 - Train Loss: 0.000011 - Dev Loss: 0.674376\n",
            "Epoch 81 Iteration 20820 - Train Loss: 0.000012 - Dev Loss: 0.674654\n",
            "Epoch 81 Iteration 20830 - Train Loss: 0.000010 - Dev Loss: 0.674860\n",
            "Epoch 81 Iteration 20840 - Train Loss: 0.000012 - Dev Loss: 0.675195\n",
            "Epoch 81 Iteration 20850 - Train Loss: 0.000010 - Dev Loss: 0.675314\n",
            "Epoch 81 Iteration 20860 - Train Loss: 0.000010 - Dev Loss: 0.675176\n",
            "Epoch 81 Iteration 20870 - Train Loss: 0.000010 - Dev Loss: 0.675161\n",
            "Epoch 81 Iteration 20880 - Train Loss: 0.000010 - Dev Loss: 0.675175\n",
            "Epoch 81 Iteration 20890 - Train Loss: 0.000014 - Dev Loss: 0.675294\n",
            "Epoch 81 Iteration 20900 - Train Loss: 0.000012 - Dev Loss: 0.675515\n",
            "Epoch 81 Iteration 20910 - Train Loss: 0.000010 - Dev Loss: 0.675558\n",
            "Epoch 81 Iteration 20920 - Train Loss: 0.000012 - Dev Loss: 0.675576\n",
            "Epoch 81 Iteration 20930 - Train Loss: 0.000011 - Dev Loss: 0.675897\n",
            "Epoch 81 Iteration 20940 - Train Loss: 0.000010 - Dev Loss: 0.676053\n",
            "Epoch 81 Iteration 20950 - Train Loss: 0.000011 - Dev Loss: 0.676016\n",
            "Epoch 81 Iteration 20960 - Train Loss: 0.000009 - Dev Loss: 0.675913\n",
            "Epoch 81 Iteration 20970 - Train Loss: 0.000012 - Dev Loss: 0.676128\n",
            "Epoch 81 Iteration 20980 - Train Loss: 0.000010 - Dev Loss: 0.676034\n",
            "Epoch 81 Iteration 20990 - Train Loss: 0.000011 - Dev Loss: 0.675946\n",
            "Epoch 82 Iteration 21000 - Train Loss: 0.000011 - Dev Loss: 0.675864\n",
            "Epoch 82 Iteration 21010 - Train Loss: 0.000011 - Dev Loss: 0.675985\n",
            "Epoch 82 Iteration 21020 - Train Loss: 0.000010 - Dev Loss: 0.676112\n",
            "Epoch 82 Iteration 21030 - Train Loss: 0.000010 - Dev Loss: 0.676251\n",
            "Epoch 82 Iteration 21040 - Train Loss: 0.000012 - Dev Loss: 0.676365\n",
            "Epoch 82 Iteration 21050 - Train Loss: 0.000011 - Dev Loss: 0.676367\n",
            "Epoch 82 Iteration 21060 - Train Loss: 0.000010 - Dev Loss: 0.676420\n",
            "Epoch 82 Iteration 21070 - Train Loss: 0.000008 - Dev Loss: 0.676448\n",
            "Epoch 82 Iteration 21080 - Train Loss: 0.000010 - Dev Loss: 0.676448\n",
            "Epoch 82 Iteration 21090 - Train Loss: 0.000010 - Dev Loss: 0.676699\n",
            "Epoch 82 Iteration 21100 - Train Loss: 0.000011 - Dev Loss: 0.676902\n",
            "Epoch 82 Iteration 21110 - Train Loss: 0.000010 - Dev Loss: 0.676963\n",
            "Epoch 82 Iteration 21120 - Train Loss: 0.000010 - Dev Loss: 0.677003\n",
            "Epoch 82 Iteration 21130 - Train Loss: 0.000010 - Dev Loss: 0.677296\n",
            "Epoch 82 Iteration 21140 - Train Loss: 0.000012 - Dev Loss: 0.677490\n",
            "Epoch 82 Iteration 21150 - Train Loss: 0.000010 - Dev Loss: 0.677678\n",
            "Epoch 82 Iteration 21160 - Train Loss: 0.000010 - Dev Loss: 0.677808\n",
            "Epoch 82 Iteration 21170 - Train Loss: 0.000011 - Dev Loss: 0.678019\n",
            "Epoch 82 Iteration 21180 - Train Loss: 0.000011 - Dev Loss: 0.678228\n",
            "Epoch 82 Iteration 21190 - Train Loss: 0.000008 - Dev Loss: 0.678379\n",
            "Epoch 82 Iteration 21200 - Train Loss: 0.000009 - Dev Loss: 0.678354\n",
            "Epoch 82 Iteration 21210 - Train Loss: 0.000009 - Dev Loss: 0.678492\n",
            "Epoch 82 Iteration 21220 - Train Loss: 0.000010 - Dev Loss: 0.678606\n",
            "Epoch 82 Iteration 21230 - Train Loss: 0.000009 - Dev Loss: 0.678704\n",
            "Epoch 82 Iteration 21240 - Train Loss: 0.000008 - Dev Loss: 0.678690\n",
            "Epoch 83 Iteration 21250 - Train Loss: 0.000010 - Dev Loss: 0.678789\n",
            "Epoch 83 Iteration 21260 - Train Loss: 0.000008 - Dev Loss: 0.678943\n",
            "Epoch 83 Iteration 21270 - Train Loss: 0.000008 - Dev Loss: 0.679196\n",
            "Epoch 83 Iteration 21280 - Train Loss: 0.000011 - Dev Loss: 0.679455\n",
            "Epoch 83 Iteration 21290 - Train Loss: 0.000009 - Dev Loss: 0.679681\n",
            "Epoch 83 Iteration 21300 - Train Loss: 0.000010 - Dev Loss: 0.679967\n",
            "Epoch 83 Iteration 21310 - Train Loss: 0.000008 - Dev Loss: 0.679985\n",
            "Epoch 83 Iteration 21320 - Train Loss: 0.000009 - Dev Loss: 0.679887\n",
            "Epoch 83 Iteration 21330 - Train Loss: 0.000008 - Dev Loss: 0.679915\n",
            "Epoch 83 Iteration 21340 - Train Loss: 0.000011 - Dev Loss: 0.679959\n",
            "Epoch 83 Iteration 21350 - Train Loss: 0.000010 - Dev Loss: 0.680164\n",
            "Epoch 83 Iteration 21360 - Train Loss: 0.000009 - Dev Loss: 0.680278\n",
            "Epoch 83 Iteration 21370 - Train Loss: 0.000011 - Dev Loss: 0.680321\n",
            "Epoch 83 Iteration 21380 - Train Loss: 0.000009 - Dev Loss: 0.680338\n",
            "Epoch 83 Iteration 21390 - Train Loss: 0.000010 - Dev Loss: 0.680395\n",
            "Epoch 83 Iteration 21400 - Train Loss: 0.000009 - Dev Loss: 0.680619\n",
            "Epoch 83 Iteration 21410 - Train Loss: 0.000009 - Dev Loss: 0.680834\n",
            "Epoch 83 Iteration 21420 - Train Loss: 0.000008 - Dev Loss: 0.681004\n",
            "Epoch 83 Iteration 21430 - Train Loss: 0.000009 - Dev Loss: 0.681090\n",
            "Epoch 83 Iteration 21440 - Train Loss: 0.000009 - Dev Loss: 0.681068\n",
            "Epoch 83 Iteration 21450 - Train Loss: 0.000010 - Dev Loss: 0.681563\n",
            "Epoch 83 Iteration 21460 - Train Loss: 0.000009 - Dev Loss: 0.681607\n",
            "Epoch 83 Iteration 21470 - Train Loss: 0.000008 - Dev Loss: 0.681840\n",
            "Epoch 83 Iteration 21480 - Train Loss: 0.000010 - Dev Loss: 0.682086\n",
            "Epoch 83 Iteration 21490 - Train Loss: 0.000010 - Dev Loss: 0.681953\n",
            "Epoch 83 Iteration 21500 - Train Loss: 0.000008 - Dev Loss: 0.681949\n",
            "Epoch 84 Iteration 21510 - Train Loss: 0.000007 - Dev Loss: 0.681982\n",
            "Epoch 84 Iteration 21520 - Train Loss: 0.000008 - Dev Loss: 0.682185\n",
            "Epoch 84 Iteration 21530 - Train Loss: 0.000008 - Dev Loss: 0.682361\n",
            "Epoch 84 Iteration 21540 - Train Loss: 0.000008 - Dev Loss: 0.682544\n",
            "Epoch 84 Iteration 21550 - Train Loss: 0.000009 - Dev Loss: 0.682620\n",
            "Epoch 84 Iteration 21560 - Train Loss: 0.000009 - Dev Loss: 0.682654\n",
            "Epoch 84 Iteration 21570 - Train Loss: 0.000009 - Dev Loss: 0.682778\n",
            "Epoch 84 Iteration 21580 - Train Loss: 0.000009 - Dev Loss: 0.682861\n",
            "Epoch 84 Iteration 21590 - Train Loss: 0.000006 - Dev Loss: 0.682888\n",
            "Epoch 84 Iteration 21600 - Train Loss: 0.000008 - Dev Loss: 0.682914\n",
            "Epoch 84 Iteration 21610 - Train Loss: 0.000007 - Dev Loss: 0.683065\n",
            "Epoch 84 Iteration 21620 - Train Loss: 0.000010 - Dev Loss: 0.683194\n",
            "Epoch 84 Iteration 21630 - Train Loss: 0.000008 - Dev Loss: 0.683278\n",
            "Epoch 84 Iteration 21640 - Train Loss: 0.000008 - Dev Loss: 0.683524\n",
            "Epoch 84 Iteration 21650 - Train Loss: 0.000009 - Dev Loss: 0.683943\n",
            "Epoch 84 Iteration 21660 - Train Loss: 0.000010 - Dev Loss: 0.684132\n",
            "Epoch 84 Iteration 21670 - Train Loss: 0.000007 - Dev Loss: 0.684262\n",
            "Epoch 84 Iteration 21680 - Train Loss: 0.000008 - Dev Loss: 0.684586\n",
            "Epoch 84 Iteration 21690 - Train Loss: 0.000008 - Dev Loss: 0.684763\n",
            "Epoch 84 Iteration 21700 - Train Loss: 0.000007 - Dev Loss: 0.684669\n",
            "Epoch 84 Iteration 21710 - Train Loss: 0.000007 - Dev Loss: 0.684704\n",
            "Epoch 84 Iteration 21720 - Train Loss: 0.000010 - Dev Loss: 0.684864\n",
            "Epoch 84 Iteration 21730 - Train Loss: 0.000007 - Dev Loss: 0.684783\n",
            "Epoch 84 Iteration 21740 - Train Loss: 0.000009 - Dev Loss: 0.684719\n",
            "Epoch 84 Iteration 21750 - Train Loss: 0.000007 - Dev Loss: 0.684777\n",
            "Epoch 85 Iteration 21760 - Train Loss: 0.000008 - Dev Loss: 0.684742\n",
            "Epoch 85 Iteration 21770 - Train Loss: 0.000007 - Dev Loss: 0.684831\n",
            "Epoch 85 Iteration 21780 - Train Loss: 0.000008 - Dev Loss: 0.684965\n",
            "Epoch 85 Iteration 21790 - Train Loss: 0.000008 - Dev Loss: 0.684976\n",
            "Epoch 85 Iteration 21800 - Train Loss: 0.000008 - Dev Loss: 0.685026\n",
            "Epoch 85 Iteration 21810 - Train Loss: 0.000010 - Dev Loss: 0.685367\n",
            "Epoch 85 Iteration 21820 - Train Loss: 0.000007 - Dev Loss: 0.685785\n",
            "Epoch 85 Iteration 21830 - Train Loss: 0.000007 - Dev Loss: 0.685972\n",
            "Epoch 85 Iteration 21840 - Train Loss: 0.000007 - Dev Loss: 0.686204\n",
            "Epoch 85 Iteration 21850 - Train Loss: 0.000007 - Dev Loss: 0.686486\n",
            "Epoch 85 Iteration 21860 - Train Loss: 0.000006 - Dev Loss: 0.686658\n",
            "Epoch 85 Iteration 21870 - Train Loss: 0.000008 - Dev Loss: 0.686707\n",
            "Epoch 85 Iteration 21880 - Train Loss: 0.000008 - Dev Loss: 0.686758\n",
            "Epoch 85 Iteration 21890 - Train Loss: 0.000009 - Dev Loss: 0.686860\n",
            "Epoch 85 Iteration 21900 - Train Loss: 0.000006 - Dev Loss: 0.686923\n",
            "Epoch 85 Iteration 21910 - Train Loss: 0.000007 - Dev Loss: 0.686963\n",
            "Epoch 85 Iteration 21920 - Train Loss: 0.000008 - Dev Loss: 0.687084\n",
            "Epoch 85 Iteration 21930 - Train Loss: 0.000007 - Dev Loss: 0.687143\n",
            "Epoch 85 Iteration 21940 - Train Loss: 0.000006 - Dev Loss: 0.687338\n",
            "Epoch 85 Iteration 21950 - Train Loss: 0.000007 - Dev Loss: 0.687463\n",
            "Epoch 85 Iteration 21960 - Train Loss: 0.000009 - Dev Loss: 0.687543\n",
            "Epoch 85 Iteration 21970 - Train Loss: 0.000008 - Dev Loss: 0.687689\n",
            "Epoch 85 Iteration 21980 - Train Loss: 0.000008 - Dev Loss: 0.687772\n",
            "Epoch 85 Iteration 21990 - Train Loss: 0.000007 - Dev Loss: 0.687720\n",
            "Epoch 85 Iteration 22000 - Train Loss: 0.000008 - Dev Loss: 0.687759\n",
            "Epoch 85 Iteration 22010 - Train Loss: 0.000008 - Dev Loss: 0.688155\n",
            "Epoch 86 Iteration 22020 - Train Loss: 0.000008 - Dev Loss: 0.688274\n",
            "Epoch 86 Iteration 22030 - Train Loss: 0.000007 - Dev Loss: 0.688117\n",
            "Epoch 86 Iteration 22040 - Train Loss: 0.000007 - Dev Loss: 0.688132\n",
            "Epoch 86 Iteration 22050 - Train Loss: 0.000006 - Dev Loss: 0.688189\n",
            "Epoch 86 Iteration 22060 - Train Loss: 0.000010 - Dev Loss: 0.688535\n",
            "Epoch 86 Iteration 22070 - Train Loss: 0.000006 - Dev Loss: 0.688718\n",
            "Epoch 86 Iteration 22080 - Train Loss: 0.000006 - Dev Loss: 0.688792\n",
            "Epoch 86 Iteration 22090 - Train Loss: 0.000007 - Dev Loss: 0.689099\n",
            "Epoch 86 Iteration 22100 - Train Loss: 0.000007 - Dev Loss: 0.689416\n",
            "Epoch 86 Iteration 22110 - Train Loss: 0.000007 - Dev Loss: 0.689728\n",
            "Epoch 86 Iteration 22120 - Train Loss: 0.000007 - Dev Loss: 0.689774\n",
            "Epoch 86 Iteration 22130 - Train Loss: 0.000007 - Dev Loss: 0.689665\n",
            "Epoch 86 Iteration 22140 - Train Loss: 0.000007 - Dev Loss: 0.689752\n",
            "Epoch 86 Iteration 22150 - Train Loss: 0.000006 - Dev Loss: 0.689763\n",
            "Epoch 86 Iteration 22160 - Train Loss: 0.000007 - Dev Loss: 0.689845\n",
            "Epoch 86 Iteration 22170 - Train Loss: 0.000005 - Dev Loss: 0.690102\n",
            "Epoch 86 Iteration 22180 - Train Loss: 0.000007 - Dev Loss: 0.690255\n",
            "Epoch 86 Iteration 22190 - Train Loss: 0.000007 - Dev Loss: 0.690678\n",
            "Epoch 86 Iteration 22200 - Train Loss: 0.000008 - Dev Loss: 0.690808\n",
            "Epoch 86 Iteration 22210 - Train Loss: 0.000007 - Dev Loss: 0.690906\n",
            "Epoch 86 Iteration 22220 - Train Loss: 0.000006 - Dev Loss: 0.691046\n",
            "Epoch 86 Iteration 22230 - Train Loss: 0.000007 - Dev Loss: 0.690899\n",
            "Epoch 86 Iteration 22240 - Train Loss: 0.000007 - Dev Loss: 0.690998\n",
            "Epoch 86 Iteration 22250 - Train Loss: 0.000007 - Dev Loss: 0.691037\n",
            "Epoch 86 Iteration 22260 - Train Loss: 0.000006 - Dev Loss: 0.691320\n",
            "Epoch 86 Iteration 22270 - Train Loss: 0.000007 - Dev Loss: 0.691386\n",
            "Epoch 87 Iteration 22280 - Train Loss: 0.000007 - Dev Loss: 0.691525\n",
            "Epoch 87 Iteration 22290 - Train Loss: 0.000006 - Dev Loss: 0.691798\n",
            "Epoch 87 Iteration 22300 - Train Loss: 0.000005 - Dev Loss: 0.692143\n",
            "Epoch 87 Iteration 22310 - Train Loss: 0.000006 - Dev Loss: 0.692294\n",
            "Epoch 87 Iteration 22320 - Train Loss: 0.000006 - Dev Loss: 0.692095\n",
            "Epoch 87 Iteration 22330 - Train Loss: 0.000006 - Dev Loss: 0.691991\n",
            "Epoch 87 Iteration 22340 - Train Loss: 0.000007 - Dev Loss: 0.691932\n",
            "Epoch 87 Iteration 22350 - Train Loss: 0.000006 - Dev Loss: 0.691951\n",
            "Epoch 87 Iteration 22360 - Train Loss: 0.000006 - Dev Loss: 0.692209\n",
            "Epoch 87 Iteration 22370 - Train Loss: 0.000006 - Dev Loss: 0.692572\n",
            "Epoch 87 Iteration 22380 - Train Loss: 0.000006 - Dev Loss: 0.692919\n",
            "Epoch 87 Iteration 22390 - Train Loss: 0.000007 - Dev Loss: 0.693431\n",
            "Epoch 87 Iteration 22400 - Train Loss: 0.000006 - Dev Loss: 0.693801\n",
            "Epoch 87 Iteration 22410 - Train Loss: 0.000007 - Dev Loss: 0.694147\n",
            "Epoch 87 Iteration 22420 - Train Loss: 0.000006 - Dev Loss: 0.694380\n",
            "Epoch 87 Iteration 22430 - Train Loss: 0.000006 - Dev Loss: 0.694279\n",
            "Epoch 87 Iteration 22440 - Train Loss: 0.000006 - Dev Loss: 0.694454\n",
            "Epoch 87 Iteration 22450 - Train Loss: 0.000006 - Dev Loss: 0.694375\n",
            "Epoch 87 Iteration 22460 - Train Loss: 0.000005 - Dev Loss: 0.694450\n",
            "Epoch 87 Iteration 22470 - Train Loss: 0.000007 - Dev Loss: 0.694375\n",
            "Epoch 87 Iteration 22480 - Train Loss: 0.000006 - Dev Loss: 0.694307\n",
            "Epoch 87 Iteration 22490 - Train Loss: 0.000006 - Dev Loss: 0.694389\n",
            "Epoch 87 Iteration 22500 - Train Loss: 0.000006 - Dev Loss: 0.694525\n",
            "Epoch 87 Iteration 22510 - Train Loss: 0.000006 - Dev Loss: 0.694497\n",
            "Epoch 87 Iteration 22520 - Train Loss: 0.000006 - Dev Loss: 0.694735\n",
            "Epoch 88 Iteration 22530 - Train Loss: 0.000005 - Dev Loss: 0.694845\n",
            "Epoch 88 Iteration 22540 - Train Loss: 0.000007 - Dev Loss: 0.694843\n",
            "Epoch 88 Iteration 22550 - Train Loss: 0.000005 - Dev Loss: 0.694907\n",
            "Epoch 88 Iteration 22560 - Train Loss: 0.000007 - Dev Loss: 0.695087\n",
            "Epoch 88 Iteration 22570 - Train Loss: 0.000006 - Dev Loss: 0.695130\n",
            "Epoch 88 Iteration 22580 - Train Loss: 0.000005 - Dev Loss: 0.695188\n",
            "Epoch 88 Iteration 22590 - Train Loss: 0.000006 - Dev Loss: 0.695310\n",
            "Epoch 88 Iteration 22600 - Train Loss: 0.000005 - Dev Loss: 0.695598\n",
            "Epoch 88 Iteration 22610 - Train Loss: 0.000005 - Dev Loss: 0.695955\n",
            "Epoch 88 Iteration 22620 - Train Loss: 0.000006 - Dev Loss: 0.696279\n",
            "Epoch 88 Iteration 22630 - Train Loss: 0.000005 - Dev Loss: 0.696438\n",
            "Epoch 88 Iteration 22640 - Train Loss: 0.000006 - Dev Loss: 0.696622\n",
            "Epoch 88 Iteration 22650 - Train Loss: 0.000006 - Dev Loss: 0.696572\n",
            "Epoch 88 Iteration 22660 - Train Loss: 0.000005 - Dev Loss: 0.696270\n",
            "Epoch 88 Iteration 22670 - Train Loss: 0.000006 - Dev Loss: 0.696050\n",
            "Epoch 88 Iteration 22680 - Train Loss: 0.000006 - Dev Loss: 0.695903\n",
            "Epoch 88 Iteration 22690 - Train Loss: 0.000005 - Dev Loss: 0.696080\n",
            "Epoch 88 Iteration 22700 - Train Loss: 0.000005 - Dev Loss: 0.696336\n",
            "Epoch 88 Iteration 22710 - Train Loss: 0.000006 - Dev Loss: 0.696499\n",
            "Epoch 88 Iteration 22720 - Train Loss: 0.000006 - Dev Loss: 0.697223\n",
            "Epoch 88 Iteration 22730 - Train Loss: 0.000005 - Dev Loss: 0.697580\n",
            "Epoch 88 Iteration 22740 - Train Loss: 0.000006 - Dev Loss: 0.697789\n",
            "Epoch 88 Iteration 22750 - Train Loss: 0.000005 - Dev Loss: 0.697763\n",
            "Epoch 88 Iteration 22760 - Train Loss: 0.000006 - Dev Loss: 0.697899\n",
            "Epoch 88 Iteration 22770 - Train Loss: 0.000006 - Dev Loss: 0.698556\n",
            "Epoch 88 Iteration 22780 - Train Loss: 0.000006 - Dev Loss: 0.699088\n",
            "Epoch 89 Iteration 22790 - Train Loss: 0.000005 - Dev Loss: 0.699404\n",
            "Epoch 89 Iteration 22800 - Train Loss: 0.000004 - Dev Loss: 0.699386\n",
            "Epoch 89 Iteration 22810 - Train Loss: 0.000006 - Dev Loss: 0.699154\n",
            "Epoch 89 Iteration 22820 - Train Loss: 0.000005 - Dev Loss: 0.699163\n",
            "Epoch 89 Iteration 22830 - Train Loss: 0.000005 - Dev Loss: 0.699434\n",
            "Epoch 89 Iteration 22840 - Train Loss: 0.000005 - Dev Loss: 0.699258\n",
            "Epoch 89 Iteration 22850 - Train Loss: 0.000005 - Dev Loss: 0.699155\n",
            "Epoch 89 Iteration 22860 - Train Loss: 0.000005 - Dev Loss: 0.698976\n",
            "Epoch 89 Iteration 22870 - Train Loss: 0.000005 - Dev Loss: 0.699096\n",
            "Epoch 89 Iteration 22880 - Train Loss: 0.000005 - Dev Loss: 0.699155\n",
            "Epoch 89 Iteration 22890 - Train Loss: 0.000005 - Dev Loss: 0.699144\n",
            "Epoch 89 Iteration 22900 - Train Loss: 0.000005 - Dev Loss: 0.699061\n",
            "Epoch 89 Iteration 22910 - Train Loss: 0.000006 - Dev Loss: 0.699402\n",
            "Epoch 89 Iteration 22920 - Train Loss: 0.000005 - Dev Loss: 0.699787\n",
            "Epoch 89 Iteration 22930 - Train Loss: 0.000005 - Dev Loss: 0.700066\n",
            "Epoch 89 Iteration 22940 - Train Loss: 0.000005 - Dev Loss: 0.700386\n",
            "Epoch 89 Iteration 22950 - Train Loss: 0.000004 - Dev Loss: 0.700826\n",
            "Epoch 89 Iteration 22960 - Train Loss: 0.000005 - Dev Loss: 0.701082\n",
            "Epoch 89 Iteration 22970 - Train Loss: 0.000005 - Dev Loss: 0.700966\n",
            "Epoch 89 Iteration 22980 - Train Loss: 0.000005 - Dev Loss: 0.700856\n",
            "Epoch 89 Iteration 22990 - Train Loss: 0.000005 - Dev Loss: 0.701167\n",
            "Epoch 89 Iteration 23000 - Train Loss: 0.000005 - Dev Loss: 0.701387\n",
            "Epoch 89 Iteration 23010 - Train Loss: 0.000006 - Dev Loss: 0.701404\n",
            "Epoch 89 Iteration 23020 - Train Loss: 0.000005 - Dev Loss: 0.701645\n",
            "Epoch 89 Iteration 23030 - Train Loss: 0.000005 - Dev Loss: 0.702198\n",
            "Epoch 90 Iteration 23040 - Train Loss: 0.000005 - Dev Loss: 0.702841\n",
            "Epoch 90 Iteration 23050 - Train Loss: 0.000004 - Dev Loss: 0.703334\n",
            "Epoch 90 Iteration 23060 - Train Loss: 0.000005 - Dev Loss: 0.703469\n",
            "Epoch 90 Iteration 23070 - Train Loss: 0.000004 - Dev Loss: 0.703440\n",
            "Epoch 90 Iteration 23080 - Train Loss: 0.000005 - Dev Loss: 0.703565\n",
            "Epoch 90 Iteration 23090 - Train Loss: 0.000005 - Dev Loss: 0.703699\n",
            "Epoch 90 Iteration 23100 - Train Loss: 0.000004 - Dev Loss: 0.703772\n",
            "Epoch 90 Iteration 23110 - Train Loss: 0.000004 - Dev Loss: 0.703899\n",
            "Epoch 90 Iteration 23120 - Train Loss: 0.000004 - Dev Loss: 0.704008\n",
            "Epoch 90 Iteration 23130 - Train Loss: 0.000004 - Dev Loss: 0.704125\n",
            "Epoch 90 Iteration 23140 - Train Loss: 0.000004 - Dev Loss: 0.704418\n",
            "Epoch 90 Iteration 23150 - Train Loss: 0.000005 - Dev Loss: 0.704583\n",
            "Epoch 90 Iteration 23160 - Train Loss: 0.000004 - Dev Loss: 0.704705\n",
            "Epoch 90 Iteration 23170 - Train Loss: 0.000006 - Dev Loss: 0.704235\n",
            "Epoch 90 Iteration 23180 - Train Loss: 0.000005 - Dev Loss: 0.704023\n",
            "Epoch 90 Iteration 23190 - Train Loss: 0.000005 - Dev Loss: 0.704084\n",
            "Epoch 90 Iteration 23200 - Train Loss: 0.000005 - Dev Loss: 0.704150\n",
            "Epoch 90 Iteration 23210 - Train Loss: 0.000005 - Dev Loss: 0.704400\n",
            "Epoch 90 Iteration 23220 - Train Loss: 0.000004 - Dev Loss: 0.704638\n",
            "Epoch 90 Iteration 23230 - Train Loss: 0.000004 - Dev Loss: 0.704948\n",
            "Epoch 90 Iteration 23240 - Train Loss: 0.000004 - Dev Loss: 0.705291\n",
            "Epoch 90 Iteration 23250 - Train Loss: 0.000004 - Dev Loss: 0.705694\n",
            "Epoch 90 Iteration 23260 - Train Loss: 0.000004 - Dev Loss: 0.705784\n",
            "Epoch 90 Iteration 23270 - Train Loss: 0.000004 - Dev Loss: 0.705656\n",
            "Epoch 90 Iteration 23280 - Train Loss: 0.000005 - Dev Loss: 0.705318\n",
            "Epoch 90 Iteration 23290 - Train Loss: 0.000005 - Dev Loss: 0.705248\n",
            "Epoch 91 Iteration 23300 - Train Loss: 0.000004 - Dev Loss: 0.705494\n",
            "Epoch 91 Iteration 23310 - Train Loss: 0.000004 - Dev Loss: 0.706026\n",
            "Epoch 91 Iteration 23320 - Train Loss: 0.000004 - Dev Loss: 0.706586\n",
            "Epoch 91 Iteration 23330 - Train Loss: 0.000005 - Dev Loss: 0.706839\n",
            "Epoch 91 Iteration 23340 - Train Loss: 0.000004 - Dev Loss: 0.706924\n",
            "Epoch 91 Iteration 23350 - Train Loss: 0.000004 - Dev Loss: 0.706979\n",
            "Epoch 91 Iteration 23360 - Train Loss: 0.000004 - Dev Loss: 0.706881\n",
            "Epoch 91 Iteration 23370 - Train Loss: 0.000004 - Dev Loss: 0.707049\n",
            "Epoch 91 Iteration 23380 - Train Loss: 0.000004 - Dev Loss: 0.707195\n",
            "Epoch 91 Iteration 23390 - Train Loss: 0.000004 - Dev Loss: 0.707361\n",
            "Epoch 91 Iteration 23400 - Train Loss: 0.000004 - Dev Loss: 0.707591\n",
            "Epoch 91 Iteration 23410 - Train Loss: 0.000004 - Dev Loss: 0.707761\n",
            "Epoch 91 Iteration 23420 - Train Loss: 0.000004 - Dev Loss: 0.707577\n",
            "Epoch 91 Iteration 23430 - Train Loss: 0.000004 - Dev Loss: 0.707718\n",
            "Epoch 91 Iteration 23440 - Train Loss: 0.000004 - Dev Loss: 0.708049\n",
            "Epoch 91 Iteration 23450 - Train Loss: 0.000004 - Dev Loss: 0.707930\n",
            "Epoch 91 Iteration 23460 - Train Loss: 0.000004 - Dev Loss: 0.707958\n",
            "Epoch 91 Iteration 23470 - Train Loss: 0.000004 - Dev Loss: 0.707900\n",
            "Epoch 91 Iteration 23480 - Train Loss: 0.000004 - Dev Loss: 0.707990\n",
            "Epoch 91 Iteration 23490 - Train Loss: 0.000004 - Dev Loss: 0.708236\n",
            "Epoch 91 Iteration 23500 - Train Loss: 0.000004 - Dev Loss: 0.708508\n",
            "Epoch 91 Iteration 23510 - Train Loss: 0.000005 - Dev Loss: 0.708828\n",
            "Epoch 91 Iteration 23520 - Train Loss: 0.000003 - Dev Loss: 0.709380\n",
            "Epoch 91 Iteration 23530 - Train Loss: 0.000004 - Dev Loss: 0.709632\n",
            "Epoch 91 Iteration 23540 - Train Loss: 0.000004 - Dev Loss: 0.709797\n",
            "Epoch 91 Iteration 23550 - Train Loss: 0.000004 - Dev Loss: 0.710079\n",
            "Epoch 92 Iteration 23560 - Train Loss: 0.000004 - Dev Loss: 0.710218\n",
            "Epoch 92 Iteration 23570 - Train Loss: 0.000004 - Dev Loss: 0.710155\n",
            "Epoch 92 Iteration 23580 - Train Loss: 0.000004 - Dev Loss: 0.710372\n",
            "Epoch 92 Iteration 23590 - Train Loss: 0.000003 - Dev Loss: 0.710521\n",
            "Epoch 92 Iteration 23600 - Train Loss: 0.000004 - Dev Loss: 0.710484\n",
            "Epoch 92 Iteration 23610 - Train Loss: 0.000003 - Dev Loss: 0.710690\n",
            "Epoch 92 Iteration 23620 - Train Loss: 0.000004 - Dev Loss: 0.710841\n",
            "Epoch 92 Iteration 23630 - Train Loss: 0.000004 - Dev Loss: 0.711103\n",
            "Epoch 92 Iteration 23640 - Train Loss: 0.000003 - Dev Loss: 0.711137\n",
            "Epoch 92 Iteration 23650 - Train Loss: 0.000004 - Dev Loss: 0.710930\n",
            "Epoch 92 Iteration 23660 - Train Loss: 0.000004 - Dev Loss: 0.710785\n",
            "Epoch 92 Iteration 23670 - Train Loss: 0.000003 - Dev Loss: 0.710928\n",
            "Epoch 92 Iteration 23680 - Train Loss: 0.000003 - Dev Loss: 0.711190\n",
            "Epoch 92 Iteration 23690 - Train Loss: 0.000004 - Dev Loss: 0.711410\n",
            "Epoch 92 Iteration 23700 - Train Loss: 0.000003 - Dev Loss: 0.711595\n",
            "Epoch 92 Iteration 23710 - Train Loss: 0.000004 - Dev Loss: 0.711805\n",
            "Epoch 92 Iteration 23720 - Train Loss: 0.000003 - Dev Loss: 0.712031\n",
            "Epoch 92 Iteration 23730 - Train Loss: 0.000004 - Dev Loss: 0.712215\n",
            "Epoch 92 Iteration 23740 - Train Loss: 0.000004 - Dev Loss: 0.712496\n",
            "Epoch 92 Iteration 23750 - Train Loss: 0.000004 - Dev Loss: 0.712868\n",
            "Epoch 92 Iteration 23760 - Train Loss: 0.000003 - Dev Loss: 0.713187\n",
            "Epoch 92 Iteration 23770 - Train Loss: 0.000005 - Dev Loss: 0.713277\n",
            "Epoch 92 Iteration 23780 - Train Loss: 0.000004 - Dev Loss: 0.713598\n",
            "Epoch 92 Iteration 23790 - Train Loss: 0.000004 - Dev Loss: 0.713802\n",
            "Epoch 92 Iteration 23800 - Train Loss: 0.000004 - Dev Loss: 0.713894\n",
            "Epoch 93 Iteration 23810 - Train Loss: 0.000004 - Dev Loss: 0.714208\n",
            "Epoch 93 Iteration 23820 - Train Loss: 0.000003 - Dev Loss: 0.714547\n",
            "Epoch 93 Iteration 23830 - Train Loss: 0.000003 - Dev Loss: 0.714906\n",
            "Epoch 93 Iteration 23840 - Train Loss: 0.000003 - Dev Loss: 0.715274\n",
            "Epoch 93 Iteration 23850 - Train Loss: 0.000003 - Dev Loss: 0.715593\n",
            "Epoch 93 Iteration 23860 - Train Loss: 0.000004 - Dev Loss: 0.715700\n",
            "Epoch 93 Iteration 23870 - Train Loss: 0.000003 - Dev Loss: 0.715497\n",
            "Epoch 93 Iteration 23880 - Train Loss: 0.000003 - Dev Loss: 0.715343\n",
            "Epoch 93 Iteration 23890 - Train Loss: 0.000003 - Dev Loss: 0.715478\n",
            "Epoch 93 Iteration 23900 - Train Loss: 0.000003 - Dev Loss: 0.715773\n",
            "Epoch 93 Iteration 23910 - Train Loss: 0.000003 - Dev Loss: 0.715809\n",
            "Epoch 93 Iteration 23920 - Train Loss: 0.000004 - Dev Loss: 0.715845\n",
            "Epoch 93 Iteration 23930 - Train Loss: 0.000004 - Dev Loss: 0.715622\n",
            "Epoch 93 Iteration 23940 - Train Loss: 0.000003 - Dev Loss: 0.715727\n",
            "Epoch 93 Iteration 23950 - Train Loss: 0.000003 - Dev Loss: 0.715950\n",
            "Epoch 93 Iteration 23960 - Train Loss: 0.000003 - Dev Loss: 0.716321\n",
            "Epoch 93 Iteration 23970 - Train Loss: 0.000003 - Dev Loss: 0.716270\n",
            "Epoch 93 Iteration 23980 - Train Loss: 0.000003 - Dev Loss: 0.716406\n",
            "Epoch 93 Iteration 23990 - Train Loss: 0.000003 - Dev Loss: 0.716667\n",
            "Epoch 93 Iteration 24000 - Train Loss: 0.000003 - Dev Loss: 0.716731\n",
            "Epoch 93 Iteration 24010 - Train Loss: 0.000004 - Dev Loss: 0.716906\n",
            "Epoch 93 Iteration 24020 - Train Loss: 0.000004 - Dev Loss: 0.716807\n",
            "Epoch 93 Iteration 24030 - Train Loss: 0.000003 - Dev Loss: 0.716800\n",
            "Epoch 93 Iteration 24040 - Train Loss: 0.000003 - Dev Loss: 0.716724\n",
            "Epoch 93 Iteration 24050 - Train Loss: 0.000003 - Dev Loss: 0.716873\n",
            "Epoch 93 Iteration 24060 - Train Loss: 0.000003 - Dev Loss: 0.717239\n",
            "Epoch 94 Iteration 24070 - Train Loss: 0.000003 - Dev Loss: 0.717679\n",
            "Epoch 94 Iteration 24080 - Train Loss: 0.000003 - Dev Loss: 0.717891\n",
            "Epoch 94 Iteration 24090 - Train Loss: 0.000003 - Dev Loss: 0.718082\n",
            "Epoch 94 Iteration 24100 - Train Loss: 0.000003 - Dev Loss: 0.718263\n",
            "Epoch 94 Iteration 24110 - Train Loss: 0.000003 - Dev Loss: 0.718716\n",
            "Epoch 94 Iteration 24120 - Train Loss: 0.000003 - Dev Loss: 0.719100\n",
            "Epoch 94 Iteration 24130 - Train Loss: 0.000003 - Dev Loss: 0.719404\n",
            "Epoch 94 Iteration 24140 - Train Loss: 0.000003 - Dev Loss: 0.720039\n",
            "Epoch 94 Iteration 24150 - Train Loss: 0.000003 - Dev Loss: 0.720275\n",
            "Epoch 94 Iteration 24160 - Train Loss: 0.000003 - Dev Loss: 0.720186\n",
            "Epoch 94 Iteration 24170 - Train Loss: 0.000003 - Dev Loss: 0.720099\n",
            "Epoch 94 Iteration 24180 - Train Loss: 0.000003 - Dev Loss: 0.720287\n",
            "Epoch 94 Iteration 24190 - Train Loss: 0.000003 - Dev Loss: 0.720730\n",
            "Epoch 94 Iteration 24200 - Train Loss: 0.000003 - Dev Loss: 0.721403\n",
            "Epoch 94 Iteration 24210 - Train Loss: 0.000003 - Dev Loss: 0.721599\n",
            "Epoch 94 Iteration 24220 - Train Loss: 0.000003 - Dev Loss: 0.721670\n",
            "Epoch 94 Iteration 24230 - Train Loss: 0.000003 - Dev Loss: 0.721602\n",
            "Epoch 94 Iteration 24240 - Train Loss: 0.000003 - Dev Loss: 0.721483\n",
            "Epoch 94 Iteration 24250 - Train Loss: 0.000003 - Dev Loss: 0.721601\n",
            "Epoch 94 Iteration 24260 - Train Loss: 0.000003 - Dev Loss: 0.721957\n",
            "Epoch 94 Iteration 24270 - Train Loss: 0.000002 - Dev Loss: 0.722122\n",
            "Epoch 94 Iteration 24280 - Train Loss: 0.000003 - Dev Loss: 0.722192\n",
            "Epoch 94 Iteration 24290 - Train Loss: 0.000003 - Dev Loss: 0.722069\n",
            "Epoch 94 Iteration 24300 - Train Loss: 0.000003 - Dev Loss: 0.722202\n",
            "Epoch 94 Iteration 24310 - Train Loss: 0.000003 - Dev Loss: 0.722131\n",
            "Epoch 95 Iteration 24320 - Train Loss: 0.000003 - Dev Loss: 0.722030\n",
            "Epoch 95 Iteration 24330 - Train Loss: 0.000002 - Dev Loss: 0.722123\n",
            "Epoch 95 Iteration 24340 - Train Loss: 0.000003 - Dev Loss: 0.722302\n",
            "Epoch 95 Iteration 24350 - Train Loss: 0.000003 - Dev Loss: 0.722345\n",
            "Epoch 95 Iteration 24360 - Train Loss: 0.000003 - Dev Loss: 0.722762\n",
            "Epoch 95 Iteration 24370 - Train Loss: 0.000003 - Dev Loss: 0.722731\n",
            "Epoch 95 Iteration 24380 - Train Loss: 0.000003 - Dev Loss: 0.722990\n",
            "Epoch 95 Iteration 24390 - Train Loss: 0.000002 - Dev Loss: 0.723325\n",
            "Epoch 95 Iteration 24400 - Train Loss: 0.000003 - Dev Loss: 0.723605\n",
            "Epoch 95 Iteration 24410 - Train Loss: 0.000003 - Dev Loss: 0.723931\n",
            "Epoch 95 Iteration 24420 - Train Loss: 0.000003 - Dev Loss: 0.724175\n",
            "Epoch 95 Iteration 24430 - Train Loss: 0.000003 - Dev Loss: 0.724308\n",
            "Epoch 95 Iteration 24440 - Train Loss: 0.000002 - Dev Loss: 0.724353\n",
            "Epoch 95 Iteration 24450 - Train Loss: 0.000003 - Dev Loss: 0.724252\n",
            "Epoch 95 Iteration 24460 - Train Loss: 0.000003 - Dev Loss: 0.724266\n",
            "Epoch 95 Iteration 24470 - Train Loss: 0.000002 - Dev Loss: 0.724446\n",
            "Epoch 95 Iteration 24480 - Train Loss: 0.000002 - Dev Loss: 0.724625\n",
            "Epoch 95 Iteration 24490 - Train Loss: 0.000003 - Dev Loss: 0.724930\n",
            "Epoch 95 Iteration 24500 - Train Loss: 0.000002 - Dev Loss: 0.725317\n",
            "Epoch 95 Iteration 24510 - Train Loss: 0.000002 - Dev Loss: 0.725794\n",
            "Epoch 95 Iteration 24520 - Train Loss: 0.000003 - Dev Loss: 0.726064\n",
            "Epoch 95 Iteration 24530 - Train Loss: 0.000003 - Dev Loss: 0.726804\n",
            "Epoch 95 Iteration 24540 - Train Loss: 0.000003 - Dev Loss: 0.727227\n",
            "Epoch 95 Iteration 24550 - Train Loss: 0.000003 - Dev Loss: 0.727231\n",
            "Epoch 95 Iteration 24560 - Train Loss: 0.000003 - Dev Loss: 0.727276\n",
            "Epoch 95 Iteration 24570 - Train Loss: 0.000002 - Dev Loss: 0.727213\n",
            "Epoch 96 Iteration 24580 - Train Loss: 0.000003 - Dev Loss: 0.727215\n",
            "Epoch 96 Iteration 24590 - Train Loss: 0.000002 - Dev Loss: 0.727511\n",
            "Epoch 96 Iteration 24600 - Train Loss: 0.000002 - Dev Loss: 0.727863\n",
            "Epoch 96 Iteration 24610 - Train Loss: 0.000002 - Dev Loss: 0.727988\n",
            "Epoch 96 Iteration 24620 - Train Loss: 0.000003 - Dev Loss: 0.728199\n",
            "Epoch 96 Iteration 24630 - Train Loss: 0.000002 - Dev Loss: 0.728331\n",
            "Epoch 96 Iteration 24640 - Train Loss: 0.000002 - Dev Loss: 0.728311\n",
            "Epoch 96 Iteration 24650 - Train Loss: 0.000002 - Dev Loss: 0.728306\n",
            "Epoch 96 Iteration 24660 - Train Loss: 0.000002 - Dev Loss: 0.728452\n",
            "Epoch 96 Iteration 24670 - Train Loss: 0.000002 - Dev Loss: 0.728567\n",
            "Epoch 96 Iteration 24680 - Train Loss: 0.000003 - Dev Loss: 0.728611\n",
            "Epoch 96 Iteration 24690 - Train Loss: 0.000002 - Dev Loss: 0.728644\n",
            "Epoch 96 Iteration 24700 - Train Loss: 0.000002 - Dev Loss: 0.729003\n",
            "Epoch 96 Iteration 24710 - Train Loss: 0.000003 - Dev Loss: 0.729438\n",
            "Epoch 96 Iteration 24720 - Train Loss: 0.000002 - Dev Loss: 0.729798\n",
            "Epoch 96 Iteration 24730 - Train Loss: 0.000003 - Dev Loss: 0.730048\n",
            "Epoch 96 Iteration 24740 - Train Loss: 0.000003 - Dev Loss: 0.730418\n",
            "Epoch 96 Iteration 24750 - Train Loss: 0.000003 - Dev Loss: 0.730516\n",
            "Epoch 96 Iteration 24760 - Train Loss: 0.000002 - Dev Loss: 0.730476\n",
            "Epoch 96 Iteration 24770 - Train Loss: 0.000002 - Dev Loss: 0.731176\n",
            "Epoch 96 Iteration 24780 - Train Loss: 0.000002 - Dev Loss: 0.731583\n",
            "Epoch 96 Iteration 24790 - Train Loss: 0.000003 - Dev Loss: 0.731337\n",
            "Epoch 96 Iteration 24800 - Train Loss: 0.000003 - Dev Loss: 0.731088\n",
            "Epoch 96 Iteration 24810 - Train Loss: 0.000002 - Dev Loss: 0.730998\n",
            "Epoch 96 Iteration 24820 - Train Loss: 0.000002 - Dev Loss: 0.730853\n",
            "Epoch 96 Iteration 24830 - Train Loss: 0.000002 - Dev Loss: 0.730544\n",
            "Epoch 97 Iteration 24840 - Train Loss: 0.000002 - Dev Loss: 0.730415\n",
            "Epoch 97 Iteration 24850 - Train Loss: 0.000002 - Dev Loss: 0.731081\n",
            "Epoch 97 Iteration 24860 - Train Loss: 0.000002 - Dev Loss: 0.731812\n",
            "Epoch 97 Iteration 24870 - Train Loss: 0.000002 - Dev Loss: 0.732267\n",
            "Epoch 97 Iteration 24880 - Train Loss: 0.000002 - Dev Loss: 0.732395\n",
            "Epoch 97 Iteration 24890 - Train Loss: 0.000002 - Dev Loss: 0.732380\n",
            "Epoch 97 Iteration 24900 - Train Loss: 0.000002 - Dev Loss: 0.732315\n",
            "Epoch 97 Iteration 24910 - Train Loss: 0.000002 - Dev Loss: 0.732662\n",
            "Epoch 97 Iteration 24920 - Train Loss: 0.000002 - Dev Loss: 0.732848\n",
            "Epoch 97 Iteration 24930 - Train Loss: 0.000002 - Dev Loss: 0.733028\n",
            "Epoch 97 Iteration 24940 - Train Loss: 0.000002 - Dev Loss: 0.733240\n",
            "Epoch 97 Iteration 24950 - Train Loss: 0.000002 - Dev Loss: 0.733341\n",
            "Epoch 97 Iteration 24960 - Train Loss: 0.000002 - Dev Loss: 0.733399\n",
            "Epoch 97 Iteration 24970 - Train Loss: 0.000002 - Dev Loss: 0.733586\n",
            "Epoch 97 Iteration 24980 - Train Loss: 0.000002 - Dev Loss: 0.734079\n",
            "Epoch 97 Iteration 24990 - Train Loss: 0.000002 - Dev Loss: 0.734504\n",
            "Epoch 97 Iteration 25000 - Train Loss: 0.000002 - Dev Loss: 0.734548\n",
            "Epoch 97 Iteration 25010 - Train Loss: 0.000002 - Dev Loss: 0.734660\n",
            "Epoch 97 Iteration 25020 - Train Loss: 0.000002 - Dev Loss: 0.734789\n",
            "Epoch 97 Iteration 25030 - Train Loss: 0.000002 - Dev Loss: 0.734667\n",
            "Epoch 97 Iteration 25040 - Train Loss: 0.000002 - Dev Loss: 0.734406\n",
            "Epoch 97 Iteration 25050 - Train Loss: 0.000002 - Dev Loss: 0.734162\n",
            "Epoch 97 Iteration 25060 - Train Loss: 0.000002 - Dev Loss: 0.734233\n",
            "Epoch 97 Iteration 25070 - Train Loss: 0.000002 - Dev Loss: 0.734796\n",
            "Epoch 97 Iteration 25080 - Train Loss: 0.000002 - Dev Loss: 0.735228\n",
            "Epoch 98 Iteration 25090 - Train Loss: 0.000002 - Dev Loss: 0.735622\n",
            "Epoch 98 Iteration 25100 - Train Loss: 0.000002 - Dev Loss: 0.735940\n",
            "Epoch 98 Iteration 25110 - Train Loss: 0.000002 - Dev Loss: 0.736179\n",
            "Epoch 98 Iteration 25120 - Train Loss: 0.000002 - Dev Loss: 0.736440\n",
            "Epoch 98 Iteration 25130 - Train Loss: 0.000002 - Dev Loss: 0.736486\n",
            "Epoch 98 Iteration 25140 - Train Loss: 0.000002 - Dev Loss: 0.736369\n",
            "Epoch 98 Iteration 25150 - Train Loss: 0.000002 - Dev Loss: 0.736313\n",
            "Epoch 98 Iteration 25160 - Train Loss: 0.000002 - Dev Loss: 0.736637\n",
            "Epoch 98 Iteration 25170 - Train Loss: 0.000002 - Dev Loss: 0.737162\n",
            "Epoch 98 Iteration 25180 - Train Loss: 0.000002 - Dev Loss: 0.737288\n",
            "Epoch 98 Iteration 25190 - Train Loss: 0.000002 - Dev Loss: 0.737398\n",
            "Epoch 98 Iteration 25200 - Train Loss: 0.000002 - Dev Loss: 0.737590\n",
            "Epoch 98 Iteration 25210 - Train Loss: 0.000002 - Dev Loss: 0.737888\n",
            "Epoch 98 Iteration 25220 - Train Loss: 0.000002 - Dev Loss: 0.738128\n",
            "Epoch 98 Iteration 25230 - Train Loss: 0.000002 - Dev Loss: 0.738115\n",
            "Epoch 98 Iteration 25240 - Train Loss: 0.000002 - Dev Loss: 0.738349\n",
            "Epoch 98 Iteration 25250 - Train Loss: 0.000002 - Dev Loss: 0.738425\n",
            "Epoch 98 Iteration 25260 - Train Loss: 0.000002 - Dev Loss: 0.738554\n",
            "Epoch 98 Iteration 25270 - Train Loss: 0.000002 - Dev Loss: 0.738790\n",
            "Epoch 98 Iteration 25280 - Train Loss: 0.000002 - Dev Loss: 0.739059\n",
            "Epoch 98 Iteration 25290 - Train Loss: 0.000002 - Dev Loss: 0.739340\n",
            "Epoch 98 Iteration 25300 - Train Loss: 0.000002 - Dev Loss: 0.739499\n",
            "Epoch 98 Iteration 25310 - Train Loss: 0.000002 - Dev Loss: 0.739777\n",
            "Epoch 98 Iteration 25320 - Train Loss: 0.000002 - Dev Loss: 0.739946\n",
            "Epoch 98 Iteration 25330 - Train Loss: 0.000002 - Dev Loss: 0.740053\n",
            "Epoch 98 Iteration 25340 - Train Loss: 0.000002 - Dev Loss: 0.740599\n",
            "Epoch 99 Iteration 25350 - Train Loss: 0.000002 - Dev Loss: 0.740796\n",
            "Epoch 99 Iteration 25360 - Train Loss: 0.000001 - Dev Loss: 0.740605\n",
            "Epoch 99 Iteration 25370 - Train Loss: 0.000002 - Dev Loss: 0.740627\n",
            "Epoch 99 Iteration 25380 - Train Loss: 0.000002 - Dev Loss: 0.741169\n",
            "Epoch 99 Iteration 25390 - Train Loss: 0.000002 - Dev Loss: 0.741636\n",
            "Epoch 99 Iteration 25400 - Train Loss: 0.000002 - Dev Loss: 0.742150\n",
            "Epoch 99 Iteration 25410 - Train Loss: 0.000002 - Dev Loss: 0.742219\n",
            "Epoch 99 Iteration 25420 - Train Loss: 0.000002 - Dev Loss: 0.742135\n",
            "Epoch 99 Iteration 25430 - Train Loss: 0.000002 - Dev Loss: 0.742153\n",
            "Epoch 99 Iteration 25440 - Train Loss: 0.000002 - Dev Loss: 0.742172\n",
            "Epoch 99 Iteration 25450 - Train Loss: 0.000002 - Dev Loss: 0.742590\n",
            "Epoch 99 Iteration 25460 - Train Loss: 0.000002 - Dev Loss: 0.742989\n",
            "Epoch 99 Iteration 25470 - Train Loss: 0.000002 - Dev Loss: 0.742610\n",
            "Epoch 99 Iteration 25480 - Train Loss: 0.000002 - Dev Loss: 0.742203\n",
            "Epoch 99 Iteration 25490 - Train Loss: 0.000002 - Dev Loss: 0.742108\n",
            "Epoch 99 Iteration 25500 - Train Loss: 0.000002 - Dev Loss: 0.742503\n",
            "Epoch 99 Iteration 25510 - Train Loss: 0.000002 - Dev Loss: 0.742886\n",
            "Epoch 99 Iteration 25520 - Train Loss: 0.000002 - Dev Loss: 0.743421\n",
            "Epoch 99 Iteration 25530 - Train Loss: 0.000001 - Dev Loss: 0.743839\n",
            "Epoch 99 Iteration 25540 - Train Loss: 0.000002 - Dev Loss: 0.744470\n",
            "Epoch 99 Iteration 25550 - Train Loss: 0.000002 - Dev Loss: 0.744979\n",
            "Epoch 99 Iteration 25560 - Train Loss: 0.000002 - Dev Loss: 0.745111\n",
            "Epoch 99 Iteration 25570 - Train Loss: 0.000002 - Dev Loss: 0.745282\n",
            "Epoch 99 Iteration 25580 - Train Loss: 0.000002 - Dev Loss: 0.745342\n",
            "Epoch 99 Iteration 25590 - Train Loss: 0.000002 - Dev Loss: 0.745699\n"
          ]
        }
      ],
      "source": [
        "# Load datasets.\n",
        "train_dataset = CoNLLDataset('./datasets/pt_bosque-ud-train.conllu', 4096)\n",
        "dev_dataset = CoNLLDataset('./datasets/pt_bosque-ud-dev.conllu', 1024)\n",
        "\n",
        "dev_dataset.token_vocab = train_dataset.token_vocab\n",
        "dev_dataset.pos_vocab = train_dataset.pos_vocab\n",
        "\n",
        "# Hyperparameters / constants.\n",
        "input_vocab_size = len(train_dataset.token_vocab)\n",
        "output_vocab_size = len(train_dataset.pos_vocab)\n",
        "batch_size = 16\n",
        "epochs = 100\n",
        "n_layers = 1\n",
        "\n",
        "# Initialize the model.\n",
        "model = Tagger(input_vocab_size, output_vocab_size, n_layers)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Loss function weights.\n",
        "weight = torch.ones(output_vocab_size)\n",
        "weight[0] = 0\n",
        "if torch.cuda.is_available():\n",
        "    weight = weight.cuda()\n",
        "    \n",
        "# Initialize loss function and optimizer.\n",
        "loss_function = torch.nn.NLLLoss(weight)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Main training loop.\n",
        "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                         collate_fn=collate_annotations)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=collate_annotations)\n",
        "\n",
        "losses = []\n",
        "i = 0\n",
        "\n",
        "# For time counting\n",
        "startTime = time.time()\n",
        "for epoch in range(epochs):\n",
        "    for inputs, targets, lengths in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(inputs, lengths=lengths)\n",
        "\n",
        "        outputs = outputs.view(-1, output_vocab_size)\n",
        "        targets = targets.view(-1)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #losses.append(loss.data[0])\n",
        "        losses.append(loss.item())\n",
        "        if (i % 10) == 0:\n",
        "            # Compute dev loss over entire dev set.\n",
        "            # NOTE: This is expensive. You may want to only use a \n",
        "            # subset of the dev set.\n",
        "            #print('iteration, ', i)\n",
        "            dev_losses = []\n",
        "            for inputs, targets, lengths in dev_loader:\n",
        "                outputs, _ = model(inputs, lengths=lengths)\n",
        "                outputs = outputs.view(-1, output_vocab_size)\n",
        "                targets = targets.view(-1)\n",
        "                loss = loss_function(outputs, targets)\n",
        "                dev_losses.append(loss.item())\n",
        "            avg_train_loss = np.mean(losses)\n",
        "            avg_dev_loss = np.mean(dev_losses)\n",
        "            losses = []\n",
        "            #print('here')\n",
        "            print('Epoch %i Iteration %i - Train Loss: %0.6f - Dev Loss: %0.6f' % (epoch, i, avg_train_loss, avg_dev_loss), end='\\n')\n",
        "            # torch.save(model, 'pos_tagger_lstm.pt')\n",
        "        i += 1\n",
        "        \n",
        "# torch.save(model, 'pos_tagger_lstm.final.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('======================================================================')\n",
        "print('Finished')\n",
        "\n",
        "# For time counting\n",
        "endTime = time.time()\n",
        "elapsedTime = endTime - startTime\n",
        "print( f'Running Time: {elapsedTime / 60:.2} minutes' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JDEuk32V9Pxx",
        "outputId": "6f2c40e9-6b62-4fe7-ff09-a10d4919ae8b"
      },
      "id": "JDEuk32V9Pxx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Finished\n",
            "Running Time: 6.8e+01 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = 6.8e+01\n",
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "us-Lgku_Gcs5",
        "outputId": "91ca018e-e4f9-4296-cff0-95219cb6e75e"
      },
      "id": "us-Lgku_Gcs5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "68.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect the predictions and targets\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for inputs, targets, lengths in dev_loader:\n",
        "    outputs, _ = model(inputs, lengths=lengths)\n",
        "    _, preds = torch.max(outputs, dim=2)\n",
        "    targets = targets.view(-1)\n",
        "    preds = preds.view(-1)\n",
        "    if torch.cuda.is_available():\n",
        "        targets = targets.cpu()\n",
        "        preds = preds.cpu()\n",
        "    y_true.append(targets.data.numpy())\n",
        "    y_pred.append(preds.data.numpy())"
      ],
      "metadata": {
        "id": "yEu5KDea5yLu"
      },
      "id": "yEu5KDea5yLu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack into numpy arrays\n",
        "y_real = np.concatenate(y_true)\n",
        "y_pred = np.concatenate(y_pred)"
      ],
      "metadata": {
        "id": "9tqmb51F5zf2"
      },
      "id": "9tqmb51F5zf2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_real_temp = []\n",
        "for id in y_real:\n",
        "  y_real_temp.append(dev_dataset.pos_vocab._id2word[ id ])\n",
        "y_real = y_real_temp\n",
        "# print(y_real)"
      ],
      "metadata": {
        "id": "Kqqd2ceo51WE"
      },
      "id": "Kqqd2ceo51WE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_temp = []\n",
        "for id in y_pred:\n",
        "  y_pred_temp.append(dev_dataset.pos_vocab._id2word[ id ])\n",
        "y_pred = y_pred_temp\n",
        "# print(y_pred)"
      ],
      "metadata": {
        "id": "nJp_3sGh5_qS"
      },
      "id": "nJp_3sGh5_qS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( classification_report( y_real, y_pred ) )\n",
        "f1 = f1_score( y_real, y_pred, average='weighted' )\n",
        "acc = accuracy_score( y_real, y_pred )\n",
        "print( f'F1: {f1:.2}' )\n",
        "print( f'Accuracy: {acc:.2}' )\n",
        "\n",
        "# # Compute accuracy\n",
        "# acc = np.mean(y_real[y_real != 0] == y_pred[y_real != 0])\n",
        "# print('Accuracy - %0.6f\\n' % acc)\n",
        "\n",
        "# # Evaluate f1-score\n",
        "# from sklearn.metrics import f1_score\n",
        "# score = f1_score(y_real, y_pred, average=None)\n",
        "# print('F1-scores:\\n')\n",
        "# for label, score in zip(dev_dataset.pos_vocab._id2word[1:], score[1:]):\n",
        "#     print('%s - %0.6f' % (label, score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_FQmtlEOwYk",
        "outputId": "13ac89d3-ffde-4012-d63d-ec4a9957cfb8"
      },
      "id": "L_FQmtlEOwYk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <pad>       0.00      0.00      0.00     33153\n",
            "         ADJ       0.73      0.71      0.72      1157\n",
            "         ADP       0.96      0.97      0.97      3549\n",
            "         ADV       0.73      0.89      0.80       844\n",
            "         AUX       0.92      0.94      0.93       581\n",
            "       CCONJ       0.99      0.99      0.99       542\n",
            "         DET       0.96      0.98      0.97      3702\n",
            "        INTJ       0.00      0.00      0.00         3\n",
            "        NOUN       0.89      0.86      0.87      4415\n",
            "         NUM       0.96      0.78      0.86       461\n",
            "        PRON       0.88      0.88      0.88       835\n",
            "       PROPN       0.66      0.81      0.73      2143\n",
            "       PUNCT       1.00      1.00      1.00      3267\n",
            "       SCONJ       0.79      0.70      0.74       542\n",
            "         SYM       1.00      1.00      1.00        36\n",
            "        VERB       0.87      0.72      0.79      2166\n",
            "           X       0.00      0.00      0.00        19\n",
            "           _       0.99      0.96      0.98      1753\n",
            "\n",
            "    accuracy                           0.39     59168\n",
            "   macro avg       0.74      0.73      0.73     59168\n",
            "weighted avg       0.40      0.39      0.39     59168\n",
            "\n",
            "F1: 0.39\n",
            "Accuracy: 0.39\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "tagger_lstm.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
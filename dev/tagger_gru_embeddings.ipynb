{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tagger_gru_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mudando o diretório para o meu Google Drive para não precisar ficar baixando os datasets novamente."
      ],
      "metadata": {
        "id": "Ko9vDXvyXSlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYV22az9XSrU",
        "outputId": "24e17b86-cb0a-43a1-f03f-1ecab605a253"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PGnjt39XhdH",
        "outputId": "b17d56f6-3438-4f74-9a57-ca8e8f032299"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNUsW8kNXhf8",
        "outputId": "926ded28-ce4d-41a4-8d81-1e80b7d9d1d0"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Zm6Zy6Xhh2",
        "outputId": "32f51aa0-681c-4db3-c4ee-3c47d252bf5d"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings\n",
        "\n",
        "Baseado em https://colab.research.google.com/drive/1BuLyMlebp43-3KNn-puezjW5S1CGuSI5?usp=sharing"
      ],
      "metadata": {
        "id": "_eBTGJTxMxea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjSOQB7lMPRZ",
        "outputId": "fc1dff6b-aab5-4d05-a65e-e40fffb9462f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-13 23:20:48--  http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s50.zip\n",
            "Connecting to 143.107.183.175:22980... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170360268 (162M) [application/octet-stream]\n",
            "Saving to: ‘download.php?file=embeddings%2Fword2vec%2Fcbow_s50.zip’\n",
            "\n",
            "download.php?file=e 100%[===================>] 162.47M  1.60MB/s    in 60s     \n",
            "\n",
            "2022-06-13 23:21:48 (2.70 MB/s) - ‘download.php?file=embeddings%2Fword2vec%2Fcbow_s50.zip’ saved [170360268/170360268]\n",
            "\n",
            "Archive:  download.php?file=embeddings%2Fword2vec%2Fcbow_s50.zip\n",
            "  inflating: cbow_s50.txt            \n"
          ]
        }
      ],
      "source": [
        "# !wget http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s50.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip download.php?file=embeddings%2Fword2vec%2Fcbow_s50.zip"
      ],
      "metadata": {
        "id": "bbAlt9nKYy0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import KeyedVectors\n",
        "word2vec = KeyedVectors.load_word2vec_format('cbow_s50.txt')\n",
        "word2vec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKVdAeduMzW1",
        "outputId": "009c3042-3b7c-40b6-e9c0-21f151607315"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<gensim.models.keyedvectors.Word2VecKeyedVectors at 0x7f060c98df10>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec['menino']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5vb5x8UxMzZA",
        "outputId": "5c9818a0-7962-4fd5-991c-cf738437df00"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.047754, -0.190243,  0.290581,  0.035822,  0.2301  , -0.139099,\n",
              "       -0.232351, -0.119084,  0.327645,  0.160017, -0.5318  ,  0.093309,\n",
              "       -0.545777, -0.166715,  0.044872, -0.094386, -0.017529, -0.053898,\n",
              "        0.189092, -0.233779, -0.302459,  0.707696, -0.146762,  0.258651,\n",
              "        0.25436 , -0.071892,  0.132296, -0.072721,  0.162642,  0.348834,\n",
              "        0.129191, -0.030967,  0.048024,  0.26683 , -0.076066,  0.352168,\n",
              "        0.629779, -0.403468, -0.473612,  0.456509,  0.008285,  0.066872,\n",
              "        0.082632, -0.128989,  0.107645,  0.119981,  0.219388, -0.141599,\n",
              "       -0.20074 , -0.30657 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.most_similar('homem')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JJxbykVMzbe",
        "outputId": "7ca61e37-d8c5-49ee-8113-4d182a8013bb"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('monstro', 0.9085395336151123),\n",
              " ('bebé', 0.9072304368019104),\n",
              " ('indivíduo', 0.9050755500793457),\n",
              " ('rapaz', 0.9036116003990173),\n",
              " ('mendigo', 0.9007540345191956),\n",
              " ('rapazola', 0.8992964625358582),\n",
              " ('novelo', 0.8938027620315552),\n",
              " ('pássaro', 0.889799952507019),\n",
              " ('cão', 0.8882535099983215),\n",
              " ('cãozinho', 0.8869854807853699)]"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.similarity('menino', 'cachorro')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ricn90w1Mzd8",
        "outputId": "350d3b09-bbe9-4df4-bd6a-545934dc5ac7"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8441181"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2vec.most_similar(positive=['amar', 'odiando'], negative=['odiar'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1_oJu3HMzgQ",
        "outputId": "a0ed9341-d8e3-42d2-dfa1-e306ecfcee4d"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('amando', 0.7472066879272461),\n",
              " ('desperto', 0.7231094837188721),\n",
              " ('quieto', 0.6835169196128845),\n",
              " ('tranqüilo', 0.68125319480896),\n",
              " ('surdo', 0.6798273921012878),\n",
              " ('louco', 0.6784767508506775),\n",
              " ('quieta', 0.6757060289382935),\n",
              " ('sã³brio', 0.6748781800270081),\n",
              " ('rouco', 0.6719405651092529),\n",
              " ('sossegado', 0.6716687679290771)]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Train Word Embedding in PyTorch\n",
        "\n",
        "Baseado em https://androidkt.com/pre-train-word-embedding-in-pytorch/"
      ],
      "metadata": {
        "id": "dFLp5W7UNbGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-lY1Jr4NRe0",
        "outputId": "987e8494-f45a-41da-dc3f-ea6ccc6e923c"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-06-13 23:22:28--  http://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/wordvecs/glove.6B.zip [following]\n",
            "--2022-06-13 23:22:28--  https://nlp.stanford.edu/data/wordvecs/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip [following]\n",
            "--2022-06-13 23:22:29--  http://downloads.cs.stanford.edu/nlp/data/wordvecs/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182753 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  5.05MB/s    in 2m 41s  \n",
            "\n",
            "2022-06-13 23:25:10 (5.12 MB/s) - ‘glove.6B.zip’ saved [862182753/862182753]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n",
            "  inflating: glove.6B.50d.txt        \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip glove.6B.zip"
      ],
      "metadata": {
        "id": "oJSOUzg7Y2CU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "glove = pd.read_csv('glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
        "glove_embedding = {key: val.values for key, val in glove.T.items()}"
      ],
      "metadata": {
        "id": "R4Uuu5-PNRhV"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def create_embedding_matrix(word_index,embedding_dict,dimension):\n",
        "  embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
        " \n",
        "  for word,index in word_index.items():\n",
        "    if word in embedding_dict:\n",
        "      embedding_matrix[index]=embedding_dict[word]\n",
        "  return embedding_matrix\n",
        " \n",
        "text=[\"The cat sat on mat\",\"we can play with model\"]\n",
        " \n",
        "tokenizer=tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
        "tokenizer.fit_on_texts(text)\n",
        " \n",
        "text_token=tokenizer.texts_to_sequences(text)\n",
        " \n",
        "embedding_matrix=create_embedding_matrix(\n",
        "    tokenizer.word_index,\n",
        "    embedding_dict=glove_embedding,\n",
        "    dimension=100)"
      ],
      "metadata": {
        "id": "mFF2NQWmNRjr"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_token"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRLDrSYyRb-l",
        "outputId": "106a830e-61ad-4f4b-dedf-3e6211379374"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]]"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.word_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3FafuXLBRZ08",
        "outputId": "b03b2cc0-31e6-4400-fb50-e39f3f937457"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'can': 7,\n",
              " 'cat': 2,\n",
              " 'mat': 5,\n",
              " 'model': 10,\n",
              " 'on': 4,\n",
              " 'play': 8,\n",
              " 'sat': 3,\n",
              " 'the': 1,\n",
              " 'we': 6,\n",
              " 'with': 9}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "vocab_size=embedding_matrix.shape[0]\n",
        "vector_size=embedding_matrix.shape[1]\n",
        " \n",
        "embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=vector_size)"
      ],
      "metadata": {
        "id": "c250HDnNNRqT"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))"
      ],
      "metadata": {
        "id": "wdScrDwONRtO"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding(torch.LongTensor([1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEeyOVuRNRvn",
        "outputId": "26d73e85-99e0-43bd-e16e-c8bfde3a10e4"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0382, -0.2449,  0.7281, -0.3996,  0.0832,  0.0440, -0.3914,  0.3344,\n",
              "         -0.5755,  0.0875,  0.2879, -0.0673,  0.3091, -0.2638, -0.1323, -0.2076,\n",
              "          0.3340, -0.3385, -0.3174, -0.4834,  0.1464, -0.3730,  0.3458,  0.0520,\n",
              "          0.4495, -0.4697,  0.0263, -0.5415, -0.1552, -0.1411, -0.0397,  0.2828,\n",
              "          0.1439,  0.2346, -0.3102,  0.0862,  0.2040,  0.5262,  0.1716, -0.0824,\n",
              "         -0.7179, -0.4153,  0.2033, -0.1276,  0.4137,  0.5519,  0.5791, -0.3348,\n",
              "         -0.3656, -0.5486, -0.0629,  0.2658,  0.3020,  0.9977, -0.8048, -3.0243,\n",
              "          0.0125, -0.3694,  2.2167,  0.7220, -0.2498,  0.9214,  0.0345,  0.4674,\n",
              "          1.1079, -0.1936, -0.0746,  0.2335, -0.0521, -0.2204,  0.0572, -0.1581,\n",
              "         -0.3080, -0.4162,  0.3797,  0.1501, -0.5321, -0.2055, -1.2526,  0.0716,\n",
              "          0.7056,  0.4974, -0.4206,  0.2615, -1.5380, -0.3022, -0.0734, -0.2831,\n",
              "          0.3710, -0.2522,  0.0162, -0.0171, -0.3898,  0.8742, -0.7257, -0.5106,\n",
              "         -0.5203, -0.1459,  0.8278,  0.2706]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding.weight.requires_grad=False"
      ],
      "metadata": {
        "id": "fSdfYkOGNyyj"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vec=embedding(torch.LongTensor(text_token))\n",
        "print(embedding)\n",
        "print(embedding_vec.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBcSa4tHNy0s",
        "outputId": "5f2d679b-88ae-4bbb-f952-1ef004819fc5"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(11, 100)\n",
            "torch.Size([2, 5, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dim=vector_size\n",
        "lstm=nn.LSTM(embedding_dim,128,bidirectional=True,batch_first=True)(embedding_vec)\n",
        "lstm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xqlHvcTNy5d",
        "outputId": "c9c08128-0efc-4d0d-d33d-ab34608631a6"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[ 0.0294, -0.0968, -0.0618,  ...,  0.0936,  0.0588,  0.0329],\n",
              "          [ 0.0009, -0.0113,  0.0264,  ...,  0.0776,  0.0696, -0.0025],\n",
              "          [-0.0274, -0.0991, -0.0305,  ...,  0.0622,  0.0385,  0.1160],\n",
              "          [-0.0125, -0.0931,  0.0946,  ...,  0.1278,  0.0946, -0.0558],\n",
              "          [ 0.0382, -0.1083,  0.0845,  ...,  0.0812,  0.0982, -0.0679]],\n",
              " \n",
              "         [[ 0.0227, -0.1032,  0.0542,  ...,  0.0688,  0.0428, -0.0040],\n",
              "          [ 0.0758, -0.1596,  0.0624,  ...,  0.0737,  0.0669, -0.0095],\n",
              "          [ 0.1236, -0.1146,  0.0667,  ...,  0.0565,  0.0367, -0.0545],\n",
              "          [ 0.0411, -0.0807,  0.0586,  ...,  0.0327,  0.0499, -0.0277],\n",
              "          [ 0.0435, -0.0697,  0.0235,  ...,  0.0005,  0.0724, -0.0294]]],\n",
              "        grad_fn=<TransposeBackward0>),\n",
              " (tensor([[[ 0.0382, -0.1083,  0.0845,  0.0403,  0.0590,  0.0583, -0.0088,\n",
              "            -0.0112,  0.1354, -0.0874, -0.0189,  0.0089, -0.0761,  0.0647,\n",
              "             0.0745,  0.0204,  0.0393,  0.0553,  0.0390,  0.1281,  0.0952,\n",
              "             0.1663,  0.0517,  0.0027, -0.0980, -0.1916, -0.0679, -0.1737,\n",
              "             0.0321, -0.1261,  0.1428,  0.0616,  0.1141,  0.1019,  0.1496,\n",
              "             0.1281,  0.0181, -0.0700, -0.1259, -0.1042,  0.0197,  0.0306,\n",
              "             0.0293,  0.0127,  0.0438, -0.0105,  0.0625, -0.0152, -0.0493,\n",
              "            -0.1854, -0.0171,  0.1435, -0.0336, -0.0731,  0.0103,  0.0821,\n",
              "            -0.1259,  0.0244,  0.0441, -0.0046,  0.1144, -0.0455,  0.0073,\n",
              "            -0.1669, -0.2205,  0.1078,  0.0146,  0.2191, -0.1546, -0.2652,\n",
              "             0.0446,  0.0977,  0.2730,  0.0335, -0.0109,  0.0070,  0.0722,\n",
              "             0.0405, -0.0074,  0.0347,  0.0693, -0.1516, -0.0589,  0.0206,\n",
              "             0.0365, -0.0183, -0.2076, -0.0870, -0.1404, -0.0685,  0.0054,\n",
              "             0.0102, -0.0953, -0.0898, -0.0266, -0.0517,  0.1309,  0.1126,\n",
              "             0.2095, -0.0406,  0.1596, -0.0358, -0.1035,  0.0560, -0.2058,\n",
              "            -0.0102,  0.1257, -0.0621, -0.0630,  0.1714, -0.0024, -0.0226,\n",
              "            -0.0480,  0.0401, -0.0847,  0.0971,  0.0732,  0.1590,  0.0422,\n",
              "            -0.1238,  0.0945, -0.0313, -0.1403,  0.0189,  0.0545, -0.0879,\n",
              "             0.0305, -0.0357],\n",
              "           [ 0.0435, -0.0697,  0.0235,  0.0091,  0.0979,  0.1036, -0.0297,\n",
              "             0.1183,  0.0921, -0.0403,  0.0235,  0.0157, -0.0819,  0.1724,\n",
              "             0.1564,  0.1015,  0.1366,  0.0481, -0.0360,  0.1197,  0.0172,\n",
              "            -0.0243,  0.0324,  0.0822, -0.0508, -0.3322,  0.0592, -0.1137,\n",
              "             0.0235,  0.1265,  0.1906,  0.2167, -0.0060,  0.1608,  0.0119,\n",
              "             0.1756,  0.1190, -0.0331, -0.0500, -0.0954,  0.0464,  0.0131,\n",
              "             0.0840, -0.0607,  0.0457, -0.0478,  0.0820, -0.1161,  0.0447,\n",
              "            -0.1326, -0.0435, -0.1279,  0.1067, -0.2226,  0.0781,  0.1884,\n",
              "            -0.0056,  0.1498, -0.1268,  0.0682, -0.0219,  0.0490,  0.0520,\n",
              "            -0.0495,  0.1105, -0.0439,  0.1208,  0.1491, -0.0076, -0.1323,\n",
              "             0.0373, -0.0076,  0.1877,  0.0188, -0.1127,  0.0097, -0.0395,\n",
              "            -0.0992,  0.1237,  0.1241,  0.0115, -0.1117, -0.0024,  0.1556,\n",
              "             0.0431, -0.2377, -0.1716,  0.1163, -0.0521, -0.1851,  0.1812,\n",
              "            -0.0631, -0.1323, -0.1207, -0.0012, -0.0759, -0.0007, -0.1313,\n",
              "             0.1459, -0.0678,  0.0181,  0.0717, -0.1786, -0.0837, -0.0538,\n",
              "             0.1272, -0.0228,  0.0122, -0.0415,  0.1497,  0.1034,  0.0023,\n",
              "            -0.0625, -0.0339, -0.1372,  0.0052,  0.0369,  0.1566, -0.0818,\n",
              "            -0.1496,  0.0939, -0.1213,  0.0343,  0.0331,  0.0054,  0.0735,\n",
              "            -0.1146, -0.1038]],\n",
              "  \n",
              "          [[ 0.1126,  0.0485, -0.0525,  0.0658,  0.1307, -0.0486,  0.0195,\n",
              "             0.0537, -0.1409, -0.0319, -0.0382, -0.1452, -0.0399,  0.0399,\n",
              "            -0.1505, -0.0058, -0.0421,  0.1370, -0.1892,  0.1418, -0.0352,\n",
              "             0.0117,  0.0436,  0.1253, -0.0492,  0.2441,  0.0962, -0.1299,\n",
              "            -0.2609,  0.1192,  0.0247, -0.1300,  0.0352,  0.0233, -0.0785,\n",
              "             0.0850, -0.0621,  0.0031,  0.0351, -0.1314,  0.1208,  0.0196,\n",
              "            -0.0338,  0.1785,  0.1243, -0.0661,  0.0183,  0.0342,  0.0522,\n",
              "             0.0628, -0.0051, -0.0480, -0.0798,  0.0712, -0.0748,  0.0221,\n",
              "            -0.1504,  0.0343, -0.1011,  0.0479,  0.0414, -0.0293,  0.0822,\n",
              "             0.0814, -0.0173,  0.0456,  0.0414, -0.0283, -0.0007, -0.1132,\n",
              "            -0.2103, -0.0183, -0.1335,  0.1480,  0.1750, -0.1230, -0.0597,\n",
              "            -0.0222, -0.0469,  0.0257, -0.1345,  0.0923, -0.1404, -0.2073,\n",
              "            -0.2562, -0.0336,  0.1667, -0.0059,  0.1379, -0.1643,  0.0545,\n",
              "             0.0286,  0.0489,  0.1755, -0.0446, -0.1481,  0.1860, -0.0407,\n",
              "             0.0612, -0.1513,  0.0520, -0.0335,  0.1021, -0.1459,  0.0689,\n",
              "             0.0608,  0.1420, -0.0631,  0.0227, -0.0298, -0.0367, -0.1212,\n",
              "            -0.0156, -0.1154, -0.0967, -0.0147,  0.0195, -0.0444,  0.0850,\n",
              "            -0.0742, -0.2013,  0.0575,  0.2109, -0.0884, -0.1165,  0.0936,\n",
              "             0.0588,  0.0329],\n",
              "           [ 0.0860,  0.1595,  0.1880,  0.0281,  0.1470, -0.0093, -0.0307,\n",
              "             0.1812, -0.1319,  0.0063,  0.0160, -0.1005, -0.1572,  0.1280,\n",
              "            -0.0499, -0.1303, -0.1900,  0.0655, -0.2478,  0.2614, -0.2007,\n",
              "            -0.0679,  0.0345,  0.1573,  0.0409,  0.1980, -0.0275, -0.0740,\n",
              "            -0.2721,  0.0940, -0.1284, -0.0068,  0.1650, -0.1765, -0.1128,\n",
              "             0.0890, -0.1391,  0.1491, -0.0503, -0.0342,  0.1377, -0.0471,\n",
              "            -0.0458,  0.1976,  0.1228, -0.0535,  0.0863,  0.0246,  0.0391,\n",
              "             0.2706, -0.2066,  0.0286, -0.1045, -0.0034, -0.0489,  0.0749,\n",
              "            -0.0434,  0.0054, -0.2733,  0.1534, -0.0419,  0.1286,  0.0061,\n",
              "             0.0930,  0.0245, -0.1799, -0.0353, -0.0692, -0.0814, -0.1067,\n",
              "            -0.2153,  0.0299, -0.0538,  0.1439,  0.1374, -0.0335, -0.1094,\n",
              "             0.0425, -0.1140,  0.0194, -0.1431,  0.1276, -0.0873, -0.2432,\n",
              "            -0.2249, -0.0857,  0.1921, -0.0801,  0.0636, -0.2022,  0.1610,\n",
              "             0.1199,  0.0998,  0.1584,  0.0149, -0.1494,  0.2540, -0.0547,\n",
              "             0.2318, -0.1196,  0.0704, -0.1225,  0.1292, -0.2340, -0.0528,\n",
              "            -0.0345,  0.1007, -0.0845, -0.0982, -0.1041, -0.0905, -0.2027,\n",
              "             0.0594, -0.0563, -0.0129, -0.1305,  0.0231, -0.0672,  0.0664,\n",
              "             0.1158, -0.3087,  0.0614,  0.1467,  0.1004, -0.1911,  0.0688,\n",
              "             0.0428, -0.0040]]], grad_fn=<StackBackward0>),\n",
              "  tensor([[[ 0.0708, -0.1718,  0.2050,  0.0761,  0.1177,  0.0993, -0.0244,\n",
              "            -0.0221,  0.2483, -0.2126, -0.0390,  0.0192, -0.1691,  0.1433,\n",
              "             0.1828,  0.0566,  0.0630,  0.1275,  0.0758,  0.2641,  0.1962,\n",
              "             0.2756,  0.1250,  0.0057, -0.2182, -0.3857, -0.1362, -0.3690,\n",
              "             0.0563, -0.2561,  0.3037,  0.1250,  0.2600,  0.1992,  0.2945,\n",
              "             0.2346,  0.0344, -0.1220, -0.3254, -0.2116,  0.0393,  0.0654,\n",
              "             0.0668,  0.0253,  0.0816, -0.0242,  0.1509, -0.0299, -0.0860,\n",
              "            -0.4559, -0.0312,  0.2358, -0.0824, -0.1588,  0.0223,  0.1612,\n",
              "            -0.2455,  0.0510,  0.1331, -0.0086,  0.2134, -0.0774,  0.0123,\n",
              "            -0.3207, -0.4000,  0.1993,  0.0245,  0.4857, -0.3044, -0.5452,\n",
              "             0.0883,  0.2203,  0.4833,  0.0588, -0.0201,  0.0153,  0.1548,\n",
              "             0.0746, -0.0155,  0.0903,  0.1289, -0.3685, -0.1392,  0.0517,\n",
              "             0.0608, -0.0481, -0.4378, -0.1705, -0.2841, -0.1660,  0.0087,\n",
              "             0.0191, -0.1912, -0.1642, -0.0525, -0.1107,  0.2954,  0.1919,\n",
              "             0.4926, -0.0734,  0.3053, -0.0560, -0.2281,  0.0968, -0.4128,\n",
              "            -0.0222,  0.2154, -0.1388, -0.1330,  0.4019, -0.0047, -0.0418,\n",
              "            -0.0963,  0.0736, -0.1469,  0.1611,  0.1883,  0.3185,  0.1139,\n",
              "            -0.3389,  0.1962, -0.0610, -0.2835,  0.0438,  0.1139, -0.2009,\n",
              "             0.0624, -0.0778],\n",
              "           [ 0.1061, -0.1381,  0.0554,  0.0180,  0.1717,  0.2602, -0.0588,\n",
              "             0.2242,  0.1686, -0.0816,  0.0383,  0.0302, -0.1515,  0.3529,\n",
              "             0.3607,  0.2461,  0.2724,  0.0828, -0.0758,  0.2023,  0.0360,\n",
              "            -0.0484,  0.1005,  0.1359, -0.0926, -0.6561,  0.1099, -0.2202,\n",
              "             0.0410,  0.2518,  0.3888,  0.3903, -0.0122,  0.2910,  0.0243,\n",
              "             0.2838,  0.1926, -0.0640, -0.1320, -0.1785,  0.0987,  0.0279,\n",
              "             0.1688, -0.1303,  0.1141, -0.1156,  0.1489, -0.2671,  0.1094,\n",
              "            -0.3457, -0.0836, -0.2706,  0.2909, -0.3937,  0.2063,  0.4908,\n",
              "            -0.0103,  0.2491, -0.3572,  0.1354, -0.0460,  0.1149,  0.1444,\n",
              "            -0.0918,  0.2182, -0.1116,  0.2855,  0.3158, -0.0157, -0.3631,\n",
              "             0.0639, -0.0149,  0.5070,  0.0362, -0.2265,  0.0174, -0.0893,\n",
              "            -0.3066,  0.2940,  0.2376,  0.0176, -0.2251, -0.0037,  0.3231,\n",
              "             0.0744, -0.4561, -0.4557,  0.2280, -0.1276, -0.3956,  0.3045,\n",
              "            -0.1056, -0.2721, -0.1875, -0.0023, -0.1681, -0.0017, -0.2564,\n",
              "             0.4024, -0.1317,  0.0377,  0.1422, -0.3779, -0.1970, -0.0951,\n",
              "             0.2506, -0.0571,  0.0257, -0.0737,  0.3727,  0.1921,  0.0046,\n",
              "            -0.1212, -0.0577, -0.2702,  0.0085,  0.0642,  0.3511, -0.1378,\n",
              "            -0.2836,  0.1902, -0.2290,  0.0805,  0.0733,  0.0109,  0.1274,\n",
              "            -0.3149, -0.2088]],\n",
              "  \n",
              "          [[ 0.1819,  0.1048, -0.0809,  0.1647,  0.2768, -0.0805,  0.0347,\n",
              "             0.1226, -0.2380, -0.0541, -0.0602, -0.2901, -0.0961,  0.0836,\n",
              "            -0.3472, -0.0112, -0.1064,  0.3007, -0.3942,  0.3259, -0.0733,\n",
              "             0.0193,  0.0931,  0.2274, -0.1249,  0.5822,  0.1664, -0.2080,\n",
              "            -0.4813,  0.2543,  0.0595, -0.2906,  0.0763,  0.0413, -0.1579,\n",
              "             0.1880, -0.1456,  0.0076,  0.0613, -0.2918,  0.2382,  0.0499,\n",
              "            -0.0610,  0.4119,  0.2936, -0.1648,  0.0473,  0.0610,  0.1623,\n",
              "             0.1228, -0.0103, -0.0993, -0.1593,  0.1405, -0.1920,  0.0334,\n",
              "            -0.2697,  0.0875, -0.1978,  0.0918,  0.0959, -0.0629,  0.1505,\n",
              "             0.1373, -0.0314,  0.0756,  0.0909, -0.0542, -0.0013, -0.1958,\n",
              "            -0.4257, -0.0426, -0.2279,  0.3362,  0.3209, -0.3030, -0.1264,\n",
              "            -0.0409, -0.1360,  0.0440, -0.2400,  0.1583, -0.3173, -0.3323,\n",
              "            -0.4695, -0.1116,  0.2855, -0.0129,  0.3397, -0.3425,  0.1028,\n",
              "             0.0736,  0.0864,  0.3282, -0.0988, -0.2879,  0.4168, -0.0917,\n",
              "             0.1030, -0.2789,  0.1029, -0.0967,  0.1892, -0.4133,  0.1405,\n",
              "             0.1095,  0.2478, -0.1027,  0.0574, -0.0490, -0.0754, -0.2559,\n",
              "            -0.0352, -0.2505, -0.1606, -0.0289,  0.0391, -0.0862,  0.1927,\n",
              "            -0.1179, -0.5042,  0.1065,  0.4007, -0.1673, -0.2269,  0.1913,\n",
              "             0.1383,  0.0725],\n",
              "           [ 0.1451,  0.3795,  0.2937,  0.0723,  0.3252, -0.0183, -0.0627,\n",
              "             0.4215, -0.1985,  0.0092,  0.0267, -0.2203, -0.3321,  0.3056,\n",
              "            -0.1113, -0.2130, -0.3961,  0.1257, -0.4399,  0.4774, -0.4606,\n",
              "            -0.1122,  0.0651,  0.2963,  0.0802,  0.5017, -0.0434, -0.1217,\n",
              "            -0.4557,  0.2156, -0.2717, -0.0136,  0.4706, -0.3600, -0.2571,\n",
              "             0.1986, -0.2743,  0.4063, -0.0946, -0.0729,  0.2705, -0.1282,\n",
              "            -0.0788,  0.3866,  0.2677, -0.1453,  0.2447,  0.0441,  0.1218,\n",
              "             0.6229, -0.4734,  0.0540, -0.3234, -0.0075, -0.1016,  0.1212,\n",
              "            -0.0886,  0.0143, -0.5529,  0.3246, -0.0939,  0.2921,  0.0137,\n",
              "             0.1949,  0.0488, -0.2889, -0.0746, -0.1202, -0.1465, -0.2176,\n",
              "            -0.4219,  0.0657, -0.0850,  0.3375,  0.2329, -0.0769, -0.1876,\n",
              "             0.0758, -0.2653,  0.0366, -0.2347,  0.2530, -0.1770, -0.3944,\n",
              "            -0.4095, -0.2117,  0.2976, -0.1929,  0.1599, -0.3659,  0.2885,\n",
              "             0.3740,  0.1861,  0.2834,  0.0317, -0.2913,  0.5889, -0.1035,\n",
              "             0.4331, -0.3096,  0.1397, -0.3365,  0.2254, -0.4899, -0.1142,\n",
              "            -0.0655,  0.1651, -0.1409, -0.1986, -0.1917, -0.1910, -0.4290,\n",
              "             0.1153, -0.1119, -0.0208, -0.2373,  0.0583, -0.1245,  0.1559,\n",
              "             0.2000, -0.7437,  0.1235,  0.2762,  0.1892, -0.4083,  0.1418,\n",
              "             0.1171, -0.0119]]], grad_fn=<StackBackward0>)))"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova tentativa de treinar o GRU com embeddings pré-treinados."
      ],
      "metadata": {
        "id": "LfHCvqg2QEvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec['menino']"
      ],
      "metadata": {
        "id": "BcA_aV9kQKV3"
      },
      "execution_count": 258,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec['pad']"
      ],
      "metadata": {
        "id": "Sj6fPI34Qpdg"
      },
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec['oov']"
      ],
      "metadata": {
        "id": "rzdqONdNQr_Y"
      },
      "execution_count": 260,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec.vocab"
      ],
      "metadata": {
        "id": "UpbgRfR4QKYG"
      },
      "execution_count": 261,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec.vectors"
      ],
      "metadata": {
        "id": "goOMnxWEQKaP"
      },
      "execution_count": 262,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "{'can': 7,\n",
        " 'cat': 2,\n",
        " 'mat': 5,\n",
        " 'model': 10,\n",
        " 'on': 4,\n",
        " 'play': 8,\n",
        " 'sat': 3,\n",
        " 'the': 1,\n",
        " 'we': 6,\n",
        " 'with': 9}\n",
        " '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qsjO2HioR3u5",
        "outputId": "b1b84415-e0d5-4833-f9bd-916e61eb138c"
      },
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n{'can': 7,\\n 'cat': 2,\\n 'mat': 5,\\n 'model': 10,\\n 'on': 4,\\n 'play': 8,\\n 'sat': 3,\\n 'the': 1,\\n 'we': 6,\\n 'with': 9}\\n \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2index = {token: token_index for token_index, token in enumerate(word2vec.index2word)}\n",
        "# word2index['menino']"
      ],
      "metadata": {
        "id": "ks3i5GbbRHFX"
      },
      "execution_count": 264,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2index"
      ],
      "metadata": {
        "id": "-C-u7RbwS9On"
      },
      "execution_count": 265,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# glove_embedding"
      ],
      "metadata": {
        "id": "xUyJ7JQYTL4t"
      },
      "execution_count": 266,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "{'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
        "        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
        "         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
        "        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
        "         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
        "        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
        "         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
        "         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
        "        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
        "        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
        "        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
        "        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
        "        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
        "        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
        "        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
        "         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
        "        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ]),\n",
        " ',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\n",
        " [...]\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        },
        "id": "N4tUdUDgTNTp",
        "outputId": "bc1a974a-4931-438f-9178-a2b9ae161e08"
      },
      "execution_count": 267,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n{'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\\n        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\\n         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\\n        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\\n         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\\n        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\\n         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\\n         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\\n        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\\n        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\\n        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\\n        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\\n        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\\n        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\\n        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\\n         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\\n        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ]),\\n ',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\\n [...]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 267
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec_embedding = {}\n",
        "\n",
        "# for index, token in enumerate(word2vec.vocab):\n",
        "#     if index < 3:\n",
        "#         print(f'token: {token}')\n",
        "#         print(f'embeddings: {word2vec[token]}')\n",
        "\n",
        "#         {'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
        "#         -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
        "#          0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
        "#         -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
        "#          0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
        "#         -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
        "#          0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
        "#          0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
        "#         -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
        "#         -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
        "#         -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
        "#         -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
        "#         -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
        "#         -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
        "#         -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
        "#          0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
        "#         -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ]),\n",
        "#  ',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\n",
        "#  [...]\n",
        "#  '''"
      ],
      "metadata": {
        "id": "P9ymWtcCTYtW"
      },
      "execution_count": 268,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_embedding_matrix_word2vec(word_index,embedding_dict,dimension):\n",
        "#   embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
        " \n",
        "#   for word,index in word_index.items():\n",
        "#     if word in embedding_dict:\n",
        "#       embedding_matrix[index]=embedding_dict[word]\n",
        "#   return embedding_matrix\n",
        " \n",
        "# embedding_matrix_word2vec=create_embedding_matrix(\n",
        "#     word2index,\n",
        "#     embedding_dict=glove_embedding,\n",
        "#     dimension=100)"
      ],
      "metadata": {
        "id": "OUeSBZmDQKcS"
      },
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s100.zip"
      ],
      "metadata": {
        "id": "2ZR2LAuVVTXx"
      },
      "execution_count": 270,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip download.php?file=embeddings%2Fglove%2Fglove_s100.zip"
      ],
      "metadata": {
        "id": "OaoF4imiZHPH"
      },
      "execution_count": 271,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_pt = pd.read_csv(\n",
        "    'glove_s100.txt', \n",
        "    sep=\" \", \n",
        "    quoting=3, \n",
        "    header=None, \n",
        "    index_col=0,\n",
        "    skiprows=1)"
      ],
      "metadata": {
        "id": "vioiUcsaQKf9"
      },
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_pt.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "pGLfKfyVbKkg",
        "outputId": "bcf2560c-9676-4135-cea0-f99111299ae2"
      },
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         1         2         3         4         5         6         7    \\\n",
              "0                                                                          \n",
              ",  -0.392279 -0.383096 -0.163537 -1.615735 -0.500976 -0.007344  0.465154   \n",
              "de -0.059871 -0.266130 -1.288952 -2.352894  0.414237  0.621193  1.073003   \n",
              ".  -0.316228  0.152535 -0.348308 -1.317098 -0.343182  0.486299 -0.361778   \n",
              "a  -1.186349 -0.385310 -0.378241 -2.474666  0.707291  0.086132  0.244584   \n",
              "o  -0.540110 -0.063359  0.194538 -2.323175 -0.100174  1.276602  0.238280   \n",
              "\n",
              "         8         9         10   ...       91        92        93        94   \\\n",
              "0                                 ...                                           \n",
              ",  -0.527951 -0.646091 -0.321491  ... -0.497059  1.318589 -0.233006 -0.156836   \n",
              "de -0.548189 -0.643191  0.966722  ... -0.388322  1.054918 -0.412016  0.565986   \n",
              ".  -0.758097 -0.200598  0.647857  ... -0.692086  0.909492 -0.121445 -0.189453   \n",
              "a  -0.624107 -0.237829  0.392953  ... -0.316421  1.011388  0.202223 -0.575371   \n",
              "o  -0.623534 -0.347138 -0.129575  ...  0.323425  1.159988 -0.642872 -1.545277   \n",
              "\n",
              "         95        96        97        98        99        100  \n",
              "0                                                               \n",
              ",   0.445024  0.582988  0.177718  0.774904  2.415028 -0.148173  \n",
              "de  0.697279 -0.073342  0.275684  0.049941  2.603193  0.559911  \n",
              ".   0.740305  0.316062  0.507474  0.699510  2.571814  0.632679  \n",
              "a   0.026287 -0.275881  0.052405  0.313878  3.199491  0.827020  \n",
              "o   0.151334 -0.785550  0.704339  1.013909  2.478992 -0.193909  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4c83b068-1f0f-4fdb-ba04-3ece6fb2a806\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>,</th>\n",
              "      <td>-0.392279</td>\n",
              "      <td>-0.383096</td>\n",
              "      <td>-0.163537</td>\n",
              "      <td>-1.615735</td>\n",
              "      <td>-0.500976</td>\n",
              "      <td>-0.007344</td>\n",
              "      <td>0.465154</td>\n",
              "      <td>-0.527951</td>\n",
              "      <td>-0.646091</td>\n",
              "      <td>-0.321491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.497059</td>\n",
              "      <td>1.318589</td>\n",
              "      <td>-0.233006</td>\n",
              "      <td>-0.156836</td>\n",
              "      <td>0.445024</td>\n",
              "      <td>0.582988</td>\n",
              "      <td>0.177718</td>\n",
              "      <td>0.774904</td>\n",
              "      <td>2.415028</td>\n",
              "      <td>-0.148173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>de</th>\n",
              "      <td>-0.059871</td>\n",
              "      <td>-0.266130</td>\n",
              "      <td>-1.288952</td>\n",
              "      <td>-2.352894</td>\n",
              "      <td>0.414237</td>\n",
              "      <td>0.621193</td>\n",
              "      <td>1.073003</td>\n",
              "      <td>-0.548189</td>\n",
              "      <td>-0.643191</td>\n",
              "      <td>0.966722</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.388322</td>\n",
              "      <td>1.054918</td>\n",
              "      <td>-0.412016</td>\n",
              "      <td>0.565986</td>\n",
              "      <td>0.697279</td>\n",
              "      <td>-0.073342</td>\n",
              "      <td>0.275684</td>\n",
              "      <td>0.049941</td>\n",
              "      <td>2.603193</td>\n",
              "      <td>0.559911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>-0.316228</td>\n",
              "      <td>0.152535</td>\n",
              "      <td>-0.348308</td>\n",
              "      <td>-1.317098</td>\n",
              "      <td>-0.343182</td>\n",
              "      <td>0.486299</td>\n",
              "      <td>-0.361778</td>\n",
              "      <td>-0.758097</td>\n",
              "      <td>-0.200598</td>\n",
              "      <td>0.647857</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.692086</td>\n",
              "      <td>0.909492</td>\n",
              "      <td>-0.121445</td>\n",
              "      <td>-0.189453</td>\n",
              "      <td>0.740305</td>\n",
              "      <td>0.316062</td>\n",
              "      <td>0.507474</td>\n",
              "      <td>0.699510</td>\n",
              "      <td>2.571814</td>\n",
              "      <td>0.632679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>-1.186349</td>\n",
              "      <td>-0.385310</td>\n",
              "      <td>-0.378241</td>\n",
              "      <td>-2.474666</td>\n",
              "      <td>0.707291</td>\n",
              "      <td>0.086132</td>\n",
              "      <td>0.244584</td>\n",
              "      <td>-0.624107</td>\n",
              "      <td>-0.237829</td>\n",
              "      <td>0.392953</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.316421</td>\n",
              "      <td>1.011388</td>\n",
              "      <td>0.202223</td>\n",
              "      <td>-0.575371</td>\n",
              "      <td>0.026287</td>\n",
              "      <td>-0.275881</td>\n",
              "      <td>0.052405</td>\n",
              "      <td>0.313878</td>\n",
              "      <td>3.199491</td>\n",
              "      <td>0.827020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o</th>\n",
              "      <td>-0.540110</td>\n",
              "      <td>-0.063359</td>\n",
              "      <td>0.194538</td>\n",
              "      <td>-2.323175</td>\n",
              "      <td>-0.100174</td>\n",
              "      <td>1.276602</td>\n",
              "      <td>0.238280</td>\n",
              "      <td>-0.623534</td>\n",
              "      <td>-0.347138</td>\n",
              "      <td>-0.129575</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323425</td>\n",
              "      <td>1.159988</td>\n",
              "      <td>-0.642872</td>\n",
              "      <td>-1.545277</td>\n",
              "      <td>0.151334</td>\n",
              "      <td>-0.785550</td>\n",
              "      <td>0.704339</td>\n",
              "      <td>1.013909</td>\n",
              "      <td>2.478992</td>\n",
              "      <td>-0.193909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4c83b068-1f0f-4fdb-ba04-3ece6fb2a806')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4c83b068-1f0f-4fdb-ba04-3ece6fb2a806 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4c83b068-1f0f-4fdb-ba04-3ece6fb2a806');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_pt.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "kos_5dqxbQun",
        "outputId": "69965c9b-487f-4937-f211-3236f01a4f69"
      },
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             1         2         3         4         5         6         7    \\\n",
              "0                                                                              \n",
              "~$0.0b  0.023192  0.042274 -0.136690  0.096456 -0.024662  0.064788 -0.119517   \n",
              "~.      0.109924 -0.039958 -0.114303  0.271989  0.022783  0.019153 -0.197778   \n",
              "~>      0.091712 -0.137760 -0.148611  0.280811 -0.040886 -0.156137 -0.345717   \n",
              "~~     -0.029480 -0.069960 -0.124492  0.287964 -0.103688 -0.109228 -0.165033   \n",
              "<unk>   0.077257  0.064637 -0.029866  0.150767 -0.004830 -0.024283 -0.078053   \n",
              "\n",
              "             8         9         10   ...       91        92        93   \\\n",
              "0                                     ...                                 \n",
              "~$0.0b -0.017335  0.140895  0.030265  ...  0.283668 -0.092165  0.006212   \n",
              "~.     -0.027550  0.036257 -0.106391  ...  0.012212 -0.060298  0.015915   \n",
              "~>      0.131649 -0.047881 -0.126024  ...  0.091572  0.002053  0.144309   \n",
              "~~      0.106509 -0.014567 -0.223258  ...  0.158334 -0.154956 -0.081261   \n",
              "<unk>   0.034162  0.049797 -0.111888  ...  0.059529 -0.140611  0.036282   \n",
              "\n",
              "             94        95        96        97        98        99        100  \n",
              "0                                                                             \n",
              "~$0.0b  0.041488 -0.003957 -0.003753  0.025884 -0.059045  0.213298 -0.000441  \n",
              "~.     -0.016765 -0.109300  0.064726 -0.048884  0.034652 -0.218065  0.065903  \n",
              "~>     -0.234035 -0.003793  0.038706  0.107760  0.125965 -0.256933  0.107929  \n",
              "~~      0.057896 -0.140982  0.074473 -0.101146 -0.107334  0.052051  0.020874  \n",
              "<unk>   0.008047 -0.034854  0.027526 -0.075541 -0.054225 -0.150991 -0.027147  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-26d55e9f-2b80-4d4b-a0ff-181befdc10d5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>~$0.0b</th>\n",
              "      <td>0.023192</td>\n",
              "      <td>0.042274</td>\n",
              "      <td>-0.136690</td>\n",
              "      <td>0.096456</td>\n",
              "      <td>-0.024662</td>\n",
              "      <td>0.064788</td>\n",
              "      <td>-0.119517</td>\n",
              "      <td>-0.017335</td>\n",
              "      <td>0.140895</td>\n",
              "      <td>0.030265</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283668</td>\n",
              "      <td>-0.092165</td>\n",
              "      <td>0.006212</td>\n",
              "      <td>0.041488</td>\n",
              "      <td>-0.003957</td>\n",
              "      <td>-0.003753</td>\n",
              "      <td>0.025884</td>\n",
              "      <td>-0.059045</td>\n",
              "      <td>0.213298</td>\n",
              "      <td>-0.000441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>~.</th>\n",
              "      <td>0.109924</td>\n",
              "      <td>-0.039958</td>\n",
              "      <td>-0.114303</td>\n",
              "      <td>0.271989</td>\n",
              "      <td>0.022783</td>\n",
              "      <td>0.019153</td>\n",
              "      <td>-0.197778</td>\n",
              "      <td>-0.027550</td>\n",
              "      <td>0.036257</td>\n",
              "      <td>-0.106391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012212</td>\n",
              "      <td>-0.060298</td>\n",
              "      <td>0.015915</td>\n",
              "      <td>-0.016765</td>\n",
              "      <td>-0.109300</td>\n",
              "      <td>0.064726</td>\n",
              "      <td>-0.048884</td>\n",
              "      <td>0.034652</td>\n",
              "      <td>-0.218065</td>\n",
              "      <td>0.065903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>~&gt;</th>\n",
              "      <td>0.091712</td>\n",
              "      <td>-0.137760</td>\n",
              "      <td>-0.148611</td>\n",
              "      <td>0.280811</td>\n",
              "      <td>-0.040886</td>\n",
              "      <td>-0.156137</td>\n",
              "      <td>-0.345717</td>\n",
              "      <td>0.131649</td>\n",
              "      <td>-0.047881</td>\n",
              "      <td>-0.126024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.091572</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0.144309</td>\n",
              "      <td>-0.234035</td>\n",
              "      <td>-0.003793</td>\n",
              "      <td>0.038706</td>\n",
              "      <td>0.107760</td>\n",
              "      <td>0.125965</td>\n",
              "      <td>-0.256933</td>\n",
              "      <td>0.107929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>~~</th>\n",
              "      <td>-0.029480</td>\n",
              "      <td>-0.069960</td>\n",
              "      <td>-0.124492</td>\n",
              "      <td>0.287964</td>\n",
              "      <td>-0.103688</td>\n",
              "      <td>-0.109228</td>\n",
              "      <td>-0.165033</td>\n",
              "      <td>0.106509</td>\n",
              "      <td>-0.014567</td>\n",
              "      <td>-0.223258</td>\n",
              "      <td>...</td>\n",
              "      <td>0.158334</td>\n",
              "      <td>-0.154956</td>\n",
              "      <td>-0.081261</td>\n",
              "      <td>0.057896</td>\n",
              "      <td>-0.140982</td>\n",
              "      <td>0.074473</td>\n",
              "      <td>-0.101146</td>\n",
              "      <td>-0.107334</td>\n",
              "      <td>0.052051</td>\n",
              "      <td>0.020874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&lt;unk&gt;</th>\n",
              "      <td>0.077257</td>\n",
              "      <td>0.064637</td>\n",
              "      <td>-0.029866</td>\n",
              "      <td>0.150767</td>\n",
              "      <td>-0.004830</td>\n",
              "      <td>-0.024283</td>\n",
              "      <td>-0.078053</td>\n",
              "      <td>0.034162</td>\n",
              "      <td>0.049797</td>\n",
              "      <td>-0.111888</td>\n",
              "      <td>...</td>\n",
              "      <td>0.059529</td>\n",
              "      <td>-0.140611</td>\n",
              "      <td>0.036282</td>\n",
              "      <td>0.008047</td>\n",
              "      <td>-0.034854</td>\n",
              "      <td>0.027526</td>\n",
              "      <td>-0.075541</td>\n",
              "      <td>-0.054225</td>\n",
              "      <td>-0.150991</td>\n",
              "      <td>-0.027147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-26d55e9f-2b80-4d4b-a0ff-181befdc10d5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-26d55e9f-2b80-4d4b-a0ff-181befdc10d5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-26d55e9f-2b80-4d4b-a0ff-181befdc10d5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embedding_pt = {key: val.values for key, val in glove_pt.T.items()}"
      ],
      "metadata": {
        "id": "WhfC-8EeZfRV"
      },
      "execution_count": 275,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# glove_embedding_pt"
      ],
      "metadata": {
        "id": "RjcT0CykbTwO"
      },
      "execution_count": 276,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_pt = [\"The cat sat on mat\",\"we can play with model\"]\n",
        "text_pt = [\"PT em o governo\", \"BRASÍLIA Pesquisa Datafolha publicada hoje revela um dado supreendente: recusando uma postura radical, a esmagadora maioria (77%) dos eleitores quer o PT participando do Governo Fernando Henrique Cardoso.\", \"Tem sentido -- aliás, muitíssimo sentido.\"]\n",
        "\n",
        "tokens = text_pt[1].split()\n",
        "print(f'tokens (large sentence): {tokens}')\n",
        "print(f'len(tokens) (large sentence): {len(tokens)}')\n",
        "print()\n",
        "\n",
        "max_length = 0\n",
        "for sentence in text_pt:\n",
        "    tokens = sentence.split()\n",
        "    len_tokens = len(tokens)\n",
        "    if len_tokens > max_length:\n",
        "        max_length = len_tokens\n",
        "\n",
        "for index, sentence in enumerate(text_pt):\n",
        "    tokens = sentence.split()\n",
        "    len_tokens = len(tokens)\n",
        "    if len_tokens < max_length:\n",
        "        difference = max_length - len_tokens\n",
        "        for i in range(0, difference):\n",
        "            tokens.append( '<unk>' )\n",
        "    text_pt[index] = ' '.join(tokens)\n",
        "\n",
        "for sentence in text_pt:\n",
        "    tokens = sentence.split()\n",
        "    print(f'tokens: {tokens}')\n",
        "    print(f'len(tokens): {len(tokens)}')\n",
        "\n",
        "print()\n",
        "print(len(text_pt))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysQLBCz8fSGc",
        "outputId": "855229fb-593d-4109-aa64-7ee0f1c32992"
      },
      "execution_count": 277,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens (large sentence): ['BRASÍLIA', 'Pesquisa', 'Datafolha', 'publicada', 'hoje', 'revela', 'um', 'dado', 'supreendente:', 'recusando', 'uma', 'postura', 'radical,', 'a', 'esmagadora', 'maioria', '(77%)', 'dos', 'eleitores', 'quer', 'o', 'PT', 'participando', 'do', 'Governo', 'Fernando', 'Henrique', 'Cardoso.']\n",
            "len(tokens) (large sentence): 28\n",
            "\n",
            "tokens: ['PT', 'em', 'o', 'governo', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 28\n",
            "tokens: ['BRASÍLIA', 'Pesquisa', 'Datafolha', 'publicada', 'hoje', 'revela', 'um', 'dado', 'supreendente:', 'recusando', 'uma', 'postura', 'radical,', 'a', 'esmagadora', 'maioria', '(77%)', 'dos', 'eleitores', 'quer', 'o', 'PT', 'participando', 'do', 'Governo', 'Fernando', 'Henrique', 'Cardoso.']\n",
            "len(tokens): 28\n",
            "tokens: ['Tem', 'sentido', '--', 'aliás,', 'muitíssimo', 'sentido.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 28\n",
            "\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix_pt( word_index, embedding_dict, dimension ):\n",
        "  embedding_matrix = np.zeros( (len(word_index)+1, dimension) )\n",
        " \n",
        "  for word,index in word_index.items():\n",
        "    if word in embedding_dict:\n",
        "      embedding_matrix[index]=embedding_dict[word]\n",
        "  return embedding_matrix\n",
        " \n",
        "tokenizer_pt = tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
        "tokenizer_pt.fit_on_texts(text_pt)\n",
        " \n",
        "# Trying to solve a bug.\n",
        "total_sentences = len(text_pt)\n",
        "last_sentence = text_pt[total_sentences - 1]\n",
        "last_sentence_tokens = last_sentence.split()\n",
        "last_sentence_tokens.append( '<unk>' )\n",
        "text_pt[total_sentences - 1] = ' '.join( last_sentence_tokens )\n",
        "\n",
        "text_token_pt = tokenizer_pt.texts_to_sequences(text_pt)\n",
        " \n",
        "embedding_matrix_pt = create_embedding_matrix_pt(\n",
        "    tokenizer_pt.word_index,\n",
        "    embedding_dict = glove_embedding_pt,\n",
        "    dimension = 100)"
      ],
      "metadata": {
        "id": "KeN3DP0DVrQf"
      },
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in text_token_pt:\n",
        "    print(len(item))\n",
        "    print(item)\n",
        "    print('-------------------------')\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2S2YPjDj_Z9",
        "outputId": "9ee17089-4bc7-4edc-e0f2-8f119d70f63a"
      },
      "execution_count": 279,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n",
            "[2, 6, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "28\n",
            "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 3, 2, 27, 28, 4, 29, 30, 31]\n",
            "-------------------------\n",
            "\n",
            "28\n",
            "[32, 5, 33, 34, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_matrix_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_22_zejfVrTg",
        "outputId": "66675928-b539-4646-ff93-086b1452d5e6"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
              "         0.      ],\n",
              "       [ 0.156559,  0.111655, -0.015184, ..., -0.009003, -0.178693,\n",
              "        -0.02881 ],\n",
              "       [-0.360137,  0.413591,  0.595686, ..., -0.271249,  0.947247,\n",
              "        -0.11366 ],\n",
              "       ...,\n",
              "       [-0.447209,  0.020918, -0.909347, ..., -0.163448,  2.087506,\n",
              "        -0.756201],\n",
              "       [ 0.409635, -0.1308  , -0.343453, ...,  0.576715,  1.726277,\n",
              "        -0.463   ],\n",
              "       [-0.374381, -0.641518, -0.083434, ...,  0.759932,  0.753288,\n",
              "        -0.396907]])"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_pt = embedding_matrix_pt.shape[0]\n",
        "vector_size_pt = embedding_matrix_pt.shape[1]\n",
        " \n",
        "embedding_pt = nn.Embedding(\n",
        "    num_embeddings = vocab_size_pt,\n",
        "    embedding_dim = vector_size_pt)"
      ],
      "metadata": {
        "id": "TYL8vmN-VrWh"
      },
      "execution_count": 281,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d4YKE8mcECN",
        "outputId": "764357d3-b340-4b61-8669-35ec50919a1b"
      },
      "execution_count": 282,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(35, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 282
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt.weight = nn.Parameter(\n",
        "    torch.tensor( \n",
        "        embedding_matrix_pt,\n",
        "        dtype = torch.float32))"
      ],
      "metadata": {
        "id": "B3IZEm_XVrkT"
      },
      "execution_count": 283,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggr7dMqJcMN3",
        "outputId": "fc85f95a-744f-4ccc-c964-b39a9f8daaad"
      },
      "execution_count": 284,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(35, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 284
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt( torch.LongTensor([1]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDUMLGT_cMQW",
        "outputId": "1311d652-4cec-42d0-e0cf-5db62dba0475"
      },
      "execution_count": 285,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1566,  0.1117, -0.0152,  0.2379, -0.0216, -0.0107,  0.1072,  0.0079,\n",
              "          0.0494, -0.0778, -0.0899,  0.0529, -0.0396,  0.2029, -0.0374,  0.1199,\n",
              "          0.0809,  0.1342, -0.0090, -0.0834, -0.0824, -0.0700,  0.1080,  0.2166,\n",
              "          0.1193, -0.0090, -0.1851, -0.1200,  0.0541, -0.1695, -0.0515,  0.0963,\n",
              "         -0.0076,  0.0464, -0.0442,  0.0612, -0.0656,  0.0922,  0.2037, -0.0509,\n",
              "          0.0409, -0.0548,  0.1614, -0.2111,  0.0966,  0.0693, -0.0541, -0.0616,\n",
              "         -0.0084, -0.0246, -0.1267,  0.0437, -0.0291,  0.0008, -0.0207,  0.0924,\n",
              "          0.0360,  0.0383,  0.1084,  0.0118, -0.0112, -0.0261,  0.1788, -0.0073,\n",
              "          0.0591, -0.0003, -0.0276,  0.0295, -0.1592,  0.1003,  0.0111,  0.0169,\n",
              "         -0.0067,  0.1499, -0.2063, -0.1196,  0.0076, -0.0756,  0.1790,  0.1040,\n",
              "          0.0168,  0.2922,  0.1378,  0.1308, -0.0529,  0.1065,  0.1111,  0.1954,\n",
              "          0.0441,  0.0470, -0.0312, -0.2474, -0.0717,  0.0511,  0.0974,  0.0909,\n",
              "          0.0424, -0.0090, -0.1787, -0.0288]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 285
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make it untrainable by freezing its gradient."
      ],
      "metadata": {
        "id": "AtnQ7qExcgQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt.weight.requires_grad = False"
      ],
      "metadata": {
        "id": "hiewvx_KcMXO"
      },
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for item in text_token_pt:\n",
        "    print(len(item))\n",
        "    print(item)\n",
        "    print('-------------------------')\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cGJr_HcjU0L",
        "outputId": "f574121c-6575-4f59-e5ef-c02acffc99fa"
      },
      "execution_count": 287,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28\n",
            "[2, 6, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "28\n",
            "[7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 3, 2, 27, 28, 4, 29, 30, 31]\n",
            "-------------------------\n",
            "\n",
            "28\n",
            "[32, 5, 33, 34, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = [32, 5, 33, 34, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
        "len(temp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1E0bQL3jrkP",
        "outputId": "186d2824-7cf2-4bd2-8283-b83f3dc6e9d4"
      },
      "execution_count": 288,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27"
            ]
          },
          "metadata": {},
          "execution_count": 288
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.LongTensor(text_token_pt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad65xI3NjSyE",
        "outputId": "a6c7dbdf-c15e-4b41-ef0f-5d5bc79cf662"
      },
      "execution_count": 289,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 2,  6,  3,  4,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1],\n",
              "        [ 7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24,\n",
              "         25, 26,  3,  2, 27, 28,  4, 29, 30, 31],\n",
              "        [32,  5, 33, 34,  5,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
              "          1,  1,  1,  1,  1,  1,  1,  1,  1,  1]])"
            ]
          },
          "metadata": {},
          "execution_count": 289
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vec_pt = embedding_pt(\n",
        "    torch.LongTensor(text_token_pt))\n",
        "print(embedding_pt)\n",
        "print(embedding_vec_pt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw018uD6cgCz",
        "outputId": "7dbfef25-3647-42d3-e16c-ba4f4a8f40b0"
      },
      "execution_count": 290,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(35, 100)\n",
            "torch.Size([3, 28, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Iu1OWgbPcMZ0"
      },
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gitDtJHZcMch"
      },
      "execution_count": 290,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tagger_gru_embeddings.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Mudando o diretório para o meu Google Drive para não precisar ficar baixando os datasets novamente."
      ],
      "metadata": {
        "id": "Ko9vDXvyXSlO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYV22az9XSrU",
        "outputId": "9a44d179-22bc-43bb-a353-5e41f24d9580"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PGnjt39XhdH",
        "outputId": "d614392e-5242-4ee9-eb9a-24c3aad01002"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNUsW8kNXhf8",
        "outputId": "3760ac05-654d-4797-9593-521e60eb2bb0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "13Zm6Zy6Xhh2",
        "outputId": "64e43dee-bbc6-4450-a2eb-f8501a96763c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "BMVNR0MzsBUt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "mnhnR46vsBbR"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install pyconll\n",
        "import pyconll # https://github.com/soutsios/pos-tagger-bert/blob/master/pos_tagger_bert.ipynb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_aAU1n7Rnkow",
        "outputId": "d84b08ef-5de4-4ced-c433-4b6f518e0c3b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyconll\n",
            "  Downloading pyconll-3.1.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyconll\n",
            "Successfully installed pyconll-3.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Embeddings\n",
        "\n",
        "Baseado em https://colab.research.google.com/drive/1BuLyMlebp43-3KNn-puezjW5S1CGuSI5?usp=sharing"
      ],
      "metadata": {
        "id": "_eBTGJTxMxea"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qjSOQB7lMPRZ"
      },
      "outputs": [],
      "source": [
        "# !wget http://143.107.183.175:22980/download.php?file=embeddings/word2vec/cbow_s50.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip download.php?file=embeddings%2Fword2vec%2Fcbow_s50.zip"
      ],
      "metadata": {
        "id": "bbAlt9nKYy0Q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec = KeyedVectors.load_word2vec_format('cbow_s50.txt')\n",
        "# word2vec"
      ],
      "metadata": {
        "id": "kKVdAeduMzW1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec['menino']"
      ],
      "metadata": {
        "id": "5vb5x8UxMzZA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec.most_similar('homem')"
      ],
      "metadata": {
        "id": "_JJxbykVMzbe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec.similarity('menino', 'cachorro')"
      ],
      "metadata": {
        "id": "ricn90w1Mzd8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec.most_similar(positive=['amar', 'odiando'], negative=['odiar'])"
      ],
      "metadata": {
        "id": "e1_oJu3HMzgQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Train Word Embedding in PyTorch\n",
        "\n",
        "Baseado em https://androidkt.com/pre-train-word-embedding-in-pytorch/"
      ],
      "metadata": {
        "id": "dFLp5W7UNbGT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://nlp.stanford.edu/data/wordvecs/glove.6B.zip"
      ],
      "metadata": {
        "id": "T-lY1Jr4NRe0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip glove.6B.zip"
      ],
      "metadata": {
        "id": "oJSOUzg7Y2CU"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# glove = pd.read_csv('glove.6B.100d.txt', sep=\" \", quoting=3, header=None, index_col=0)\n",
        "# glove_embedding = {key: val.values for key, val in glove.T.items()}"
      ],
      "metadata": {
        "id": "R4Uuu5-PNRhV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_embedding_matrix(word_index,embedding_dict,dimension):\n",
        "#   embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
        " \n",
        "#   for word,index in word_index.items():\n",
        "#     if word in embedding_dict:\n",
        "#       embedding_matrix[index]=embedding_dict[word]\n",
        "#   return embedding_matrix\n",
        " \n",
        "# text=[\"The cat sat on mat\",\"we can play with model\"]\n",
        " \n",
        "# tokenizer=tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
        "# tokenizer.fit_on_texts(text)\n",
        " \n",
        "# text_token=tokenizer.texts_to_sequences(text)\n",
        " \n",
        "# embedding_matrix=create_embedding_matrix(\n",
        "#     tokenizer.word_index,\n",
        "#     embedding_dict=glove_embedding,dimension=EMBEDDINGS_SIZE)"
      ],
      "metadata": {
        "id": "mFF2NQWmNRjr"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_token"
      ],
      "metadata": {
        "id": "aRLDrSYyRb-l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer.word_index"
      ],
      "metadata": {
        "id": "3FafuXLBRZ08"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab_size=embedding_matrix.shape[0]\n",
        "# vector_size=embedding_matrix.shape[1]\n",
        " \n",
        "# embedding=nn.Embedding(num_embeddings=vocab_size,embedding_dim=vector_size)"
      ],
      "metadata": {
        "id": "c250HDnNNRqT"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding.weight=nn.Parameter(torch.tensor(embedding_matrix,dtype=torch.float32))"
      ],
      "metadata": {
        "id": "wdScrDwONRtO"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding(torch.LongTensor([1]))"
      ],
      "metadata": {
        "id": "pEeyOVuRNRvn"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding.weight.requires_grad=False"
      ],
      "metadata": {
        "id": "fSdfYkOGNyyj"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_vec=embedding(torch.LongTensor(text_token))\n",
        "# print(embedding)\n",
        "# print(embedding_vec.shape)"
      ],
      "metadata": {
        "id": "dBcSa4tHNy0s"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_dim=vector_size\n",
        "# lstm=nn.LSTM(embedding_dim,128,bidirectional=True,batch_first=True)(embedding_vec)\n",
        "# lstm"
      ],
      "metadata": {
        "id": "4xqlHvcTNy5d"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nova tentativa de treinar o GRU com embeddings pré-treinados."
      ],
      "metadata": {
        "id": "LfHCvqg2QEvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EMBEDDINGS_SIZE = 100"
      ],
      "metadata": {
        "id": "xgNgjRFpe29r"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "{'can': 7,\n",
        " 'cat': 2,\n",
        " 'mat': 5,\n",
        " 'model': 10,\n",
        " 'on': 4,\n",
        " 'play': 8,\n",
        " 'sat': 3,\n",
        " 'the': 1,\n",
        " 'we': 6,\n",
        " 'with': 9}\n",
        " '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "qsjO2HioR3u5",
        "outputId": "1a39960a-a71c-4b70-8349-7c454246e435"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n{'can': 7,\\n 'cat': 2,\\n 'mat': 5,\\n 'model': 10,\\n 'on': 4,\\n 'play': 8,\\n 'sat': 3,\\n 'the': 1,\\n 'we': 6,\\n 'with': 9}\\n \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2index = {token: token_index for token_index, token in enumerate(word2vec.index2word)}\n",
        "# word2index['menino']"
      ],
      "metadata": {
        "id": "ks3i5GbbRHFX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# word2index"
      ],
      "metadata": {
        "id": "-C-u7RbwS9On"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# glove_embedding"
      ],
      "metadata": {
        "id": "xUyJ7JQYTL4t"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "{'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
        "        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
        "         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
        "        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
        "         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
        "        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
        "         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
        "         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
        "        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
        "        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
        "        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
        "        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
        "        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
        "        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
        "        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
        "         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
        "        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ]),\n",
        " ',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\n",
        " [...]\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "N4tUdUDgTNTp",
        "outputId": "fdeeee98-3c7a-4ec0-d492-6bb092ae698d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n{'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\\n        -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\\n         0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\\n        -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\\n         0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\\n        -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\\n         0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\\n         0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\\n        -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\\n        -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\\n        -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\\n        -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\\n        -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\\n        -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\\n        -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\\n         0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\\n        -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ]),\\n ',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\\n [...]\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# word2vec_embedding = {}\n",
        "\n",
        "# for index, token in enumerate(word2vec.vocab):\n",
        "#     if index < 3:\n",
        "#         print(f'token: {token}')\n",
        "#         print(f'embeddings: {word2vec[token]}')\n",
        "\n",
        "#         {'the': array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
        "#         -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
        "#          0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
        "#         -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
        "#          0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
        "#         -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
        "#          0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
        "#          0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
        "#         -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
        "#         -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
        "#         -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
        "#         -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
        "#         -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
        "#         -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
        "#         -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
        "#          0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
        "#         -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ]),\n",
        "#  ',': array([-0.10767  ,  0.11053  ,  0.59812  , -0.54361  ,  0.67396  ,\n",
        "#  [...]\n",
        "#  '''"
      ],
      "metadata": {
        "id": "P9ymWtcCTYtW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_embedding_matrix_word2vec(word_index,embedding_dict,dimension):\n",
        "#   embedding_matrix=np.zeros((len(word_index)+1,dimension))\n",
        " \n",
        "#   for word,index in word_index.items():\n",
        "#     if word in embedding_dict:\n",
        "#       embedding_matrix[index]=embedding_dict[word]\n",
        "#   return embedding_matrix\n",
        " \n",
        "# embedding_matrix_word2vec=create_embedding_matrix(\n",
        "#     word2index,\n",
        "#     embedding_dict=glove_embedding,\n",
        "#     dimension=EMBEDDINGS_SIZE)"
      ],
      "metadata": {
        "id": "OUeSBZmDQKcS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !wget http://143.107.183.175:22980/download.php?file=embeddings/glove/glove_s100.zip"
      ],
      "metadata": {
        "id": "2ZR2LAuVVTXx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip download.php?file=embeddings%2Fglove%2Fglove_s100.zip"
      ],
      "metadata": {
        "id": "OaoF4imiZHPH"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_pt = pd.read_csv(\n",
        "    'glove_s100.txt', \n",
        "    sep=\" \", \n",
        "    quoting=3, \n",
        "    header=None, \n",
        "    index_col=0,\n",
        "    skiprows=1)"
      ],
      "metadata": {
        "id": "vioiUcsaQKf9"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "glove_pt.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "pGLfKfyVbKkg",
        "outputId": "adcea3c3-7544-4c7d-b925-7d05cfb00d03"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         1         2         3         4         5         6         7    \\\n",
              "0                                                                          \n",
              ",  -0.392279 -0.383096 -0.163537 -1.615735 -0.500976 -0.007344  0.465154   \n",
              "de -0.059871 -0.266130 -1.288952 -2.352894  0.414237  0.621193  1.073003   \n",
              ".  -0.316228  0.152535 -0.348308 -1.317098 -0.343182  0.486299 -0.361778   \n",
              "a  -1.186349 -0.385310 -0.378241 -2.474666  0.707291  0.086132  0.244584   \n",
              "o  -0.540110 -0.063359  0.194538 -2.323175 -0.100174  1.276602  0.238280   \n",
              "\n",
              "         8         9         10   ...       91        92        93        94   \\\n",
              "0                                 ...                                           \n",
              ",  -0.527951 -0.646091 -0.321491  ... -0.497059  1.318589 -0.233006 -0.156836   \n",
              "de -0.548189 -0.643191  0.966722  ... -0.388322  1.054918 -0.412016  0.565986   \n",
              ".  -0.758097 -0.200598  0.647857  ... -0.692086  0.909492 -0.121445 -0.189453   \n",
              "a  -0.624107 -0.237829  0.392953  ... -0.316421  1.011388  0.202223 -0.575371   \n",
              "o  -0.623534 -0.347138 -0.129575  ...  0.323425  1.159988 -0.642872 -1.545277   \n",
              "\n",
              "         95        96        97        98        99        100  \n",
              "0                                                               \n",
              ",   0.445024  0.582988  0.177718  0.774904  2.415028 -0.148173  \n",
              "de  0.697279 -0.073342  0.275684  0.049941  2.603193  0.559911  \n",
              ".   0.740305  0.316062  0.507474  0.699510  2.571814  0.632679  \n",
              "a   0.026287 -0.275881  0.052405  0.313878  3.199491  0.827020  \n",
              "o   0.151334 -0.785550  0.704339  1.013909  2.478992 -0.193909  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-207ff8a6-0b63-4ac8-b8da-c87ef19f6500\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>,</th>\n",
              "      <td>-0.392279</td>\n",
              "      <td>-0.383096</td>\n",
              "      <td>-0.163537</td>\n",
              "      <td>-1.615735</td>\n",
              "      <td>-0.500976</td>\n",
              "      <td>-0.007344</td>\n",
              "      <td>0.465154</td>\n",
              "      <td>-0.527951</td>\n",
              "      <td>-0.646091</td>\n",
              "      <td>-0.321491</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.497059</td>\n",
              "      <td>1.318589</td>\n",
              "      <td>-0.233006</td>\n",
              "      <td>-0.156836</td>\n",
              "      <td>0.445024</td>\n",
              "      <td>0.582988</td>\n",
              "      <td>0.177718</td>\n",
              "      <td>0.774904</td>\n",
              "      <td>2.415028</td>\n",
              "      <td>-0.148173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>de</th>\n",
              "      <td>-0.059871</td>\n",
              "      <td>-0.266130</td>\n",
              "      <td>-1.288952</td>\n",
              "      <td>-2.352894</td>\n",
              "      <td>0.414237</td>\n",
              "      <td>0.621193</td>\n",
              "      <td>1.073003</td>\n",
              "      <td>-0.548189</td>\n",
              "      <td>-0.643191</td>\n",
              "      <td>0.966722</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.388322</td>\n",
              "      <td>1.054918</td>\n",
              "      <td>-0.412016</td>\n",
              "      <td>0.565986</td>\n",
              "      <td>0.697279</td>\n",
              "      <td>-0.073342</td>\n",
              "      <td>0.275684</td>\n",
              "      <td>0.049941</td>\n",
              "      <td>2.603193</td>\n",
              "      <td>0.559911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>.</th>\n",
              "      <td>-0.316228</td>\n",
              "      <td>0.152535</td>\n",
              "      <td>-0.348308</td>\n",
              "      <td>-1.317098</td>\n",
              "      <td>-0.343182</td>\n",
              "      <td>0.486299</td>\n",
              "      <td>-0.361778</td>\n",
              "      <td>-0.758097</td>\n",
              "      <td>-0.200598</td>\n",
              "      <td>0.647857</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.692086</td>\n",
              "      <td>0.909492</td>\n",
              "      <td>-0.121445</td>\n",
              "      <td>-0.189453</td>\n",
              "      <td>0.740305</td>\n",
              "      <td>0.316062</td>\n",
              "      <td>0.507474</td>\n",
              "      <td>0.699510</td>\n",
              "      <td>2.571814</td>\n",
              "      <td>0.632679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>a</th>\n",
              "      <td>-1.186349</td>\n",
              "      <td>-0.385310</td>\n",
              "      <td>-0.378241</td>\n",
              "      <td>-2.474666</td>\n",
              "      <td>0.707291</td>\n",
              "      <td>0.086132</td>\n",
              "      <td>0.244584</td>\n",
              "      <td>-0.624107</td>\n",
              "      <td>-0.237829</td>\n",
              "      <td>0.392953</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.316421</td>\n",
              "      <td>1.011388</td>\n",
              "      <td>0.202223</td>\n",
              "      <td>-0.575371</td>\n",
              "      <td>0.026287</td>\n",
              "      <td>-0.275881</td>\n",
              "      <td>0.052405</td>\n",
              "      <td>0.313878</td>\n",
              "      <td>3.199491</td>\n",
              "      <td>0.827020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>o</th>\n",
              "      <td>-0.540110</td>\n",
              "      <td>-0.063359</td>\n",
              "      <td>0.194538</td>\n",
              "      <td>-2.323175</td>\n",
              "      <td>-0.100174</td>\n",
              "      <td>1.276602</td>\n",
              "      <td>0.238280</td>\n",
              "      <td>-0.623534</td>\n",
              "      <td>-0.347138</td>\n",
              "      <td>-0.129575</td>\n",
              "      <td>...</td>\n",
              "      <td>0.323425</td>\n",
              "      <td>1.159988</td>\n",
              "      <td>-0.642872</td>\n",
              "      <td>-1.545277</td>\n",
              "      <td>0.151334</td>\n",
              "      <td>-0.785550</td>\n",
              "      <td>0.704339</td>\n",
              "      <td>1.013909</td>\n",
              "      <td>2.478992</td>\n",
              "      <td>-0.193909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-207ff8a6-0b63-4ac8-b8da-c87ef19f6500')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-207ff8a6-0b63-4ac8-b8da-c87ef19f6500 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-207ff8a6-0b63-4ac8-b8da-c87ef19f6500');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_pt.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "kos_5dqxbQun",
        "outputId": "6b1ca50c-cc07-47f8-83c1-36090e6f7652"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             1         2         3         4         5         6         7    \\\n",
              "0                                                                              \n",
              "~$0.0b  0.023192  0.042274 -0.136690  0.096456 -0.024662  0.064788 -0.119517   \n",
              "~.      0.109924 -0.039958 -0.114303  0.271989  0.022783  0.019153 -0.197778   \n",
              "~>      0.091712 -0.137760 -0.148611  0.280811 -0.040886 -0.156137 -0.345717   \n",
              "~~     -0.029480 -0.069960 -0.124492  0.287964 -0.103688 -0.109228 -0.165033   \n",
              "<unk>   0.077257  0.064637 -0.029866  0.150767 -0.004830 -0.024283 -0.078053   \n",
              "\n",
              "             8         9         10   ...       91        92        93   \\\n",
              "0                                     ...                                 \n",
              "~$0.0b -0.017335  0.140895  0.030265  ...  0.283668 -0.092165  0.006212   \n",
              "~.     -0.027550  0.036257 -0.106391  ...  0.012212 -0.060298  0.015915   \n",
              "~>      0.131649 -0.047881 -0.126024  ...  0.091572  0.002053  0.144309   \n",
              "~~      0.106509 -0.014567 -0.223258  ...  0.158334 -0.154956 -0.081261   \n",
              "<unk>   0.034162  0.049797 -0.111888  ...  0.059529 -0.140611  0.036282   \n",
              "\n",
              "             94        95        96        97        98        99        100  \n",
              "0                                                                             \n",
              "~$0.0b  0.041488 -0.003957 -0.003753  0.025884 -0.059045  0.213298 -0.000441  \n",
              "~.     -0.016765 -0.109300  0.064726 -0.048884  0.034652 -0.218065  0.065903  \n",
              "~>     -0.234035 -0.003793  0.038706  0.107760  0.125965 -0.256933  0.107929  \n",
              "~~      0.057896 -0.140982  0.074473 -0.101146 -0.107334  0.052051  0.020874  \n",
              "<unk>   0.008047 -0.034854  0.027526 -0.075541 -0.054225 -0.150991 -0.027147  \n",
              "\n",
              "[5 rows x 100 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5862b3b8-f7da-4a87-adbd-43463fc70d58\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>91</th>\n",
              "      <th>92</th>\n",
              "      <th>93</th>\n",
              "      <th>94</th>\n",
              "      <th>95</th>\n",
              "      <th>96</th>\n",
              "      <th>97</th>\n",
              "      <th>98</th>\n",
              "      <th>99</th>\n",
              "      <th>100</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>~$0.0b</th>\n",
              "      <td>0.023192</td>\n",
              "      <td>0.042274</td>\n",
              "      <td>-0.136690</td>\n",
              "      <td>0.096456</td>\n",
              "      <td>-0.024662</td>\n",
              "      <td>0.064788</td>\n",
              "      <td>-0.119517</td>\n",
              "      <td>-0.017335</td>\n",
              "      <td>0.140895</td>\n",
              "      <td>0.030265</td>\n",
              "      <td>...</td>\n",
              "      <td>0.283668</td>\n",
              "      <td>-0.092165</td>\n",
              "      <td>0.006212</td>\n",
              "      <td>0.041488</td>\n",
              "      <td>-0.003957</td>\n",
              "      <td>-0.003753</td>\n",
              "      <td>0.025884</td>\n",
              "      <td>-0.059045</td>\n",
              "      <td>0.213298</td>\n",
              "      <td>-0.000441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>~.</th>\n",
              "      <td>0.109924</td>\n",
              "      <td>-0.039958</td>\n",
              "      <td>-0.114303</td>\n",
              "      <td>0.271989</td>\n",
              "      <td>0.022783</td>\n",
              "      <td>0.019153</td>\n",
              "      <td>-0.197778</td>\n",
              "      <td>-0.027550</td>\n",
              "      <td>0.036257</td>\n",
              "      <td>-0.106391</td>\n",
              "      <td>...</td>\n",
              "      <td>0.012212</td>\n",
              "      <td>-0.060298</td>\n",
              "      <td>0.015915</td>\n",
              "      <td>-0.016765</td>\n",
              "      <td>-0.109300</td>\n",
              "      <td>0.064726</td>\n",
              "      <td>-0.048884</td>\n",
              "      <td>0.034652</td>\n",
              "      <td>-0.218065</td>\n",
              "      <td>0.065903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>~&gt;</th>\n",
              "      <td>0.091712</td>\n",
              "      <td>-0.137760</td>\n",
              "      <td>-0.148611</td>\n",
              "      <td>0.280811</td>\n",
              "      <td>-0.040886</td>\n",
              "      <td>-0.156137</td>\n",
              "      <td>-0.345717</td>\n",
              "      <td>0.131649</td>\n",
              "      <td>-0.047881</td>\n",
              "      <td>-0.126024</td>\n",
              "      <td>...</td>\n",
              "      <td>0.091572</td>\n",
              "      <td>0.002053</td>\n",
              "      <td>0.144309</td>\n",
              "      <td>-0.234035</td>\n",
              "      <td>-0.003793</td>\n",
              "      <td>0.038706</td>\n",
              "      <td>0.107760</td>\n",
              "      <td>0.125965</td>\n",
              "      <td>-0.256933</td>\n",
              "      <td>0.107929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>~~</th>\n",
              "      <td>-0.029480</td>\n",
              "      <td>-0.069960</td>\n",
              "      <td>-0.124492</td>\n",
              "      <td>0.287964</td>\n",
              "      <td>-0.103688</td>\n",
              "      <td>-0.109228</td>\n",
              "      <td>-0.165033</td>\n",
              "      <td>0.106509</td>\n",
              "      <td>-0.014567</td>\n",
              "      <td>-0.223258</td>\n",
              "      <td>...</td>\n",
              "      <td>0.158334</td>\n",
              "      <td>-0.154956</td>\n",
              "      <td>-0.081261</td>\n",
              "      <td>0.057896</td>\n",
              "      <td>-0.140982</td>\n",
              "      <td>0.074473</td>\n",
              "      <td>-0.101146</td>\n",
              "      <td>-0.107334</td>\n",
              "      <td>0.052051</td>\n",
              "      <td>0.020874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>&lt;unk&gt;</th>\n",
              "      <td>0.077257</td>\n",
              "      <td>0.064637</td>\n",
              "      <td>-0.029866</td>\n",
              "      <td>0.150767</td>\n",
              "      <td>-0.004830</td>\n",
              "      <td>-0.024283</td>\n",
              "      <td>-0.078053</td>\n",
              "      <td>0.034162</td>\n",
              "      <td>0.049797</td>\n",
              "      <td>-0.111888</td>\n",
              "      <td>...</td>\n",
              "      <td>0.059529</td>\n",
              "      <td>-0.140611</td>\n",
              "      <td>0.036282</td>\n",
              "      <td>0.008047</td>\n",
              "      <td>-0.034854</td>\n",
              "      <td>0.027526</td>\n",
              "      <td>-0.075541</td>\n",
              "      <td>-0.054225</td>\n",
              "      <td>-0.150991</td>\n",
              "      <td>-0.027147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 100 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5862b3b8-f7da-4a87-adbd-43463fc70d58')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5862b3b8-f7da-4a87-adbd-43463fc70d58 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5862b3b8-f7da-4a87-adbd-43463fc70d58');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embedding_pt = {key: val.values for key, val in glove_pt.T.items()}"
      ],
      "metadata": {
        "id": "WhfC-8EeZfRV"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# glove_embedding_pt"
      ],
      "metadata": {
        "id": "RjcT0CykbTwO"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Carregando o dataset do UD\n",
        "\n",
        "Baseado em https://github.com/soutsios/pos-tagger-bert/blob/master/pos_tagger_bert.ipynb"
      ],
      "metadata": {
        "id": "auJ0PVq6naAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset\n",
        "train_X = list()\n",
        "train_y = list()\n",
        "data = pyconll.load_from_file( './datasets/pt_bosque-ud-train.conllu' )\n",
        "train_tagged_sentences=[]\n",
        "t=0\n",
        "for sentence in data:\n",
        "    tagged_sentence=[]\n",
        "    X_sentence = list()\n",
        "    y_sentence = list()\n",
        "    for token in sentence:\n",
        "        if token.upos and token.form:\n",
        "            t+=1\n",
        "            tagged_sentence.append((token.form.lower(), token.upos))\n",
        "\n",
        "            X_sentence.append( token.form )\n",
        "            y_sentence.append( token.upos )\n",
        "    train_X.append( ' '.join(str(t) for t in X_sentence) )\n",
        "    train_y.append( [str(tag) for tag in y_sentence] )\n",
        "    train_tagged_sentences.append(tagged_sentence)"
      ],
      "metadata": {
        "id": "Q7KXXmB2nZdQ"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# devset\n",
        "dev_X = list()\n",
        "dev_y = list()\n",
        "data = pyconll.load_from_file( './datasets/pt_bosque-ud-dev.conllu' )\n",
        "dev_tagged_sentences=[]\n",
        "t=0\n",
        "for sentence in data:\n",
        "    tagged_sentence=[]\n",
        "    X_sentence = list()\n",
        "    y_sentence = list()\n",
        "    for token in sentence:\n",
        "        if token.upos and token.form:\n",
        "            t+=1\n",
        "            tagged_sentence.append((token.form.lower(), token.upos))\n",
        "\n",
        "            X_sentence.append( token.form )\n",
        "            y_sentence.append( token.upos )\n",
        "    dev_X.append( ' '.join(str(t) for t in X_sentence) )\n",
        "    dev_y.append( [str(tag) for tag in y_sentence] )\n",
        "    dev_tagged_sentences.append(tagged_sentence)"
      ],
      "metadata": {
        "id": "JzloIADCdlkl"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pt = train_X"
      ],
      "metadata": {
        "id": "1-lKMctLnZfs"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_pt_dev = dev_X"
      ],
      "metadata": {
        "id": "QPSzGLSJd7Ej"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_pt = [\"The cat sat on mat\",\"we can play with model\"]\n",
        "# text_pt = [\"PT em o governo\", \"BRASÍLIA Pesquisa Datafolha publicada hoje revela um dado supreendente: recusando uma postura radical, a esmagadora maioria (77%) dos eleitores quer o PT participando do Governo Fernando Henrique Cardoso.\", \"Tem sentido -- aliás, muitíssimo sentido.\"]\n",
        "\n",
        "max_length = 0\n",
        "for sentence in text_pt:\n",
        "    tokens = sentence.split()\n",
        "    len_tokens = len(tokens)\n",
        "    if len_tokens > max_length:\n",
        "        max_length = len_tokens\n",
        "\n",
        "for index, sentence in enumerate(text_pt):\n",
        "    tokens = sentence.split()\n",
        "    len_tokens = len(tokens)\n",
        "    if len_tokens < max_length:\n",
        "        difference = max_length - len_tokens\n",
        "        for i in range(0, difference):\n",
        "            tokens.append( '<unk>' )\n",
        "    text_pt[index] = ' '.join(tokens)\n",
        "\n",
        "for index, sentence in enumerate(text_pt):\n",
        "    if index < 5:\n",
        "      tokens = sentence.split()\n",
        "      print(f'tokens: {tokens}')\n",
        "      print(f'len(tokens): {len(tokens)}')\n",
        "      print('-----------------------------------')\n",
        "\n",
        "print()\n",
        "print( f'len(text_pt): {len(text_pt)}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ysQLBCz8fSGc",
        "outputId": "bfaf4626-011f-447c-9928-0e0ef2402a92"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['PT', 'em', 'o', 'governo', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 201\n",
            "-----------------------------------\n",
            "tokens: ['BRASÍLIA', 'Pesquisa', 'Datafolha', 'publicada', 'hoje', 'revela', 'um', 'dado', 'supreendente', ':', 'recusando', 'uma', 'postura', 'radical', ',', 'a', 'esmagadora', 'maioria', '(', '77', '%', ')', 'de', 'os', 'eleitores', 'quer', 'o', 'PT', 'participando', 'de', 'o', 'Governo', 'Fernando', 'Henrique', 'Cardoso', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 201\n",
            "-----------------------------------\n",
            "tokens: ['Tem', 'sentido', '--', 'aliás', ',', 'muitíssimo', 'sentido', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 201\n",
            "-----------------------------------\n",
            "tokens: ['Muito', 'mais', 'de', 'o', 'que', 'em', 'os', 'tempos', 'em', 'a', 'ditadura', ',', 'a', 'solidez', 'de', 'o', 'PT', 'está', ',', 'agora', ',', 'ameaçada', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 201\n",
            "-----------------------------------\n",
            "tokens: ['Nem', 'Lula', 'nem', 'o', 'partido', 'ainda', 'encontraram', 'um', 'discurso', 'para', 'se', 'diferenciar', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 201\n",
            "-----------------------------------\n",
            "\n",
            "len(text_pt): 7018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = 0\n",
        "for sentence in text_pt_dev:\n",
        "    tokens = sentence.split()\n",
        "    len_tokens = len(tokens)\n",
        "    if len_tokens > max_length:\n",
        "        max_length = len_tokens\n",
        "\n",
        "for index, sentence in enumerate(text_pt_dev):\n",
        "    tokens = sentence.split()\n",
        "    len_tokens = len(tokens)\n",
        "    if len_tokens < max_length:\n",
        "        difference = max_length - len_tokens\n",
        "        for i in range(0, difference):\n",
        "            tokens.append( '<unk>' )\n",
        "    text_pt_dev[index] = ' '.join(tokens)\n",
        "\n",
        "for index, sentence in enumerate(text_pt_dev):\n",
        "    if index < 5:\n",
        "      tokens = sentence.split()\n",
        "      print(f'tokens: {tokens}')\n",
        "      print(f'len(tokens): {len(tokens)}')\n",
        "      print('-----------------------------------')\n",
        "\n",
        "print()\n",
        "print( f'len(text_pt_dev): {len(text_pt_dev)}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f-b7n9rpd_Io",
        "outputId": "8104b304-f4f9-4760-ae75-4e176a13f392"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tokens: ['Pequenos', 'são', 'agentes', 'de', 'as', 'transformações', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 132\n",
            "-----------------------------------\n",
            "tokens: ['Já', 'não', 'é', 'correto', 'pensar', 'que', 'o', 'progresso', 'técnico', 'é', 'um', 'privilégio', 'de', 'as', 'grandes', 'empresas', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 132\n",
            "-----------------------------------\n",
            "tokens: ['MAILSON', 'DA', 'NÓBREGA', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 132\n",
            "-----------------------------------\n",
            "tokens: ['Os', 'anos', '80', 'foram', 'um', 'divisor', 'de', 'águas', 'em', 'a', 'industrialização', 'brasileira', '.', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 132\n",
            "-----------------------------------\n",
            "tokens: ['Pelo', 'menos', 'três', 'acontecimentos', 'podem', 'ser', 'destacados', 'por', 'o', 'seu', 'papel', 'indutor', 'de', 'transformações', ':', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>', '<unk>']\n",
            "len(tokens): 132\n",
            "-----------------------------------\n",
            "\n",
            "len(text_pt_dev): 1172\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_embedding_matrix_pt( word_index, embedding_dict, dimension ):\n",
        "  embedding_matrix = np.zeros( (len(word_index)+1, dimension) )\n",
        " \n",
        "  for word,index in word_index.items():\n",
        "    if word in embedding_dict:\n",
        "      embedding_matrix[index] = embedding_dict[word]\n",
        "  return embedding_matrix\n",
        "\n",
        "tokenizer_pt = tf.keras.preprocessing.text.Tokenizer(split=\" \")\n",
        "tokenizer_pt.fit_on_texts(text_pt)\n",
        " \n",
        "# # Trying to solve a bug.\n",
        "# total_sentences = len(text_pt)\n",
        "# last_sentence = text_pt[total_sentences - 1]\n",
        "# last_sentence_tokens = last_sentence.split()\n",
        "# last_sentence_tokens.append( '<unk>' )\n",
        "# text_pt[total_sentences - 1] = ' '.join( last_sentence_tokens )\n",
        "\n",
        "text_token_pt = tokenizer_pt.texts_to_sequences(text_pt)\n",
        "embedding_matrix_pt = create_embedding_matrix_pt(\n",
        "    tokenizer_pt.word_index,\n",
        "    embedding_dict = glove_embedding_pt,\n",
        "    dimension = EMBEDDINGS_SIZE)"
      ],
      "metadata": {
        "id": "KeN3DP0DVrQf"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Completando o tamanho das sentenças com o id de token = \\<unk\\>."
      ],
      "metadata": {
        "id": "BF8O85XHf_Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset\n",
        "max_length = 0\n",
        "for item in text_token_pt:\n",
        "    len_item = len(item)\n",
        "    if len_item > max_length:\n",
        "        max_length = len_item\n",
        "\n",
        "for index, item in enumerate(text_token_pt):\n",
        "    len_item = len(item)\n",
        "    if len_item < max_length:\n",
        "        difference = max_length - len_item\n",
        "        for i in range(0, difference):\n",
        "            item.append( 1 )\n",
        "    text_token_pt[index] = item\n",
        "\n",
        "for index, item in enumerate(text_token_pt):\n",
        "    if index < 5:\n",
        "        \n",
        "        print( f'len(item): {len(item)}' )\n",
        "        print(item)\n",
        "        print('-------------------------')\n",
        "        print()\n",
        "\n",
        "print('-------------------------')\n",
        "print()        \n",
        "last_item_index = len(text_token_pt) - 1\n",
        "last_item = text_token_pt[last_item_index]\n",
        "print( f'len(last item): {len(last_item)}' )\n",
        "print( last_item )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2S2YPjDj_Z9",
        "outputId": "b19ce2eb-3bcb-4a5c-9e64-6316b338606a"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(item): 204\n",
            "[436, 5, 4, 52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "len(item): 204\n",
            "[1681, 533, 2147, 2917, 73, 1513, 14, 1090, 9454, 6145, 16, 2148, 1884, 3, 3524, 608, 3525, 2, 8, 1682, 282, 4, 436, 6146, 2, 4, 52, 249, 386, 639, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "len(item): 204\n",
            "[32, 387, 734, 9455, 387, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "len(item): 204\n",
            "[51, 20, 2, 4, 6, 5, 8, 735, 5, 3, 4464, 3, 9456, 2, 4, 436, 34, 70, 6147, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "len(item): 204\n",
            "[143, 609, 143, 4, 198, 35, 4465, 14, 881, 13, 15, 4466, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "-------------------------\n",
            "\n",
            "len(last item): 204\n",
            "[8, 6144, 3522, 2, 3, 374, 322, 83, 20, 6409, 5, 4, 379, 67, 1804, 4, 42, 146, 2, 3, 1166, 5421, 5304, 12, 8, 21119, 9140, 6072, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# devset\n",
        "max_length = 0\n",
        "for item in text_token_pt_dev:\n",
        "    len_item = len(item)\n",
        "    if len_item > max_length:\n",
        "        max_length = len_item\n",
        "\n",
        "for index, item in enumerate(text_token_pt_dev):\n",
        "    len_item = len(item)\n",
        "    if len_item < max_length:\n",
        "        difference = max_length - len_item\n",
        "        for i in range(0, difference):\n",
        "            item.append( 1 )\n",
        "    text_token_pt_dev[index] = item\n",
        "\n",
        "for index, item in enumerate(text_token_pt_dev):\n",
        "    if index < 5:\n",
        "        \n",
        "        print( f'len(item): {len(item)}' )\n",
        "        print(item)\n",
        "        print('-------------------------')\n",
        "        print()\n",
        "\n",
        "print('-------------------------')\n",
        "print()        \n",
        "last_item_index = len(text_token_pt_dev) - 1\n",
        "last_item = text_token_pt_dev[last_item_index]\n",
        "print( f'len(last item): {len(last_item)}' )\n",
        "print( last_item )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8U7MYJ8gN0I",
        "outputId": "808fc394-8552-4a0b-80b7-9b7881e3b04b"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(item): 135\n",
            "[1275, 24, 844, 2, 11, 1276, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "len(item): 135\n",
            "[36, 18, 19, 2315, 610, 6, 4, 2316, 212, 19, 12, 2317, 2, 11, 162, 163, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "len(item): 135\n",
            "[2318, 2319, 2320, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "len(item): 135\n",
            "[8, 34, 611, 63, 12, 2321, 2, 2322, 5, 3, 2323, 612, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "len(item): 135\n",
            "[1277, 95, 52, 1278, 213, 26, 2324, 13, 4, 27, 164, 2325, 2, 1276, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "-------------------------\n",
            "\n",
            "-------------------------\n",
            "\n",
            "len(last item): 135\n",
            "[356, 11, 6693, 24, 6694, 159, 61, 989, 3, 39, 360, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset\n",
        "embedding_matrix_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_22_zejfVrTg",
        "outputId": "8c31fe6d-d7f6-4b44-c1ff-e3758bc4db92"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
              "         0.      ],\n",
              "       [ 0.156559,  0.111655, -0.015184, ..., -0.009003, -0.178693,\n",
              "        -0.02881 ],\n",
              "       [-0.059871, -0.26613 , -1.288952, ...,  0.049941,  2.603193,\n",
              "         0.559911],\n",
              "       ...,\n",
              "       [-0.521869, -0.323804,  0.429143, ..., -0.355543,  0.04608 ,\n",
              "         0.165209],\n",
              "       [ 0.354441, -0.620891, -0.351661, ...,  0.287087, -0.913356,\n",
              "         0.603573],\n",
              "       [-0.4722  ,  0.268814, -0.390876, ...,  0.548052, -0.250022,\n",
              "         0.388714]])"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# devset\n",
        "embedding_matrix_pt_dev"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njNK0GjhglI7",
        "outputId": "82f3143b-c517-4c79-d4b0-ccace6d3d1a4"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
              "         0.      ],\n",
              "       [ 0.156559,  0.111655, -0.015184, ..., -0.009003, -0.178693,\n",
              "        -0.02881 ],\n",
              "       [-0.059871, -0.26613 , -1.288952, ...,  0.049941,  2.603193,\n",
              "         0.559911],\n",
              "       ...,\n",
              "       [ 0.018154,  0.148979, -0.004639, ...,  1.02579 , -0.397611,\n",
              "        -0.097808],\n",
              "       [ 0.023733, -0.344766, -1.683688, ...,  0.508497,  0.548053,\n",
              "        -0.61285 ],\n",
              "       [-0.453163,  0.616099, -1.446902, ...,  0.45914 ,  1.369714,\n",
              "        -0.409569]])"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vocab size and pos vocab size"
      ],
      "metadata": {
        "id": "4sJlRqz_hHbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size_pt = embedding_matrix_pt.shape[0]\n",
        "vector_size_pt = embedding_matrix_pt.shape[1]"
      ],
      "metadata": {
        "id": "TYL8vmN-VrWh"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding layers"
      ],
      "metadata": {
        "id": "oC0nMteYhtQ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt = nn.Embedding(\n",
        "    num_embeddings = vocab_size_pt,\n",
        "    embedding_dim = vector_size_pt)"
      ],
      "metadata": {
        "id": "wLKmWrGJhmHe"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d4YKE8mcECN",
        "outputId": "f417b6d5-a25a-4c6b-a7c3-e8ec1aac8369"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(21120, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt.weight = nn.Parameter(\n",
        "    torch.tensor( \n",
        "        embedding_matrix_pt,\n",
        "        dtype = torch.float32))"
      ],
      "metadata": {
        "id": "B3IZEm_XVrkT"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggr7dMqJcMN3",
        "outputId": "56780fe6-2f60-4a02-eca3-c3d1719742f5"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(21120, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt( torch.LongTensor([1]) )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDUMLGT_cMQW",
        "outputId": "e9e33777-d50a-4851-b2c1-01a105ac97b4"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1566,  0.1117, -0.0152,  0.2379, -0.0216, -0.0107,  0.1072,  0.0079,\n",
              "          0.0494, -0.0778, -0.0899,  0.0529, -0.0396,  0.2029, -0.0374,  0.1199,\n",
              "          0.0809,  0.1342, -0.0090, -0.0834, -0.0824, -0.0700,  0.1080,  0.2166,\n",
              "          0.1193, -0.0090, -0.1851, -0.1200,  0.0541, -0.1695, -0.0515,  0.0963,\n",
              "         -0.0076,  0.0464, -0.0442,  0.0612, -0.0656,  0.0922,  0.2037, -0.0509,\n",
              "          0.0409, -0.0548,  0.1614, -0.2111,  0.0966,  0.0693, -0.0541, -0.0616,\n",
              "         -0.0084, -0.0246, -0.1267,  0.0437, -0.0291,  0.0008, -0.0207,  0.0924,\n",
              "          0.0360,  0.0383,  0.1084,  0.0118, -0.0112, -0.0261,  0.1788, -0.0073,\n",
              "          0.0591, -0.0003, -0.0276,  0.0295, -0.1592,  0.1003,  0.0111,  0.0169,\n",
              "         -0.0067,  0.1499, -0.2063, -0.1196,  0.0076, -0.0756,  0.1790,  0.1040,\n",
              "          0.0168,  0.2922,  0.1378,  0.1308, -0.0529,  0.1065,  0.1111,  0.1954,\n",
              "          0.0441,  0.0470, -0.0312, -0.2474, -0.0717,  0.0511,  0.0974,  0.0909,\n",
              "          0.0424, -0.0090, -0.1787, -0.0288]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make it untrainable by freezing its gradient."
      ],
      "metadata": {
        "id": "AtnQ7qExcgQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_pt.weight.requires_grad = False"
      ],
      "metadata": {
        "id": "hiewvx_KcMXO"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.LongTensor(text_token_pt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad65xI3NjSyE",
        "outputId": "b4671fa6-09be-418e-c404-a96645dc85d8"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 436,    5,    4,  ...,    1,    1,    1],\n",
              "        [1681,  533, 2147,  ...,    1,    1,    1],\n",
              "        [  32,  387,  734,  ...,    1,    1,    1],\n",
              "        ...,\n",
              "        [4463,   19, 1705,  ...,    1,    1,    1],\n",
              "        [4463,   18, 5329,  ...,    1,    1,    1],\n",
              "        [   8, 6144, 3522,  ...,    1,    1,    1]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_vec_pt = embedding_pt(\n",
        "    torch.LongTensor(text_token_pt))\n",
        "print(embedding_pt)\n",
        "print(embedding_vec_pt.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dw018uD6cgCz",
        "outputId": "807dd364-0e4e-4b2a-c3da-86ad743c3b67"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Embedding(21120, 100)\n",
            "torch.Size([7018, 204, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# embedding_dim_pt = EMBEDDINGS_SIZE\n",
        "# lstm_pt = nn.LSTM(\n",
        "#     embedding_dim_pt,\n",
        "#     128,\n",
        "#     bidirectional = True,\n",
        "#     batch_first = True)(embedding_vec_pt)"
      ],
      "metadata": {
        "id": "Iu1OWgbPcMZ0"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lstm_pt"
      ],
      "metadata": {
        "id": "gitDtJHZcMch"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tagger - GRU"
      ],
      "metadata": {
        "id": "uu1DhUrombYs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Tagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 output_dim,\n",
        "                 n_layers,\n",
        "                 embedding_layer, \n",
        "                 embedding_dim=64,\n",
        "                 hidden_dim=64,\n",
        "                 dropout=0.5,\n",
        "                 bidirectional=True,\n",
        "                 pad_idx=0):\n",
        "        \"\"\"Initializes the tagger.\n",
        "        \n",
        "        Args:\n",
        "            input_dim: Size of the input vocabulary, projection\n",
        "            output_dim: Size of the output vocabulary.\n",
        "            embedding_dim: Dimension of the word embeddings.\n",
        "            hidden_dim: Number of units in each LSTM hidden layer.\n",
        "            bidirectional: Whether or not to use a bidirectional rnn.\n",
        "        \"\"\"\n",
        "        super(Tagger, self).__init__()\n",
        "\n",
        "        # Store parameters\n",
        "        self.input_dim = input_dim \n",
        "        self.output_dim = output_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bidirectional = bidirectional\n",
        "          \n",
        "        # Define layers\n",
        "        # self.word_embeddings = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "        self.word_embeddings = embedding_layer\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \n",
        "                          bidirectional=bidirectional,\n",
        "                          dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.activation = nn.LogSoftmax(dim=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, lengths=None, hidden=None):\n",
        "        \"\"\"Computes a forward pass of the language model.\n",
        "        \n",
        "        Args:\n",
        "            x: A LongTensor w/ dimension [seq_len, batch_size].\n",
        "            lengths: The lengths of the sequences in x.\n",
        "            hidden: Hidden state to be fed into the lstm.\n",
        "            \n",
        "        Returns:\n",
        "            net: Probability of the next word in the sequence.\n",
        "            hidden: Hidden state of the lstm.\n",
        "        \"\"\"\n",
        "        seq_len, batch_size = x.size()\n",
        "        \n",
        "        # If no hidden state is provided, then default to zeros.\n",
        "        if hidden is None:\n",
        "            if self.bidirectional:\n",
        "                num_directions = 2\n",
        "            else:\n",
        "                num_directions = 1\n",
        "            hidden = Variable(torch.zeros(num_directions, batch_size, self.hidden_dim))\n",
        "            if torch.cuda.is_available():\n",
        "                hidden = hidden.cuda()\n",
        "\n",
        "        # net = self.word_embeddings(x)\n",
        "        net = self.word_embeddings\n",
        "        # Pack before feeding into the RNN.\n",
        "        if lengths is not None:\n",
        "            lengths = lengths.data.view(-1).tolist()\n",
        "            net = pack_padded_sequence(net, lengths)\n",
        "        net, hidden = self.rnn(net, hidden)\n",
        "        # Unpack after\n",
        "        if lengths is not None:\n",
        "            net, _ = pad_packed_sequence(net)\n",
        "        net = self.fc(net)\n",
        "        net = self.activation(net)\n",
        "\n",
        "        return net, hidden"
      ],
      "metadata": {
        "id": "wG7uTSlmmazP"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Model"
      ],
      "metadata": {
        "id": "iWRgYqXAt_cG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Vocabulário"
      ],
      "metadata": {
        "id": "bdw95DaXztBQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_pt.document_count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_QdkTLPvpWj",
        "outputId": "6322eb3a-18a4-453a-b65e-b5ca78d0ef76"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7018"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dC1O78FEv5xn",
        "outputId": "6dc36682-4439-48ae-88fc-a3c9863edd5a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7018"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario = []\n",
        "for index, item in enumerate(tokenizer_pt.word_docs):\n",
        "    # if index < 5:\n",
        "    #   print( f'item: {item}' )\n",
        "    #   print( '----------------------------------' )\n",
        "\n",
        "    if item not in vocabulario:\n",
        "        vocabulario.append( item )\n",
        "\n",
        "# print( f'vocabulario[0]: {vocabulario[0]}' )\n",
        "# print( f'vocabulario[1]: {vocabulario[1]}' )\n",
        "# print( f'vocabulario[2]: {vocabulario[2]}' )\n",
        "# print( f'len(vocabulario): {len(vocabulario)}' )"
      ],
      "metadata": {
        "id": "WaEKbnpewCiB"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario_pos = []\n",
        "for index, item in enumerate(train_y):\n",
        "    \n",
        "    # if index < 5:\n",
        "    #     print( f'item: {item}' )\n",
        "    #     print( '----------------------------------' )\n",
        "\n",
        "    for tag in item:\n",
        "        if tag not in vocabulario_pos:\n",
        "            vocabulario_pos.append( tag )\n",
        "\n",
        "# print( f'vocabulario_pos[0]: {vocabulario_pos[0]}' )\n",
        "# print( f'vocabulario_pos[1]: {vocabulario_pos[1]}' )\n",
        "# print( f'vocabulario_pos[2]: {vocabulario_pos[2]}' )\n",
        "# print( f'vocabulario_pos[3]: {vocabulario_pos[3]}' )\n",
        "# print( f'vocabulario_pos[4]: {vocabulario_pos[4]}' )\n",
        "# print( f'vocabulario_pos[5]: {vocabulario_pos[5]}' )\n",
        "# print( f'len(vocabulario_pos): {len(vocabulario_pos)}' )"
      ],
      "metadata": {
        "id": "KbS9cTObxiHr"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqmTzIHY1skN",
        "outputId": "e7580bd0-d60c-4338-fe6c-bad91a70e03f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROPN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'ADJ',\n",
              " 'PUNCT',\n",
              " 'NUM',\n",
              " 'SYM',\n",
              " 'PRON',\n",
              " 'AUX',\n",
              " 'CCONJ',\n",
              " 'SCONJ',\n",
              " 'X',\n",
              " 'INTJ',\n",
              " 'PART']"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario_pos.append('<unk>')"
      ],
      "metadata": {
        "id": "WKNmcQQS1v-E"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario_pos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xMZK3AAn1zzI",
        "outputId": "d5443597-e392-47e0-c762-c8ea4b79a9b6"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROPN',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'ADJ',\n",
              " 'PUNCT',\n",
              " 'NUM',\n",
              " 'SYM',\n",
              " 'PRON',\n",
              " 'AUX',\n",
              " 'CCONJ',\n",
              " 'SCONJ',\n",
              " 'X',\n",
              " 'INTJ',\n",
              " 'PART',\n",
              " '<unk>']"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario_pos_dict = {}\n",
        "for index, tag in enumerate(vocabulario_pos):\n",
        "    vocabulario_pos_dict[tag] = (index + 1)\n",
        "vocabulario_pos_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8CPdiB0u13nY",
        "outputId": "51a1c7f7-12da-45d6-edf8-f34e4a5c1a91"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<unk>': 18,\n",
              " 'ADJ': 7,\n",
              " 'ADP': 2,\n",
              " 'ADV': 6,\n",
              " 'AUX': 12,\n",
              " 'CCONJ': 13,\n",
              " 'DET': 3,\n",
              " 'INTJ': 16,\n",
              " 'NOUN': 4,\n",
              " 'NUM': 9,\n",
              " 'PART': 17,\n",
              " 'PRON': 11,\n",
              " 'PROPN': 1,\n",
              " 'PUNCT': 8,\n",
              " 'SCONJ': 14,\n",
              " 'SYM': 10,\n",
              " 'VERB': 5,\n",
              " 'X': 15}"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train_dataset and devset"
      ],
      "metadata": {
        "id": "f4JwyTxY0Nh-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset\n",
        "len(text_token_pt[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qFBvJzQK0opK",
        "outputId": "e91c360d-6e21-4861-bb4e-a50dc4ae82c5"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "204"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# devset\n",
        "len(text_token_pt_dev[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VOiLuGk_jtuw",
        "outputId": "467da82e-1f40-4ca4-ec3e-08cee67bf022"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "135"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset\n",
        "len(train_y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdsL06-B0v-i",
        "outputId": "96fe68a6-ded3-42ee-f15d-06d7477b1da1"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# devset\n",
        "len(dev_y[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QcO0lGNmj0YN",
        "outputId": "be56faaf-e72e-4ce8-aa9d-cfabe95be0e3"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tags_0 = []\n",
        "# for tag in train_y[0]:\n",
        "#     tag_index = vocabulario_pos_dict[ tag ]\n",
        "#     tags_0.append(tag_index)\n",
        "\n",
        "# item_dict = (text_token_pt[0], tags_0)\n",
        "# # item_dict"
      ],
      "metadata": {
        "id": "J4dNap5e04vE"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# trainset\n",
        "train_dataset = []\n",
        "for index, item in enumerate(text_token_pt):\n",
        "\n",
        "    if index < 5: \n",
        "        print( item )\n",
        "        len_item = len(item)\n",
        "        print( f'len_item: {len_item}' )\n",
        "\n",
        "    tags = []\n",
        "    for tag in train_y[ index ]:\n",
        "        tag_index = vocabulario_pos_dict[ tag ]\n",
        "        tags.append( tag_index )\n",
        "\n",
        "    len_item = len(item)\n",
        "    difference = len_item - len(train_y[ index ])\n",
        "    for i in range(0, difference):\n",
        "        tag_index = vocabulario_pos_dict[ '<unk>' ]\n",
        "        tags.append( tag_index )\n",
        "\n",
        "    if index < 5: \n",
        "        print( f'len(tags): {len(tags)}' )\n",
        "        print( '-----------------------------------' )\n",
        "\n",
        "    item_dict = ( text_token_pt[ index ], tags )\n",
        "    train_dataset.append( item_dict )\n",
        "\n",
        "print()\n",
        "print( f'train_dataset[0]: {train_dataset[0]}' )\n",
        "print( f'train_dataset[1]: {train_dataset[1]}' )\n",
        "print( f'train_dataset[2]: {train_dataset[2]}' )\n",
        "print( f'train_dataset[3]: {train_dataset[3]}' )\n",
        "print( f'train_dataset[4]: {train_dataset[4]}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F_7QpZbh0bsJ",
        "outputId": "4f26f6e6-9fa5-4a46-bdce-8bb02fc3de9f"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[436, 5, 4, 52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 204\n",
            "len(tags): 204\n",
            "-----------------------------------\n",
            "[1681, 533, 2147, 2917, 73, 1513, 14, 1090, 9454, 6145, 16, 2148, 1884, 3, 3524, 608, 3525, 2, 8, 1682, 282, 4, 436, 6146, 2, 4, 52, 249, 386, 639, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 204\n",
            "len(tags): 204\n",
            "-----------------------------------\n",
            "[32, 387, 734, 9455, 387, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 204\n",
            "len(tags): 204\n",
            "-----------------------------------\n",
            "[51, 20, 2, 4, 6, 5, 8, 735, 5, 3, 4464, 3, 9456, 2, 4, 436, 34, 70, 6147, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 204\n",
            "len(tags): 204\n",
            "-----------------------------------\n",
            "[143, 609, 143, 4, 198, 35, 4465, 14, 881, 13, 15, 4466, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 204\n",
            "len(tags): 204\n",
            "-----------------------------------\n",
            "\n",
            "train_dataset[0]: ([436, 5, 4, 52, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 2, 3, 4, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
            "train_dataset[1]: ([1681, 533, 2147, 2917, 73, 1513, 14, 1090, 9454, 6145, 16, 2148, 1884, 3, 3524, 608, 3525, 2, 8, 1682, 282, 4, 436, 6146, 2, 4, 52, 249, 386, 639, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 5, 6, 5, 3, 4, 7, 8, 5, 3, 4, 7, 8, 3, 7, 4, 8, 9, 10, 8, 2, 3, 4, 5, 3, 1, 5, 2, 3, 4, 1, 1, 1, 8, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
            "train_dataset[2]: ([32, 387, 734, 9455, 387, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [5, 4, 8, 6, 8, 3, 4, 8, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
            "train_dataset[3]: ([51, 20, 2, 4, 6, 5, 8, 735, 5, 3, 4464, 3, 9456, 2, 4, 436, 34, 70, 6147, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [6, 6, 2, 11, 11, 2, 3, 4, 2, 3, 4, 8, 3, 4, 2, 3, 1, 12, 8, 6, 8, 5, 8, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
            "train_dataset[4]: ([143, 609, 143, 4, 198, 35, 4465, 14, 881, 13, 15, 4466, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [13, 1, 13, 3, 4, 6, 5, 3, 4, 14, 11, 5, 8, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# devset\n",
        "dev_dataset = []\n",
        "for index, item in enumerate(text_token_pt_dev):\n",
        "\n",
        "    if index < 5: \n",
        "        print( item )\n",
        "        len_item = len(item)\n",
        "        print( f'len_item: {len_item}' )\n",
        "\n",
        "    tags = []\n",
        "    for tag in dev_y[ index ]:\n",
        "        tag_index = vocabulario_pos_dict[ tag ]\n",
        "        tags.append( tag_index )\n",
        "\n",
        "    len_item = len(item)\n",
        "    difference = len_item - len(dev_y[ index ])\n",
        "    for i in range(0, difference):\n",
        "        tag_index = vocabulario_pos_dict[ '<unk>' ]\n",
        "        tags.append( tag_index )\n",
        "\n",
        "    if index < 5: \n",
        "        print( f'len(tags): {len(tags)}' )\n",
        "        print( '-----------------------------------' )\n",
        "\n",
        "    item_dict = ( text_token_pt_dev[ index ], tags )\n",
        "    dev_dataset.append( item_dict )\n",
        "\n",
        "print()\n",
        "print( f'dev_dataset[0]: {dev_dataset[0]}' )\n",
        "print( f'dev_dataset[1]: {dev_dataset[1]}' )\n",
        "print( f'dev_dataset[2]: {dev_dataset[2]}' )\n",
        "print( f'dev_dataset[3]: {dev_dataset[3]}' )\n",
        "print( f'dev_dataset[4]: {dev_dataset[4]}' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Lz2WeJPjE74",
        "outputId": "23d32f93-905e-455f-d66b-3a259c3d6f05"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1275, 24, 844, 2, 11, 1276, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 135\n",
            "len(tags): 135\n",
            "-----------------------------------\n",
            "[36, 18, 19, 2315, 610, 6, 4, 2316, 212, 19, 12, 2317, 2, 11, 162, 163, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 135\n",
            "len(tags): 135\n",
            "-----------------------------------\n",
            "[2318, 2319, 2320, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 135\n",
            "len(tags): 135\n",
            "-----------------------------------\n",
            "[8, 34, 611, 63, 12, 2321, 2, 2322, 5, 3, 2323, 612, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 135\n",
            "len(tags): 135\n",
            "-----------------------------------\n",
            "[1277, 95, 52, 1278, 213, 26, 2324, 13, 4, 27, 164, 2325, 2, 1276, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "len_item: 135\n",
            "len(tags): 135\n",
            "-----------------------------------\n",
            "\n",
            "dev_dataset[0]: ([1275, 24, 844, 2, 11, 1276, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [4, 12, 4, 2, 3, 4, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
            "dev_dataset[1]: ([36, 18, 19, 2315, 610, 6, 4, 2316, 212, 19, 12, 2317, 2, 11, 162, 163, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [6, 6, 12, 7, 5, 14, 3, 4, 7, 12, 3, 4, 2, 3, 7, 4, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
            "dev_dataset[2]: ([2318, 2319, 2320, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
            "dev_dataset[3]: ([8, 34, 611, 63, 12, 2321, 2, 2322, 5, 3, 2323, 612, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [3, 4, 9, 12, 3, 4, 2, 4, 2, 3, 4, 7, 8, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n",
            "dev_dataset[4]: ([1277, 95, 52, 1278, 213, 26, 2324, 13, 4, 27, 164, 2325, 2, 1276, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [6, 6, 9, 4, 5, 12, 5, 2, 3, 3, 4, 4, 2, 4, 8, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 18])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' # Com base no tagger_gru.ipynb\n",
        "\n",
        "train_dataset[0]\n",
        "([235, 19, 7, 5, 75], [6, 7, 3, 2, 1])\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "UB3xTnFp0NoU",
        "outputId": "0c466bd1-8d28-4f94-c05d-5dbed75a1759"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' # Com base no tagger_gru.ipynb\\n\\ntrain_dataset[0]\\n([235, 19, 7, 5, 75], [6, 7, 3, 2, 1])\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training..."
      ],
      "metadata": {
        "id": "hT0pKcGRzxEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# dev_dataset.token_vocab = vocabulario\n",
        "# dev_dataset.pos_vocab = vocabulario_pos\n",
        "\n",
        "# Hyperparameters / constants.\n",
        "input_vocab_size = tokenizer_pt.document_count\n",
        "output_vocab_size = len( train_y )\n",
        "batch_size = 16\n",
        "epochs = 1\n",
        "n_layers = 1\n",
        "\n",
        "# Initialize the model.\n",
        "model = Tagger(\n",
        "    input_vocab_size, \n",
        "    output_vocab_size, \n",
        "    n_layers,\n",
        "    embedding_layer = embedding_vec_pt)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Loss function weights.\n",
        "weight = torch.ones(output_vocab_size)\n",
        "weight[0] = 0\n",
        "if torch.cuda.is_available():\n",
        "    weight = weight.cuda()\n",
        "    \n",
        "# Initialize loss function and optimizer.\n",
        "loss_function = torch.nn.NLLLoss(weight)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Main training loop.\n",
        "data_loader = DataLoader(\n",
        "    train_dataset, \n",
        "    batch_size = batch_size, \n",
        "    shuffle = True)\n",
        "dev_loader = DataLoader(\n",
        "    dev_dataset, \n",
        "    batch_size = batch_size, \n",
        "    shuffle = True)\n",
        "\n",
        "losses = []\n",
        "i = 0\n",
        "for epoch in range(epochs):\n",
        "    for inputs, targets, lengths in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(inputs, lengths=lengths)\n",
        "\n",
        "        outputs = outputs.view(-1, output_vocab_size)\n",
        "        # print('---------------outputs----------------')\n",
        "        # print(outputs.shape)\n",
        "        # print(outputs)\n",
        "        targets = targets.view(-1)\n",
        "        # print('---------------targets----------------')\n",
        "        # print(targets.shape)\n",
        "        # print(targets)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #losses.append(loss.data[0])\n",
        "        losses.append(loss.item())\n",
        "        if (i % 10) == 0:\n",
        "            # Compute dev loss over entire dev set.\n",
        "            # NOTE: This is expensive. You may want to only use a \n",
        "            # subset of the dev set.\n",
        "            #print('iteration, ', i)\n",
        "            dev_losses = []\n",
        "            for inputs, targets, lengths in dev_loader:\n",
        "                outputs, _ = model(inputs, lengths=lengths)\n",
        "                outputs = outputs.view(-1, output_vocab_size)\n",
        "                targets = targets.view(-1)\n",
        "                loss = loss_function(outputs, targets)\n",
        "                dev_losses.append(loss.item())\n",
        "            avg_train_loss = np.mean(losses)\n",
        "            avg_dev_loss = np.mean(dev_losses)\n",
        "            losses = []\n",
        "            #print('here')\n",
        "            print('Epoch %i Iteration %i - Train Loss: %0.6f - Dev Loss: %0.6f' % (epoch, i, avg_train_loss, avg_dev_loss), end='\\n')\n",
        "            torch.save(model, 'pos_tagger_gru.pt')\n",
        "        i += 1\n",
        "        \n",
        "torch.save(model, 'pos_tagger_gru.final.pt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "-ghzLs_7ma9x",
        "outputId": "017fe7f5-b468-4374-b6fe-c5a10d22098c"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-134-0a295653274c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "UfWqn8-6mbDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "nPwlGWH3mbF5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
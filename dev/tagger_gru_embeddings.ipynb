{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5CispoBeMZp",
        "outputId": "5b870f99-e383-444d-e390-d110ae39833b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/', force_remount=True)\n",
        "drive.mount('/content/drive/')"
      ],
      "id": "D5CispoBeMZp"
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyQlEYq0IMVd",
        "outputId": "15ee3bb9-73de-4537-e67c-079f28173346"
      },
      "id": "fyQlEYq0IMVd",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llemgM4yeMca",
        "outputId": "cf676790-ef15-48a8-cd58-6be6f9b122b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ],
      "source": [
        "cd \"drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning/\""
      ],
      "id": "llemgM4yeMca"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu8ejWihdQUz",
        "outputId": "a1c52190-b558-4ce8-fa40-b7ed257b2a68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ],
      "id": "Wu8ejWihdQUz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ca39af7-84d8-469f-aaf6-f5764501dbdb"
      },
      "source": [
        "# Imports"
      ],
      "id": "9ca39af7-84d8-469f-aaf6-f5764501dbdb"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3a53f45d-33b3-4a40-b0e2-674577ca0149"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ],
      "id": "3a53f45d-33b3-4a40-b0e2-674577ca0149"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kNcTTJXs3Aiw",
        "outputId": "41bcc418-30b7-4bb0-d054-774df3643227"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyconll in /usr/local/lib/python3.7/dist-packages (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pyconll\n",
        "import pyconll # https://github.com/soutsios/pos-tagger-bert/blob/master/pos_tagger_bert.ipynb"
      ],
      "id": "kNcTTJXs3Aiw"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "S2U87WXb3F3H"
      },
      "outputs": [],
      "source": [
        "# trainset\n",
        "train_X = list()\n",
        "train_y = list()\n",
        "data = pyconll.load_from_file( './datasets/pt_bosque-ud-train.conllu' )\n",
        "train_tagged_sentences=[]\n",
        "t=0\n",
        "for sentence in data:\n",
        "    tagged_sentence=[]\n",
        "    X_sentence = list()\n",
        "    y_sentence = list()\n",
        "    for token in sentence:\n",
        "        if token.upos and token.form:\n",
        "            t+=1\n",
        "            tagged_sentence.append((token.form.lower(), token.upos))\n",
        "\n",
        "            X_sentence.append( token.form )\n",
        "            y_sentence.append( token.upos )\n",
        "    train_X.append( ' '.join(str(t) for t in X_sentence) )\n",
        "    train_y.append( [str(tag) for tag in y_sentence] )\n",
        "    train_tagged_sentences.append(tagged_sentence)"
      ],
      "id": "S2U87WXb3F3H"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Fy_SXSKA3PbE",
        "outputId": "7a36b1ae-b102-447f-cb56-a08945c980a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PT em o governo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train_X[0]"
      ],
      "id": "Fy_SXSKA3PbE"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "604QdoRu3ZdK",
        "outputId": "73a2ff70-db1c-4b2b-c5c5-ccfd22df7681"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROPN', 'ADP', 'DET', 'NOUN']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "train_y[0]"
      ],
      "id": "604QdoRu3ZdK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6d6J9_oo2Slm"
      },
      "source": [
        "# CBOW\n",
        "\n",
        "Baseado em https://colab.research.google.com/drive/1dBIKowtIEhM8MaPgDTkBvPLhikCuxOsU?usp=sharing#scrollTo=IaASmsvNL4vh"
      ],
      "id": "6d6J9_oo2Slm"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "y7u1tYbW5TgX"
      },
      "outputs": [],
      "source": [
        "treino = train_X"
      ],
      "id": "y7u1tYbW5TgX"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PjEvdsX85hbj"
      },
      "outputs": [],
      "source": [
        "# treino[0].split()"
      ],
      "id": "PjEvdsX85hbj"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ScSqZiGA2exw",
        "outputId": "1b2a84d3-f2ae-4bbd-e4bb-4f992a485abc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Número de palavras:  23809\n"
          ]
        }
      ],
      "source": [
        "def get_vocab(texts):\n",
        "  vocab = []\n",
        "  for row in texts:\n",
        "    for word in row.split():\n",
        "      vocab.append( word )\n",
        "    # vocab.extend(row)\n",
        "\n",
        "  # vocab = list(set(vocab))\n",
        "  # vocab += ['<pad>', '<oov>']\n",
        "  vocab.append( '<pad>' )\n",
        "  vocab.append( '<oov>' )\n",
        "  vocab = set(vocab)\n",
        "  w2id = { w:i for i, w in enumerate(vocab) }\n",
        "  id2w = { i:w for i, w in enumerate(vocab) }\n",
        "  return vocab, w2id, id2w\n",
        "\n",
        "vocab, w2id, id2w = get_vocab(treino)\n",
        "print('Número de palavras: ', len(vocab))"
      ],
      "id": "ScSqZiGA2exw"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "jSyRckeF5X6u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "ecf5d3cd-7f03-4b73-b90c-9b30bd936df4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alcoolismo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "vocab_list = list(vocab)\n",
        "vocab_list[0]"
      ],
      "id": "jSyRckeF5X6u"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "cts-xq776Qfc"
      },
      "outputs": [],
      "source": [
        "# vocab_list = list(vocab)\n",
        "# # vocab_list[ 0 ]\n",
        "\n",
        "# for i, word in enumerate(vocab_list):\n",
        "#   if word == '<oov>':\n",
        "#     print(f'encontrou na posição: {i}')"
      ],
      "id": "cts-xq776Qfc"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_AGs8vtK66WC"
      },
      "outputs": [],
      "source": [
        "# vocab_list[12984]"
      ],
      "id": "_AGs8vtK66WC"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzfdpdAc2g1Q",
        "outputId": "33b4049e-6a93-4794-e5be-4e7e6d2f2902"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'publicada hoje revela dado supreendente :', 'word': 'um'}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "def context_window(sentence, size=3):\n",
        "\n",
        "  tokens = sentence.split()\n",
        "  tokens = (['<pad>'] * size) + tokens + (['<pad>'] * size)\n",
        "\n",
        "  contexts = []\n",
        "  for i in range(size, len(tokens)-size):\n",
        "    context = tokens[i-size:i] + tokens[i+1:i+size+1]\n",
        "    word = tokens[i]\n",
        "    contexts.append({ 'context': ' '.join(context), 'word': word })\n",
        "  return contexts\n",
        "\n",
        "data = []\n",
        "wsize = 3 # windows size\n",
        "for sentence in treino:\n",
        "  data.extend( context_window(sentence, size=wsize) )\n",
        "\n",
        "data[10]"
      ],
      "id": "bzfdpdAc2g1Q"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7LKkKTx2g5a",
        "outputId": "dceec68a-98fe-45d1-f7c3-05bb67b7c29a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context': 'com as prioridades o PT .', 'word': 'de'}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "data[110]"
      ],
      "id": "n7LKkKTx2g5a"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dVi3SZyg-N1V"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "class CBOW(nn.Module):\n",
        "  def __init__(self, embedding_dim, nvocab, window_size, w2id, device):\n",
        "    '''\n",
        "    Inicilizando uma rede neural CBOW\n",
        "\n",
        "    params:\n",
        "    ---\n",
        "      embedding_dim: dimensão dos embeddings\n",
        "      nvocab: tamanho do vocabulário de palavras para as quais treinaremos word embeddings\n",
        "      window_size: janela de contexto\n",
        "      w2id: mapping de um token para seu índice na matriz de embeddings\n",
        "      device: dispositivo onde a rede neural será alocada (e.g. cpu ou cuda)\n",
        "    '''\n",
        "    super(CBOW, self).__init__()\n",
        "    self.device = device\n",
        "    self.w2id = w2id\n",
        "    self.lookup = nn.Embedding(nvocab, embedding_dim)\n",
        "    self.Wb = nn.Linear(2 * window_size * embedding_dim, nvocab)\n",
        "    self.softmax = nn.LogSoftmax(1)\n",
        "\n",
        "  def forward(self, X):\n",
        "    '''\n",
        "    Forward pass\n",
        "\n",
        "    params:\n",
        "    ---\n",
        "      X: lista de contextos de entrada\n",
        "\n",
        "    return:\n",
        "    ---\n",
        "      probabilidade entre as palavras do vocabulário\n",
        "    '''\n",
        "    contexts = []\n",
        "    for context in X:\n",
        "      idxs = []\n",
        "      for token in context.split():\n",
        "        try:\n",
        "          idxs.append(w2id[token])\n",
        "        except:\n",
        "          idxs.append(w2id['<oov>'])\n",
        "      contexts.append(idxs)\n",
        "\n",
        "    contexts = torch.tensor(contexts).to(self.device)\n",
        "    embeddings = self.lookup(contexts)\n",
        "\n",
        "    batch_size, window_size, embedding_dim = embeddings.size()\n",
        "    concatenation = embeddings.view(batch_size, window_size * embedding_dim)\n",
        "\n",
        "    z = self.Wb(concatenation)\n",
        "    return self.softmax(z)"
      ],
      "id": "dVi3SZyg-N1V"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Z_gRqj9t-SWd"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "embedding_dim = 300\n",
        "nvocab = len(vocab)\n",
        "nepochs = 1\n",
        "batch_size = 256\n",
        "batch_status = 256\n",
        "learning_rate = 0.01\n",
        "window_size = wsize"
      ],
      "id": "Z_gRqj9t-SWd"
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "J5Bt-_U6-Thz"
      },
      "outputs": [],
      "source": [
        "model = CBOW(embedding_dim, nvocab, window_size=window_size, w2id=w2id, device=device).to(device)\n",
        "criterion = nn.NLLLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=learning_rate)"
      ],
      "id": "J5Bt-_U6-Thz"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "p22Goxy5-Uwz"
      },
      "outputs": [],
      "source": [
        "traindata = DataLoader(data, batch_size=batch_size, shuffle=True)"
      ],
      "id": "p22Goxy5-Uwz"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4CUMtEY-Z8O",
        "outputId": "2a835e42-cb60-4a09-b1e0-612965c0cab7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [256/672 (38%)]\tLoss: 12.224694\tTotal Loss: 11.654450\n",
            "Train Epoch: 1 [512/672 (76%)]\tLoss: 12.244439\tTotal Loss: 12.005810\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(nepochs):\n",
        "  losses = []\n",
        "  for batch_idx, row in enumerate(traindata):\n",
        "    X = row['context']\n",
        "    y = []\n",
        "    for word in row['word']:\n",
        "      try:\n",
        "        y.append(w2id[word])\n",
        "      except:\n",
        "        y.append(w2id['oov'])\n",
        "    y = torch.tensor(y).to(device)\n",
        "\n",
        "    # Forward\n",
        "    outputs = model(X)\n",
        "    \n",
        "    # Calculate loss\n",
        "    loss = criterion(outputs, y)\n",
        "    losses.append(float(loss))\n",
        "    \n",
        "    # Backpropagation\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Display\n",
        "    if (batch_idx+1) % batch_status == 0:\n",
        "      print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tTotal Loss: {:.6f}'.format(\n",
        "                            epoch+1, batch_idx + 1, len(traindata),\n",
        "                            100. * batch_idx / len(traindata), float(loss), \n",
        "                            round(sum(losses) / len(losses), 5)))"
      ],
      "id": "b4CUMtEY-Z8O"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AWtcn5uG-c0V"
      },
      "outputs": [],
      "source": [
        "embeddings = model.lookup.weight.data.cpu().numpy()\n",
        "\n",
        "w2emb = { w:emb for (w, emb) in zip(vocab, list(embeddings))}"
      ],
      "id": "AWtcn5uG-c0V"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embeddings do <oov> # out of vocabulary"
      ],
      "metadata": {
        "id": "cjEd2SCyYd6E"
      },
      "id": "cjEd2SCyYd6E"
    },
    {
      "cell_type": "code",
      "source": [
        "for item in w2emb:\n",
        "    if item == '<oov>':\n",
        "      print(w2emb[item])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRCSYAhDXyom",
        "outputId": "80a81b5b-3fe4-44d3-9d7b-68ca68b98cfc"
      },
      "id": "TRCSYAhDXyom",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.5564119   2.1444917  -0.20005907  0.36524644 -0.76497597 -0.7233162\n",
            " -0.7138069   1.6978066  -0.41962638  1.443237   -0.84837484  0.35500878\n",
            "  0.39613372  0.18711847  1.7530961   1.5089612  -0.27636933 -1.0474018\n",
            " -0.22606228  0.06669471  1.052878   -0.8542973   0.7173114  -0.55797875\n",
            " -0.6449889  -0.4655621  -0.23992103  0.3673692  -0.27819481 -0.12351319\n",
            "  1.5860025   0.03737472  0.32384056  1.799033    0.13007745 -0.9245642\n",
            "  0.56869525  0.81832004 -0.67650473 -0.10205963  1.2199509   1.2841225\n",
            " -0.46631333  0.28424415 -0.31432626  0.25387853  1.040279   -0.44382775\n",
            " -0.06255431 -0.41091433  2.2101982   0.6796816  -0.33141983  0.02304517\n",
            "  0.52505606  0.74834347 -2.1222868   0.7208082   0.6900885  -0.10526986\n",
            "  0.69924265  0.8234417  -0.7287255   0.94828945 -0.0982637  -0.57110894\n",
            " -0.42309964  0.84777653 -0.20756602 -1.1941216  -0.68958753  1.3032284\n",
            " -1.5807886   1.213773    0.05851575 -1.3904632   0.92844194  0.0347477\n",
            "  0.46749958 -1.474885    0.8126051  -0.5059858   0.27785516 -0.37969652\n",
            " -0.99379957 -0.32024446 -1.7664357   1.4916967   0.3997939   1.0524273\n",
            " -1.3803251  -0.4069252   1.34009    -0.5543967  -0.17180109 -0.17667225\n",
            "  1.5654956  -0.9649354  -0.5241899  -0.6281553   0.8697781   0.9904657\n",
            "  0.3501814   2.2563534   2.2626083  -0.69620526 -1.9618917  -1.2469312\n",
            " -0.54918313  0.54413944 -1.5851061  -0.47104847 -1.7468961   0.19496149\n",
            "  0.08806208  0.6397419  -0.60264677 -0.2522837  -0.5111888   0.1099968\n",
            "  0.5888527   1.6338927  -0.8765811   1.6397889  -0.73544294  1.1998689\n",
            "  0.07722962 -0.97963977  1.1531787  -0.37512526  1.1340027  -0.17324094\n",
            "  0.09352408  0.4198172  -0.7176754   0.81619096 -0.20362255 -0.89475775\n",
            "  0.33267125  0.6434088   0.73006517  0.92737377  1.040139    0.6861788\n",
            "  0.06118137  0.04754311  1.4654325   0.989798    0.6253675  -1.4268149\n",
            " -0.04534939  0.24165814 -1.7830032   0.31429556  0.530348    0.7392184\n",
            "  0.8943104   0.40042493 -0.73682773 -0.2439894  -1.4539429  -0.25182635\n",
            " -0.7094753  -0.6927464   0.40383422  0.3031091   0.92516893 -0.07571612\n",
            "  1.0957375   0.79953367 -0.7970045  -0.23012239  1.1532983   0.8133958\n",
            " -0.9697539   0.297988   -1.0780878   0.5645635  -0.76375574 -0.35094652\n",
            " -0.69507205  0.9791191   0.46998334  0.90697587  1.028598   -0.28276068\n",
            " -1.0791763   0.19711989 -1.7266372   0.8105379  -0.50782204 -0.3123589\n",
            " -1.0141367   0.00711016 -0.04215628  1.1997098  -0.34951442 -0.6314083\n",
            " -0.4667513   1.4888495  -1.3217173   0.170809    0.68909013 -0.2790529\n",
            "  0.6955215  -0.6795424  -0.8904484  -1.7085689   0.2604864   0.36688605\n",
            "  1.1890647   0.4240064  -0.77749187  1.5629225   1.3231391   0.7481332\n",
            "  0.3123795   0.38802898  1.0053444   0.7020931  -0.3784826   1.1426582\n",
            "  1.2378317   1.7112966   0.82669145 -0.6291462   0.59466     1.0218514\n",
            " -3.0281217   0.47145063 -0.27801225 -2.705916    0.05177095  0.89390415\n",
            "  1.313031   -0.7255782   1.2538626  -0.23088464 -0.62913305 -0.6118019\n",
            "  0.2962257   0.51342434  0.50623727 -0.34639737 -2.566004   -0.6871653\n",
            "  0.37171966  0.6860462  -1.4280279  -1.1583736  -1.7623332  -0.29431492\n",
            "  0.13253433  2.618156   -0.65969074  0.6295255  -0.62176377  0.8776355\n",
            "  0.09639989 -1.1576865   0.23865356 -2.22899     1.5504885  -0.9821752\n",
            " -0.21585763 -0.05776736  1.0008651   0.42969862  1.4440346  -1.6796474\n",
            " -1.3261787   0.1425582  -0.22717524  0.8492748  -0.36300018 -0.25349367\n",
            "  0.3590296   1.0467757  -0.72202754 -1.8640243  -0.16474487 -1.6394321\n",
            "  0.38278684 -0.3713004   0.7976573  -0.6061934   2.235848    0.05688926\n",
            " -0.24744545 -0.13968532 -0.77988553 -0.87745863 -2.2668815  -0.34752837\n",
            "  0.3761395  -2.316098    1.1402498   1.0046695  -1.2872641  -0.09395637]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujadYSa5AZSv",
        "outputId": "b37f05a7-b9e6-44ad-8397-96cece1d0380"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23809\n",
            "(23809, 300)\n"
          ]
        }
      ],
      "source": [
        "print( len(vocab) )\n",
        "print( embeddings.shape )"
      ],
      "id": "ujadYSa5AZSv"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "Ks3O4GtyCsGT",
        "outputId": "aaae74b1-2411-4b3e-b59c-06262c0dfe05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'alcoolismo'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "vocab = list(vocab)\n",
        "vocab[0]"
      ],
      "id": "Ks3O4GtyCsGT"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PaRBoLo3BDbW",
        "outputId": "bffbde1d-64a1-4581-8904-6a878b4799b3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.29244775"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "embeddings[2][299]"
      ],
      "id": "PaRBoLo3BDbW"
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKAWHmpb-94i",
        "outputId": "bacf0332-54d6-4ebd-910c-e58447500f97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('PT', 1.0)\n",
            "('Adams', 0.2689972)\n",
            "('corre', 0.22977057)\n",
            "('Iraque', 0.22664815)\n",
            "('Económico', 0.21962862)\n",
            "('seu', 0.21746045)\n",
            "('legislativo', 0.21477422)\n",
            "('levanta', 0.21124323)\n",
            "('eternidade', 0.21048647)\n",
            "('aroma', 0.20498201)\n"
          ]
        }
      ],
      "source": [
        "similarities = cosine_similarity([w2emb['PT']], embeddings)[0]\n",
        "\n",
        "candidates = sorted(\n",
        "    [(vocab[i], sim) for i, sim in enumerate(similarities)], \n",
        "    key = lambda x: x[1], \n",
        "    reverse=True\n",
        ")[:10]\n",
        "for cand in candidates:\n",
        "  print(cand)"
      ],
      "id": "OKAWHmpb-94i"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrfeMRBWDXaG",
        "outputId": "b9ae25ce-b401-42fa-c53b-6470749c342f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('televisão', 1.0)\n",
            "('porta', 0.24294639)\n",
            "('Ernest', 0.24153084)\n",
            "(')', 0.22526795)\n",
            "('Libreville', 0.22238092)\n",
            "('bandeiras', 0.21741703)\n",
            "('elétrica', 0.21710885)\n",
            "('pena', 0.21193829)\n",
            "('fomentado', 0.21099864)\n",
            "('assinantes', 0.21071836)\n"
          ]
        }
      ],
      "source": [
        "similarities = cosine_similarity([w2emb['televisão']], embeddings)[0]\n",
        "  \n",
        "candidates = sorted(\n",
        "    [(vocab[i], sim) for i, sim in enumerate(similarities)], \n",
        "    key = lambda x: x[1], \n",
        "    reverse=True\n",
        ")[:10]\n",
        "for cand in candidates:\n",
        "  print(cand)"
      ],
      "id": "JrfeMRBWDXaG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Daqui pra baixo foi baseado no notebook da professora Aline Paes: 8_3_tagger_pos_v2.ipynb"
      ],
      "metadata": {
        "id": "dzLl8NkMORZV"
      },
      "id": "dzLl8NkMORZV"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4beefaac-3b23-4d8a-b2d1-a337eb0e8c33"
      },
      "source": [
        "# Vocab"
      ],
      "id": "4beefaac-3b23-4d8a-b2d1-a337eb0e8c33"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "de8dbcfa-a7fe-4393-95c6-ee59e7c0da6a"
      },
      "outputs": [],
      "source": [
        "class Vocab(object):\n",
        "    def __init__(self, iter, max_size=None, sos_token=None, eos_token=None, unk_token=None):\n",
        "        \"\"\"Initialize the vocabulary.\n",
        "        Args:\n",
        "            iter: An iterable which produces sequences of tokens used to update\n",
        "                the vocabulary.\n",
        "            max_size: (Optional) Maximum number of tokens in the vocabulary.\n",
        "            sos_token: (Optional) Token denoting the start of a sequence.\n",
        "            eos_token: (Optional) Token denoting the end of a sequence.\n",
        "            unk_token: (Optional) Token denoting an unknown element in a\n",
        "                sequence.\n",
        "        \"\"\"\n",
        "        self.max_size = max_size\n",
        "        self.pad_token = '<pad>'\n",
        "        self.sos_token = sos_token\n",
        "        self.eos_token = eos_token\n",
        "        self.unk_token = unk_token\n",
        "\n",
        "        # Add special tokens.\n",
        "        id2word = [self.pad_token]\n",
        "        if sos_token is not None:\n",
        "            id2word.append(self.sos_token)\n",
        "        if eos_token is not None:\n",
        "            id2word.append(self.eos_token)\n",
        "        if unk_token is not None:\n",
        "            id2word.append(self.unk_token)\n",
        "\n",
        "        # Update counter with token counts.\n",
        "        counter = Counter()\n",
        "        for x in iter:\n",
        "            counter.update(x)\n",
        "\n",
        "        # Extract lookup tables.\n",
        "        if max_size is not None:\n",
        "            counts = counter.most_common(max_size)\n",
        "        else:\n",
        "            counts = counter.items()\n",
        "            counts = sorted(counts, key=lambda x: x[1], reverse=True)\n",
        "        words = [x[0] for x in counts]\n",
        "        id2word.extend(words)\n",
        "        word2id = {x: i for i, x in enumerate(id2word)}\n",
        "\n",
        "        self._id2word = id2word\n",
        "        self._word2id = word2id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._id2word)\n",
        "\n",
        "    def word2id(self, word):\n",
        "        \"\"\"Map a word in the vocabulary to its unique integer id.\n",
        "        Args:\n",
        "            word: Word to lookup.\n",
        "        Returns:\n",
        "            id: The integer id of the word being looked up.\n",
        "        \"\"\"\n",
        "        if word in self._word2id:\n",
        "            return self._word2id[word]\n",
        "        elif self.unk_token is not None:\n",
        "            return self._word2id[self.unk_token]\n",
        "        else:\n",
        "            raise KeyError('Word \"%s\" not in vocabulary.' % word)\n",
        "\n",
        "    def id2word(self, id):\n",
        "        \"\"\"Map an integer id to its corresponding word in the vocabulary.\n",
        "        Args:\n",
        "            id: Integer id of the word being looked up.\n",
        "        Returns:\n",
        "            word: The corresponding word.\n",
        "        \"\"\"\n",
        "        return self._id2word[id]"
      ],
      "id": "de8dbcfa-a7fe-4393-95c6-ee59e7c0da6a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e94ad8b-ff9e-4d97-be37-2fad7f172072"
      },
      "source": [
        "# CoNLLDataset e Annotation"
      ],
      "id": "0e94ad8b-ff9e-4d97-be37-2fad7f172072"
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {
        "id": "5ef8512e-d6b2-4e96-a9c8-7fcb464af35c"
      },
      "outputs": [],
      "source": [
        "class Annotation(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"A helper object for storing annotation data.\"\"\"\n",
        "        self.tokens = []\n",
        "        self.pos_tags = []\n",
        "\n",
        "\n",
        "class CoNLLDataset(Dataset):\n",
        "    # def __init__(self, fname, max_exs=None):\n",
        "    def __init__(self, fname):\n",
        "        \"\"\"Initializes the CoNLLDataset.\n",
        "        Args:\n",
        "            fname: The .conllu file to load data from.\n",
        "        \"\"\"\n",
        "        self.fname = fname\n",
        "        # self.annotations = self.process_conll_file(fname, max_exs)\n",
        "        self.annotations = self.process_conll_file(fname)\n",
        "        self.token_vocab = Vocab([x.tokens for x in self.annotations],\n",
        "                                 unk_token='<unk>')\n",
        "        self.pos_vocab = Vocab([x.pos_tags for x in self.annotations])\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        annotation = self.annotations[idx]\n",
        "        input = [self.token_vocab.word2id(x) for x in annotation.tokens]\n",
        "        target = [self.pos_vocab.word2id(x) for x in annotation.pos_tags]\n",
        "        return input, target\n",
        "\n",
        "    # def process_conll_file(self, fname, max_exs):\n",
        "    #     # Read the entire file.\n",
        "    #     with open(fname, 'r') as f:\n",
        "    #         raw_text = f.read()\n",
        "    #     # Split into chunks on blank lines.\n",
        "    #     chunks = re.split(r'^\\n', raw_text, flags=re.MULTILINE)\n",
        "    #     #print(chunks)\n",
        "    #     # Process each chunk into an annotation.\n",
        "    #     annotations = []\n",
        "    #     exs = 0\n",
        "    #     for chunk in chunks:\n",
        "    #         if not max_exs or exs < max_exs:\n",
        "    #             annotation = Annotation()\n",
        "    #             lines = chunk.split('\\n')\n",
        "    #             # Iterate over all lines in the chunk.\n",
        "    #             for line in lines:\n",
        "    #                 # If line is empty ignore it.\n",
        "    #                 if len(line)==0:\n",
        "    #                     continue\n",
        "    #                 # If line is a commend ignore it.\n",
        "    #                 if line[0] == '#':\n",
        "    #                     continue\n",
        "    #                 # Otherwise split on tabs and retrieve the token and the\n",
        "    #                 # POS tag fields.\n",
        "    #                 fields = line.split('\\t')\n",
        "    #                 annotation.tokens.append(fields[1])\n",
        "    #                 annotation.pos_tags.append(fields[3])\n",
        "    #             if (len(annotation.tokens) > 0) and (len(annotation.pos_tags) > 0):\n",
        "    #                 annotations.append(annotation)\n",
        "    #         exs += 1\n",
        "    #     return annotations\n",
        "\n",
        "    def process_conll_file(self, fname):\n",
        "        # print(f'fname: {fname}')\n",
        "        data = pyconll.load_from_file( fname )\n",
        "        annotations = []\n",
        "\n",
        "        for sentence in data:\n",
        "            annotation = Annotation()\n",
        "            tokens_list = []\n",
        "            pos_list = []\n",
        "            \n",
        "            for token in sentence:\n",
        "                if token.upos and token.form:\n",
        "                    # print(f'token: {type(token)}')\n",
        "                    # print(f'token.form: {token.form}')\n",
        "                    # print(f'token.upos: {token.upos}')\n",
        "                    tokens_list.append( token.form )\n",
        "                    pos_list.append( token.upos )\n",
        "            \n",
        "            annotation.tokens.append( tokens_list )\n",
        "            annotation.pos_tags.append( pos_list )\n",
        "                        \n",
        "            annotation.tokens = annotation.tokens[0]\n",
        "            annotation.pos_tags = annotation.pos_tags[0]\n",
        "            # print(f'annotation.tokens: {annotation.tokens}')\n",
        "            # print(f'annotation.pos_tags: {annotation.pos_tags}')\n",
        "            # print('-----------------------------------------')\n",
        "\n",
        "            annotations.append(annotation)\n",
        "\n",
        "        return annotations"
      ],
      "id": "5ef8512e-d6b2-4e96-a9c8-7fcb464af35c"
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_temp = CoNLLDataset('./datasets/pt_bosque-ud-train.conllu')"
      ],
      "metadata": {
        "id": "Z7_w_j25O72M"
      },
      "id": "Z7_w_j25O72M",
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_temp.annotations[1].tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oU5OgiDeqbb-",
        "outputId": "94ec732f-3963-4d30-ac7e-c57aea7e1431"
      },
      "id": "oU5OgiDeqbb-",
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['BRASÍLIA',\n",
              " 'Pesquisa',\n",
              " 'Datafolha',\n",
              " 'publicada',\n",
              " 'hoje',\n",
              " 'revela',\n",
              " 'um',\n",
              " 'dado',\n",
              " 'supreendente',\n",
              " ':',\n",
              " 'recusando',\n",
              " 'uma',\n",
              " 'postura',\n",
              " 'radical',\n",
              " ',',\n",
              " 'a',\n",
              " 'esmagadora',\n",
              " 'maioria',\n",
              " '(',\n",
              " '77',\n",
              " '%',\n",
              " ')',\n",
              " 'de',\n",
              " 'os',\n",
              " 'eleitores',\n",
              " 'quer',\n",
              " 'o',\n",
              " 'PT',\n",
              " 'participando',\n",
              " 'de',\n",
              " 'o',\n",
              " 'Governo',\n",
              " 'Fernando',\n",
              " 'Henrique',\n",
              " 'Cardoso',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_temp.annotations[1].pos_tags"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pq7wp_ltn7Ic",
        "outputId": "fb013baf-a6e4-4ecb-f61b-b4a794f28baf"
      },
      "id": "pq7wp_ltn7Ic",
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PROPN',\n",
              " 'PROPN',\n",
              " 'PROPN',\n",
              " 'VERB',\n",
              " 'ADV',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADJ',\n",
              " 'PUNCT',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'ADJ',\n",
              " 'PUNCT',\n",
              " 'DET',\n",
              " 'ADJ',\n",
              " 'NOUN',\n",
              " 'PUNCT',\n",
              " 'NUM',\n",
              " 'SYM',\n",
              " 'PUNCT',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'VERB',\n",
              " 'DET',\n",
              " 'PROPN',\n",
              " 'VERB',\n",
              " 'ADP',\n",
              " 'DET',\n",
              " 'NOUN',\n",
              " 'PROPN',\n",
              " 'PROPN',\n",
              " 'PROPN',\n",
              " 'PUNCT']"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(dataset_temp.annotations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GA9u_xffSi4_",
        "outputId": "88ae9582-64fb-40b7-b9e7-61b47fcbacac"
      },
      "id": "GA9u_xffSi4_",
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7018"
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e5907be-6c34-4e65-b922-9e814b771922"
      },
      "source": [
        "# Funções: pad() e collate_annotations()"
      ],
      "id": "1e5907be-6c34-4e65-b922-9e814b771922"
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "22bfb3a3-52e1-4c2c-8563-723e15182391"
      },
      "outputs": [],
      "source": [
        "def pad(sequences, max_length, pad_value=0):\n",
        "    \"\"\"Pads a list of sequences.\n",
        "    Args:\n",
        "        sequences: A list of sequences to be padded.\n",
        "        max_length: The length to pad to.\n",
        "        pad_value: The value used for padding.\n",
        "    Returns:\n",
        "        A list of padded sequences.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for sequence in sequences:\n",
        "        padded = sequence + [0]*(max_length - len(sequence))\n",
        "        out.append(padded)\n",
        "    return out\n",
        "\n",
        "\n",
        "def collate_annotations(batch):\n",
        "    \"\"\"Function used to collate data returned by CoNLLDataset.\"\"\"\n",
        "    # Get inputs, targets, and lengths.\n",
        "    inputs, targets = zip(*batch)\n",
        "    lengths = [len(x) for x in inputs]\n",
        "    # Sort by length.\n",
        "    sort = sorted(zip(inputs, targets, lengths),\n",
        "                  key=lambda x: x[2],\n",
        "                  reverse=True)\n",
        "    inputs, targets, lengths = zip(*sort)\n",
        "    # Pad.\n",
        "    max_length = max(lengths)\n",
        "    inputs = pad(inputs, max_length)\n",
        "    targets = pad(targets, max_length)\n",
        "    # Transpose.\n",
        "    inputs = list(map(list, zip(*inputs)))\n",
        "    targets = list(map(list, zip(*targets)))\n",
        "    # Convert to PyTorch variables.\n",
        "    inputs = Variable(torch.LongTensor(inputs))\n",
        "    targets = Variable(torch.LongTensor(targets))\n",
        "    lengths = Variable(torch.LongTensor(lengths))\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "        lengths = lengths.cuda()\n",
        "    return inputs, targets, lengths"
      ],
      "id": "22bfb3a3-52e1-4c2c-8563-723e15182391"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cdecfc14-2652-47be-895b-3a89b6e65db9"
      },
      "source": [
        "# Tagger - GRU"
      ],
      "id": "cdecfc14-2652-47be-895b-3a89b6e65db9"
    },
    {
      "cell_type": "code",
      "execution_count": 192,
      "metadata": {
        "id": "e09b9f91-6d8c-40b7-b21b-e8838c66e419"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class Tagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 embedding_dim=64,\n",
        "                 hidden_dim=64,\n",
        "                 dropout=0.5,\n",
        "                 bidirectional=True,\n",
        "                 pad_idx=0):\n",
        "        \"\"\"Initializes the tagger.\n",
        "        \n",
        "        Args:\n",
        "            input_dim: Size of the input vocabulary, projection\n",
        "            output_dim: Size of the output vocabulary.\n",
        "            embedding_dim: Dimension of the word embeddings.\n",
        "            hidden_dim: Number of units in each LSTM hidden layer.\n",
        "            bidirectional: Whether or not to use a bidirectional rnn.\n",
        "        \"\"\"\n",
        "        super(Tagger, self).__init__()\n",
        "\n",
        "        # Store parameters\n",
        "        self.input_dim = input_dim \n",
        "        self.output_dim = output_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bidirectional = bidirectional\n",
        "          \n",
        "        # Define layers\n",
        "        self.word_embeddings = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \n",
        "                          bidirectional=bidirectional,\n",
        "                          dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.activation = nn.LogSoftmax(dim=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, lengths=None, hidden=None):\n",
        "        \"\"\"Computes a forward pass of the language model.\n",
        "        \n",
        "        Args:\n",
        "            x: A LongTensor w/ dimension [seq_len, batch_size].\n",
        "            lengths: The lengths of the sequences in x.\n",
        "            hidden: Hidden state to be fed into the lstm.\n",
        "            \n",
        "        Returns:\n",
        "            net: Probability of the next word in the sequence.\n",
        "            hidden: Hidden state of the lstm.\n",
        "        \"\"\"\n",
        "        seq_len, batch_size = x.size()\n",
        "        \n",
        "        # If no hidden state is provided, then default to zeros.\n",
        "        if hidden is None:\n",
        "            if self.bidirectional:\n",
        "                num_directions = 2\n",
        "            else:\n",
        "                num_directions = 1\n",
        "            hidden = Variable(torch.zeros(num_directions, batch_size, self.hidden_dim))\n",
        "            if torch.cuda.is_available():\n",
        "                hidden = hidden.cuda()\n",
        "\n",
        "        net = self.word_embeddings(x)\n",
        "        # Pack before feeding into the RNN.\n",
        "        if lengths is not None:\n",
        "            lengths = lengths.data.view(-1).tolist()\n",
        "            net = pack_padded_sequence(net, lengths)\n",
        "        net, hidden = self.rnn(net, hidden)\n",
        "        # Unpack after\n",
        "        if lengths is not None:\n",
        "            net, _ = pad_packed_sequence(net)\n",
        "        net = self.fc(net)\n",
        "        net = self.activation(net)\n",
        "\n",
        "        return net, hidden"
      ],
      "id": "e09b9f91-6d8c-40b7-b21b-e8838c66e419"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66d0c518-c0a6-42bb-bf88-c37e55c0fbd9"
      },
      "source": [
        "# Training Model"
      ],
      "id": "66d0c518-c0a6-42bb-bf88-c37e55c0fbd9"
    },
    {
      "cell_type": "code",
      "execution_count": 193,
      "metadata": {
        "id": "-OOL4u89gfz6"
      },
      "outputs": [],
      "source": [
        "# Load datasets.\n",
        "# train_dataset = CoNLLDataset('./datasets/pt_bosque-ud-train.conllu', 4096)\n",
        "# dev_dataset = CoNLLDataset('./datasets/pt_bosque-ud-dev.conllu', 1024)\n",
        "train_dataset = CoNLLDataset('./datasets/pt_bosque-ud-train.conllu')\n",
        "dev_dataset = CoNLLDataset('./datasets/pt_bosque-ud-dev.conllu')"
      ],
      "id": "-OOL4u89gfz6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Substituindo os ids das palavras pela representação de embeddings."
      ],
      "metadata": {
        "id": "0LSlDxBjUMpV"
      },
      "id": "0LSlDxBjUMpV"
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_embeddings = []\n",
        "\n",
        "for sentence in train_dataset:\n",
        "\n",
        "    # print(f'sentence: {sentence}')\n",
        "    setence_words_embeddings = []\n",
        "    setence_pos_tags = []\n",
        "\n",
        "    for i in range(0, len(sentence[0])):\n",
        "\n",
        "        word_id = sentence[0][i]\n",
        "        pos_tag = sentence[1][i]\n",
        "\n",
        "        # print(f'i: {i}')\n",
        "        # print(f'word_id: {word_id}')\n",
        "        # print(f'pos_tag: {pos_tag}')\n",
        "\n",
        "        # print(f'{word_id} - {train_dataset.token_vocab.id2word( word_id )}')\n",
        "        word = train_dataset.token_vocab.id2word( word_id )\n",
        "        if word in w2emb:\n",
        "            embeddings = w2emb[ word ]\n",
        "        else:\n",
        "            embeddings = w2emb['<oov>']\n",
        "\n",
        "        embeddings = list(embeddings)\n",
        "        # print(f'embeddings: {embeddings}')\n",
        "        # print(f'{word_id} - {word} - {embeddings}')\n",
        "\n",
        "        setence_words_embeddings.append(embeddings)\n",
        "        setence_pos_tags.append(pos_tag)\n",
        "        # print(f'setence_words_embeddings: {setence_words_embeddings}')\n",
        "        # print(f'setence_pos_tags: {setence_pos_tags}')\n",
        "        # print(f'len(setence_words_embeddings): {len(setence_words_embeddings)}')\n",
        "        # print(f'len(setence_pos_tags): {len(setence_pos_tags)}')\n",
        "\n",
        "        new_sentence_embdeddings_pos = ((setence_words_embeddings, setence_pos_tags))\n",
        "        # print(f'sentence: {sentence}')\n",
        "        # print(f'new_sentence_embdeddings_pos: {new_sentence_embdeddings_pos}')\n",
        "        train_dataset_embeddings.append( new_sentence_embdeddings_pos )\n",
        "\n",
        "        # print('------------------------------------------------')"
      ],
      "metadata": {
        "id": "g58gi9kSJWji"
      },
      "id": "g58gi9kSJWji",
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs6DeAc0TgG0",
        "outputId": "a567e18d-ac4c-43bc-8f58-daaf3f8ce835"
      },
      "id": "Bs6DeAc0TgG0",
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[396, 7, 5, 107]"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_embeddings[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hyhmfy-arHxa",
        "outputId": "77057924-16a1-4e56-da70-243215c6fdbe"
      },
      "id": "Hyhmfy-arHxa",
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.06372718,\n",
              "  1.081287,\n",
              "  -0.2566062,\n",
              "  0.35581657,\n",
              "  0.20967016,\n",
              "  -0.36711636,\n",
              "  0.366946,\n",
              "  -0.3230368,\n",
              "  -0.34950674,\n",
              "  0.4455702,\n",
              "  -0.7013678,\n",
              "  0.20763332,\n",
              "  0.7158997,\n",
              "  0.07245133,\n",
              "  0.05840904,\n",
              "  1.7177013,\n",
              "  1.2872624,\n",
              "  0.007037018,\n",
              "  -0.36843827,\n",
              "  0.30398393,\n",
              "  1.9073563,\n",
              "  0.046871826,\n",
              "  0.362007,\n",
              "  0.19549051,\n",
              "  -0.055350173,\n",
              "  -0.018726848,\n",
              "  -0.70453614,\n",
              "  0.5320796,\n",
              "  0.21127453,\n",
              "  1.4585506,\n",
              "  0.15391096,\n",
              "  -0.99725866,\n",
              "  0.109845065,\n",
              "  -0.020156017,\n",
              "  0.96515375,\n",
              "  1.9662554,\n",
              "  0.8686647,\n",
              "  0.0358276,\n",
              "  0.13300346,\n",
              "  0.0016626305,\n",
              "  0.2117124,\n",
              "  -0.42018014,\n",
              "  0.069936104,\n",
              "  -0.3920737,\n",
              "  0.6753673,\n",
              "  0.28072768,\n",
              "  0.38520417,\n",
              "  -0.23346636,\n",
              "  -0.09435507,\n",
              "  -0.08085937,\n",
              "  -0.007921909,\n",
              "  -0.049984373,\n",
              "  1.0996103,\n",
              "  -0.12756191,\n",
              "  -0.57305413,\n",
              "  -0.0906943,\n",
              "  -0.18224198,\n",
              "  -0.71684444,\n",
              "  0.30599272,\n",
              "  -0.9337199,\n",
              "  -0.3402406,\n",
              "  0.08233886,\n",
              "  -0.12936674,\n",
              "  -0.048676677,\n",
              "  -1.148141,\n",
              "  -0.265937,\n",
              "  0.14547049,\n",
              "  0.20106123,\n",
              "  0.7871115,\n",
              "  0.0467316,\n",
              "  0.37001476,\n",
              "  0.25859573,\n",
              "  -0.1932874,\n",
              "  0.15227121,\n",
              "  -0.9664524,\n",
              "  -0.9591928,\n",
              "  -0.7624523,\n",
              "  -0.07831785,\n",
              "  0.26224315,\n",
              "  -0.9360457,\n",
              "  -0.6024347,\n",
              "  -0.100979745,\n",
              "  0.0090000685,\n",
              "  -0.7707501,\n",
              "  0.075180456,\n",
              "  -0.7947064,\n",
              "  -0.2816814,\n",
              "  0.48935875,\n",
              "  0.08751537,\n",
              "  -0.8001722,\n",
              "  -0.36688596,\n",
              "  0.37152243,\n",
              "  -0.1771037,\n",
              "  -0.36373323,\n",
              "  -0.50271946,\n",
              "  -0.28352714,\n",
              "  -1.0547155,\n",
              "  0.75629294,\n",
              "  -0.933083,\n",
              "  -0.12812622,\n",
              "  -0.011600916,\n",
              "  0.8967122,\n",
              "  -1.1458066,\n",
              "  0.16362725,\n",
              "  0.3683528,\n",
              "  1.4188989,\n",
              "  -0.60400814,\n",
              "  0.031383496,\n",
              "  0.23712853,\n",
              "  0.85988116,\n",
              "  0.23687339,\n",
              "  0.87570107,\n",
              "  -0.12749588,\n",
              "  -0.5388552,\n",
              "  -0.020999411,\n",
              "  0.29103607,\n",
              "  -0.9802869,\n",
              "  1.3249602,\n",
              "  -0.24870618,\n",
              "  1.057709,\n",
              "  2.3566551,\n",
              "  -0.19924004,\n",
              "  0.44819525,\n",
              "  0.056492962,\n",
              "  -0.32668144,\n",
              "  -0.36056006,\n",
              "  -0.08794432,\n",
              "  -0.93602175,\n",
              "  -0.34992993,\n",
              "  0.12274587,\n",
              "  -0.10208813,\n",
              "  1.1051462,\n",
              "  -0.31939432,\n",
              "  1.1725352,\n",
              "  -0.12476992,\n",
              "  0.20372844,\n",
              "  -0.22290604,\n",
              "  0.06569898,\n",
              "  -0.31762686,\n",
              "  1.0868597,\n",
              "  -0.090878725,\n",
              "  -0.55399674,\n",
              "  -1.0946723,\n",
              "  0.043481365,\n",
              "  -0.005812096,\n",
              "  -0.2817849,\n",
              "  0.8549238,\n",
              "  0.1669907,\n",
              "  -1.1517125,\n",
              "  0.57864267,\n",
              "  -1.0441968,\n",
              "  0.6754023,\n",
              "  0.061240908,\n",
              "  1.5305414,\n",
              "  -0.8261177,\n",
              "  1.0224041,\n",
              "  0.9249804,\n",
              "  -0.32420865,\n",
              "  -1.4137812,\n",
              "  0.20947477,\n",
              "  -0.29527417,\n",
              "  -0.17414202,\n",
              "  -0.040787656,\n",
              "  -0.2367585,\n",
              "  0.6397661,\n",
              "  -0.057225715,\n",
              "  0.67932934,\n",
              "  -0.32956517,\n",
              "  0.7933583,\n",
              "  -0.19555613,\n",
              "  0.34387615,\n",
              "  0.06265616,\n",
              "  0.07162569,\n",
              "  -0.96173805,\n",
              "  -0.053785387,\n",
              "  0.7778594,\n",
              "  -0.3276487,\n",
              "  -0.917016,\n",
              "  -0.9388664,\n",
              "  0.13197146,\n",
              "  -0.21743894,\n",
              "  0.44010893,\n",
              "  0.54174125,\n",
              "  -0.23716946,\n",
              "  0.09388318,\n",
              "  -0.53589576,\n",
              "  1.001673,\n",
              "  0.25897142,\n",
              "  0.7238234,\n",
              "  0.48884955,\n",
              "  0.18332489,\n",
              "  1.2084366,\n",
              "  0.8020086,\n",
              "  -0.8992238,\n",
              "  0.45900917,\n",
              "  -0.2521107,\n",
              "  0.13744581,\n",
              "  -0.4491561,\n",
              "  -0.9049304,\n",
              "  -0.99047464,\n",
              "  0.21644366,\n",
              "  -0.02021508,\n",
              "  0.00030899062,\n",
              "  1.1382844,\n",
              "  0.06248691,\n",
              "  1.8253031,\n",
              "  0.2165822,\n",
              "  -0.20076434,\n",
              "  -0.07807895,\n",
              "  -0.11972387,\n",
              "  1.0079817,\n",
              "  -0.27834028,\n",
              "  0.50660026,\n",
              "  -0.06464993,\n",
              "  -1.4205974,\n",
              "  -0.111983106,\n",
              "  0.040536087,\n",
              "  -0.10234122,\n",
              "  -0.31079718,\n",
              "  -0.26001686,\n",
              "  0.0034731056,\n",
              "  -0.70629066,\n",
              "  -0.2077131,\n",
              "  -0.16383447,\n",
              "  0.14461604,\n",
              "  0.008636888,\n",
              "  -0.36653537,\n",
              "  0.65722346,\n",
              "  -1.016722,\n",
              "  -0.021882817,\n",
              "  1.1467028,\n",
              "  -0.17828526,\n",
              "  -0.948344,\n",
              "  0.098252095,\n",
              "  0.024464896,\n",
              "  0.2189097,\n",
              "  -0.24392761,\n",
              "  -0.7130577,\n",
              "  0.09524739,\n",
              "  -0.08843837,\n",
              "  -0.8733692,\n",
              "  -0.054664023,\n",
              "  0.00036502426,\n",
              "  0.4452453,\n",
              "  -0.35146424,\n",
              "  0.28400722,\n",
              "  0.03350738,\n",
              "  0.119209446,\n",
              "  -0.7533325,\n",
              "  -0.012024853,\n",
              "  0.2483871,\n",
              "  -0.5152819,\n",
              "  0.40588433,\n",
              "  0.36219853,\n",
              "  -1.1796994,\n",
              "  -0.3848285,\n",
              "  0.016091079,\n",
              "  -0.5517637,\n",
              "  -0.33975077,\n",
              "  1.3582784,\n",
              "  0.17714405,\n",
              "  -0.25497964,\n",
              "  -0.11721627,\n",
              "  0.83445907,\n",
              "  0.011520235,\n",
              "  -0.08571271,\n",
              "  -1.3456805,\n",
              "  -0.15762958,\n",
              "  0.037313636,\n",
              "  -0.21370144,\n",
              "  -0.20689562,\n",
              "  -0.48809084,\n",
              "  0.37793165,\n",
              "  0.40595737,\n",
              "  -0.22252542,\n",
              "  -0.22216909,\n",
              "  0.07363122,\n",
              "  -0.016889513,\n",
              "  -1.9044163,\n",
              "  -0.027313847,\n",
              "  -0.12523548,\n",
              "  0.6096165,\n",
              "  0.9808078,\n",
              "  -0.03436354,\n",
              "  -0.21899608,\n",
              "  -0.17765175,\n",
              "  -0.8830685,\n",
              "  -0.5257147,\n",
              "  -1.4707041,\n",
              "  -0.45082042,\n",
              "  -0.056313418,\n",
              "  0.6656539,\n",
              "  -0.28650385,\n",
              "  -0.98320144,\n",
              "  0.85901,\n",
              "  -0.21829721,\n",
              "  -0.63703984,\n",
              "  0.19372569,\n",
              "  -0.571344,\n",
              "  -0.10763226],\n",
              " [0.05815203,\n",
              "  -0.114808016,\n",
              "  0.21598664,\n",
              "  -0.091081224,\n",
              "  -0.13379069,\n",
              "  -0.031145174,\n",
              "  -0.0751396,\n",
              "  -0.02267536,\n",
              "  -0.5609628,\n",
              "  -0.09331572,\n",
              "  -0.16930725,\n",
              "  0.064811304,\n",
              "  0.07632986,\n",
              "  -0.10635636,\n",
              "  0.11654597,\n",
              "  0.015249734,\n",
              "  0.3332348,\n",
              "  -0.040203318,\n",
              "  -0.056161333,\n",
              "  0.06971202,\n",
              "  0.03803344,\n",
              "  0.0056230687,\n",
              "  -0.08705268,\n",
              "  -0.04138264,\n",
              "  0.17325073,\n",
              "  -0.10644652,\n",
              "  0.18148725,\n",
              "  -0.101971395,\n",
              "  -0.063315175,\n",
              "  -0.039727867,\n",
              "  -0.020333989,\n",
              "  0.16832665,\n",
              "  -0.04368675,\n",
              "  -0.124407046,\n",
              "  -0.045778155,\n",
              "  -0.022390736,\n",
              "  -0.16598459,\n",
              "  0.014571197,\n",
              "  -0.0367724,\n",
              "  -0.08845049,\n",
              "  0.055043943,\n",
              "  0.04780981,\n",
              "  -0.005934156,\n",
              "  0.053470436,\n",
              "  -0.1681836,\n",
              "  -0.24690257,\n",
              "  -0.05668426,\n",
              "  -0.025972975,\n",
              "  0.18716525,\n",
              "  0.07911916,\n",
              "  0.13157076,\n",
              "  -0.0268637,\n",
              "  -1.3067639,\n",
              "  -0.186044,\n",
              "  0.029951839,\n",
              "  -0.044162873,\n",
              "  0.100399405,\n",
              "  -0.35395667,\n",
              "  -0.044144396,\n",
              "  -0.011148631,\n",
              "  -0.09934373,\n",
              "  -0.056935925,\n",
              "  -0.047552194,\n",
              "  0.05219081,\n",
              "  -0.10117077,\n",
              "  0.028700866,\n",
              "  0.021876445,\n",
              "  0.026198786,\n",
              "  0.091476984,\n",
              "  -0.041362606,\n",
              "  -0.11009736,\n",
              "  0.14048193,\n",
              "  0.2916878,\n",
              "  0.06806833,\n",
              "  -0.049543884,\n",
              "  0.024125613,\n",
              "  -0.03010517,\n",
              "  -0.05895033,\n",
              "  0.021106517,\n",
              "  0.036428507,\n",
              "  -0.54165876,\n",
              "  0.06767264,\n",
              "  0.20646626,\n",
              "  -0.051836874,\n",
              "  0.07496069,\n",
              "  -0.076288305,\n",
              "  0.13622811,\n",
              "  -0.090674125,\n",
              "  0.012697146,\n",
              "  0.031194422,\n",
              "  -0.24336109,\n",
              "  -0.40655363,\n",
              "  -0.0432093,\n",
              "  0.012450507,\n",
              "  -0.30582616,\n",
              "  -0.053349994,\n",
              "  -0.04851207,\n",
              "  -0.15268618,\n",
              "  0.051567648,\n",
              "  -0.03584114,\n",
              "  -0.040185794,\n",
              "  -0.09007953,\n",
              "  -0.011267472,\n",
              "  -0.023215381,\n",
              "  0.3727063,\n",
              "  0.17393778,\n",
              "  0.011774387,\n",
              "  -0.09675175,\n",
              "  -0.017591173,\n",
              "  -0.09241216,\n",
              "  -0.0065412247,\n",
              "  0.14058478,\n",
              "  0.0033834747,\n",
              "  -0.07889787,\n",
              "  -0.46479118,\n",
              "  -0.1564571,\n",
              "  -0.00014121117,\n",
              "  0.023678523,\n",
              "  -0.056256358,\n",
              "  -0.03888438,\n",
              "  -0.51288855,\n",
              "  -0.7324658,\n",
              "  0.046602942,\n",
              "  -0.10032542,\n",
              "  -0.17267965,\n",
              "  0.022321926,\n",
              "  -0.02640406,\n",
              "  0.1120463,\n",
              "  0.0622902,\n",
              "  0.12064027,\n",
              "  -0.0165984,\n",
              "  -0.11063854,\n",
              "  -0.1028679,\n",
              "  0.07063889,\n",
              "  0.037413713,\n",
              "  -0.017875327,\n",
              "  -0.06351753,\n",
              "  0.2522428,\n",
              "  -0.9024238,\n",
              "  0.42668477,\n",
              "  0.03607478,\n",
              "  0.023540052,\n",
              "  -0.091611475,\n",
              "  0.054901734,\n",
              "  0.009347188,\n",
              "  -1.243348,\n",
              "  0.114641696,\n",
              "  -0.01941833,\n",
              "  0.08191366,\n",
              "  0.0150264315,\n",
              "  0.026807047,\n",
              "  0.019338869,\n",
              "  0.013214288,\n",
              "  -0.017745543,\n",
              "  -0.19620481,\n",
              "  -0.08811326,\n",
              "  -0.024754021,\n",
              "  0.03114945,\n",
              "  -0.48602095,\n",
              "  0.10580647,\n",
              "  -0.1170586,\n",
              "  0.09302091,\n",
              "  -0.047285557,\n",
              "  -0.08369471,\n",
              "  -0.098185904,\n",
              "  -0.03851085,\n",
              "  -0.08472644,\n",
              "  -0.041002586,\n",
              "  -0.04566867,\n",
              "  0.062416732,\n",
              "  0.09956799,\n",
              "  -0.12460333,\n",
              "  0.062783465,\n",
              "  0.10566039,\n",
              "  -0.05150288,\n",
              "  0.012748025,\n",
              "  0.06637465,\n",
              "  0.018225571,\n",
              "  0.008442214,\n",
              "  -0.08025035,\n",
              "  0.025308875,\n",
              "  -0.09847398,\n",
              "  -0.046995822,\n",
              "  -0.070801005,\n",
              "  0.063467495,\n",
              "  0.0427498,\n",
              "  -0.028591905,\n",
              "  0.19238847,\n",
              "  0.471573,\n",
              "  -0.22802399,\n",
              "  -0.05561176,\n",
              "  0.09733116,\n",
              "  -0.0012502733,\n",
              "  0.052239876,\n",
              "  -0.025210923,\n",
              "  -0.19806324,\n",
              "  0.07048275,\n",
              "  -0.05091278,\n",
              "  0.028358387,\n",
              "  -0.066074625,\n",
              "  0.010988391,\n",
              "  -0.025180656,\n",
              "  0.08456452,\n",
              "  0.060336582,\n",
              "  -0.0059750783,\n",
              "  0.12407906,\n",
              "  -0.10748519,\n",
              "  -0.094989054,\n",
              "  -0.108802706,\n",
              "  0.017148718,\n",
              "  0.14023857,\n",
              "  -0.111436985,\n",
              "  -0.0609363,\n",
              "  0.101000585,\n",
              "  0.012278948,\n",
              "  -0.021069603,\n",
              "  0.0065945666,\n",
              "  -0.036287326,\n",
              "  0.03877131,\n",
              "  -0.07348647,\n",
              "  0.058411688,\n",
              "  -0.024700996,\n",
              "  0.034132555,\n",
              "  -0.030679468,\n",
              "  0.38387832,\n",
              "  0.0018572407,\n",
              "  -0.1232897,\n",
              "  0.023588521,\n",
              "  -0.024974674,\n",
              "  -0.05811162,\n",
              "  -0.018403752,\n",
              "  -0.055151507,\n",
              "  -0.13894163,\n",
              "  -0.6349574,\n",
              "  0.08882477,\n",
              "  0.05390165,\n",
              "  -0.07487335,\n",
              "  -0.08571661,\n",
              "  -0.021094661,\n",
              "  -0.035607025,\n",
              "  0.044739746,\n",
              "  0.005852558,\n",
              "  0.048183944,\n",
              "  -0.0314868,\n",
              "  0.047271907,\n",
              "  0.06147665,\n",
              "  0.003693642,\n",
              "  0.10776407,\n",
              "  -0.0003116588,\n",
              "  0.044355646,\n",
              "  -1.2221926,\n",
              "  0.07934814,\n",
              "  0.14709039,\n",
              "  -0.038859896,\n",
              "  0.005879815,\n",
              "  -0.045793865,\n",
              "  0.14855333,\n",
              "  -0.004985236,\n",
              "  -0.06715267,\n",
              "  0.12960772,\n",
              "  0.038274076,\n",
              "  -0.0135759385,\n",
              "  -0.030614324,\n",
              "  -0.083256535,\n",
              "  -0.13488649,\n",
              "  -0.026638312,\n",
              "  -0.029373508,\n",
              "  0.015263878,\n",
              "  -0.08993665,\n",
              "  -0.053952415,\n",
              "  -0.0012788363,\n",
              "  0.03707814,\n",
              "  0.28610817,\n",
              "  0.6633394,\n",
              "  -0.1566323,\n",
              "  0.07207088,\n",
              "  0.0044255713,\n",
              "  -0.021385375,\n",
              "  -0.060474157,\n",
              "  -0.040602274,\n",
              "  0.23771001,\n",
              "  0.15758651,\n",
              "  0.025424477,\n",
              "  0.081984594,\n",
              "  0.12712367,\n",
              "  0.05902213,\n",
              "  0.065710254,\n",
              "  0.054770842,\n",
              "  -0.03714782,\n",
              "  -0.196217,\n",
              "  0.008796328,\n",
              "  0.08917105,\n",
              "  0.39375985,\n",
              "  0.026331004,\n",
              "  -0.10371756,\n",
              "  -0.12048008,\n",
              "  0.07372835,\n",
              "  0.010880117,\n",
              "  -0.03130895,\n",
              "  0.006825185],\n",
              " [0.004728314,\n",
              "  0.0044931127,\n",
              "  0.058480375,\n",
              "  0.018165987,\n",
              "  -0.02152166,\n",
              "  -0.024178412,\n",
              "  -0.04866216,\n",
              "  -0.0933258,\n",
              "  -0.15685916,\n",
              "  0.03817789,\n",
              "  -0.09773636,\n",
              "  0.058528144,\n",
              "  0.04121861,\n",
              "  -0.0063999416,\n",
              "  0.11522258,\n",
              "  -0.083688594,\n",
              "  0.068421505,\n",
              "  -0.07179895,\n",
              "  -0.11988084,\n",
              "  0.055203456,\n",
              "  0.059428055,\n",
              "  -0.020245751,\n",
              "  -0.1654658,\n",
              "  0.0019307627,\n",
              "  0.009791865,\n",
              "  -0.076827146,\n",
              "  -0.09040131,\n",
              "  -0.0136922775,\n",
              "  0.043065906,\n",
              "  -0.16938949,\n",
              "  0.11786432,\n",
              "  0.034040477,\n",
              "  0.02065905,\n",
              "  -0.3959091,\n",
              "  0.01023775,\n",
              "  -0.05018309,\n",
              "  -0.116853,\n",
              "  0.0231076,\n",
              "  -0.071410924,\n",
              "  0.20275025,\n",
              "  -0.14516099,\n",
              "  0.016310176,\n",
              "  0.021436619,\n",
              "  0.11335171,\n",
              "  0.41598725,\n",
              "  -0.13051225,\n",
              "  0.11926874,\n",
              "  -0.18019235,\n",
              "  -0.09792086,\n",
              "  0.07504947,\n",
              "  0.15265153,\n",
              "  -0.16476382,\n",
              "  0.13086301,\n",
              "  -0.13796644,\n",
              "  -0.03008459,\n",
              "  -0.082035504,\n",
              "  0.019697139,\n",
              "  0.010546359,\n",
              "  -0.13628939,\n",
              "  -0.014388382,\n",
              "  -0.023523154,\n",
              "  0.005966652,\n",
              "  -0.1663422,\n",
              "  -0.09880361,\n",
              "  -0.038313646,\n",
              "  0.0298446,\n",
              "  -0.0038478738,\n",
              "  -0.10875245,\n",
              "  0.06153647,\n",
              "  -0.012116223,\n",
              "  0.14778717,\n",
              "  0.020383043,\n",
              "  -0.11035961,\n",
              "  -0.040156405,\n",
              "  -0.17879723,\n",
              "  -0.03004666,\n",
              "  0.08414762,\n",
              "  -0.045509193,\n",
              "  0.29620868,\n",
              "  -0.01683816,\n",
              "  0.021150928,\n",
              "  0.74199396,\n",
              "  0.015630068,\n",
              "  0.07946617,\n",
              "  -0.12576985,\n",
              "  0.055667587,\n",
              "  0.8371833,\n",
              "  -0.03692903,\n",
              "  -0.0032048011,\n",
              "  -0.08529894,\n",
              "  0.06810683,\n",
              "  0.049517475,\n",
              "  0.026188366,\n",
              "  -0.059135217,\n",
              "  -0.028786052,\n",
              "  -0.023793295,\n",
              "  -0.077551045,\n",
              "  0.072866365,\n",
              "  -0.013990401,\n",
              "  -0.13994718,\n",
              "  -0.062042523,\n",
              "  0.0745245,\n",
              "  -0.12383017,\n",
              "  -0.13683003,\n",
              "  0.07644513,\n",
              "  1.2297839,\n",
              "  0.04578854,\n",
              "  0.053164367,\n",
              "  0.09812101,\n",
              "  -0.15625454,\n",
              "  -0.074592486,\n",
              "  -0.17312187,\n",
              "  0.015703876,\n",
              "  0.011863323,\n",
              "  -0.07824817,\n",
              "  0.19010709,\n",
              "  -0.115931764,\n",
              "  -0.18228455,\n",
              "  -0.48551464,\n",
              "  0.0038297363,\n",
              "  -0.078155,\n",
              "  -0.05156166,\n",
              "  0.054600477,\n",
              "  0.03861678,\n",
              "  0.054787904,\n",
              "  -0.05194313,\n",
              "  -0.08387293,\n",
              "  0.14838953,\n",
              "  0.018742917,\n",
              "  0.019078795,\n",
              "  -0.0015982738,\n",
              "  -0.060041226,\n",
              "  0.06898157,\n",
              "  -0.029864715,\n",
              "  1.4258276,\n",
              "  -0.11391224,\n",
              "  0.07024713,\n",
              "  -0.040110182,\n",
              "  -0.0969143,\n",
              "  -0.02874364,\n",
              "  0.11071481,\n",
              "  0.10449867,\n",
              "  0.022909982,\n",
              "  -0.089403994,\n",
              "  -0.0077623245,\n",
              "  0.0614853,\n",
              "  0.019920869,\n",
              "  -0.15042134,\n",
              "  0.016786007,\n",
              "  -0.006524481,\n",
              "  0.11372229,\n",
              "  0.04620498,\n",
              "  0.08334258,\n",
              "  -0.052977104,\n",
              "  0.08026742,\n",
              "  0.039518878,\n",
              "  -1.0618662,\n",
              "  0.019890059,\n",
              "  0.0072280583,\n",
              "  0.09294957,\n",
              "  0.0981094,\n",
              "  -0.044882074,\n",
              "  0.11471429,\n",
              "  0.032623775,\n",
              "  -0.06155543,\n",
              "  0.00012591195,\n",
              "  0.02074396,\n",
              "  -0.062221047,\n",
              "  -0.018479297,\n",
              "  -0.10038288,\n",
              "  0.09150893,\n",
              "  -0.10319743,\n",
              "  0.029118687,\n",
              "  0.025034983,\n",
              "  -0.01854371,\n",
              "  0.033664804,\n",
              "  -0.053581953,\n",
              "  -0.039073385,\n",
              "  -0.22787961,\n",
              "  -0.07764185,\n",
              "  0.040375993,\n",
              "  -0.01471208,\n",
              "  0.14779688,\n",
              "  -0.005392525,\n",
              "  0.0005861717,\n",
              "  0.04044337,\n",
              "  0.096546635,\n",
              "  0.014142449,\n",
              "  0.04789666,\n",
              "  -0.03907239,\n",
              "  0.070082486,\n",
              "  0.2495773,\n",
              "  -0.016700419,\n",
              "  -0.105708055,\n",
              "  -0.066722214,\n",
              "  0.049546357,\n",
              "  -0.5191245,\n",
              "  0.023336533,\n",
              "  -0.87424254,\n",
              "  0.5285439,\n",
              "  -0.10117667,\n",
              "  0.1318564,\n",
              "  -0.11059374,\n",
              "  -0.014648769,\n",
              "  0.14928307,\n",
              "  -0.08324422,\n",
              "  0.0027673598,\n",
              "  0.0026318692,\n",
              "  0.06788786,\n",
              "  -0.26764,\n",
              "  0.088762574,\n",
              "  -0.008484324,\n",
              "  0.04246435,\n",
              "  -0.0499969,\n",
              "  0.05456107,\n",
              "  0.0041988413,\n",
              "  -0.05678072,\n",
              "  -0.11780594,\n",
              "  -0.119684435,\n",
              "  -0.02899867,\n",
              "  0.14367576,\n",
              "  -0.0024740018,\n",
              "  0.05148289,\n",
              "  -0.17685033,\n",
              "  -0.13265467,\n",
              "  0.09071299,\n",
              "  0.026753172,\n",
              "  0.042887583,\n",
              "  0.0411231,\n",
              "  0.108996175,\n",
              "  0.0019496459,\n",
              "  -0.0108221285,\n",
              "  -0.09772105,\n",
              "  0.056311328,\n",
              "  0.34898624,\n",
              "  0.13599135,\n",
              "  0.009863435,\n",
              "  -0.000902329,\n",
              "  -0.06478567,\n",
              "  -0.08224454,\n",
              "  0.0872003,\n",
              "  0.0006483043,\n",
              "  -0.08328254,\n",
              "  -0.041160427,\n",
              "  0.0032224394,\n",
              "  -0.12569338,\n",
              "  -0.037982848,\n",
              "  -0.12251084,\n",
              "  -0.042210784,\n",
              "  0.12545742,\n",
              "  -1.6960658,\n",
              "  -0.027531143,\n",
              "  -0.061372824,\n",
              "  -0.12082669,\n",
              "  -0.15705676,\n",
              "  -0.0832231,\n",
              "  0.14178932,\n",
              "  -0.10515323,\n",
              "  0.053712413,\n",
              "  0.018660063,\n",
              "  0.032540612,\n",
              "  -0.010874442,\n",
              "  0.045439165,\n",
              "  0.09141244,\n",
              "  -0.05985577,\n",
              "  0.224094,\n",
              "  0.020903552,\n",
              "  -0.046956297,\n",
              "  0.01355143,\n",
              "  -0.010583249,\n",
              "  -0.018158058,\n",
              "  -0.06788301,\n",
              "  0.08314104,\n",
              "  -0.018621828,\n",
              "  -0.01595394,\n",
              "  0.068991,\n",
              "  -0.06261966,\n",
              "  -0.0070883934,\n",
              "  -0.0071326876,\n",
              "  0.11021345,\n",
              "  -0.0134643195,\n",
              "  0.06510595,\n",
              "  0.086700626,\n",
              "  -0.0002525903,\n",
              "  -0.10659879,\n",
              "  -0.05019091,\n",
              "  -0.15339758,\n",
              "  0.066310175,\n",
              "  -1.3496937,\n",
              "  -0.09571473,\n",
              "  0.0006650768,\n",
              "  -0.018106902,\n",
              "  0.029740443,\n",
              "  0.06281239,\n",
              "  -0.73045707,\n",
              "  -0.013693566,\n",
              "  -0.033578448,\n",
              "  -0.115258835,\n",
              "  0.059849855,\n",
              "  -0.09260761],\n",
              " [-0.00022552192,\n",
              "  0.647276,\n",
              "  0.062416308,\n",
              "  -0.15132031,\n",
              "  -0.2163895,\n",
              "  0.5073022,\n",
              "  0.089424685,\n",
              "  -0.16217431,\n",
              "  0.1989929,\n",
              "  -0.40119544,\n",
              "  0.4430458,\n",
              "  0.9386963,\n",
              "  0.8507782,\n",
              "  0.1362373,\n",
              "  0.13774823,\n",
              "  0.025676077,\n",
              "  1.2654629,\n",
              "  0.24303173,\n",
              "  0.3917366,\n",
              "  0.6946369,\n",
              "  -0.044943456,\n",
              "  0.14713243,\n",
              "  0.95415556,\n",
              "  0.30990797,\n",
              "  -0.08812207,\n",
              "  -0.09819583,\n",
              "  -0.011619181,\n",
              "  -0.6257317,\n",
              "  -0.024230853,\n",
              "  0.003692643,\n",
              "  -0.053658083,\n",
              "  -0.098747596,\n",
              "  0.2170667,\n",
              "  0.17643568,\n",
              "  0.45836225,\n",
              "  0.40683693,\n",
              "  -0.018279374,\n",
              "  -0.053633254,\n",
              "  0.33560017,\n",
              "  0.084271744,\n",
              "  -0.33120435,\n",
              "  0.033149485,\n",
              "  0.04833696,\n",
              "  -0.15471199,\n",
              "  0.71157664,\n",
              "  0.31806174,\n",
              "  -0.026827285,\n",
              "  -0.27805245,\n",
              "  0.10567466,\n",
              "  0.0020128952,\n",
              "  0.10093945,\n",
              "  -0.38280296,\n",
              "  -0.04307174,\n",
              "  0.22875404,\n",
              "  -0.086237065,\n",
              "  -0.5241643,\n",
              "  0.07407738,\n",
              "  -0.006779033,\n",
              "  0.5517288,\n",
              "  0.022598298,\n",
              "  -0.6193161,\n",
              "  0.02164792,\n",
              "  -1.0938514,\n",
              "  -0.12747465,\n",
              "  0.12070119,\n",
              "  -0.27290258,\n",
              "  0.09911752,\n",
              "  0.17902969,\n",
              "  0.19857374,\n",
              "  0.080962695,\n",
              "  0.016374813,\n",
              "  -0.6158096,\n",
              "  0.16661675,\n",
              "  -0.08936338,\n",
              "  0.040104445,\n",
              "  0.26260987,\n",
              "  0.083389595,\n",
              "  0.008312939,\n",
              "  -0.15163536,\n",
              "  -0.14859864,\n",
              "  -0.30177954,\n",
              "  0.004963204,\n",
              "  0.20478612,\n",
              "  0.22995277,\n",
              "  -0.060228452,\n",
              "  0.017271215,\n",
              "  0.7254949,\n",
              "  -0.076365,\n",
              "  0.66203517,\n",
              "  -0.51474607,\n",
              "  0.09599237,\n",
              "  -0.19132064,\n",
              "  -0.025580855,\n",
              "  0.1863714,\n",
              "  0.09618933,\n",
              "  -0.20319545,\n",
              "  0.042316735,\n",
              "  0.16446245,\n",
              "  -0.1657894,\n",
              "  -0.20526668,\n",
              "  0.120214075,\n",
              "  0.55538327,\n",
              "  -0.04587661,\n",
              "  0.13281831,\n",
              "  0.08545526,\n",
              "  0.46161127,\n",
              "  0.14963576,\n",
              "  -0.448623,\n",
              "  -0.26927748,\n",
              "  -0.003980944,\n",
              "  0.025921337,\n",
              "  0.19956194,\n",
              "  -0.686911,\n",
              "  0.2624588,\n",
              "  0.015050103,\n",
              "  0.13314454,\n",
              "  0.27435258,\n",
              "  0.34220013,\n",
              "  -0.77380675,\n",
              "  -0.07062142,\n",
              "  0.522955,\n",
              "  0.50186557,\n",
              "  0.0034225408,\n",
              "  -1.4316059,\n",
              "  -0.22019349,\n",
              "  0.11335911,\n",
              "  0.06323678,\n",
              "  -0.01965616,\n",
              "  0.12288352,\n",
              "  -1.1383983,\n",
              "  0.94416374,\n",
              "  0.034078073,\n",
              "  -0.15032707,\n",
              "  -0.3267679,\n",
              "  0.283613,\n",
              "  -0.25732124,\n",
              "  0.74599004,\n",
              "  0.56843466,\n",
              "  -0.0069510066,\n",
              "  -0.36926416,\n",
              "  -0.09063699,\n",
              "  -0.54193515,\n",
              "  0.34965968,\n",
              "  -0.10707242,\n",
              "  0.022654809,\n",
              "  -0.016327025,\n",
              "  -0.13079649,\n",
              "  0.26829362,\n",
              "  0.054121077,\n",
              "  0.14530209,\n",
              "  -0.0102292,\n",
              "  0.054530773,\n",
              "  -0.029787341,\n",
              "  -0.6057776,\n",
              "  0.002163279,\n",
              "  0.075100444,\n",
              "  0.002225395,\n",
              "  0.082401834,\n",
              "  0.015282153,\n",
              "  -0.21729314,\n",
              "  0.12920445,\n",
              "  0.4922411,\n",
              "  -0.9576851,\n",
              "  0.10604191,\n",
              "  -0.2637859,\n",
              "  -0.058335483,\n",
              "  -0.49509922,\n",
              "  -0.209462,\n",
              "  -0.28686082,\n",
              "  -0.10802614,\n",
              "  -0.0143052135,\n",
              "  0.19296129,\n",
              "  -0.7924533,\n",
              "  0.09300165,\n",
              "  0.16263224,\n",
              "  -0.18098146,\n",
              "  0.113007486,\n",
              "  -0.058551848,\n",
              "  0.26728904,\n",
              "  0.06613522,\n",
              "  0.5873903,\n",
              "  -0.30870408,\n",
              "  -0.12230686,\n",
              "  -0.2660772,\n",
              "  0.62043417,\n",
              "  0.832626,\n",
              "  -0.27248982,\n",
              "  -0.067729324,\n",
              "  0.2665853,\n",
              "  -0.14408556,\n",
              "  0.09645011,\n",
              "  -0.04386632,\n",
              "  0.019075856,\n",
              "  0.10173101,\n",
              "  0.006811345,\n",
              "  0.061339397,\n",
              "  -0.4455904,\n",
              "  0.65666527,\n",
              "  -0.27111834,\n",
              "  0.06277074,\n",
              "  -0.29437524,\n",
              "  -0.05740449,\n",
              "  -0.64903826,\n",
              "  0.28198215,\n",
              "  0.051379036,\n",
              "  -0.051730897,\n",
              "  0.1101464,\n",
              "  0.4865899,\n",
              "  0.10079866,\n",
              "  0.16966861,\n",
              "  0.19071245,\n",
              "  0.122138776,\n",
              "  1.1781332,\n",
              "  -0.028714791,\n",
              "  -0.8850775,\n",
              "  0.089419685,\n",
              "  0.04106486,\n",
              "  -0.2942627,\n",
              "  0.20474638,\n",
              "  0.042782333,\n",
              "  0.087149784,\n",
              "  0.0023550699,\n",
              "  0.39270896,\n",
              "  -0.00892449,\n",
              "  0.0097331805,\n",
              "  -0.07020744,\n",
              "  1.6705334,\n",
              "  0.69002944,\n",
              "  -0.008789532,\n",
              "  -0.46021888,\n",
              "  0.21248777,\n",
              "  0.05239578,\n",
              "  0.76000786,\n",
              "  -0.055014692,\n",
              "  0.17850214,\n",
              "  0.26516035,\n",
              "  1.1744108,\n",
              "  -0.12346742,\n",
              "  -0.09018677,\n",
              "  -0.15210532,\n",
              "  -0.23600173,\n",
              "  -1.4337547,\n",
              "  0.20588824,\n",
              "  0.9716288,\n",
              "  0.2618084,\n",
              "  0.08333156,\n",
              "  -0.17273106,\n",
              "  0.10664581,\n",
              "  0.5823336,\n",
              "  0.10920711,\n",
              "  -0.0047804904,\n",
              "  0.15881915,\n",
              "  0.020750338,\n",
              "  0.08850843,\n",
              "  -0.25128162,\n",
              "  -0.027612748,\n",
              "  -0.15424176,\n",
              "  -0.10132377,\n",
              "  -0.0023422672,\n",
              "  -0.2722077,\n",
              "  -1.3925648,\n",
              "  -0.041350838,\n",
              "  -0.017836895,\n",
              "  0.05249515,\n",
              "  -0.4748822,\n",
              "  0.3433412,\n",
              "  0.0177577,\n",
              "  -0.4555807,\n",
              "  0.016913187,\n",
              "  0.093677975,\n",
              "  0.022636611,\n",
              "  -0.32408327,\n",
              "  -0.56768745,\n",
              "  0.15921068,\n",
              "  0.14626475,\n",
              "  0.11375373,\n",
              "  0.4382459,\n",
              "  -0.21958771,\n",
              "  -0.009967081,\n",
              "  0.0102251815,\n",
              "  0.751476,\n",
              "  0.06800384,\n",
              "  0.052923385,\n",
              "  -0.20357242,\n",
              "  0.78763986,\n",
              "  0.15059492,\n",
              "  -1.1666656,\n",
              "  -0.6355193,\n",
              "  -0.9537889,\n",
              "  0.13814752,\n",
              "  -0.1402825,\n",
              "  0.3431527,\n",
              "  0.26414853,\n",
              "  -0.72234344,\n",
              "  0.024978854,\n",
              "  0.059027568,\n",
              "  -0.12785971,\n",
              "  1.0183456,\n",
              "  1.0146984,\n",
              "  0.0982538]]"
            ]
          },
          "metadata": {},
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7l7gL0Tgv4Kx",
        "outputId": "10a95344-6505-4feb-dde7-260eb52fb780"
      },
      "id": "7l7gL0Tgv4Kx",
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 3, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_embeddings[0][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWcDQNDcv4T3",
        "outputId": "3a14f707-e4be-4441-feaf-5f4558570826"
      },
      "id": "zWcDQNDcv4T3",
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 3, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dev_dataset_embeddings = []\n",
        "\n",
        "for sentence in dev_dataset:\n",
        "\n",
        "    # print(f'sentence: {sentence}')\n",
        "    setence_words_embeddings = []\n",
        "    setence_pos_tags = []\n",
        "\n",
        "    for i in range(0, len(sentence[0])):\n",
        "\n",
        "        word_id = sentence[0][i]\n",
        "        pos_tag = sentence[1][i]\n",
        "\n",
        "        # print(f'i: {i}')\n",
        "        # print(f'word_id: {word_id}')\n",
        "        # print(f'pos_tag: {pos_tag}')\n",
        "\n",
        "        # print(f'{word_id} - {dev_dataset.token_vocab.id2word( word_id )}')\n",
        "        word = dev_dataset.token_vocab.id2word( word_id )\n",
        "        if word in w2emb:\n",
        "            embeddings = w2emb[ word ]\n",
        "        else:\n",
        "            embeddings = w2emb['<oov>']\n",
        "\n",
        "        embeddings = list(embeddings)\n",
        "        # print(f'embeddings: {embeddings}')\n",
        "        # print(f'{word_id} - {word} - {embeddings}')\n",
        "\n",
        "        setence_words_embeddings.append(embeddings)\n",
        "        setence_pos_tags.append(pos_tag)\n",
        "        # print(f'setence_words_embeddings: {setence_words_embeddings}')\n",
        "        # print(f'setence_pos_tags: {setence_pos_tags}')\n",
        "        # print(f'len(setence_words_embeddings): {len(setence_words_embeddings)}')\n",
        "        # print(f'len(setence_pos_tags): {len(setence_pos_tags)}')\n",
        "\n",
        "        new_sentence_embdeddings_pos = ((setence_words_embeddings, setence_pos_tags))\n",
        "        # print(f'sentence: {sentence}')\n",
        "        # print(f'new_sentence_embdeddings_pos: {new_sentence_embdeddings_pos}')\n",
        "        dev_dataset_embeddings.append( new_sentence_embdeddings_pos )\n",
        "\n",
        "        # print('------------------------------------------------')"
      ],
      "metadata": {
        "id": "actMly28aq9y"
      },
      "id": "actMly28aq9y",
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_embeddings[0] # primeira sentença: embeddings das palavras + pos_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSvBdu8cfjjG",
        "outputId": "a6adda64-3324-410d-ebe2-ffb30d2c7301"
      },
      "id": "GSvBdu8cfjjG",
      "execution_count": 227,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([[0.06372718,\n",
              "   1.081287,\n",
              "   -0.2566062,\n",
              "   0.35581657,\n",
              "   0.20967016,\n",
              "   -0.36711636,\n",
              "   0.366946,\n",
              "   -0.3230368,\n",
              "   -0.34950674,\n",
              "   0.4455702,\n",
              "   -0.7013678,\n",
              "   0.20763332,\n",
              "   0.7158997,\n",
              "   0.07245133,\n",
              "   0.05840904,\n",
              "   1.7177013,\n",
              "   1.2872624,\n",
              "   0.007037018,\n",
              "   -0.36843827,\n",
              "   0.30398393,\n",
              "   1.9073563,\n",
              "   0.046871826,\n",
              "   0.362007,\n",
              "   0.19549051,\n",
              "   -0.055350173,\n",
              "   -0.018726848,\n",
              "   -0.70453614,\n",
              "   0.5320796,\n",
              "   0.21127453,\n",
              "   1.4585506,\n",
              "   0.15391096,\n",
              "   -0.99725866,\n",
              "   0.109845065,\n",
              "   -0.020156017,\n",
              "   0.96515375,\n",
              "   1.9662554,\n",
              "   0.8686647,\n",
              "   0.0358276,\n",
              "   0.13300346,\n",
              "   0.0016626305,\n",
              "   0.2117124,\n",
              "   -0.42018014,\n",
              "   0.069936104,\n",
              "   -0.3920737,\n",
              "   0.6753673,\n",
              "   0.28072768,\n",
              "   0.38520417,\n",
              "   -0.23346636,\n",
              "   -0.09435507,\n",
              "   -0.08085937,\n",
              "   -0.007921909,\n",
              "   -0.049984373,\n",
              "   1.0996103,\n",
              "   -0.12756191,\n",
              "   -0.57305413,\n",
              "   -0.0906943,\n",
              "   -0.18224198,\n",
              "   -0.71684444,\n",
              "   0.30599272,\n",
              "   -0.9337199,\n",
              "   -0.3402406,\n",
              "   0.08233886,\n",
              "   -0.12936674,\n",
              "   -0.048676677,\n",
              "   -1.148141,\n",
              "   -0.265937,\n",
              "   0.14547049,\n",
              "   0.20106123,\n",
              "   0.7871115,\n",
              "   0.0467316,\n",
              "   0.37001476,\n",
              "   0.25859573,\n",
              "   -0.1932874,\n",
              "   0.15227121,\n",
              "   -0.9664524,\n",
              "   -0.9591928,\n",
              "   -0.7624523,\n",
              "   -0.07831785,\n",
              "   0.26224315,\n",
              "   -0.9360457,\n",
              "   -0.6024347,\n",
              "   -0.100979745,\n",
              "   0.0090000685,\n",
              "   -0.7707501,\n",
              "   0.075180456,\n",
              "   -0.7947064,\n",
              "   -0.2816814,\n",
              "   0.48935875,\n",
              "   0.08751537,\n",
              "   -0.8001722,\n",
              "   -0.36688596,\n",
              "   0.37152243,\n",
              "   -0.1771037,\n",
              "   -0.36373323,\n",
              "   -0.50271946,\n",
              "   -0.28352714,\n",
              "   -1.0547155,\n",
              "   0.75629294,\n",
              "   -0.933083,\n",
              "   -0.12812622,\n",
              "   -0.011600916,\n",
              "   0.8967122,\n",
              "   -1.1458066,\n",
              "   0.16362725,\n",
              "   0.3683528,\n",
              "   1.4188989,\n",
              "   -0.60400814,\n",
              "   0.031383496,\n",
              "   0.23712853,\n",
              "   0.85988116,\n",
              "   0.23687339,\n",
              "   0.87570107,\n",
              "   -0.12749588,\n",
              "   -0.5388552,\n",
              "   -0.020999411,\n",
              "   0.29103607,\n",
              "   -0.9802869,\n",
              "   1.3249602,\n",
              "   -0.24870618,\n",
              "   1.057709,\n",
              "   2.3566551,\n",
              "   -0.19924004,\n",
              "   0.44819525,\n",
              "   0.056492962,\n",
              "   -0.32668144,\n",
              "   -0.36056006,\n",
              "   -0.08794432,\n",
              "   -0.93602175,\n",
              "   -0.34992993,\n",
              "   0.12274587,\n",
              "   -0.10208813,\n",
              "   1.1051462,\n",
              "   -0.31939432,\n",
              "   1.1725352,\n",
              "   -0.12476992,\n",
              "   0.20372844,\n",
              "   -0.22290604,\n",
              "   0.06569898,\n",
              "   -0.31762686,\n",
              "   1.0868597,\n",
              "   -0.090878725,\n",
              "   -0.55399674,\n",
              "   -1.0946723,\n",
              "   0.043481365,\n",
              "   -0.005812096,\n",
              "   -0.2817849,\n",
              "   0.8549238,\n",
              "   0.1669907,\n",
              "   -1.1517125,\n",
              "   0.57864267,\n",
              "   -1.0441968,\n",
              "   0.6754023,\n",
              "   0.061240908,\n",
              "   1.5305414,\n",
              "   -0.8261177,\n",
              "   1.0224041,\n",
              "   0.9249804,\n",
              "   -0.32420865,\n",
              "   -1.4137812,\n",
              "   0.20947477,\n",
              "   -0.29527417,\n",
              "   -0.17414202,\n",
              "   -0.040787656,\n",
              "   -0.2367585,\n",
              "   0.6397661,\n",
              "   -0.057225715,\n",
              "   0.67932934,\n",
              "   -0.32956517,\n",
              "   0.7933583,\n",
              "   -0.19555613,\n",
              "   0.34387615,\n",
              "   0.06265616,\n",
              "   0.07162569,\n",
              "   -0.96173805,\n",
              "   -0.053785387,\n",
              "   0.7778594,\n",
              "   -0.3276487,\n",
              "   -0.917016,\n",
              "   -0.9388664,\n",
              "   0.13197146,\n",
              "   -0.21743894,\n",
              "   0.44010893,\n",
              "   0.54174125,\n",
              "   -0.23716946,\n",
              "   0.09388318,\n",
              "   -0.53589576,\n",
              "   1.001673,\n",
              "   0.25897142,\n",
              "   0.7238234,\n",
              "   0.48884955,\n",
              "   0.18332489,\n",
              "   1.2084366,\n",
              "   0.8020086,\n",
              "   -0.8992238,\n",
              "   0.45900917,\n",
              "   -0.2521107,\n",
              "   0.13744581,\n",
              "   -0.4491561,\n",
              "   -0.9049304,\n",
              "   -0.99047464,\n",
              "   0.21644366,\n",
              "   -0.02021508,\n",
              "   0.00030899062,\n",
              "   1.1382844,\n",
              "   0.06248691,\n",
              "   1.8253031,\n",
              "   0.2165822,\n",
              "   -0.20076434,\n",
              "   -0.07807895,\n",
              "   -0.11972387,\n",
              "   1.0079817,\n",
              "   -0.27834028,\n",
              "   0.50660026,\n",
              "   -0.06464993,\n",
              "   -1.4205974,\n",
              "   -0.111983106,\n",
              "   0.040536087,\n",
              "   -0.10234122,\n",
              "   -0.31079718,\n",
              "   -0.26001686,\n",
              "   0.0034731056,\n",
              "   -0.70629066,\n",
              "   -0.2077131,\n",
              "   -0.16383447,\n",
              "   0.14461604,\n",
              "   0.008636888,\n",
              "   -0.36653537,\n",
              "   0.65722346,\n",
              "   -1.016722,\n",
              "   -0.021882817,\n",
              "   1.1467028,\n",
              "   -0.17828526,\n",
              "   -0.948344,\n",
              "   0.098252095,\n",
              "   0.024464896,\n",
              "   0.2189097,\n",
              "   -0.24392761,\n",
              "   -0.7130577,\n",
              "   0.09524739,\n",
              "   -0.08843837,\n",
              "   -0.8733692,\n",
              "   -0.054664023,\n",
              "   0.00036502426,\n",
              "   0.4452453,\n",
              "   -0.35146424,\n",
              "   0.28400722,\n",
              "   0.03350738,\n",
              "   0.119209446,\n",
              "   -0.7533325,\n",
              "   -0.012024853,\n",
              "   0.2483871,\n",
              "   -0.5152819,\n",
              "   0.40588433,\n",
              "   0.36219853,\n",
              "   -1.1796994,\n",
              "   -0.3848285,\n",
              "   0.016091079,\n",
              "   -0.5517637,\n",
              "   -0.33975077,\n",
              "   1.3582784,\n",
              "   0.17714405,\n",
              "   -0.25497964,\n",
              "   -0.11721627,\n",
              "   0.83445907,\n",
              "   0.011520235,\n",
              "   -0.08571271,\n",
              "   -1.3456805,\n",
              "   -0.15762958,\n",
              "   0.037313636,\n",
              "   -0.21370144,\n",
              "   -0.20689562,\n",
              "   -0.48809084,\n",
              "   0.37793165,\n",
              "   0.40595737,\n",
              "   -0.22252542,\n",
              "   -0.22216909,\n",
              "   0.07363122,\n",
              "   -0.016889513,\n",
              "   -1.9044163,\n",
              "   -0.027313847,\n",
              "   -0.12523548,\n",
              "   0.6096165,\n",
              "   0.9808078,\n",
              "   -0.03436354,\n",
              "   -0.21899608,\n",
              "   -0.17765175,\n",
              "   -0.8830685,\n",
              "   -0.5257147,\n",
              "   -1.4707041,\n",
              "   -0.45082042,\n",
              "   -0.056313418,\n",
              "   0.6656539,\n",
              "   -0.28650385,\n",
              "   -0.98320144,\n",
              "   0.85901,\n",
              "   -0.21829721,\n",
              "   -0.63703984,\n",
              "   0.19372569,\n",
              "   -0.571344,\n",
              "   -0.10763226],\n",
              "  [0.05815203,\n",
              "   -0.114808016,\n",
              "   0.21598664,\n",
              "   -0.091081224,\n",
              "   -0.13379069,\n",
              "   -0.031145174,\n",
              "   -0.0751396,\n",
              "   -0.02267536,\n",
              "   -0.5609628,\n",
              "   -0.09331572,\n",
              "   -0.16930725,\n",
              "   0.064811304,\n",
              "   0.07632986,\n",
              "   -0.10635636,\n",
              "   0.11654597,\n",
              "   0.015249734,\n",
              "   0.3332348,\n",
              "   -0.040203318,\n",
              "   -0.056161333,\n",
              "   0.06971202,\n",
              "   0.03803344,\n",
              "   0.0056230687,\n",
              "   -0.08705268,\n",
              "   -0.04138264,\n",
              "   0.17325073,\n",
              "   -0.10644652,\n",
              "   0.18148725,\n",
              "   -0.101971395,\n",
              "   -0.063315175,\n",
              "   -0.039727867,\n",
              "   -0.020333989,\n",
              "   0.16832665,\n",
              "   -0.04368675,\n",
              "   -0.124407046,\n",
              "   -0.045778155,\n",
              "   -0.022390736,\n",
              "   -0.16598459,\n",
              "   0.014571197,\n",
              "   -0.0367724,\n",
              "   -0.08845049,\n",
              "   0.055043943,\n",
              "   0.04780981,\n",
              "   -0.005934156,\n",
              "   0.053470436,\n",
              "   -0.1681836,\n",
              "   -0.24690257,\n",
              "   -0.05668426,\n",
              "   -0.025972975,\n",
              "   0.18716525,\n",
              "   0.07911916,\n",
              "   0.13157076,\n",
              "   -0.0268637,\n",
              "   -1.3067639,\n",
              "   -0.186044,\n",
              "   0.029951839,\n",
              "   -0.044162873,\n",
              "   0.100399405,\n",
              "   -0.35395667,\n",
              "   -0.044144396,\n",
              "   -0.011148631,\n",
              "   -0.09934373,\n",
              "   -0.056935925,\n",
              "   -0.047552194,\n",
              "   0.05219081,\n",
              "   -0.10117077,\n",
              "   0.028700866,\n",
              "   0.021876445,\n",
              "   0.026198786,\n",
              "   0.091476984,\n",
              "   -0.041362606,\n",
              "   -0.11009736,\n",
              "   0.14048193,\n",
              "   0.2916878,\n",
              "   0.06806833,\n",
              "   -0.049543884,\n",
              "   0.024125613,\n",
              "   -0.03010517,\n",
              "   -0.05895033,\n",
              "   0.021106517,\n",
              "   0.036428507,\n",
              "   -0.54165876,\n",
              "   0.06767264,\n",
              "   0.20646626,\n",
              "   -0.051836874,\n",
              "   0.07496069,\n",
              "   -0.076288305,\n",
              "   0.13622811,\n",
              "   -0.090674125,\n",
              "   0.012697146,\n",
              "   0.031194422,\n",
              "   -0.24336109,\n",
              "   -0.40655363,\n",
              "   -0.0432093,\n",
              "   0.012450507,\n",
              "   -0.30582616,\n",
              "   -0.053349994,\n",
              "   -0.04851207,\n",
              "   -0.15268618,\n",
              "   0.051567648,\n",
              "   -0.03584114,\n",
              "   -0.040185794,\n",
              "   -0.09007953,\n",
              "   -0.011267472,\n",
              "   -0.023215381,\n",
              "   0.3727063,\n",
              "   0.17393778,\n",
              "   0.011774387,\n",
              "   -0.09675175,\n",
              "   -0.017591173,\n",
              "   -0.09241216,\n",
              "   -0.0065412247,\n",
              "   0.14058478,\n",
              "   0.0033834747,\n",
              "   -0.07889787,\n",
              "   -0.46479118,\n",
              "   -0.1564571,\n",
              "   -0.00014121117,\n",
              "   0.023678523,\n",
              "   -0.056256358,\n",
              "   -0.03888438,\n",
              "   -0.51288855,\n",
              "   -0.7324658,\n",
              "   0.046602942,\n",
              "   -0.10032542,\n",
              "   -0.17267965,\n",
              "   0.022321926,\n",
              "   -0.02640406,\n",
              "   0.1120463,\n",
              "   0.0622902,\n",
              "   0.12064027,\n",
              "   -0.0165984,\n",
              "   -0.11063854,\n",
              "   -0.1028679,\n",
              "   0.07063889,\n",
              "   0.037413713,\n",
              "   -0.017875327,\n",
              "   -0.06351753,\n",
              "   0.2522428,\n",
              "   -0.9024238,\n",
              "   0.42668477,\n",
              "   0.03607478,\n",
              "   0.023540052,\n",
              "   -0.091611475,\n",
              "   0.054901734,\n",
              "   0.009347188,\n",
              "   -1.243348,\n",
              "   0.114641696,\n",
              "   -0.01941833,\n",
              "   0.08191366,\n",
              "   0.0150264315,\n",
              "   0.026807047,\n",
              "   0.019338869,\n",
              "   0.013214288,\n",
              "   -0.017745543,\n",
              "   -0.19620481,\n",
              "   -0.08811326,\n",
              "   -0.024754021,\n",
              "   0.03114945,\n",
              "   -0.48602095,\n",
              "   0.10580647,\n",
              "   -0.1170586,\n",
              "   0.09302091,\n",
              "   -0.047285557,\n",
              "   -0.08369471,\n",
              "   -0.098185904,\n",
              "   -0.03851085,\n",
              "   -0.08472644,\n",
              "   -0.041002586,\n",
              "   -0.04566867,\n",
              "   0.062416732,\n",
              "   0.09956799,\n",
              "   -0.12460333,\n",
              "   0.062783465,\n",
              "   0.10566039,\n",
              "   -0.05150288,\n",
              "   0.012748025,\n",
              "   0.06637465,\n",
              "   0.018225571,\n",
              "   0.008442214,\n",
              "   -0.08025035,\n",
              "   0.025308875,\n",
              "   -0.09847398,\n",
              "   -0.046995822,\n",
              "   -0.070801005,\n",
              "   0.063467495,\n",
              "   0.0427498,\n",
              "   -0.028591905,\n",
              "   0.19238847,\n",
              "   0.471573,\n",
              "   -0.22802399,\n",
              "   -0.05561176,\n",
              "   0.09733116,\n",
              "   -0.0012502733,\n",
              "   0.052239876,\n",
              "   -0.025210923,\n",
              "   -0.19806324,\n",
              "   0.07048275,\n",
              "   -0.05091278,\n",
              "   0.028358387,\n",
              "   -0.066074625,\n",
              "   0.010988391,\n",
              "   -0.025180656,\n",
              "   0.08456452,\n",
              "   0.060336582,\n",
              "   -0.0059750783,\n",
              "   0.12407906,\n",
              "   -0.10748519,\n",
              "   -0.094989054,\n",
              "   -0.108802706,\n",
              "   0.017148718,\n",
              "   0.14023857,\n",
              "   -0.111436985,\n",
              "   -0.0609363,\n",
              "   0.101000585,\n",
              "   0.012278948,\n",
              "   -0.021069603,\n",
              "   0.0065945666,\n",
              "   -0.036287326,\n",
              "   0.03877131,\n",
              "   -0.07348647,\n",
              "   0.058411688,\n",
              "   -0.024700996,\n",
              "   0.034132555,\n",
              "   -0.030679468,\n",
              "   0.38387832,\n",
              "   0.0018572407,\n",
              "   -0.1232897,\n",
              "   0.023588521,\n",
              "   -0.024974674,\n",
              "   -0.05811162,\n",
              "   -0.018403752,\n",
              "   -0.055151507,\n",
              "   -0.13894163,\n",
              "   -0.6349574,\n",
              "   0.08882477,\n",
              "   0.05390165,\n",
              "   -0.07487335,\n",
              "   -0.08571661,\n",
              "   -0.021094661,\n",
              "   -0.035607025,\n",
              "   0.044739746,\n",
              "   0.005852558,\n",
              "   0.048183944,\n",
              "   -0.0314868,\n",
              "   0.047271907,\n",
              "   0.06147665,\n",
              "   0.003693642,\n",
              "   0.10776407,\n",
              "   -0.0003116588,\n",
              "   0.044355646,\n",
              "   -1.2221926,\n",
              "   0.07934814,\n",
              "   0.14709039,\n",
              "   -0.038859896,\n",
              "   0.005879815,\n",
              "   -0.045793865,\n",
              "   0.14855333,\n",
              "   -0.004985236,\n",
              "   -0.06715267,\n",
              "   0.12960772,\n",
              "   0.038274076,\n",
              "   -0.0135759385,\n",
              "   -0.030614324,\n",
              "   -0.083256535,\n",
              "   -0.13488649,\n",
              "   -0.026638312,\n",
              "   -0.029373508,\n",
              "   0.015263878,\n",
              "   -0.08993665,\n",
              "   -0.053952415,\n",
              "   -0.0012788363,\n",
              "   0.03707814,\n",
              "   0.28610817,\n",
              "   0.6633394,\n",
              "   -0.1566323,\n",
              "   0.07207088,\n",
              "   0.0044255713,\n",
              "   -0.021385375,\n",
              "   -0.060474157,\n",
              "   -0.040602274,\n",
              "   0.23771001,\n",
              "   0.15758651,\n",
              "   0.025424477,\n",
              "   0.081984594,\n",
              "   0.12712367,\n",
              "   0.05902213,\n",
              "   0.065710254,\n",
              "   0.054770842,\n",
              "   -0.03714782,\n",
              "   -0.196217,\n",
              "   0.008796328,\n",
              "   0.08917105,\n",
              "   0.39375985,\n",
              "   0.026331004,\n",
              "   -0.10371756,\n",
              "   -0.12048008,\n",
              "   0.07372835,\n",
              "   0.010880117,\n",
              "   -0.03130895,\n",
              "   0.006825185],\n",
              "  [0.004728314,\n",
              "   0.0044931127,\n",
              "   0.058480375,\n",
              "   0.018165987,\n",
              "   -0.02152166,\n",
              "   -0.024178412,\n",
              "   -0.04866216,\n",
              "   -0.0933258,\n",
              "   -0.15685916,\n",
              "   0.03817789,\n",
              "   -0.09773636,\n",
              "   0.058528144,\n",
              "   0.04121861,\n",
              "   -0.0063999416,\n",
              "   0.11522258,\n",
              "   -0.083688594,\n",
              "   0.068421505,\n",
              "   -0.07179895,\n",
              "   -0.11988084,\n",
              "   0.055203456,\n",
              "   0.059428055,\n",
              "   -0.020245751,\n",
              "   -0.1654658,\n",
              "   0.0019307627,\n",
              "   0.009791865,\n",
              "   -0.076827146,\n",
              "   -0.09040131,\n",
              "   -0.0136922775,\n",
              "   0.043065906,\n",
              "   -0.16938949,\n",
              "   0.11786432,\n",
              "   0.034040477,\n",
              "   0.02065905,\n",
              "   -0.3959091,\n",
              "   0.01023775,\n",
              "   -0.05018309,\n",
              "   -0.116853,\n",
              "   0.0231076,\n",
              "   -0.071410924,\n",
              "   0.20275025,\n",
              "   -0.14516099,\n",
              "   0.016310176,\n",
              "   0.021436619,\n",
              "   0.11335171,\n",
              "   0.41598725,\n",
              "   -0.13051225,\n",
              "   0.11926874,\n",
              "   -0.18019235,\n",
              "   -0.09792086,\n",
              "   0.07504947,\n",
              "   0.15265153,\n",
              "   -0.16476382,\n",
              "   0.13086301,\n",
              "   -0.13796644,\n",
              "   -0.03008459,\n",
              "   -0.082035504,\n",
              "   0.019697139,\n",
              "   0.010546359,\n",
              "   -0.13628939,\n",
              "   -0.014388382,\n",
              "   -0.023523154,\n",
              "   0.005966652,\n",
              "   -0.1663422,\n",
              "   -0.09880361,\n",
              "   -0.038313646,\n",
              "   0.0298446,\n",
              "   -0.0038478738,\n",
              "   -0.10875245,\n",
              "   0.06153647,\n",
              "   -0.012116223,\n",
              "   0.14778717,\n",
              "   0.020383043,\n",
              "   -0.11035961,\n",
              "   -0.040156405,\n",
              "   -0.17879723,\n",
              "   -0.03004666,\n",
              "   0.08414762,\n",
              "   -0.045509193,\n",
              "   0.29620868,\n",
              "   -0.01683816,\n",
              "   0.021150928,\n",
              "   0.74199396,\n",
              "   0.015630068,\n",
              "   0.07946617,\n",
              "   -0.12576985,\n",
              "   0.055667587,\n",
              "   0.8371833,\n",
              "   -0.03692903,\n",
              "   -0.0032048011,\n",
              "   -0.08529894,\n",
              "   0.06810683,\n",
              "   0.049517475,\n",
              "   0.026188366,\n",
              "   -0.059135217,\n",
              "   -0.028786052,\n",
              "   -0.023793295,\n",
              "   -0.077551045,\n",
              "   0.072866365,\n",
              "   -0.013990401,\n",
              "   -0.13994718,\n",
              "   -0.062042523,\n",
              "   0.0745245,\n",
              "   -0.12383017,\n",
              "   -0.13683003,\n",
              "   0.07644513,\n",
              "   1.2297839,\n",
              "   0.04578854,\n",
              "   0.053164367,\n",
              "   0.09812101,\n",
              "   -0.15625454,\n",
              "   -0.074592486,\n",
              "   -0.17312187,\n",
              "   0.015703876,\n",
              "   0.011863323,\n",
              "   -0.07824817,\n",
              "   0.19010709,\n",
              "   -0.115931764,\n",
              "   -0.18228455,\n",
              "   -0.48551464,\n",
              "   0.0038297363,\n",
              "   -0.078155,\n",
              "   -0.05156166,\n",
              "   0.054600477,\n",
              "   0.03861678,\n",
              "   0.054787904,\n",
              "   -0.05194313,\n",
              "   -0.08387293,\n",
              "   0.14838953,\n",
              "   0.018742917,\n",
              "   0.019078795,\n",
              "   -0.0015982738,\n",
              "   -0.060041226,\n",
              "   0.06898157,\n",
              "   -0.029864715,\n",
              "   1.4258276,\n",
              "   -0.11391224,\n",
              "   0.07024713,\n",
              "   -0.040110182,\n",
              "   -0.0969143,\n",
              "   -0.02874364,\n",
              "   0.11071481,\n",
              "   0.10449867,\n",
              "   0.022909982,\n",
              "   -0.089403994,\n",
              "   -0.0077623245,\n",
              "   0.0614853,\n",
              "   0.019920869,\n",
              "   -0.15042134,\n",
              "   0.016786007,\n",
              "   -0.006524481,\n",
              "   0.11372229,\n",
              "   0.04620498,\n",
              "   0.08334258,\n",
              "   -0.052977104,\n",
              "   0.08026742,\n",
              "   0.039518878,\n",
              "   -1.0618662,\n",
              "   0.019890059,\n",
              "   0.0072280583,\n",
              "   0.09294957,\n",
              "   0.0981094,\n",
              "   -0.044882074,\n",
              "   0.11471429,\n",
              "   0.032623775,\n",
              "   -0.06155543,\n",
              "   0.00012591195,\n",
              "   0.02074396,\n",
              "   -0.062221047,\n",
              "   -0.018479297,\n",
              "   -0.10038288,\n",
              "   0.09150893,\n",
              "   -0.10319743,\n",
              "   0.029118687,\n",
              "   0.025034983,\n",
              "   -0.01854371,\n",
              "   0.033664804,\n",
              "   -0.053581953,\n",
              "   -0.039073385,\n",
              "   -0.22787961,\n",
              "   -0.07764185,\n",
              "   0.040375993,\n",
              "   -0.01471208,\n",
              "   0.14779688,\n",
              "   -0.005392525,\n",
              "   0.0005861717,\n",
              "   0.04044337,\n",
              "   0.096546635,\n",
              "   0.014142449,\n",
              "   0.04789666,\n",
              "   -0.03907239,\n",
              "   0.070082486,\n",
              "   0.2495773,\n",
              "   -0.016700419,\n",
              "   -0.105708055,\n",
              "   -0.066722214,\n",
              "   0.049546357,\n",
              "   -0.5191245,\n",
              "   0.023336533,\n",
              "   -0.87424254,\n",
              "   0.5285439,\n",
              "   -0.10117667,\n",
              "   0.1318564,\n",
              "   -0.11059374,\n",
              "   -0.014648769,\n",
              "   0.14928307,\n",
              "   -0.08324422,\n",
              "   0.0027673598,\n",
              "   0.0026318692,\n",
              "   0.06788786,\n",
              "   -0.26764,\n",
              "   0.088762574,\n",
              "   -0.008484324,\n",
              "   0.04246435,\n",
              "   -0.0499969,\n",
              "   0.05456107,\n",
              "   0.0041988413,\n",
              "   -0.05678072,\n",
              "   -0.11780594,\n",
              "   -0.119684435,\n",
              "   -0.02899867,\n",
              "   0.14367576,\n",
              "   -0.0024740018,\n",
              "   0.05148289,\n",
              "   -0.17685033,\n",
              "   -0.13265467,\n",
              "   0.09071299,\n",
              "   0.026753172,\n",
              "   0.042887583,\n",
              "   0.0411231,\n",
              "   0.108996175,\n",
              "   0.0019496459,\n",
              "   -0.0108221285,\n",
              "   -0.09772105,\n",
              "   0.056311328,\n",
              "   0.34898624,\n",
              "   0.13599135,\n",
              "   0.009863435,\n",
              "   -0.000902329,\n",
              "   -0.06478567,\n",
              "   -0.08224454,\n",
              "   0.0872003,\n",
              "   0.0006483043,\n",
              "   -0.08328254,\n",
              "   -0.041160427,\n",
              "   0.0032224394,\n",
              "   -0.12569338,\n",
              "   -0.037982848,\n",
              "   -0.12251084,\n",
              "   -0.042210784,\n",
              "   0.12545742,\n",
              "   -1.6960658,\n",
              "   -0.027531143,\n",
              "   -0.061372824,\n",
              "   -0.12082669,\n",
              "   -0.15705676,\n",
              "   -0.0832231,\n",
              "   0.14178932,\n",
              "   -0.10515323,\n",
              "   0.053712413,\n",
              "   0.018660063,\n",
              "   0.032540612,\n",
              "   -0.010874442,\n",
              "   0.045439165,\n",
              "   0.09141244,\n",
              "   -0.05985577,\n",
              "   0.224094,\n",
              "   0.020903552,\n",
              "   -0.046956297,\n",
              "   0.01355143,\n",
              "   -0.010583249,\n",
              "   -0.018158058,\n",
              "   -0.06788301,\n",
              "   0.08314104,\n",
              "   -0.018621828,\n",
              "   -0.01595394,\n",
              "   0.068991,\n",
              "   -0.06261966,\n",
              "   -0.0070883934,\n",
              "   -0.0071326876,\n",
              "   0.11021345,\n",
              "   -0.0134643195,\n",
              "   0.06510595,\n",
              "   0.086700626,\n",
              "   -0.0002525903,\n",
              "   -0.10659879,\n",
              "   -0.05019091,\n",
              "   -0.15339758,\n",
              "   0.066310175,\n",
              "   -1.3496937,\n",
              "   -0.09571473,\n",
              "   0.0006650768,\n",
              "   -0.018106902,\n",
              "   0.029740443,\n",
              "   0.06281239,\n",
              "   -0.73045707,\n",
              "   -0.013693566,\n",
              "   -0.033578448,\n",
              "   -0.115258835,\n",
              "   0.059849855,\n",
              "   -0.09260761],\n",
              "  [-0.00022552192,\n",
              "   0.647276,\n",
              "   0.062416308,\n",
              "   -0.15132031,\n",
              "   -0.2163895,\n",
              "   0.5073022,\n",
              "   0.089424685,\n",
              "   -0.16217431,\n",
              "   0.1989929,\n",
              "   -0.40119544,\n",
              "   0.4430458,\n",
              "   0.9386963,\n",
              "   0.8507782,\n",
              "   0.1362373,\n",
              "   0.13774823,\n",
              "   0.025676077,\n",
              "   1.2654629,\n",
              "   0.24303173,\n",
              "   0.3917366,\n",
              "   0.6946369,\n",
              "   -0.044943456,\n",
              "   0.14713243,\n",
              "   0.95415556,\n",
              "   0.30990797,\n",
              "   -0.08812207,\n",
              "   -0.09819583,\n",
              "   -0.011619181,\n",
              "   -0.6257317,\n",
              "   -0.024230853,\n",
              "   0.003692643,\n",
              "   -0.053658083,\n",
              "   -0.098747596,\n",
              "   0.2170667,\n",
              "   0.17643568,\n",
              "   0.45836225,\n",
              "   0.40683693,\n",
              "   -0.018279374,\n",
              "   -0.053633254,\n",
              "   0.33560017,\n",
              "   0.084271744,\n",
              "   -0.33120435,\n",
              "   0.033149485,\n",
              "   0.04833696,\n",
              "   -0.15471199,\n",
              "   0.71157664,\n",
              "   0.31806174,\n",
              "   -0.026827285,\n",
              "   -0.27805245,\n",
              "   0.10567466,\n",
              "   0.0020128952,\n",
              "   0.10093945,\n",
              "   -0.38280296,\n",
              "   -0.04307174,\n",
              "   0.22875404,\n",
              "   -0.086237065,\n",
              "   -0.5241643,\n",
              "   0.07407738,\n",
              "   -0.006779033,\n",
              "   0.5517288,\n",
              "   0.022598298,\n",
              "   -0.6193161,\n",
              "   0.02164792,\n",
              "   -1.0938514,\n",
              "   -0.12747465,\n",
              "   0.12070119,\n",
              "   -0.27290258,\n",
              "   0.09911752,\n",
              "   0.17902969,\n",
              "   0.19857374,\n",
              "   0.080962695,\n",
              "   0.016374813,\n",
              "   -0.6158096,\n",
              "   0.16661675,\n",
              "   -0.08936338,\n",
              "   0.040104445,\n",
              "   0.26260987,\n",
              "   0.083389595,\n",
              "   0.008312939,\n",
              "   -0.15163536,\n",
              "   -0.14859864,\n",
              "   -0.30177954,\n",
              "   0.004963204,\n",
              "   0.20478612,\n",
              "   0.22995277,\n",
              "   -0.060228452,\n",
              "   0.017271215,\n",
              "   0.7254949,\n",
              "   -0.076365,\n",
              "   0.66203517,\n",
              "   -0.51474607,\n",
              "   0.09599237,\n",
              "   -0.19132064,\n",
              "   -0.025580855,\n",
              "   0.1863714,\n",
              "   0.09618933,\n",
              "   -0.20319545,\n",
              "   0.042316735,\n",
              "   0.16446245,\n",
              "   -0.1657894,\n",
              "   -0.20526668,\n",
              "   0.120214075,\n",
              "   0.55538327,\n",
              "   -0.04587661,\n",
              "   0.13281831,\n",
              "   0.08545526,\n",
              "   0.46161127,\n",
              "   0.14963576,\n",
              "   -0.448623,\n",
              "   -0.26927748,\n",
              "   -0.003980944,\n",
              "   0.025921337,\n",
              "   0.19956194,\n",
              "   -0.686911,\n",
              "   0.2624588,\n",
              "   0.015050103,\n",
              "   0.13314454,\n",
              "   0.27435258,\n",
              "   0.34220013,\n",
              "   -0.77380675,\n",
              "   -0.07062142,\n",
              "   0.522955,\n",
              "   0.50186557,\n",
              "   0.0034225408,\n",
              "   -1.4316059,\n",
              "   -0.22019349,\n",
              "   0.11335911,\n",
              "   0.06323678,\n",
              "   -0.01965616,\n",
              "   0.12288352,\n",
              "   -1.1383983,\n",
              "   0.94416374,\n",
              "   0.034078073,\n",
              "   -0.15032707,\n",
              "   -0.3267679,\n",
              "   0.283613,\n",
              "   -0.25732124,\n",
              "   0.74599004,\n",
              "   0.56843466,\n",
              "   -0.0069510066,\n",
              "   -0.36926416,\n",
              "   -0.09063699,\n",
              "   -0.54193515,\n",
              "   0.34965968,\n",
              "   -0.10707242,\n",
              "   0.022654809,\n",
              "   -0.016327025,\n",
              "   -0.13079649,\n",
              "   0.26829362,\n",
              "   0.054121077,\n",
              "   0.14530209,\n",
              "   -0.0102292,\n",
              "   0.054530773,\n",
              "   -0.029787341,\n",
              "   -0.6057776,\n",
              "   0.002163279,\n",
              "   0.075100444,\n",
              "   0.002225395,\n",
              "   0.082401834,\n",
              "   0.015282153,\n",
              "   -0.21729314,\n",
              "   0.12920445,\n",
              "   0.4922411,\n",
              "   -0.9576851,\n",
              "   0.10604191,\n",
              "   -0.2637859,\n",
              "   -0.058335483,\n",
              "   -0.49509922,\n",
              "   -0.209462,\n",
              "   -0.28686082,\n",
              "   -0.10802614,\n",
              "   -0.0143052135,\n",
              "   0.19296129,\n",
              "   -0.7924533,\n",
              "   0.09300165,\n",
              "   0.16263224,\n",
              "   -0.18098146,\n",
              "   0.113007486,\n",
              "   -0.058551848,\n",
              "   0.26728904,\n",
              "   0.06613522,\n",
              "   0.5873903,\n",
              "   -0.30870408,\n",
              "   -0.12230686,\n",
              "   -0.2660772,\n",
              "   0.62043417,\n",
              "   0.832626,\n",
              "   -0.27248982,\n",
              "   -0.067729324,\n",
              "   0.2665853,\n",
              "   -0.14408556,\n",
              "   0.09645011,\n",
              "   -0.04386632,\n",
              "   0.019075856,\n",
              "   0.10173101,\n",
              "   0.006811345,\n",
              "   0.061339397,\n",
              "   -0.4455904,\n",
              "   0.65666527,\n",
              "   -0.27111834,\n",
              "   0.06277074,\n",
              "   -0.29437524,\n",
              "   -0.05740449,\n",
              "   -0.64903826,\n",
              "   0.28198215,\n",
              "   0.051379036,\n",
              "   -0.051730897,\n",
              "   0.1101464,\n",
              "   0.4865899,\n",
              "   0.10079866,\n",
              "   0.16966861,\n",
              "   0.19071245,\n",
              "   0.122138776,\n",
              "   1.1781332,\n",
              "   -0.028714791,\n",
              "   -0.8850775,\n",
              "   0.089419685,\n",
              "   0.04106486,\n",
              "   -0.2942627,\n",
              "   0.20474638,\n",
              "   0.042782333,\n",
              "   0.087149784,\n",
              "   0.0023550699,\n",
              "   0.39270896,\n",
              "   -0.00892449,\n",
              "   0.0097331805,\n",
              "   -0.07020744,\n",
              "   1.6705334,\n",
              "   0.69002944,\n",
              "   -0.008789532,\n",
              "   -0.46021888,\n",
              "   0.21248777,\n",
              "   0.05239578,\n",
              "   0.76000786,\n",
              "   -0.055014692,\n",
              "   0.17850214,\n",
              "   0.26516035,\n",
              "   1.1744108,\n",
              "   -0.12346742,\n",
              "   -0.09018677,\n",
              "   -0.15210532,\n",
              "   -0.23600173,\n",
              "   -1.4337547,\n",
              "   0.20588824,\n",
              "   0.9716288,\n",
              "   0.2618084,\n",
              "   0.08333156,\n",
              "   -0.17273106,\n",
              "   0.10664581,\n",
              "   0.5823336,\n",
              "   0.10920711,\n",
              "   -0.0047804904,\n",
              "   0.15881915,\n",
              "   0.020750338,\n",
              "   0.08850843,\n",
              "   -0.25128162,\n",
              "   -0.027612748,\n",
              "   -0.15424176,\n",
              "   -0.10132377,\n",
              "   -0.0023422672,\n",
              "   -0.2722077,\n",
              "   -1.3925648,\n",
              "   -0.041350838,\n",
              "   -0.017836895,\n",
              "   0.05249515,\n",
              "   -0.4748822,\n",
              "   0.3433412,\n",
              "   0.0177577,\n",
              "   -0.4555807,\n",
              "   0.016913187,\n",
              "   0.093677975,\n",
              "   0.022636611,\n",
              "   -0.32408327,\n",
              "   -0.56768745,\n",
              "   0.15921068,\n",
              "   0.14626475,\n",
              "   0.11375373,\n",
              "   0.4382459,\n",
              "   -0.21958771,\n",
              "   -0.009967081,\n",
              "   0.0102251815,\n",
              "   0.751476,\n",
              "   0.06800384,\n",
              "   0.052923385,\n",
              "   -0.20357242,\n",
              "   0.78763986,\n",
              "   0.15059492,\n",
              "   -1.1666656,\n",
              "   -0.6355193,\n",
              "   -0.9537889,\n",
              "   0.13814752,\n",
              "   -0.1402825,\n",
              "   0.3431527,\n",
              "   0.26414853,\n",
              "   -0.72234344,\n",
              "   0.024978854,\n",
              "   0.059027568,\n",
              "   -0.12785971,\n",
              "   1.0183456,\n",
              "   1.0146984,\n",
              "   0.0982538]],\n",
              " [6, 3, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 227
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_embeddings[0][0] # primeira sentença: embeddings das palavras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf94j9L6hkX1",
        "outputId": "752c2009-adc7-4b70-a0ce-e82c72382933"
      },
      "id": "vf94j9L6hkX1",
      "execution_count": 228,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0.06372718,\n",
              "  1.081287,\n",
              "  -0.2566062,\n",
              "  0.35581657,\n",
              "  0.20967016,\n",
              "  -0.36711636,\n",
              "  0.366946,\n",
              "  -0.3230368,\n",
              "  -0.34950674,\n",
              "  0.4455702,\n",
              "  -0.7013678,\n",
              "  0.20763332,\n",
              "  0.7158997,\n",
              "  0.07245133,\n",
              "  0.05840904,\n",
              "  1.7177013,\n",
              "  1.2872624,\n",
              "  0.007037018,\n",
              "  -0.36843827,\n",
              "  0.30398393,\n",
              "  1.9073563,\n",
              "  0.046871826,\n",
              "  0.362007,\n",
              "  0.19549051,\n",
              "  -0.055350173,\n",
              "  -0.018726848,\n",
              "  -0.70453614,\n",
              "  0.5320796,\n",
              "  0.21127453,\n",
              "  1.4585506,\n",
              "  0.15391096,\n",
              "  -0.99725866,\n",
              "  0.109845065,\n",
              "  -0.020156017,\n",
              "  0.96515375,\n",
              "  1.9662554,\n",
              "  0.8686647,\n",
              "  0.0358276,\n",
              "  0.13300346,\n",
              "  0.0016626305,\n",
              "  0.2117124,\n",
              "  -0.42018014,\n",
              "  0.069936104,\n",
              "  -0.3920737,\n",
              "  0.6753673,\n",
              "  0.28072768,\n",
              "  0.38520417,\n",
              "  -0.23346636,\n",
              "  -0.09435507,\n",
              "  -0.08085937,\n",
              "  -0.007921909,\n",
              "  -0.049984373,\n",
              "  1.0996103,\n",
              "  -0.12756191,\n",
              "  -0.57305413,\n",
              "  -0.0906943,\n",
              "  -0.18224198,\n",
              "  -0.71684444,\n",
              "  0.30599272,\n",
              "  -0.9337199,\n",
              "  -0.3402406,\n",
              "  0.08233886,\n",
              "  -0.12936674,\n",
              "  -0.048676677,\n",
              "  -1.148141,\n",
              "  -0.265937,\n",
              "  0.14547049,\n",
              "  0.20106123,\n",
              "  0.7871115,\n",
              "  0.0467316,\n",
              "  0.37001476,\n",
              "  0.25859573,\n",
              "  -0.1932874,\n",
              "  0.15227121,\n",
              "  -0.9664524,\n",
              "  -0.9591928,\n",
              "  -0.7624523,\n",
              "  -0.07831785,\n",
              "  0.26224315,\n",
              "  -0.9360457,\n",
              "  -0.6024347,\n",
              "  -0.100979745,\n",
              "  0.0090000685,\n",
              "  -0.7707501,\n",
              "  0.075180456,\n",
              "  -0.7947064,\n",
              "  -0.2816814,\n",
              "  0.48935875,\n",
              "  0.08751537,\n",
              "  -0.8001722,\n",
              "  -0.36688596,\n",
              "  0.37152243,\n",
              "  -0.1771037,\n",
              "  -0.36373323,\n",
              "  -0.50271946,\n",
              "  -0.28352714,\n",
              "  -1.0547155,\n",
              "  0.75629294,\n",
              "  -0.933083,\n",
              "  -0.12812622,\n",
              "  -0.011600916,\n",
              "  0.8967122,\n",
              "  -1.1458066,\n",
              "  0.16362725,\n",
              "  0.3683528,\n",
              "  1.4188989,\n",
              "  -0.60400814,\n",
              "  0.031383496,\n",
              "  0.23712853,\n",
              "  0.85988116,\n",
              "  0.23687339,\n",
              "  0.87570107,\n",
              "  -0.12749588,\n",
              "  -0.5388552,\n",
              "  -0.020999411,\n",
              "  0.29103607,\n",
              "  -0.9802869,\n",
              "  1.3249602,\n",
              "  -0.24870618,\n",
              "  1.057709,\n",
              "  2.3566551,\n",
              "  -0.19924004,\n",
              "  0.44819525,\n",
              "  0.056492962,\n",
              "  -0.32668144,\n",
              "  -0.36056006,\n",
              "  -0.08794432,\n",
              "  -0.93602175,\n",
              "  -0.34992993,\n",
              "  0.12274587,\n",
              "  -0.10208813,\n",
              "  1.1051462,\n",
              "  -0.31939432,\n",
              "  1.1725352,\n",
              "  -0.12476992,\n",
              "  0.20372844,\n",
              "  -0.22290604,\n",
              "  0.06569898,\n",
              "  -0.31762686,\n",
              "  1.0868597,\n",
              "  -0.090878725,\n",
              "  -0.55399674,\n",
              "  -1.0946723,\n",
              "  0.043481365,\n",
              "  -0.005812096,\n",
              "  -0.2817849,\n",
              "  0.8549238,\n",
              "  0.1669907,\n",
              "  -1.1517125,\n",
              "  0.57864267,\n",
              "  -1.0441968,\n",
              "  0.6754023,\n",
              "  0.061240908,\n",
              "  1.5305414,\n",
              "  -0.8261177,\n",
              "  1.0224041,\n",
              "  0.9249804,\n",
              "  -0.32420865,\n",
              "  -1.4137812,\n",
              "  0.20947477,\n",
              "  -0.29527417,\n",
              "  -0.17414202,\n",
              "  -0.040787656,\n",
              "  -0.2367585,\n",
              "  0.6397661,\n",
              "  -0.057225715,\n",
              "  0.67932934,\n",
              "  -0.32956517,\n",
              "  0.7933583,\n",
              "  -0.19555613,\n",
              "  0.34387615,\n",
              "  0.06265616,\n",
              "  0.07162569,\n",
              "  -0.96173805,\n",
              "  -0.053785387,\n",
              "  0.7778594,\n",
              "  -0.3276487,\n",
              "  -0.917016,\n",
              "  -0.9388664,\n",
              "  0.13197146,\n",
              "  -0.21743894,\n",
              "  0.44010893,\n",
              "  0.54174125,\n",
              "  -0.23716946,\n",
              "  0.09388318,\n",
              "  -0.53589576,\n",
              "  1.001673,\n",
              "  0.25897142,\n",
              "  0.7238234,\n",
              "  0.48884955,\n",
              "  0.18332489,\n",
              "  1.2084366,\n",
              "  0.8020086,\n",
              "  -0.8992238,\n",
              "  0.45900917,\n",
              "  -0.2521107,\n",
              "  0.13744581,\n",
              "  -0.4491561,\n",
              "  -0.9049304,\n",
              "  -0.99047464,\n",
              "  0.21644366,\n",
              "  -0.02021508,\n",
              "  0.00030899062,\n",
              "  1.1382844,\n",
              "  0.06248691,\n",
              "  1.8253031,\n",
              "  0.2165822,\n",
              "  -0.20076434,\n",
              "  -0.07807895,\n",
              "  -0.11972387,\n",
              "  1.0079817,\n",
              "  -0.27834028,\n",
              "  0.50660026,\n",
              "  -0.06464993,\n",
              "  -1.4205974,\n",
              "  -0.111983106,\n",
              "  0.040536087,\n",
              "  -0.10234122,\n",
              "  -0.31079718,\n",
              "  -0.26001686,\n",
              "  0.0034731056,\n",
              "  -0.70629066,\n",
              "  -0.2077131,\n",
              "  -0.16383447,\n",
              "  0.14461604,\n",
              "  0.008636888,\n",
              "  -0.36653537,\n",
              "  0.65722346,\n",
              "  -1.016722,\n",
              "  -0.021882817,\n",
              "  1.1467028,\n",
              "  -0.17828526,\n",
              "  -0.948344,\n",
              "  0.098252095,\n",
              "  0.024464896,\n",
              "  0.2189097,\n",
              "  -0.24392761,\n",
              "  -0.7130577,\n",
              "  0.09524739,\n",
              "  -0.08843837,\n",
              "  -0.8733692,\n",
              "  -0.054664023,\n",
              "  0.00036502426,\n",
              "  0.4452453,\n",
              "  -0.35146424,\n",
              "  0.28400722,\n",
              "  0.03350738,\n",
              "  0.119209446,\n",
              "  -0.7533325,\n",
              "  -0.012024853,\n",
              "  0.2483871,\n",
              "  -0.5152819,\n",
              "  0.40588433,\n",
              "  0.36219853,\n",
              "  -1.1796994,\n",
              "  -0.3848285,\n",
              "  0.016091079,\n",
              "  -0.5517637,\n",
              "  -0.33975077,\n",
              "  1.3582784,\n",
              "  0.17714405,\n",
              "  -0.25497964,\n",
              "  -0.11721627,\n",
              "  0.83445907,\n",
              "  0.011520235,\n",
              "  -0.08571271,\n",
              "  -1.3456805,\n",
              "  -0.15762958,\n",
              "  0.037313636,\n",
              "  -0.21370144,\n",
              "  -0.20689562,\n",
              "  -0.48809084,\n",
              "  0.37793165,\n",
              "  0.40595737,\n",
              "  -0.22252542,\n",
              "  -0.22216909,\n",
              "  0.07363122,\n",
              "  -0.016889513,\n",
              "  -1.9044163,\n",
              "  -0.027313847,\n",
              "  -0.12523548,\n",
              "  0.6096165,\n",
              "  0.9808078,\n",
              "  -0.03436354,\n",
              "  -0.21899608,\n",
              "  -0.17765175,\n",
              "  -0.8830685,\n",
              "  -0.5257147,\n",
              "  -1.4707041,\n",
              "  -0.45082042,\n",
              "  -0.056313418,\n",
              "  0.6656539,\n",
              "  -0.28650385,\n",
              "  -0.98320144,\n",
              "  0.85901,\n",
              "  -0.21829721,\n",
              "  -0.63703984,\n",
              "  0.19372569,\n",
              "  -0.571344,\n",
              "  -0.10763226],\n",
              " [0.05815203,\n",
              "  -0.114808016,\n",
              "  0.21598664,\n",
              "  -0.091081224,\n",
              "  -0.13379069,\n",
              "  -0.031145174,\n",
              "  -0.0751396,\n",
              "  -0.02267536,\n",
              "  -0.5609628,\n",
              "  -0.09331572,\n",
              "  -0.16930725,\n",
              "  0.064811304,\n",
              "  0.07632986,\n",
              "  -0.10635636,\n",
              "  0.11654597,\n",
              "  0.015249734,\n",
              "  0.3332348,\n",
              "  -0.040203318,\n",
              "  -0.056161333,\n",
              "  0.06971202,\n",
              "  0.03803344,\n",
              "  0.0056230687,\n",
              "  -0.08705268,\n",
              "  -0.04138264,\n",
              "  0.17325073,\n",
              "  -0.10644652,\n",
              "  0.18148725,\n",
              "  -0.101971395,\n",
              "  -0.063315175,\n",
              "  -0.039727867,\n",
              "  -0.020333989,\n",
              "  0.16832665,\n",
              "  -0.04368675,\n",
              "  -0.124407046,\n",
              "  -0.045778155,\n",
              "  -0.022390736,\n",
              "  -0.16598459,\n",
              "  0.014571197,\n",
              "  -0.0367724,\n",
              "  -0.08845049,\n",
              "  0.055043943,\n",
              "  0.04780981,\n",
              "  -0.005934156,\n",
              "  0.053470436,\n",
              "  -0.1681836,\n",
              "  -0.24690257,\n",
              "  -0.05668426,\n",
              "  -0.025972975,\n",
              "  0.18716525,\n",
              "  0.07911916,\n",
              "  0.13157076,\n",
              "  -0.0268637,\n",
              "  -1.3067639,\n",
              "  -0.186044,\n",
              "  0.029951839,\n",
              "  -0.044162873,\n",
              "  0.100399405,\n",
              "  -0.35395667,\n",
              "  -0.044144396,\n",
              "  -0.011148631,\n",
              "  -0.09934373,\n",
              "  -0.056935925,\n",
              "  -0.047552194,\n",
              "  0.05219081,\n",
              "  -0.10117077,\n",
              "  0.028700866,\n",
              "  0.021876445,\n",
              "  0.026198786,\n",
              "  0.091476984,\n",
              "  -0.041362606,\n",
              "  -0.11009736,\n",
              "  0.14048193,\n",
              "  0.2916878,\n",
              "  0.06806833,\n",
              "  -0.049543884,\n",
              "  0.024125613,\n",
              "  -0.03010517,\n",
              "  -0.05895033,\n",
              "  0.021106517,\n",
              "  0.036428507,\n",
              "  -0.54165876,\n",
              "  0.06767264,\n",
              "  0.20646626,\n",
              "  -0.051836874,\n",
              "  0.07496069,\n",
              "  -0.076288305,\n",
              "  0.13622811,\n",
              "  -0.090674125,\n",
              "  0.012697146,\n",
              "  0.031194422,\n",
              "  -0.24336109,\n",
              "  -0.40655363,\n",
              "  -0.0432093,\n",
              "  0.012450507,\n",
              "  -0.30582616,\n",
              "  -0.053349994,\n",
              "  -0.04851207,\n",
              "  -0.15268618,\n",
              "  0.051567648,\n",
              "  -0.03584114,\n",
              "  -0.040185794,\n",
              "  -0.09007953,\n",
              "  -0.011267472,\n",
              "  -0.023215381,\n",
              "  0.3727063,\n",
              "  0.17393778,\n",
              "  0.011774387,\n",
              "  -0.09675175,\n",
              "  -0.017591173,\n",
              "  -0.09241216,\n",
              "  -0.0065412247,\n",
              "  0.14058478,\n",
              "  0.0033834747,\n",
              "  -0.07889787,\n",
              "  -0.46479118,\n",
              "  -0.1564571,\n",
              "  -0.00014121117,\n",
              "  0.023678523,\n",
              "  -0.056256358,\n",
              "  -0.03888438,\n",
              "  -0.51288855,\n",
              "  -0.7324658,\n",
              "  0.046602942,\n",
              "  -0.10032542,\n",
              "  -0.17267965,\n",
              "  0.022321926,\n",
              "  -0.02640406,\n",
              "  0.1120463,\n",
              "  0.0622902,\n",
              "  0.12064027,\n",
              "  -0.0165984,\n",
              "  -0.11063854,\n",
              "  -0.1028679,\n",
              "  0.07063889,\n",
              "  0.037413713,\n",
              "  -0.017875327,\n",
              "  -0.06351753,\n",
              "  0.2522428,\n",
              "  -0.9024238,\n",
              "  0.42668477,\n",
              "  0.03607478,\n",
              "  0.023540052,\n",
              "  -0.091611475,\n",
              "  0.054901734,\n",
              "  0.009347188,\n",
              "  -1.243348,\n",
              "  0.114641696,\n",
              "  -0.01941833,\n",
              "  0.08191366,\n",
              "  0.0150264315,\n",
              "  0.026807047,\n",
              "  0.019338869,\n",
              "  0.013214288,\n",
              "  -0.017745543,\n",
              "  -0.19620481,\n",
              "  -0.08811326,\n",
              "  -0.024754021,\n",
              "  0.03114945,\n",
              "  -0.48602095,\n",
              "  0.10580647,\n",
              "  -0.1170586,\n",
              "  0.09302091,\n",
              "  -0.047285557,\n",
              "  -0.08369471,\n",
              "  -0.098185904,\n",
              "  -0.03851085,\n",
              "  -0.08472644,\n",
              "  -0.041002586,\n",
              "  -0.04566867,\n",
              "  0.062416732,\n",
              "  0.09956799,\n",
              "  -0.12460333,\n",
              "  0.062783465,\n",
              "  0.10566039,\n",
              "  -0.05150288,\n",
              "  0.012748025,\n",
              "  0.06637465,\n",
              "  0.018225571,\n",
              "  0.008442214,\n",
              "  -0.08025035,\n",
              "  0.025308875,\n",
              "  -0.09847398,\n",
              "  -0.046995822,\n",
              "  -0.070801005,\n",
              "  0.063467495,\n",
              "  0.0427498,\n",
              "  -0.028591905,\n",
              "  0.19238847,\n",
              "  0.471573,\n",
              "  -0.22802399,\n",
              "  -0.05561176,\n",
              "  0.09733116,\n",
              "  -0.0012502733,\n",
              "  0.052239876,\n",
              "  -0.025210923,\n",
              "  -0.19806324,\n",
              "  0.07048275,\n",
              "  -0.05091278,\n",
              "  0.028358387,\n",
              "  -0.066074625,\n",
              "  0.010988391,\n",
              "  -0.025180656,\n",
              "  0.08456452,\n",
              "  0.060336582,\n",
              "  -0.0059750783,\n",
              "  0.12407906,\n",
              "  -0.10748519,\n",
              "  -0.094989054,\n",
              "  -0.108802706,\n",
              "  0.017148718,\n",
              "  0.14023857,\n",
              "  -0.111436985,\n",
              "  -0.0609363,\n",
              "  0.101000585,\n",
              "  0.012278948,\n",
              "  -0.021069603,\n",
              "  0.0065945666,\n",
              "  -0.036287326,\n",
              "  0.03877131,\n",
              "  -0.07348647,\n",
              "  0.058411688,\n",
              "  -0.024700996,\n",
              "  0.034132555,\n",
              "  -0.030679468,\n",
              "  0.38387832,\n",
              "  0.0018572407,\n",
              "  -0.1232897,\n",
              "  0.023588521,\n",
              "  -0.024974674,\n",
              "  -0.05811162,\n",
              "  -0.018403752,\n",
              "  -0.055151507,\n",
              "  -0.13894163,\n",
              "  -0.6349574,\n",
              "  0.08882477,\n",
              "  0.05390165,\n",
              "  -0.07487335,\n",
              "  -0.08571661,\n",
              "  -0.021094661,\n",
              "  -0.035607025,\n",
              "  0.044739746,\n",
              "  0.005852558,\n",
              "  0.048183944,\n",
              "  -0.0314868,\n",
              "  0.047271907,\n",
              "  0.06147665,\n",
              "  0.003693642,\n",
              "  0.10776407,\n",
              "  -0.0003116588,\n",
              "  0.044355646,\n",
              "  -1.2221926,\n",
              "  0.07934814,\n",
              "  0.14709039,\n",
              "  -0.038859896,\n",
              "  0.005879815,\n",
              "  -0.045793865,\n",
              "  0.14855333,\n",
              "  -0.004985236,\n",
              "  -0.06715267,\n",
              "  0.12960772,\n",
              "  0.038274076,\n",
              "  -0.0135759385,\n",
              "  -0.030614324,\n",
              "  -0.083256535,\n",
              "  -0.13488649,\n",
              "  -0.026638312,\n",
              "  -0.029373508,\n",
              "  0.015263878,\n",
              "  -0.08993665,\n",
              "  -0.053952415,\n",
              "  -0.0012788363,\n",
              "  0.03707814,\n",
              "  0.28610817,\n",
              "  0.6633394,\n",
              "  -0.1566323,\n",
              "  0.07207088,\n",
              "  0.0044255713,\n",
              "  -0.021385375,\n",
              "  -0.060474157,\n",
              "  -0.040602274,\n",
              "  0.23771001,\n",
              "  0.15758651,\n",
              "  0.025424477,\n",
              "  0.081984594,\n",
              "  0.12712367,\n",
              "  0.05902213,\n",
              "  0.065710254,\n",
              "  0.054770842,\n",
              "  -0.03714782,\n",
              "  -0.196217,\n",
              "  0.008796328,\n",
              "  0.08917105,\n",
              "  0.39375985,\n",
              "  0.026331004,\n",
              "  -0.10371756,\n",
              "  -0.12048008,\n",
              "  0.07372835,\n",
              "  0.010880117,\n",
              "  -0.03130895,\n",
              "  0.006825185],\n",
              " [0.004728314,\n",
              "  0.0044931127,\n",
              "  0.058480375,\n",
              "  0.018165987,\n",
              "  -0.02152166,\n",
              "  -0.024178412,\n",
              "  -0.04866216,\n",
              "  -0.0933258,\n",
              "  -0.15685916,\n",
              "  0.03817789,\n",
              "  -0.09773636,\n",
              "  0.058528144,\n",
              "  0.04121861,\n",
              "  -0.0063999416,\n",
              "  0.11522258,\n",
              "  -0.083688594,\n",
              "  0.068421505,\n",
              "  -0.07179895,\n",
              "  -0.11988084,\n",
              "  0.055203456,\n",
              "  0.059428055,\n",
              "  -0.020245751,\n",
              "  -0.1654658,\n",
              "  0.0019307627,\n",
              "  0.009791865,\n",
              "  -0.076827146,\n",
              "  -0.09040131,\n",
              "  -0.0136922775,\n",
              "  0.043065906,\n",
              "  -0.16938949,\n",
              "  0.11786432,\n",
              "  0.034040477,\n",
              "  0.02065905,\n",
              "  -0.3959091,\n",
              "  0.01023775,\n",
              "  -0.05018309,\n",
              "  -0.116853,\n",
              "  0.0231076,\n",
              "  -0.071410924,\n",
              "  0.20275025,\n",
              "  -0.14516099,\n",
              "  0.016310176,\n",
              "  0.021436619,\n",
              "  0.11335171,\n",
              "  0.41598725,\n",
              "  -0.13051225,\n",
              "  0.11926874,\n",
              "  -0.18019235,\n",
              "  -0.09792086,\n",
              "  0.07504947,\n",
              "  0.15265153,\n",
              "  -0.16476382,\n",
              "  0.13086301,\n",
              "  -0.13796644,\n",
              "  -0.03008459,\n",
              "  -0.082035504,\n",
              "  0.019697139,\n",
              "  0.010546359,\n",
              "  -0.13628939,\n",
              "  -0.014388382,\n",
              "  -0.023523154,\n",
              "  0.005966652,\n",
              "  -0.1663422,\n",
              "  -0.09880361,\n",
              "  -0.038313646,\n",
              "  0.0298446,\n",
              "  -0.0038478738,\n",
              "  -0.10875245,\n",
              "  0.06153647,\n",
              "  -0.012116223,\n",
              "  0.14778717,\n",
              "  0.020383043,\n",
              "  -0.11035961,\n",
              "  -0.040156405,\n",
              "  -0.17879723,\n",
              "  -0.03004666,\n",
              "  0.08414762,\n",
              "  -0.045509193,\n",
              "  0.29620868,\n",
              "  -0.01683816,\n",
              "  0.021150928,\n",
              "  0.74199396,\n",
              "  0.015630068,\n",
              "  0.07946617,\n",
              "  -0.12576985,\n",
              "  0.055667587,\n",
              "  0.8371833,\n",
              "  -0.03692903,\n",
              "  -0.0032048011,\n",
              "  -0.08529894,\n",
              "  0.06810683,\n",
              "  0.049517475,\n",
              "  0.026188366,\n",
              "  -0.059135217,\n",
              "  -0.028786052,\n",
              "  -0.023793295,\n",
              "  -0.077551045,\n",
              "  0.072866365,\n",
              "  -0.013990401,\n",
              "  -0.13994718,\n",
              "  -0.062042523,\n",
              "  0.0745245,\n",
              "  -0.12383017,\n",
              "  -0.13683003,\n",
              "  0.07644513,\n",
              "  1.2297839,\n",
              "  0.04578854,\n",
              "  0.053164367,\n",
              "  0.09812101,\n",
              "  -0.15625454,\n",
              "  -0.074592486,\n",
              "  -0.17312187,\n",
              "  0.015703876,\n",
              "  0.011863323,\n",
              "  -0.07824817,\n",
              "  0.19010709,\n",
              "  -0.115931764,\n",
              "  -0.18228455,\n",
              "  -0.48551464,\n",
              "  0.0038297363,\n",
              "  -0.078155,\n",
              "  -0.05156166,\n",
              "  0.054600477,\n",
              "  0.03861678,\n",
              "  0.054787904,\n",
              "  -0.05194313,\n",
              "  -0.08387293,\n",
              "  0.14838953,\n",
              "  0.018742917,\n",
              "  0.019078795,\n",
              "  -0.0015982738,\n",
              "  -0.060041226,\n",
              "  0.06898157,\n",
              "  -0.029864715,\n",
              "  1.4258276,\n",
              "  -0.11391224,\n",
              "  0.07024713,\n",
              "  -0.040110182,\n",
              "  -0.0969143,\n",
              "  -0.02874364,\n",
              "  0.11071481,\n",
              "  0.10449867,\n",
              "  0.022909982,\n",
              "  -0.089403994,\n",
              "  -0.0077623245,\n",
              "  0.0614853,\n",
              "  0.019920869,\n",
              "  -0.15042134,\n",
              "  0.016786007,\n",
              "  -0.006524481,\n",
              "  0.11372229,\n",
              "  0.04620498,\n",
              "  0.08334258,\n",
              "  -0.052977104,\n",
              "  0.08026742,\n",
              "  0.039518878,\n",
              "  -1.0618662,\n",
              "  0.019890059,\n",
              "  0.0072280583,\n",
              "  0.09294957,\n",
              "  0.0981094,\n",
              "  -0.044882074,\n",
              "  0.11471429,\n",
              "  0.032623775,\n",
              "  -0.06155543,\n",
              "  0.00012591195,\n",
              "  0.02074396,\n",
              "  -0.062221047,\n",
              "  -0.018479297,\n",
              "  -0.10038288,\n",
              "  0.09150893,\n",
              "  -0.10319743,\n",
              "  0.029118687,\n",
              "  0.025034983,\n",
              "  -0.01854371,\n",
              "  0.033664804,\n",
              "  -0.053581953,\n",
              "  -0.039073385,\n",
              "  -0.22787961,\n",
              "  -0.07764185,\n",
              "  0.040375993,\n",
              "  -0.01471208,\n",
              "  0.14779688,\n",
              "  -0.005392525,\n",
              "  0.0005861717,\n",
              "  0.04044337,\n",
              "  0.096546635,\n",
              "  0.014142449,\n",
              "  0.04789666,\n",
              "  -0.03907239,\n",
              "  0.070082486,\n",
              "  0.2495773,\n",
              "  -0.016700419,\n",
              "  -0.105708055,\n",
              "  -0.066722214,\n",
              "  0.049546357,\n",
              "  -0.5191245,\n",
              "  0.023336533,\n",
              "  -0.87424254,\n",
              "  0.5285439,\n",
              "  -0.10117667,\n",
              "  0.1318564,\n",
              "  -0.11059374,\n",
              "  -0.014648769,\n",
              "  0.14928307,\n",
              "  -0.08324422,\n",
              "  0.0027673598,\n",
              "  0.0026318692,\n",
              "  0.06788786,\n",
              "  -0.26764,\n",
              "  0.088762574,\n",
              "  -0.008484324,\n",
              "  0.04246435,\n",
              "  -0.0499969,\n",
              "  0.05456107,\n",
              "  0.0041988413,\n",
              "  -0.05678072,\n",
              "  -0.11780594,\n",
              "  -0.119684435,\n",
              "  -0.02899867,\n",
              "  0.14367576,\n",
              "  -0.0024740018,\n",
              "  0.05148289,\n",
              "  -0.17685033,\n",
              "  -0.13265467,\n",
              "  0.09071299,\n",
              "  0.026753172,\n",
              "  0.042887583,\n",
              "  0.0411231,\n",
              "  0.108996175,\n",
              "  0.0019496459,\n",
              "  -0.0108221285,\n",
              "  -0.09772105,\n",
              "  0.056311328,\n",
              "  0.34898624,\n",
              "  0.13599135,\n",
              "  0.009863435,\n",
              "  -0.000902329,\n",
              "  -0.06478567,\n",
              "  -0.08224454,\n",
              "  0.0872003,\n",
              "  0.0006483043,\n",
              "  -0.08328254,\n",
              "  -0.041160427,\n",
              "  0.0032224394,\n",
              "  -0.12569338,\n",
              "  -0.037982848,\n",
              "  -0.12251084,\n",
              "  -0.042210784,\n",
              "  0.12545742,\n",
              "  -1.6960658,\n",
              "  -0.027531143,\n",
              "  -0.061372824,\n",
              "  -0.12082669,\n",
              "  -0.15705676,\n",
              "  -0.0832231,\n",
              "  0.14178932,\n",
              "  -0.10515323,\n",
              "  0.053712413,\n",
              "  0.018660063,\n",
              "  0.032540612,\n",
              "  -0.010874442,\n",
              "  0.045439165,\n",
              "  0.09141244,\n",
              "  -0.05985577,\n",
              "  0.224094,\n",
              "  0.020903552,\n",
              "  -0.046956297,\n",
              "  0.01355143,\n",
              "  -0.010583249,\n",
              "  -0.018158058,\n",
              "  -0.06788301,\n",
              "  0.08314104,\n",
              "  -0.018621828,\n",
              "  -0.01595394,\n",
              "  0.068991,\n",
              "  -0.06261966,\n",
              "  -0.0070883934,\n",
              "  -0.0071326876,\n",
              "  0.11021345,\n",
              "  -0.0134643195,\n",
              "  0.06510595,\n",
              "  0.086700626,\n",
              "  -0.0002525903,\n",
              "  -0.10659879,\n",
              "  -0.05019091,\n",
              "  -0.15339758,\n",
              "  0.066310175,\n",
              "  -1.3496937,\n",
              "  -0.09571473,\n",
              "  0.0006650768,\n",
              "  -0.018106902,\n",
              "  0.029740443,\n",
              "  0.06281239,\n",
              "  -0.73045707,\n",
              "  -0.013693566,\n",
              "  -0.033578448,\n",
              "  -0.115258835,\n",
              "  0.059849855,\n",
              "  -0.09260761],\n",
              " [-0.00022552192,\n",
              "  0.647276,\n",
              "  0.062416308,\n",
              "  -0.15132031,\n",
              "  -0.2163895,\n",
              "  0.5073022,\n",
              "  0.089424685,\n",
              "  -0.16217431,\n",
              "  0.1989929,\n",
              "  -0.40119544,\n",
              "  0.4430458,\n",
              "  0.9386963,\n",
              "  0.8507782,\n",
              "  0.1362373,\n",
              "  0.13774823,\n",
              "  0.025676077,\n",
              "  1.2654629,\n",
              "  0.24303173,\n",
              "  0.3917366,\n",
              "  0.6946369,\n",
              "  -0.044943456,\n",
              "  0.14713243,\n",
              "  0.95415556,\n",
              "  0.30990797,\n",
              "  -0.08812207,\n",
              "  -0.09819583,\n",
              "  -0.011619181,\n",
              "  -0.6257317,\n",
              "  -0.024230853,\n",
              "  0.003692643,\n",
              "  -0.053658083,\n",
              "  -0.098747596,\n",
              "  0.2170667,\n",
              "  0.17643568,\n",
              "  0.45836225,\n",
              "  0.40683693,\n",
              "  -0.018279374,\n",
              "  -0.053633254,\n",
              "  0.33560017,\n",
              "  0.084271744,\n",
              "  -0.33120435,\n",
              "  0.033149485,\n",
              "  0.04833696,\n",
              "  -0.15471199,\n",
              "  0.71157664,\n",
              "  0.31806174,\n",
              "  -0.026827285,\n",
              "  -0.27805245,\n",
              "  0.10567466,\n",
              "  0.0020128952,\n",
              "  0.10093945,\n",
              "  -0.38280296,\n",
              "  -0.04307174,\n",
              "  0.22875404,\n",
              "  -0.086237065,\n",
              "  -0.5241643,\n",
              "  0.07407738,\n",
              "  -0.006779033,\n",
              "  0.5517288,\n",
              "  0.022598298,\n",
              "  -0.6193161,\n",
              "  0.02164792,\n",
              "  -1.0938514,\n",
              "  -0.12747465,\n",
              "  0.12070119,\n",
              "  -0.27290258,\n",
              "  0.09911752,\n",
              "  0.17902969,\n",
              "  0.19857374,\n",
              "  0.080962695,\n",
              "  0.016374813,\n",
              "  -0.6158096,\n",
              "  0.16661675,\n",
              "  -0.08936338,\n",
              "  0.040104445,\n",
              "  0.26260987,\n",
              "  0.083389595,\n",
              "  0.008312939,\n",
              "  -0.15163536,\n",
              "  -0.14859864,\n",
              "  -0.30177954,\n",
              "  0.004963204,\n",
              "  0.20478612,\n",
              "  0.22995277,\n",
              "  -0.060228452,\n",
              "  0.017271215,\n",
              "  0.7254949,\n",
              "  -0.076365,\n",
              "  0.66203517,\n",
              "  -0.51474607,\n",
              "  0.09599237,\n",
              "  -0.19132064,\n",
              "  -0.025580855,\n",
              "  0.1863714,\n",
              "  0.09618933,\n",
              "  -0.20319545,\n",
              "  0.042316735,\n",
              "  0.16446245,\n",
              "  -0.1657894,\n",
              "  -0.20526668,\n",
              "  0.120214075,\n",
              "  0.55538327,\n",
              "  -0.04587661,\n",
              "  0.13281831,\n",
              "  0.08545526,\n",
              "  0.46161127,\n",
              "  0.14963576,\n",
              "  -0.448623,\n",
              "  -0.26927748,\n",
              "  -0.003980944,\n",
              "  0.025921337,\n",
              "  0.19956194,\n",
              "  -0.686911,\n",
              "  0.2624588,\n",
              "  0.015050103,\n",
              "  0.13314454,\n",
              "  0.27435258,\n",
              "  0.34220013,\n",
              "  -0.77380675,\n",
              "  -0.07062142,\n",
              "  0.522955,\n",
              "  0.50186557,\n",
              "  0.0034225408,\n",
              "  -1.4316059,\n",
              "  -0.22019349,\n",
              "  0.11335911,\n",
              "  0.06323678,\n",
              "  -0.01965616,\n",
              "  0.12288352,\n",
              "  -1.1383983,\n",
              "  0.94416374,\n",
              "  0.034078073,\n",
              "  -0.15032707,\n",
              "  -0.3267679,\n",
              "  0.283613,\n",
              "  -0.25732124,\n",
              "  0.74599004,\n",
              "  0.56843466,\n",
              "  -0.0069510066,\n",
              "  -0.36926416,\n",
              "  -0.09063699,\n",
              "  -0.54193515,\n",
              "  0.34965968,\n",
              "  -0.10707242,\n",
              "  0.022654809,\n",
              "  -0.016327025,\n",
              "  -0.13079649,\n",
              "  0.26829362,\n",
              "  0.054121077,\n",
              "  0.14530209,\n",
              "  -0.0102292,\n",
              "  0.054530773,\n",
              "  -0.029787341,\n",
              "  -0.6057776,\n",
              "  0.002163279,\n",
              "  0.075100444,\n",
              "  0.002225395,\n",
              "  0.082401834,\n",
              "  0.015282153,\n",
              "  -0.21729314,\n",
              "  0.12920445,\n",
              "  0.4922411,\n",
              "  -0.9576851,\n",
              "  0.10604191,\n",
              "  -0.2637859,\n",
              "  -0.058335483,\n",
              "  -0.49509922,\n",
              "  -0.209462,\n",
              "  -0.28686082,\n",
              "  -0.10802614,\n",
              "  -0.0143052135,\n",
              "  0.19296129,\n",
              "  -0.7924533,\n",
              "  0.09300165,\n",
              "  0.16263224,\n",
              "  -0.18098146,\n",
              "  0.113007486,\n",
              "  -0.058551848,\n",
              "  0.26728904,\n",
              "  0.06613522,\n",
              "  0.5873903,\n",
              "  -0.30870408,\n",
              "  -0.12230686,\n",
              "  -0.2660772,\n",
              "  0.62043417,\n",
              "  0.832626,\n",
              "  -0.27248982,\n",
              "  -0.067729324,\n",
              "  0.2665853,\n",
              "  -0.14408556,\n",
              "  0.09645011,\n",
              "  -0.04386632,\n",
              "  0.019075856,\n",
              "  0.10173101,\n",
              "  0.006811345,\n",
              "  0.061339397,\n",
              "  -0.4455904,\n",
              "  0.65666527,\n",
              "  -0.27111834,\n",
              "  0.06277074,\n",
              "  -0.29437524,\n",
              "  -0.05740449,\n",
              "  -0.64903826,\n",
              "  0.28198215,\n",
              "  0.051379036,\n",
              "  -0.051730897,\n",
              "  0.1101464,\n",
              "  0.4865899,\n",
              "  0.10079866,\n",
              "  0.16966861,\n",
              "  0.19071245,\n",
              "  0.122138776,\n",
              "  1.1781332,\n",
              "  -0.028714791,\n",
              "  -0.8850775,\n",
              "  0.089419685,\n",
              "  0.04106486,\n",
              "  -0.2942627,\n",
              "  0.20474638,\n",
              "  0.042782333,\n",
              "  0.087149784,\n",
              "  0.0023550699,\n",
              "  0.39270896,\n",
              "  -0.00892449,\n",
              "  0.0097331805,\n",
              "  -0.07020744,\n",
              "  1.6705334,\n",
              "  0.69002944,\n",
              "  -0.008789532,\n",
              "  -0.46021888,\n",
              "  0.21248777,\n",
              "  0.05239578,\n",
              "  0.76000786,\n",
              "  -0.055014692,\n",
              "  0.17850214,\n",
              "  0.26516035,\n",
              "  1.1744108,\n",
              "  -0.12346742,\n",
              "  -0.09018677,\n",
              "  -0.15210532,\n",
              "  -0.23600173,\n",
              "  -1.4337547,\n",
              "  0.20588824,\n",
              "  0.9716288,\n",
              "  0.2618084,\n",
              "  0.08333156,\n",
              "  -0.17273106,\n",
              "  0.10664581,\n",
              "  0.5823336,\n",
              "  0.10920711,\n",
              "  -0.0047804904,\n",
              "  0.15881915,\n",
              "  0.020750338,\n",
              "  0.08850843,\n",
              "  -0.25128162,\n",
              "  -0.027612748,\n",
              "  -0.15424176,\n",
              "  -0.10132377,\n",
              "  -0.0023422672,\n",
              "  -0.2722077,\n",
              "  -1.3925648,\n",
              "  -0.041350838,\n",
              "  -0.017836895,\n",
              "  0.05249515,\n",
              "  -0.4748822,\n",
              "  0.3433412,\n",
              "  0.0177577,\n",
              "  -0.4555807,\n",
              "  0.016913187,\n",
              "  0.093677975,\n",
              "  0.022636611,\n",
              "  -0.32408327,\n",
              "  -0.56768745,\n",
              "  0.15921068,\n",
              "  0.14626475,\n",
              "  0.11375373,\n",
              "  0.4382459,\n",
              "  -0.21958771,\n",
              "  -0.009967081,\n",
              "  0.0102251815,\n",
              "  0.751476,\n",
              "  0.06800384,\n",
              "  0.052923385,\n",
              "  -0.20357242,\n",
              "  0.78763986,\n",
              "  0.15059492,\n",
              "  -1.1666656,\n",
              "  -0.6355193,\n",
              "  -0.9537889,\n",
              "  0.13814752,\n",
              "  -0.1402825,\n",
              "  0.3431527,\n",
              "  0.26414853,\n",
              "  -0.72234344,\n",
              "  0.024978854,\n",
              "  0.059027568,\n",
              "  -0.12785971,\n",
              "  1.0183456,\n",
              "  1.0146984,\n",
              "  0.0982538]]"
            ]
          },
          "metadata": {},
          "execution_count": 228
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_embeddings[0][1] # primeira sentença: pos_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLarLIZ5huAz",
        "outputId": "0b8a11bc-28c5-48b1-ad42-091d0a48e3ad"
      },
      "id": "tLarLIZ5huAz",
      "execution_count": 229,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[6, 3, 2, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = DataLoader(train_dataset_embeddings, batch_size=batch_size, shuffle=True,\n",
        "                         collate_fn=collate_annotations)"
      ],
      "metadata": {
        "id": "62VIYz5lbNTK"
      },
      "id": "62VIYz5lbNTK",
      "execution_count": 230,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ws4Kjzm4bOkv",
        "outputId": "f2ecb579-f0a3-4a1e-c3d3-edca61ecab46"
      },
      "id": "ws4Kjzm4bOkv",
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7f3776fb4650>"
            ]
          },
          "metadata": {},
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for inputs, targets, lengths in data_loader:\n",
        "    if count >= 10: \n",
        "        break;\n",
        "    else:\n",
        "        print( f'inputs.shape: {inputs.shape}' )\n",
        "        print( f'inputs: {inputs}' )\n",
        "        print( f'targets: {targets}' )\n",
        "        print( f'lengths: {lengths}' )\n",
        "\n",
        "    count = count + 1\n",
        "    print('------------------------------------------')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "K7IsfK9DbSV0",
        "outputId": "48f0ebc6-1c1b-4f43-b159-df66625d5865"
      },
      "id": "K7IsfK9DbSV0",
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-232-cadfcfe143dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcount\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-191-5359301a8ae8>\u001b[0m in \u001b[0;36mcollate_annotations\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;31m# Convert to PyTorch variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: not a sequence"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "020c10db-51d4-4bec-8ba7-829d3bf554af",
        "outputId": "239e8b18-f493-4a7c-8ba0-399cea63c95f"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-c1c962e3bd9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m# outputs, _ = model(inputs, lengths=lengths)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# daniel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_vocab_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-37-794f6a198b4d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, lengths, hidden)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Pack before feeding into the RNN.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpack_padded_sequence\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1."
          ]
        }
      ],
      "source": [
        "dev_dataset.token_vocab = train_dataset.token_vocab\n",
        "dev_dataset.pos_vocab = train_dataset.pos_vocab\n",
        "\n",
        "# Hyperparameters / constants.\n",
        "input_vocab_size = len(train_dataset.token_vocab)\n",
        "output_vocab_size = len(train_dataset.pos_vocab)\n",
        "batch_size = 16\n",
        "epochs = 1\n",
        "n_layers = 1\n",
        "\n",
        "# Initialize the model.\n",
        "# model = Tagger(input_vocab_size, output_vocab_size, n_layers)\n",
        "model = Tagger(\n",
        "    input_dim = input_vocab_size,\n",
        "    output_dim = output_vocab_size, \n",
        "    n_layers = n_layers,\n",
        "    embedding_dim = embedding_dim) # daniel\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Loss function weights.\n",
        "weight = torch.ones(output_vocab_size)\n",
        "weight[0] = 0\n",
        "if torch.cuda.is_available():\n",
        "    weight = weight.cuda()\n",
        "    \n",
        "# Initialize loss function and optimizer.\n",
        "loss_function = torch.nn.NLLLoss(weight)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Main training loop.\n",
        "# data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "#                          collate_fn=collate_annotations)\n",
        "# dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False,\n",
        "#                         collate_fn=collate_annotations)\n",
        "data_loader = DataLoader(train_dataset_embeddings, batch_size=batch_size, shuffle=True,\n",
        "                         collate_fn=collate_annotations)\n",
        "dev_loader = DataLoader(dev_dataset_embeddings, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=collate_annotations)\n",
        "\n",
        "losses = []\n",
        "i = 0\n",
        "for epoch in range(epochs):\n",
        "    for inputs, targets, lengths in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        # outputs, _ = model(inputs, lengths=lengths)\n",
        "        outputs, _ = model(inputs[0], lengths=lengths) # daniel\n",
        "\n",
        "        outputs = outputs.view(-1, output_vocab_size)\n",
        "        # print('---------------outputs----------------')\n",
        "        # print(outputs.shape)\n",
        "        # print(outputs)\n",
        "        targets = targets.view(-1)\n",
        "        # print('---------------targets----------------')\n",
        "        # print(targets.shape)\n",
        "        # print(targets)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #losses.append(loss.data[0])\n",
        "        losses.append(loss.item())\n",
        "        if (i % 10) == 0:\n",
        "            # Compute dev loss over entire dev set.\n",
        "            # NOTE: This is expensive. You may want to only use a \n",
        "            # subset of the dev set.\n",
        "            #print('iteration, ', i)\n",
        "            dev_losses = []\n",
        "            for inputs, targets, lengths in dev_loader:\n",
        "                outputs, _ = model(inputs, lengths=lengths)\n",
        "                outputs = outputs.view(-1, output_vocab_size)\n",
        "                targets = targets.view(-1)\n",
        "                loss = loss_function(outputs, targets)\n",
        "                dev_losses.append(loss.item())\n",
        "            avg_train_loss = np.mean(losses)\n",
        "            avg_dev_loss = np.mean(dev_losses)\n",
        "            losses = []\n",
        "            #print('here')\n",
        "            print('Epoch %i Iteration %i - Train Loss: %0.6f - Dev Loss: %0.6f' % (epoch, i, avg_train_loss, avg_dev_loss), end='\\n')\n",
        "            torch.save(model, 'pos_tagger_gru.pt')\n",
        "        i += 1\n",
        "        \n",
        "torch.save(model, 'pos_tagger_gru.final.pt')"
      ],
      "id": "020c10db-51d4-4bec-8ba7-829d3bf554af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9867b866-0072-47a3-ad07-df9814f8772b"
      },
      "outputs": [],
      "source": [
        "train_dataset[0]"
      ],
      "id": "9867b866-0072-47a3-ad07-df9814f8772b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a09b623b-c4e3-407c-bc08-6052790330af"
      },
      "outputs": [],
      "source": [
        "# Collect the predictions and targets\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for inputs, targets, lengths in dev_loader:\n",
        "    outputs, _ = model(inputs, lengths=lengths)\n",
        "    _, preds = torch.max(outputs, dim=2)\n",
        "    targets = targets.view(-1)\n",
        "    preds = preds.view(-1)\n",
        "    if torch.cuda.is_available():\n",
        "        targets = targets.cpu()\n",
        "        preds = preds.cpu()\n",
        "    y_true.append(targets.data.numpy())\n",
        "    y_pred.append(preds.data.numpy())"
      ],
      "id": "a09b623b-c4e3-407c-bc08-6052790330af"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DV5mFtoOS2c5"
      },
      "outputs": [],
      "source": [
        "# Stack into numpy arrays\n",
        "y_real = np.concatenate(y_true)\n",
        "y_pred = np.concatenate(y_pred)"
      ],
      "id": "DV5mFtoOS2c5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t_CVNM0NDCI"
      },
      "outputs": [],
      "source": [
        "y_real_temp = []\n",
        "for id in y_real:\n",
        "  y_real_temp.append(dev_dataset.pos_vocab._id2word[ id ])\n",
        "y_real = y_real_temp\n",
        "print(y_real)"
      ],
      "id": "0t_CVNM0NDCI"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7WAiFwsXNlnF"
      },
      "outputs": [],
      "source": [
        "y_pred_temp = []\n",
        "for id in y_pred:\n",
        "  y_pred_temp.append(dev_dataset.pos_vocab._id2word[ id ])\n",
        "y_pred = y_pred_temp\n",
        "print(y_pred)"
      ],
      "id": "7WAiFwsXNlnF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bro9h8cNOQKS"
      },
      "outputs": [],
      "source": [
        "len(y_real)"
      ],
      "id": "bro9h8cNOQKS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm8--leMOQNA"
      },
      "outputs": [],
      "source": [
        "len(y_pred)"
      ],
      "id": "fm8--leMOQNA"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mRZIsqWlNlAR"
      },
      "outputs": [],
      "source": [
        "print( classification_report( y_real, y_pred ) )\n",
        "f1 = f1_score( y_real, y_pred, average='weighted' )\n",
        "acc = accuracy_score( y_real, y_pred )\n",
        "print( f'F1: {f1:.2}' )\n",
        "print( f'Accuracy: {acc:.2}' )\n",
        "\n",
        "# # Compute accuracy\n",
        "# acc = np.mean(y_real[y_real != 0] == y_pred[y_real != 0])\n",
        "# print('Accuracy - %0.6f\\n' % acc)\n",
        "\n",
        "# # Evaluate f1-score\n",
        "# from sklearn.metrics import f1_score\n",
        "# score = f1_score(y_real, y_pred, average=None)\n",
        "# print('F1-scores:\\n')\n",
        "# for label, score in zip(dev_dataset.pos_vocab._id2word[1:], score[1:]):\n",
        "#     print('%s - %0.6f' % (label, score))"
      ],
      "id": "mRZIsqWlNlAR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9a8947d2-0903-485f-b525-4e05c75a8263"
      },
      "outputs": [],
      "source": [
        "model = torch.load('pos_tagger_gru.final.pt')\n",
        "\n",
        "def inference(sentence):\n",
        "    # Convert words to id tensor.\n",
        "    ids = [[dataset.token_vocab.word2id(x)] for x in sentence]\n",
        "    ids = Variable(torch.LongTensor(ids))\n",
        "    if torch.cuda.is_available():\n",
        "        ids = ids.cuda()\n",
        "    # Get model output.\n",
        "    output, _ = model(ids)\n",
        "    _, preds = torch.max(output, dim=2)\n",
        "    if torch.cuda.is_available():\n",
        "        preds = preds.cpu()\n",
        "    preds = preds.data.view(-1).numpy()\n",
        "    pos_tags = [dataset.pos_vocab.id2word(x) for x in preds]\n",
        "    for word, tag in zip(sentence, pos_tags):\n",
        "        print('%s - %s' % (word, tag))"
      ],
      "id": "9a8947d2-0903-485f-b525-4e05c75a8263"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2e296101-701e-44eb-8937-ca35eaf8570d"
      },
      "outputs": [],
      "source": [
        "def inference_with_labels(sentence, labels):\n",
        "    #print(sentence)\n",
        "    # Convert words to id tensor.\n",
        "    ids = [[dataset.token_vocab.word2id(x)] for x in sentence]\n",
        "    print(ids)\n",
        "    ids = Variable(torch.LongTensor(ids))\n",
        "    if torch.cuda.is_available():\n",
        "        ids = ids.cuda()\n",
        "    # Get model output.\n",
        "    output, _ = model(ids)\n",
        "    _, preds = torch.max(output, dim=2)\n",
        "    if torch.cuda.is_available():\n",
        "        preds = preds.cpu()\n",
        "    preds = preds.data.view(-1).numpy()\n",
        "    pos_tags = [dataset.pos_vocab.id2word(x) for x in preds]\n",
        "    #labels = [dataset.pos_vocab.id2word(x) for x in labels]\n",
        "    #sentence = [test_dataset.token_vocab.id2word(x) for x in ids]\n",
        "    for word, tag, label in zip(sentence, pos_tags, labels):\n",
        "        print('%s - %s - %s' % (word, tag, label))"
      ],
      "id": "2e296101-701e-44eb-8937-ca35eaf8570d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c1606b1e-fe40-4cbc-a83d-feaf4c929e4a"
      },
      "outputs": [],
      "source": [
        "test_dataset = CoNLLDataset('./datasets/pt_bosque-ud-test.conllu')\n",
        "dataset = CoNLLDataset('./datasets/pt_bosque-ud-train.conllu')\n",
        "\n",
        "sentence, labels = test_dataset[10]\n",
        "sentence = [test_dataset.token_vocab.id2word(x) for x in sentence]\n",
        "print(sentence)\n",
        "labels = [test_dataset.pos_vocab.id2word(x) for x in labels]\n",
        "inference_with_labels(sentence, labels)"
      ],
      "id": "c1606b1e-fe40-4cbc-a83d-feaf4c929e4a"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "tagger_gru_embedding.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
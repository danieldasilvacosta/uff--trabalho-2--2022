{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/drive/', force_remount=True)\n",
        "drive.mount('/content/drive/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5CispoBeMZp",
        "outputId": "8445fce0-2b1f-425a-9c97-990839586f33"
      },
      "id": "D5CispoBeMZp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWsthLm6e8ny",
        "outputId": "71d4a771-299b-4b24-8198-e8ab4986b2c1"
      },
      "id": "GWsthLm6e8ny",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd \"drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llemgM4yeMca",
        "outputId": "2cba4f43-9397-48ff-c4d1-1f4e67f2e104"
      },
      "id": "llemgM4yeMca",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wu8ejWihdQUz",
        "outputId": "5f14f622-23e4-4b1b-be6a-89ce0239018f"
      },
      "id": "Wu8ejWihdQUz",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Doutorado/Disciplinas/[2022.1] [UFF] Processamento de Linguagem Natural - Professora: Aline Marins Paes Carvalho/Trabalhos/Trabalho 2 - POS  e Transfer Learning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ca39af7-84d8-469f-aaf6-f5764501dbdb",
      "metadata": {
        "id": "9ca39af7-84d8-469f-aaf6-f5764501dbdb"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3a53f45d-33b3-4a40-b0e2-674577ca0149",
      "metadata": {
        "id": "3a53f45d-33b3-4a40-b0e2-674577ca0149"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import re\n",
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4beefaac-3b23-4d8a-b2d1-a337eb0e8c33",
      "metadata": {
        "id": "4beefaac-3b23-4d8a-b2d1-a337eb0e8c33"
      },
      "source": [
        "# Vocab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de8dbcfa-a7fe-4393-95c6-ee59e7c0da6a",
      "metadata": {
        "id": "de8dbcfa-a7fe-4393-95c6-ee59e7c0da6a"
      },
      "outputs": [],
      "source": [
        "class Vocab(object):\n",
        "    def __init__(self, iter, max_size=None, sos_token=None, eos_token=None, unk_token=None):\n",
        "        \"\"\"Initialize the vocabulary.\n",
        "        Args:\n",
        "            iter: An iterable which produces sequences of tokens used to update\n",
        "                the vocabulary.\n",
        "            max_size: (Optional) Maximum number of tokens in the vocabulary.\n",
        "            sos_token: (Optional) Token denoting the start of a sequence.\n",
        "            eos_token: (Optional) Token denoting the end of a sequence.\n",
        "            unk_token: (Optional) Token denoting an unknown element in a\n",
        "                sequence.\n",
        "        \"\"\"\n",
        "        self.max_size = max_size\n",
        "        self.pad_token = '<pad>'\n",
        "        self.sos_token = sos_token\n",
        "        self.eos_token = eos_token\n",
        "        self.unk_token = unk_token\n",
        "\n",
        "        # Add special tokens.\n",
        "        id2word = [self.pad_token]\n",
        "        if sos_token is not None:\n",
        "            id2word.append(self.sos_token)\n",
        "        if eos_token is not None:\n",
        "            id2word.append(self.eos_token)\n",
        "        if unk_token is not None:\n",
        "            id2word.append(self.unk_token)\n",
        "\n",
        "        # Update counter with token counts.\n",
        "        counter = Counter()\n",
        "        for x in iter:\n",
        "            counter.update(x)\n",
        "\n",
        "        # Extract lookup tables.\n",
        "        if max_size is not None:\n",
        "            counts = counter.most_common(max_size)\n",
        "        else:\n",
        "            counts = counter.items()\n",
        "            counts = sorted(counts, key=lambda x: x[1], reverse=True)\n",
        "        words = [x[0] for x in counts]\n",
        "        id2word.extend(words)\n",
        "        word2id = {x: i for i, x in enumerate(id2word)}\n",
        "\n",
        "        self._id2word = id2word\n",
        "        self._word2id = word2id\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self._id2word)\n",
        "\n",
        "    def word2id(self, word):\n",
        "        \"\"\"Map a word in the vocabulary to its unique integer id.\n",
        "        Args:\n",
        "            word: Word to lookup.\n",
        "        Returns:\n",
        "            id: The integer id of the word being looked up.\n",
        "        \"\"\"\n",
        "        if word in self._word2id:\n",
        "            return self._word2id[word]\n",
        "        elif self.unk_token is not None:\n",
        "            return self._word2id[self.unk_token]\n",
        "        else:\n",
        "            raise KeyError('Word \"%s\" not in vocabulary.' % word)\n",
        "\n",
        "    def id2word(self, id):\n",
        "        \"\"\"Map an integer id to its corresponding word in the vocabulary.\n",
        "        Args:\n",
        "            id: Integer id of the word being looked up.\n",
        "        Returns:\n",
        "            word: The corresponding word.\n",
        "        \"\"\"\n",
        "        return self._id2word[id]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e94ad8b-ff9e-4d97-be37-2fad7f172072",
      "metadata": {
        "id": "0e94ad8b-ff9e-4d97-be37-2fad7f172072"
      },
      "source": [
        "# CoNLLDataset e Annotation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ef8512e-d6b2-4e96-a9c8-7fcb464af35c",
      "metadata": {
        "id": "5ef8512e-d6b2-4e96-a9c8-7fcb464af35c"
      },
      "outputs": [],
      "source": [
        "class Annotation(object):\n",
        "    def __init__(self):\n",
        "        \"\"\"A helper object for storing annotation data.\"\"\"\n",
        "        self.tokens = []\n",
        "        self.pos_tags = []\n",
        "\n",
        "\n",
        "class CoNLLDataset(Dataset):\n",
        "    def __init__(self, fname, max_exs=None):\n",
        "        \"\"\"Initializes the CoNLLDataset.\n",
        "        Args:\n",
        "            fname: The .conllu file to load data from.\n",
        "        \"\"\"\n",
        "        self.fname = fname\n",
        "        self.annotations = self.process_conll_file(fname, max_exs)\n",
        "        self.token_vocab = Vocab([x.tokens for x in self.annotations],\n",
        "                                 unk_token='<unk>')\n",
        "        self.pos_vocab = Vocab([x.pos_tags for x in self.annotations])\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        annotation = self.annotations[idx]\n",
        "        input = [self.token_vocab.word2id(x) for x in annotation.tokens]\n",
        "        target = [self.pos_vocab.word2id(x) for x in annotation.pos_tags]\n",
        "        return input, target\n",
        "\n",
        "    def process_conll_file(self, fname, max_exs):\n",
        "        # Read the entire file.\n",
        "        with open(fname, 'r') as f:\n",
        "            raw_text = f.read()\n",
        "        # Split into chunks on blank lines.\n",
        "        chunks = re.split(r'^\\n', raw_text, flags=re.MULTILINE)\n",
        "        #print(chunks)\n",
        "        # Process each chunk into an annotation.\n",
        "        annotations = []\n",
        "        exs = 0\n",
        "        for chunk in chunks:\n",
        "            if not max_exs or exs < max_exs:\n",
        "                annotation = Annotation()\n",
        "                lines = chunk.split('\\n')\n",
        "                # Iterate over all lines in the chunk.\n",
        "                for line in lines:\n",
        "                    # If line is empty ignore it.\n",
        "                    if len(line)==0:\n",
        "                        continue\n",
        "                    # If line is a commend ignore it.\n",
        "                    if line[0] == '#':\n",
        "                        continue\n",
        "                    # Otherwise split on tabs and retrieve the token and the\n",
        "                    # POS tag fields.\n",
        "                    fields = line.split('\\t')\n",
        "                    annotation.tokens.append(fields[1])\n",
        "                    annotation.pos_tags.append(fields[3])\n",
        "                if (len(annotation.tokens) > 0) and (len(annotation.pos_tags) > 0):\n",
        "                    annotations.append(annotation)\n",
        "            exs += 1\n",
        "        return annotations"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e5907be-6c34-4e65-b922-9e814b771922",
      "metadata": {
        "id": "1e5907be-6c34-4e65-b922-9e814b771922"
      },
      "source": [
        "# Funções: pad() e collate_annotations()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "22bfb3a3-52e1-4c2c-8563-723e15182391",
      "metadata": {
        "id": "22bfb3a3-52e1-4c2c-8563-723e15182391"
      },
      "outputs": [],
      "source": [
        "def pad(sequences, max_length, pad_value=0):\n",
        "    \"\"\"Pads a list of sequences.\n",
        "    Args:\n",
        "        sequences: A list of sequences to be padded.\n",
        "        max_length: The length to pad to.\n",
        "        pad_value: The value used for padding.\n",
        "    Returns:\n",
        "        A list of padded sequences.\n",
        "    \"\"\"\n",
        "    out = []\n",
        "    for sequence in sequences:\n",
        "        padded = sequence + [0]*(max_length - len(sequence))\n",
        "        out.append(padded)\n",
        "    return out\n",
        "\n",
        "\n",
        "def collate_annotations(batch):\n",
        "    \"\"\"Function used to collate data returned by CoNLLDataset.\"\"\"\n",
        "    # Get inputs, targets, and lengths.\n",
        "    inputs, targets = zip(*batch)\n",
        "    lengths = [len(x) for x in inputs]\n",
        "    # Sort by length.\n",
        "    sort = sorted(zip(inputs, targets, lengths),\n",
        "                  key=lambda x: x[2],\n",
        "                  reverse=True)\n",
        "    inputs, targets, lengths = zip(*sort)\n",
        "    # Pad.\n",
        "    max_length = max(lengths)\n",
        "    inputs = pad(inputs, max_length)\n",
        "    targets = pad(targets, max_length)\n",
        "    # Transpose.\n",
        "    inputs = list(map(list, zip(*inputs)))\n",
        "    targets = list(map(list, zip(*targets)))\n",
        "    # Convert to PyTorch variables.\n",
        "    inputs = Variable(torch.LongTensor(inputs))\n",
        "    targets = Variable(torch.LongTensor(targets))\n",
        "    lengths = Variable(torch.LongTensor(lengths))\n",
        "    if torch.cuda.is_available():\n",
        "        inputs = inputs.cuda()\n",
        "        targets = targets.cuda()\n",
        "        lengths = lengths.cuda()\n",
        "    return inputs, targets, lengths"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cdecfc14-2652-47be-895b-3a89b6e65db9",
      "metadata": {
        "id": "cdecfc14-2652-47be-895b-3a89b6e65db9"
      },
      "source": [
        "# Tagger - GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e09b9f91-6d8c-40b7-b21b-e8838c66e419",
      "metadata": {
        "id": "e09b9f91-6d8c-40b7-b21b-e8838c66e419"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch import nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class Tagger(nn.Module):\n",
        "    def __init__(self,\n",
        "                 input_dim,\n",
        "                 output_dim,\n",
        "                 n_layers, \n",
        "                 embedding_dim=64,\n",
        "                 hidden_dim=64,\n",
        "                 dropout=0.5,\n",
        "                 bidirectional=True,\n",
        "                 pad_idx=0):\n",
        "        \"\"\"Initializes the tagger.\n",
        "        \n",
        "        Args:\n",
        "            input_dim: Size of the input vocabulary, projection\n",
        "            output_dim: Size of the output vocabulary.\n",
        "            embedding_dim: Dimension of the word embeddings.\n",
        "            hidden_dim: Number of units in each LSTM hidden layer.\n",
        "            bidirectional: Whether or not to use a bidirectional rnn.\n",
        "        \"\"\"\n",
        "        super(Tagger, self).__init__()\n",
        "\n",
        "        # Store parameters\n",
        "        self.input_dim = input_dim \n",
        "        self.output_dim = output_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.bidirectional = bidirectional\n",
        "          \n",
        "        # Define layers\n",
        "        self.word_embeddings = nn.Embedding(input_dim, embedding_dim, padding_idx=pad_idx)\n",
        "        self.rnn = nn.GRU(embedding_dim, hidden_dim, num_layers = n_layers, \n",
        "                          bidirectional=bidirectional,\n",
        "                          dropout = dropout if n_layers > 1 else 0)\n",
        "        \n",
        "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n",
        "        self.activation = nn.LogSoftmax(dim=2)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, lengths=None, hidden=None):\n",
        "        \"\"\"Computes a forward pass of the language model.\n",
        "        \n",
        "        Args:\n",
        "            x: A LongTensor w/ dimension [seq_len, batch_size].\n",
        "            lengths: The lengths of the sequences in x.\n",
        "            hidden: Hidden state to be fed into the lstm.\n",
        "            \n",
        "        Returns:\n",
        "            net: Probability of the next word in the sequence.\n",
        "            hidden: Hidden state of the lstm.\n",
        "        \"\"\"\n",
        "        seq_len, batch_size = x.size()\n",
        "        \n",
        "        # If no hidden state is provided, then default to zeros.\n",
        "        if hidden is None:\n",
        "            if self.bidirectional:\n",
        "                num_directions = 2\n",
        "            else:\n",
        "                num_directions = 1\n",
        "            hidden = Variable(torch.zeros(num_directions, batch_size, self.hidden_dim))\n",
        "            if torch.cuda.is_available():\n",
        "                hidden = hidden.cuda()\n",
        "\n",
        "        net = self.word_embeddings(x)\n",
        "        # Pack before feeding into the RNN.\n",
        "        if lengths is not None:\n",
        "            lengths = lengths.data.view(-1).tolist()\n",
        "            net = pack_padded_sequence(net, lengths)\n",
        "        net, hidden = self.rnn(net, hidden)\n",
        "        # Unpack after\n",
        "        if lengths is not None:\n",
        "            net, _ = pad_packed_sequence(net)\n",
        "        net = self.fc(net)\n",
        "        net = self.activation(net)\n",
        "\n",
        "        return net, hidden"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66d0c518-c0a6-42bb-bf88-c37e55c0fbd9",
      "metadata": {
        "id": "66d0c518-c0a6-42bb-bf88-c37e55c0fbd9"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datasets.\n",
        "train_dataset = CoNLLDataset('./datasets/pt_bosque-ud-train.conllu', 4096)\n",
        "dev_dataset = CoNLLDataset('./datasets/pt_bosque-ud-dev.conllu', 1024)"
      ],
      "metadata": {
        "id": "-OOL4u89gfz6"
      },
      "id": "-OOL4u89gfz6",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GJWyZeCsgktu",
        "outputId": "e756c364-593d-46a9-b3be-8b8588b6a877"
      },
      "id": "GJWyZeCsgktu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([235, 19, 7, 5, 75], [6, 7, 3, 2, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "020c10db-51d4-4bec-8ba7-829d3bf554af",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "020c10db-51d4-4bec-8ba7-829d3bf554af",
        "outputId": "68bec16d-106d-4455-a16e-6fb45e4d0ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0 Iteration 0 - Train Loss: 2.935179 - Dev Loss: 2.881217\n",
            "Epoch 0 Iteration 10 - Train Loss: 2.748320 - Dev Loss: 2.553126\n",
            "Epoch 0 Iteration 20 - Train Loss: 2.426070 - Dev Loss: 2.230860\n",
            "Epoch 0 Iteration 30 - Train Loss: 2.093996 - Dev Loss: 1.949798\n",
            "Epoch 0 Iteration 40 - Train Loss: 1.912959 - Dev Loss: 1.754233\n",
            "Epoch 0 Iteration 50 - Train Loss: 1.673419 - Dev Loss: 1.588690\n",
            "Epoch 0 Iteration 60 - Train Loss: 1.547591 - Dev Loss: 1.442160\n",
            "Epoch 0 Iteration 70 - Train Loss: 1.431912 - Dev Loss: 1.317898\n",
            "Epoch 0 Iteration 80 - Train Loss: 1.349148 - Dev Loss: 1.222908\n",
            "Epoch 0 Iteration 90 - Train Loss: 1.177587 - Dev Loss: 1.151685\n",
            "Epoch 0 Iteration 100 - Train Loss: 1.160966 - Dev Loss: 1.090873\n",
            "Epoch 0 Iteration 110 - Train Loss: 1.098069 - Dev Loss: 1.041936\n",
            "Epoch 0 Iteration 120 - Train Loss: 1.050191 - Dev Loss: 1.002501\n",
            "Epoch 0 Iteration 130 - Train Loss: 1.039246 - Dev Loss: 0.968839\n",
            "Epoch 0 Iteration 140 - Train Loss: 0.979381 - Dev Loss: 0.940445\n",
            "Epoch 0 Iteration 150 - Train Loss: 0.916975 - Dev Loss: 0.914279\n",
            "Epoch 0 Iteration 160 - Train Loss: 0.957199 - Dev Loss: 0.893816\n",
            "Epoch 0 Iteration 170 - Train Loss: 0.900220 - Dev Loss: 0.873725\n",
            "Epoch 0 Iteration 180 - Train Loss: 0.977199 - Dev Loss: 0.857802\n",
            "Epoch 0 Iteration 190 - Train Loss: 0.906185 - Dev Loss: 0.837277\n",
            "Epoch 0 Iteration 200 - Train Loss: 0.864175 - Dev Loss: 0.823088\n",
            "Epoch 0 Iteration 210 - Train Loss: 0.862835 - Dev Loss: 0.812088\n",
            "Epoch 0 Iteration 220 - Train Loss: 0.800987 - Dev Loss: 0.794184\n",
            "Epoch 0 Iteration 230 - Train Loss: 0.833288 - Dev Loss: 0.780451\n",
            "Epoch 0 Iteration 240 - Train Loss: 0.840672 - Dev Loss: 0.767926\n",
            "Epoch 0 Iteration 250 - Train Loss: 0.784529 - Dev Loss: 0.758364\n",
            "Epoch 1 Iteration 260 - Train Loss: 0.779432 - Dev Loss: 0.750061\n",
            "Epoch 1 Iteration 270 - Train Loss: 0.738420 - Dev Loss: 0.737486\n",
            "Epoch 1 Iteration 280 - Train Loss: 0.748135 - Dev Loss: 0.728834\n",
            "Epoch 1 Iteration 290 - Train Loss: 0.745731 - Dev Loss: 0.726275\n",
            "Epoch 1 Iteration 300 - Train Loss: 0.782657 - Dev Loss: 0.714531\n",
            "Epoch 1 Iteration 310 - Train Loss: 0.711432 - Dev Loss: 0.700886\n",
            "Epoch 1 Iteration 320 - Train Loss: 0.699268 - Dev Loss: 0.694814\n",
            "Epoch 1 Iteration 330 - Train Loss: 0.694310 - Dev Loss: 0.691700\n",
            "Epoch 1 Iteration 340 - Train Loss: 0.722178 - Dev Loss: 0.685460\n",
            "Epoch 1 Iteration 350 - Train Loss: 0.709063 - Dev Loss: 0.676130\n",
            "Epoch 1 Iteration 360 - Train Loss: 0.690438 - Dev Loss: 0.670142\n",
            "Epoch 1 Iteration 370 - Train Loss: 0.665915 - Dev Loss: 0.663406\n",
            "Epoch 1 Iteration 380 - Train Loss: 0.699537 - Dev Loss: 0.653593\n",
            "Epoch 1 Iteration 390 - Train Loss: 0.683711 - Dev Loss: 0.651446\n",
            "Epoch 1 Iteration 400 - Train Loss: 0.661859 - Dev Loss: 0.647952\n",
            "Epoch 1 Iteration 410 - Train Loss: 0.684466 - Dev Loss: 0.642097\n",
            "Epoch 1 Iteration 420 - Train Loss: 0.653187 - Dev Loss: 0.631216\n",
            "Epoch 1 Iteration 430 - Train Loss: 0.656848 - Dev Loss: 0.624328\n",
            "Epoch 1 Iteration 440 - Train Loss: 0.710664 - Dev Loss: 0.621187\n",
            "Epoch 1 Iteration 450 - Train Loss: 0.657409 - Dev Loss: 0.623765\n",
            "Epoch 1 Iteration 460 - Train Loss: 0.671238 - Dev Loss: 0.618470\n",
            "Epoch 1 Iteration 470 - Train Loss: 0.614399 - Dev Loss: 0.607130\n",
            "Epoch 1 Iteration 480 - Train Loss: 0.630761 - Dev Loss: 0.603567\n",
            "Epoch 1 Iteration 490 - Train Loss: 0.634458 - Dev Loss: 0.595821\n",
            "Epoch 1 Iteration 500 - Train Loss: 0.610550 - Dev Loss: 0.588784\n",
            "Epoch 1 Iteration 510 - Train Loss: 0.614923 - Dev Loss: 0.585766\n",
            "Epoch 2 Iteration 520 - Train Loss: 0.586358 - Dev Loss: 0.584961\n",
            "Epoch 2 Iteration 530 - Train Loss: 0.587279 - Dev Loss: 0.577373\n",
            "Epoch 2 Iteration 540 - Train Loss: 0.574210 - Dev Loss: 0.573566\n",
            "Epoch 2 Iteration 550 - Train Loss: 0.552379 - Dev Loss: 0.574593\n",
            "Epoch 2 Iteration 560 - Train Loss: 0.602498 - Dev Loss: 0.572020\n",
            "Epoch 2 Iteration 570 - Train Loss: 0.511577 - Dev Loss: 0.577505\n",
            "Epoch 2 Iteration 580 - Train Loss: 0.527515 - Dev Loss: 0.563158\n",
            "Epoch 2 Iteration 590 - Train Loss: 0.539290 - Dev Loss: 0.556740\n",
            "Epoch 2 Iteration 600 - Train Loss: 0.533005 - Dev Loss: 0.562074\n",
            "Epoch 2 Iteration 610 - Train Loss: 0.573415 - Dev Loss: 0.564913\n",
            "Epoch 2 Iteration 620 - Train Loss: 0.536496 - Dev Loss: 0.557214\n",
            "Epoch 2 Iteration 630 - Train Loss: 0.545913 - Dev Loss: 0.553742\n",
            "Epoch 2 Iteration 640 - Train Loss: 0.528875 - Dev Loss: 0.555348\n",
            "Epoch 2 Iteration 650 - Train Loss: 0.520951 - Dev Loss: 0.543623\n",
            "Epoch 2 Iteration 660 - Train Loss: 0.531320 - Dev Loss: 0.536760\n",
            "Epoch 2 Iteration 670 - Train Loss: 0.532234 - Dev Loss: 0.535429\n",
            "Epoch 2 Iteration 680 - Train Loss: 0.539618 - Dev Loss: 0.541089\n",
            "Epoch 2 Iteration 690 - Train Loss: 0.533877 - Dev Loss: 0.525465\n",
            "Epoch 2 Iteration 700 - Train Loss: 0.486538 - Dev Loss: 0.522141\n",
            "Epoch 2 Iteration 710 - Train Loss: 0.504706 - Dev Loss: 0.520549\n",
            "Epoch 2 Iteration 720 - Train Loss: 0.491941 - Dev Loss: 0.511093\n",
            "Epoch 2 Iteration 730 - Train Loss: 0.574605 - Dev Loss: 0.517351\n",
            "Epoch 2 Iteration 740 - Train Loss: 0.508386 - Dev Loss: 0.507922\n",
            "Epoch 2 Iteration 750 - Train Loss: 0.499882 - Dev Loss: 0.508226\n",
            "Epoch 2 Iteration 760 - Train Loss: 0.509948 - Dev Loss: 0.503165\n",
            "Epoch 3 Iteration 770 - Train Loss: 0.483840 - Dev Loss: 0.510612\n",
            "Epoch 3 Iteration 780 - Train Loss: 0.434082 - Dev Loss: 0.495667\n",
            "Epoch 3 Iteration 790 - Train Loss: 0.457000 - Dev Loss: 0.494005\n",
            "Epoch 3 Iteration 800 - Train Loss: 0.438635 - Dev Loss: 0.501043\n",
            "Epoch 3 Iteration 810 - Train Loss: 0.427464 - Dev Loss: 0.498847\n",
            "Epoch 3 Iteration 820 - Train Loss: 0.478562 - Dev Loss: 0.491490\n",
            "Epoch 3 Iteration 830 - Train Loss: 0.444525 - Dev Loss: 0.487702\n",
            "Epoch 3 Iteration 840 - Train Loss: 0.443112 - Dev Loss: 0.498156\n",
            "Epoch 3 Iteration 850 - Train Loss: 0.462318 - Dev Loss: 0.482377\n",
            "Epoch 3 Iteration 860 - Train Loss: 0.452879 - Dev Loss: 0.493076\n",
            "Epoch 3 Iteration 870 - Train Loss: 0.442520 - Dev Loss: 0.491168\n",
            "Epoch 3 Iteration 880 - Train Loss: 0.439983 - Dev Loss: 0.493009\n",
            "Epoch 3 Iteration 890 - Train Loss: 0.433702 - Dev Loss: 0.483326\n",
            "Epoch 3 Iteration 900 - Train Loss: 0.431724 - Dev Loss: 0.480610\n",
            "Epoch 3 Iteration 910 - Train Loss: 0.428434 - Dev Loss: 0.493232\n",
            "Epoch 3 Iteration 920 - Train Loss: 0.421213 - Dev Loss: 0.497258\n",
            "Epoch 3 Iteration 930 - Train Loss: 0.426448 - Dev Loss: 0.487246\n",
            "Epoch 3 Iteration 940 - Train Loss: 0.429940 - Dev Loss: 0.481401\n",
            "Epoch 3 Iteration 950 - Train Loss: 0.413750 - Dev Loss: 0.481310\n",
            "Epoch 3 Iteration 960 - Train Loss: 0.458130 - Dev Loss: 0.477266\n",
            "Epoch 3 Iteration 970 - Train Loss: 0.432651 - Dev Loss: 0.470780\n",
            "Epoch 3 Iteration 980 - Train Loss: 0.400633 - Dev Loss: 0.475197\n",
            "Epoch 3 Iteration 990 - Train Loss: 0.421171 - Dev Loss: 0.474884\n",
            "Epoch 3 Iteration 1000 - Train Loss: 0.439260 - Dev Loss: 0.465078\n",
            "Epoch 3 Iteration 1010 - Train Loss: 0.408793 - Dev Loss: 0.475772\n",
            "Epoch 3 Iteration 1020 - Train Loss: 0.402657 - Dev Loss: 0.457938\n",
            "Epoch 4 Iteration 1030 - Train Loss: 0.381344 - Dev Loss: 0.449631\n",
            "Epoch 4 Iteration 1040 - Train Loss: 0.378167 - Dev Loss: 0.459497\n",
            "Epoch 4 Iteration 1050 - Train Loss: 0.364494 - Dev Loss: 0.469446\n",
            "Epoch 4 Iteration 1060 - Train Loss: 0.367561 - Dev Loss: 0.455471\n",
            "Epoch 4 Iteration 1070 - Train Loss: 0.351741 - Dev Loss: 0.457214\n",
            "Epoch 4 Iteration 1080 - Train Loss: 0.353996 - Dev Loss: 0.447918\n",
            "Epoch 4 Iteration 1090 - Train Loss: 0.376820 - Dev Loss: 0.453052\n",
            "Epoch 4 Iteration 1100 - Train Loss: 0.337320 - Dev Loss: 0.454485\n",
            "Epoch 4 Iteration 1110 - Train Loss: 0.373983 - Dev Loss: 0.450040\n",
            "Epoch 4 Iteration 1120 - Train Loss: 0.387866 - Dev Loss: 0.471003\n",
            "Epoch 4 Iteration 1130 - Train Loss: 0.373714 - Dev Loss: 0.452642\n",
            "Epoch 4 Iteration 1140 - Train Loss: 0.338691 - Dev Loss: 0.452022\n",
            "Epoch 4 Iteration 1150 - Train Loss: 0.354486 - Dev Loss: 0.455374\n",
            "Epoch 4 Iteration 1160 - Train Loss: 0.328139 - Dev Loss: 0.479065\n",
            "Epoch 4 Iteration 1170 - Train Loss: 0.360117 - Dev Loss: 0.453389\n",
            "Epoch 4 Iteration 1180 - Train Loss: 0.358681 - Dev Loss: 0.469190\n",
            "Epoch 4 Iteration 1190 - Train Loss: 0.365107 - Dev Loss: 0.472471\n",
            "Epoch 4 Iteration 1200 - Train Loss: 0.355711 - Dev Loss: 0.471694\n",
            "Epoch 4 Iteration 1210 - Train Loss: 0.350165 - Dev Loss: 0.458294\n",
            "Epoch 4 Iteration 1220 - Train Loss: 0.366694 - Dev Loss: 0.454017\n",
            "Epoch 4 Iteration 1230 - Train Loss: 0.351419 - Dev Loss: 0.456067\n",
            "Epoch 4 Iteration 1240 - Train Loss: 0.328288 - Dev Loss: 0.436845\n",
            "Epoch 4 Iteration 1250 - Train Loss: 0.345377 - Dev Loss: 0.455180\n",
            "Epoch 4 Iteration 1260 - Train Loss: 0.333913 - Dev Loss: 0.461420\n",
            "Epoch 4 Iteration 1270 - Train Loss: 0.316930 - Dev Loss: 0.445989\n",
            "Epoch 5 Iteration 1280 - Train Loss: 0.340792 - Dev Loss: 0.474629\n",
            "Epoch 5 Iteration 1290 - Train Loss: 0.301166 - Dev Loss: 0.442632\n",
            "Epoch 5 Iteration 1300 - Train Loss: 0.278634 - Dev Loss: 0.443943\n",
            "Epoch 5 Iteration 1310 - Train Loss: 0.332978 - Dev Loss: 0.463391\n",
            "Epoch 5 Iteration 1320 - Train Loss: 0.316730 - Dev Loss: 0.459255\n",
            "Epoch 5 Iteration 1330 - Train Loss: 0.283705 - Dev Loss: 0.459816\n",
            "Epoch 5 Iteration 1340 - Train Loss: 0.272520 - Dev Loss: 0.446401\n",
            "Epoch 5 Iteration 1350 - Train Loss: 0.275106 - Dev Loss: 0.463118\n",
            "Epoch 5 Iteration 1360 - Train Loss: 0.291952 - Dev Loss: 0.440047\n",
            "Epoch 5 Iteration 1370 - Train Loss: 0.276543 - Dev Loss: 0.457387\n",
            "Epoch 5 Iteration 1380 - Train Loss: 0.314517 - Dev Loss: 0.472062\n",
            "Epoch 5 Iteration 1390 - Train Loss: 0.323215 - Dev Loss: 0.443112\n",
            "Epoch 5 Iteration 1400 - Train Loss: 0.300827 - Dev Loss: 0.464621\n",
            "Epoch 5 Iteration 1410 - Train Loss: 0.270052 - Dev Loss: 0.460438\n",
            "Epoch 5 Iteration 1420 - Train Loss: 0.290678 - Dev Loss: 0.444821\n",
            "Epoch 5 Iteration 1430 - Train Loss: 0.299519 - Dev Loss: 0.450868\n",
            "Epoch 5 Iteration 1440 - Train Loss: 0.274211 - Dev Loss: 0.454319\n",
            "Epoch 5 Iteration 1450 - Train Loss: 0.282081 - Dev Loss: 0.442272\n",
            "Epoch 5 Iteration 1460 - Train Loss: 0.303162 - Dev Loss: 0.435989\n",
            "Epoch 5 Iteration 1470 - Train Loss: 0.302632 - Dev Loss: 0.438029\n",
            "Epoch 5 Iteration 1480 - Train Loss: 0.262516 - Dev Loss: 0.445764\n",
            "Epoch 5 Iteration 1490 - Train Loss: 0.299854 - Dev Loss: 0.448677\n",
            "Epoch 5 Iteration 1500 - Train Loss: 0.251995 - Dev Loss: 0.446611\n",
            "Epoch 5 Iteration 1510 - Train Loss: 0.281770 - Dev Loss: 0.443593\n",
            "Epoch 5 Iteration 1520 - Train Loss: 0.298436 - Dev Loss: 0.441431\n",
            "Epoch 5 Iteration 1530 - Train Loss: 0.265231 - Dev Loss: 0.438887\n",
            "Epoch 6 Iteration 1540 - Train Loss: 0.268538 - Dev Loss: 0.444478\n",
            "Epoch 6 Iteration 1550 - Train Loss: 0.261596 - Dev Loss: 0.460765\n",
            "Epoch 6 Iteration 1560 - Train Loss: 0.261034 - Dev Loss: 0.439655\n",
            "Epoch 6 Iteration 1570 - Train Loss: 0.226435 - Dev Loss: 0.446958\n",
            "Epoch 6 Iteration 1580 - Train Loss: 0.258036 - Dev Loss: 0.430464\n",
            "Epoch 6 Iteration 1590 - Train Loss: 0.235158 - Dev Loss: 0.434194\n",
            "Epoch 6 Iteration 1600 - Train Loss: 0.234166 - Dev Loss: 0.442041\n",
            "Epoch 6 Iteration 1610 - Train Loss: 0.229293 - Dev Loss: 0.439319\n",
            "Epoch 6 Iteration 1620 - Train Loss: 0.244421 - Dev Loss: 0.462412\n",
            "Epoch 6 Iteration 1630 - Train Loss: 0.220006 - Dev Loss: 0.443276\n",
            "Epoch 6 Iteration 1640 - Train Loss: 0.232374 - Dev Loss: 0.436343\n",
            "Epoch 6 Iteration 1650 - Train Loss: 0.234271 - Dev Loss: 0.474876\n",
            "Epoch 6 Iteration 1660 - Train Loss: 0.254129 - Dev Loss: 0.458084\n",
            "Epoch 6 Iteration 1670 - Train Loss: 0.253037 - Dev Loss: 0.465266\n",
            "Epoch 6 Iteration 1680 - Train Loss: 0.232017 - Dev Loss: 0.466898\n",
            "Epoch 6 Iteration 1690 - Train Loss: 0.255206 - Dev Loss: 0.448567\n",
            "Epoch 6 Iteration 1700 - Train Loss: 0.227549 - Dev Loss: 0.456091\n",
            "Epoch 6 Iteration 1710 - Train Loss: 0.246277 - Dev Loss: 0.477861\n",
            "Epoch 6 Iteration 1720 - Train Loss: 0.238046 - Dev Loss: 0.446707\n",
            "Epoch 6 Iteration 1730 - Train Loss: 0.252405 - Dev Loss: 0.440950\n",
            "Epoch 6 Iteration 1740 - Train Loss: 0.228316 - Dev Loss: 0.444098\n",
            "Epoch 6 Iteration 1750 - Train Loss: 0.204140 - Dev Loss: 0.462110\n",
            "Epoch 6 Iteration 1760 - Train Loss: 0.230550 - Dev Loss: 0.458395\n",
            "Epoch 6 Iteration 1770 - Train Loss: 0.221042 - Dev Loss: 0.433730\n",
            "Epoch 6 Iteration 1780 - Train Loss: 0.226955 - Dev Loss: 0.464249\n",
            "Epoch 6 Iteration 1790 - Train Loss: 0.227221 - Dev Loss: 0.461954\n",
            "Epoch 7 Iteration 1800 - Train Loss: 0.192660 - Dev Loss: 0.429514\n",
            "Epoch 7 Iteration 1810 - Train Loss: 0.219135 - Dev Loss: 0.452954\n",
            "Epoch 7 Iteration 1820 - Train Loss: 0.180025 - Dev Loss: 0.461405\n",
            "Epoch 7 Iteration 1830 - Train Loss: 0.180028 - Dev Loss: 0.433741\n",
            "Epoch 7 Iteration 1840 - Train Loss: 0.212240 - Dev Loss: 0.449719\n",
            "Epoch 7 Iteration 1850 - Train Loss: 0.163108 - Dev Loss: 0.480578\n",
            "Epoch 7 Iteration 1860 - Train Loss: 0.184196 - Dev Loss: 0.446464\n",
            "Epoch 7 Iteration 1870 - Train Loss: 0.188879 - Dev Loss: 0.465704\n",
            "Epoch 7 Iteration 1880 - Train Loss: 0.189741 - Dev Loss: 0.464160\n",
            "Epoch 7 Iteration 1890 - Train Loss: 0.212634 - Dev Loss: 0.464059\n",
            "Epoch 7 Iteration 1900 - Train Loss: 0.201925 - Dev Loss: 0.477456\n",
            "Epoch 7 Iteration 1910 - Train Loss: 0.183513 - Dev Loss: 0.469970\n",
            "Epoch 7 Iteration 1920 - Train Loss: 0.198765 - Dev Loss: 0.461314\n",
            "Epoch 7 Iteration 1930 - Train Loss: 0.178663 - Dev Loss: 0.487612\n",
            "Epoch 7 Iteration 1940 - Train Loss: 0.201673 - Dev Loss: 0.475433\n",
            "Epoch 7 Iteration 1950 - Train Loss: 0.206120 - Dev Loss: 0.466556\n",
            "Epoch 7 Iteration 1960 - Train Loss: 0.186688 - Dev Loss: 0.465223\n",
            "Epoch 7 Iteration 1970 - Train Loss: 0.195286 - Dev Loss: 0.462957\n",
            "Epoch 7 Iteration 1980 - Train Loss: 0.200037 - Dev Loss: 0.472136\n",
            "Epoch 7 Iteration 1990 - Train Loss: 0.192334 - Dev Loss: 0.480566\n",
            "Epoch 7 Iteration 2000 - Train Loss: 0.213835 - Dev Loss: 0.465042\n",
            "Epoch 7 Iteration 2010 - Train Loss: 0.171066 - Dev Loss: 0.491019\n",
            "Epoch 7 Iteration 2020 - Train Loss: 0.178116 - Dev Loss: 0.475456\n",
            "Epoch 7 Iteration 2030 - Train Loss: 0.187755 - Dev Loss: 0.460520\n",
            "Epoch 7 Iteration 2040 - Train Loss: 0.192024 - Dev Loss: 0.485742\n",
            "Epoch 8 Iteration 2050 - Train Loss: 0.189352 - Dev Loss: 0.480567\n",
            "Epoch 8 Iteration 2060 - Train Loss: 0.161369 - Dev Loss: 0.459991\n",
            "Epoch 8 Iteration 2070 - Train Loss: 0.151849 - Dev Loss: 0.492813\n",
            "Epoch 8 Iteration 2080 - Train Loss: 0.156217 - Dev Loss: 0.463596\n",
            "Epoch 8 Iteration 2090 - Train Loss: 0.153783 - Dev Loss: 0.462751\n",
            "Epoch 8 Iteration 2100 - Train Loss: 0.165338 - Dev Loss: 0.492822\n",
            "Epoch 8 Iteration 2110 - Train Loss: 0.160666 - Dev Loss: 0.475586\n",
            "Epoch 8 Iteration 2120 - Train Loss: 0.160942 - Dev Loss: 0.477928\n",
            "Epoch 8 Iteration 2130 - Train Loss: 0.154801 - Dev Loss: 0.490388\n",
            "Epoch 8 Iteration 2140 - Train Loss: 0.148886 - Dev Loss: 0.482067\n",
            "Epoch 8 Iteration 2150 - Train Loss: 0.158947 - Dev Loss: 0.463493\n",
            "Epoch 8 Iteration 2160 - Train Loss: 0.154404 - Dev Loss: 0.477052\n",
            "Epoch 8 Iteration 2170 - Train Loss: 0.159454 - Dev Loss: 0.489542\n",
            "Epoch 8 Iteration 2180 - Train Loss: 0.157959 - Dev Loss: 0.478524\n",
            "Epoch 8 Iteration 2190 - Train Loss: 0.143845 - Dev Loss: 0.479095\n",
            "Epoch 8 Iteration 2200 - Train Loss: 0.141265 - Dev Loss: 0.489432\n",
            "Epoch 8 Iteration 2210 - Train Loss: 0.160317 - Dev Loss: 0.502891\n",
            "Epoch 8 Iteration 2220 - Train Loss: 0.179279 - Dev Loss: 0.484870\n",
            "Epoch 8 Iteration 2230 - Train Loss: 0.137619 - Dev Loss: 0.486935\n",
            "Epoch 8 Iteration 2240 - Train Loss: 0.167640 - Dev Loss: 0.497833\n",
            "Epoch 8 Iteration 2250 - Train Loss: 0.157029 - Dev Loss: 0.477168\n",
            "Epoch 8 Iteration 2260 - Train Loss: 0.142636 - Dev Loss: 0.483187\n",
            "Epoch 8 Iteration 2270 - Train Loss: 0.166866 - Dev Loss: 0.497658\n",
            "Epoch 8 Iteration 2280 - Train Loss: 0.135844 - Dev Loss: 0.490056\n",
            "Epoch 8 Iteration 2290 - Train Loss: 0.150193 - Dev Loss: 0.474516\n",
            "Epoch 8 Iteration 2300 - Train Loss: 0.164031 - Dev Loss: 0.479931\n",
            "Epoch 9 Iteration 2310 - Train Loss: 0.135325 - Dev Loss: 0.496957\n",
            "Epoch 9 Iteration 2320 - Train Loss: 0.112956 - Dev Loss: 0.475364\n",
            "Epoch 9 Iteration 2330 - Train Loss: 0.132518 - Dev Loss: 0.482377\n",
            "Epoch 9 Iteration 2340 - Train Loss: 0.123628 - Dev Loss: 0.491661\n",
            "Epoch 9 Iteration 2350 - Train Loss: 0.129819 - Dev Loss: 0.488558\n",
            "Epoch 9 Iteration 2360 - Train Loss: 0.110194 - Dev Loss: 0.477286\n",
            "Epoch 9 Iteration 2370 - Train Loss: 0.131516 - Dev Loss: 0.494325\n",
            "Epoch 9 Iteration 2380 - Train Loss: 0.114571 - Dev Loss: 0.499544\n",
            "Epoch 9 Iteration 2390 - Train Loss: 0.121786 - Dev Loss: 0.493025\n",
            "Epoch 9 Iteration 2400 - Train Loss: 0.117823 - Dev Loss: 0.487497\n",
            "Epoch 9 Iteration 2410 - Train Loss: 0.144925 - Dev Loss: 0.506631\n",
            "Epoch 9 Iteration 2420 - Train Loss: 0.131341 - Dev Loss: 0.526002\n",
            "Epoch 9 Iteration 2430 - Train Loss: 0.126040 - Dev Loss: 0.497640\n",
            "Epoch 9 Iteration 2440 - Train Loss: 0.115387 - Dev Loss: 0.512876\n",
            "Epoch 9 Iteration 2450 - Train Loss: 0.125630 - Dev Loss: 0.508682\n",
            "Epoch 9 Iteration 2460 - Train Loss: 0.108418 - Dev Loss: 0.505536\n",
            "Epoch 9 Iteration 2470 - Train Loss: 0.124063 - Dev Loss: 0.528118\n",
            "Epoch 9 Iteration 2480 - Train Loss: 0.116229 - Dev Loss: 0.521076\n",
            "Epoch 9 Iteration 2490 - Train Loss: 0.128581 - Dev Loss: 0.503756\n",
            "Epoch 9 Iteration 2500 - Train Loss: 0.129066 - Dev Loss: 0.514032\n",
            "Epoch 9 Iteration 2510 - Train Loss: 0.129936 - Dev Loss: 0.505016\n",
            "Epoch 9 Iteration 2520 - Train Loss: 0.121025 - Dev Loss: 0.520238\n",
            "Epoch 9 Iteration 2530 - Train Loss: 0.112347 - Dev Loss: 0.504083\n",
            "Epoch 9 Iteration 2540 - Train Loss: 0.120496 - Dev Loss: 0.497696\n",
            "Epoch 9 Iteration 2550 - Train Loss: 0.123738 - Dev Loss: 0.507157\n",
            "Epoch 10 Iteration 2560 - Train Loss: 0.123690 - Dev Loss: 0.494587\n",
            "Epoch 10 Iteration 2570 - Train Loss: 0.114214 - Dev Loss: 0.504735\n",
            "Epoch 10 Iteration 2580 - Train Loss: 0.091925 - Dev Loss: 0.507357\n",
            "Epoch 10 Iteration 2590 - Train Loss: 0.098337 - Dev Loss: 0.492005\n",
            "Epoch 10 Iteration 2600 - Train Loss: 0.088826 - Dev Loss: 0.497418\n",
            "Epoch 10 Iteration 2610 - Train Loss: 0.096976 - Dev Loss: 0.498141\n",
            "Epoch 10 Iteration 2620 - Train Loss: 0.106514 - Dev Loss: 0.498457\n",
            "Epoch 10 Iteration 2630 - Train Loss: 0.106201 - Dev Loss: 0.502820\n",
            "Epoch 10 Iteration 2640 - Train Loss: 0.097231 - Dev Loss: 0.509481\n",
            "Epoch 10 Iteration 2650 - Train Loss: 0.081270 - Dev Loss: 0.508498\n",
            "Epoch 10 Iteration 2660 - Train Loss: 0.093043 - Dev Loss: 0.505841\n",
            "Epoch 10 Iteration 2670 - Train Loss: 0.101647 - Dev Loss: 0.508916\n",
            "Epoch 10 Iteration 2680 - Train Loss: 0.089768 - Dev Loss: 0.503412\n",
            "Epoch 10 Iteration 2690 - Train Loss: 0.095336 - Dev Loss: 0.512978\n",
            "Epoch 10 Iteration 2700 - Train Loss: 0.084208 - Dev Loss: 0.514640\n",
            "Epoch 10 Iteration 2710 - Train Loss: 0.082493 - Dev Loss: 0.501070\n",
            "Epoch 10 Iteration 2720 - Train Loss: 0.103150 - Dev Loss: 0.504332\n",
            "Epoch 10 Iteration 2730 - Train Loss: 0.101212 - Dev Loss: 0.503000\n",
            "Epoch 10 Iteration 2740 - Train Loss: 0.098872 - Dev Loss: 0.504420\n",
            "Epoch 10 Iteration 2750 - Train Loss: 0.104556 - Dev Loss: 0.521715\n",
            "Epoch 10 Iteration 2760 - Train Loss: 0.099628 - Dev Loss: 0.523983\n",
            "Epoch 10 Iteration 2770 - Train Loss: 0.102798 - Dev Loss: 0.526375\n",
            "Epoch 10 Iteration 2780 - Train Loss: 0.093906 - Dev Loss: 0.559734\n",
            "Epoch 10 Iteration 2790 - Train Loss: 0.096393 - Dev Loss: 0.536249\n",
            "Epoch 10 Iteration 2800 - Train Loss: 0.102380 - Dev Loss: 0.542213\n",
            "Epoch 10 Iteration 2810 - Train Loss: 0.098385 - Dev Loss: 0.548087\n",
            "Epoch 11 Iteration 2820 - Train Loss: 0.082107 - Dev Loss: 0.549305\n",
            "Epoch 11 Iteration 2830 - Train Loss: 0.066280 - Dev Loss: 0.546505\n",
            "Epoch 11 Iteration 2840 - Train Loss: 0.065829 - Dev Loss: 0.545755\n",
            "Epoch 11 Iteration 2850 - Train Loss: 0.087097 - Dev Loss: 0.539106\n",
            "Epoch 11 Iteration 2860 - Train Loss: 0.087825 - Dev Loss: 0.538363\n",
            "Epoch 11 Iteration 2870 - Train Loss: 0.075217 - Dev Loss: 0.552921\n",
            "Epoch 11 Iteration 2880 - Train Loss: 0.075405 - Dev Loss: 0.533163\n",
            "Epoch 11 Iteration 2890 - Train Loss: 0.075738 - Dev Loss: 0.531074\n",
            "Epoch 11 Iteration 2900 - Train Loss: 0.082891 - Dev Loss: 0.560681\n",
            "Epoch 11 Iteration 2910 - Train Loss: 0.081089 - Dev Loss: 0.551826\n",
            "Epoch 11 Iteration 2920 - Train Loss: 0.077517 - Dev Loss: 0.537237\n",
            "Epoch 11 Iteration 2930 - Train Loss: 0.076279 - Dev Loss: 0.549587\n",
            "Epoch 11 Iteration 2940 - Train Loss: 0.075797 - Dev Loss: 0.554575\n",
            "Epoch 11 Iteration 2950 - Train Loss: 0.079766 - Dev Loss: 0.555468\n",
            "Epoch 11 Iteration 2960 - Train Loss: 0.069481 - Dev Loss: 0.547045\n",
            "Epoch 11 Iteration 2970 - Train Loss: 0.079096 - Dev Loss: 0.566140\n",
            "Epoch 11 Iteration 2980 - Train Loss: 0.068169 - Dev Loss: 0.569029\n",
            "Epoch 11 Iteration 2990 - Train Loss: 0.075979 - Dev Loss: 0.543807\n",
            "Epoch 11 Iteration 3000 - Train Loss: 0.073042 - Dev Loss: 0.548452\n",
            "Epoch 11 Iteration 3010 - Train Loss: 0.085874 - Dev Loss: 0.542934\n",
            "Epoch 11 Iteration 3020 - Train Loss: 0.070398 - Dev Loss: 0.553439\n",
            "Epoch 11 Iteration 3030 - Train Loss: 0.071748 - Dev Loss: 0.556426\n",
            "Epoch 11 Iteration 3040 - Train Loss: 0.074916 - Dev Loss: 0.548097\n",
            "Epoch 11 Iteration 3050 - Train Loss: 0.062879 - Dev Loss: 0.539179\n",
            "Epoch 11 Iteration 3060 - Train Loss: 0.079131 - Dev Loss: 0.547984\n",
            "Epoch 11 Iteration 3070 - Train Loss: 0.084158 - Dev Loss: 0.568953\n",
            "Epoch 12 Iteration 3080 - Train Loss: 0.061580 - Dev Loss: 0.562208\n",
            "Epoch 12 Iteration 3090 - Train Loss: 0.061517 - Dev Loss: 0.555591\n",
            "Epoch 12 Iteration 3100 - Train Loss: 0.059489 - Dev Loss: 0.554263\n",
            "Epoch 12 Iteration 3110 - Train Loss: 0.047363 - Dev Loss: 0.568251\n",
            "Epoch 12 Iteration 3120 - Train Loss: 0.059136 - Dev Loss: 0.575810\n",
            "Epoch 12 Iteration 3130 - Train Loss: 0.054011 - Dev Loss: 0.579342\n",
            "Epoch 12 Iteration 3140 - Train Loss: 0.047443 - Dev Loss: 0.571612\n",
            "Epoch 12 Iteration 3150 - Train Loss: 0.055023 - Dev Loss: 0.575656\n",
            "Epoch 12 Iteration 3160 - Train Loss: 0.065506 - Dev Loss: 0.585112\n",
            "Epoch 12 Iteration 3170 - Train Loss: 0.059753 - Dev Loss: 0.572935\n",
            "Epoch 12 Iteration 3180 - Train Loss: 0.064530 - Dev Loss: 0.578811\n",
            "Epoch 12 Iteration 3190 - Train Loss: 0.063874 - Dev Loss: 0.586913\n",
            "Epoch 12 Iteration 3200 - Train Loss: 0.061730 - Dev Loss: 0.563038\n",
            "Epoch 12 Iteration 3210 - Train Loss: 0.062308 - Dev Loss: 0.581982\n",
            "Epoch 12 Iteration 3220 - Train Loss: 0.053094 - Dev Loss: 0.576583\n",
            "Epoch 12 Iteration 3230 - Train Loss: 0.051824 - Dev Loss: 0.555785\n",
            "Epoch 12 Iteration 3240 - Train Loss: 0.052272 - Dev Loss: 0.568502\n",
            "Epoch 12 Iteration 3250 - Train Loss: 0.067175 - Dev Loss: 0.571374\n",
            "Epoch 12 Iteration 3260 - Train Loss: 0.073142 - Dev Loss: 0.568797\n",
            "Epoch 12 Iteration 3270 - Train Loss: 0.053165 - Dev Loss: 0.549763\n",
            "Epoch 12 Iteration 3280 - Train Loss: 0.062030 - Dev Loss: 0.569738\n",
            "Epoch 12 Iteration 3290 - Train Loss: 0.053502 - Dev Loss: 0.582525\n",
            "Epoch 12 Iteration 3300 - Train Loss: 0.063652 - Dev Loss: 0.559409\n",
            "Epoch 12 Iteration 3310 - Train Loss: 0.049635 - Dev Loss: 0.558508\n",
            "Epoch 12 Iteration 3320 - Train Loss: 0.068224 - Dev Loss: 0.586554\n",
            "Epoch 13 Iteration 3330 - Train Loss: 0.059159 - Dev Loss: 0.569852\n",
            "Epoch 13 Iteration 3340 - Train Loss: 0.051151 - Dev Loss: 0.564315\n",
            "Epoch 13 Iteration 3350 - Train Loss: 0.048549 - Dev Loss: 0.581166\n",
            "Epoch 13 Iteration 3360 - Train Loss: 0.041120 - Dev Loss: 0.579511\n",
            "Epoch 13 Iteration 3370 - Train Loss: 0.039671 - Dev Loss: 0.577322\n",
            "Epoch 13 Iteration 3380 - Train Loss: 0.039349 - Dev Loss: 0.572523\n",
            "Epoch 13 Iteration 3390 - Train Loss: 0.050277 - Dev Loss: 0.552873\n",
            "Epoch 13 Iteration 3400 - Train Loss: 0.041039 - Dev Loss: 0.562523\n",
            "Epoch 13 Iteration 3410 - Train Loss: 0.038439 - Dev Loss: 0.580785\n",
            "Epoch 13 Iteration 3420 - Train Loss: 0.040192 - Dev Loss: 0.577102\n",
            "Epoch 13 Iteration 3430 - Train Loss: 0.046608 - Dev Loss: 0.584238\n",
            "Epoch 13 Iteration 3440 - Train Loss: 0.049757 - Dev Loss: 0.608946\n",
            "Epoch 13 Iteration 3450 - Train Loss: 0.035957 - Dev Loss: 0.598324\n",
            "Epoch 13 Iteration 3460 - Train Loss: 0.047979 - Dev Loss: 0.589542\n",
            "Epoch 13 Iteration 3470 - Train Loss: 0.053288 - Dev Loss: 0.604722\n",
            "Epoch 13 Iteration 3480 - Train Loss: 0.043480 - Dev Loss: 0.600268\n",
            "Epoch 13 Iteration 3490 - Train Loss: 0.049086 - Dev Loss: 0.607116\n",
            "Epoch 13 Iteration 3500 - Train Loss: 0.047950 - Dev Loss: 0.597851\n",
            "Epoch 13 Iteration 3510 - Train Loss: 0.048817 - Dev Loss: 0.585987\n",
            "Epoch 13 Iteration 3520 - Train Loss: 0.041379 - Dev Loss: 0.589131\n",
            "Epoch 13 Iteration 3530 - Train Loss: 0.043237 - Dev Loss: 0.599756\n",
            "Epoch 13 Iteration 3540 - Train Loss: 0.047761 - Dev Loss: 0.585553\n",
            "Epoch 13 Iteration 3550 - Train Loss: 0.039308 - Dev Loss: 0.606001\n",
            "Epoch 13 Iteration 3560 - Train Loss: 0.048031 - Dev Loss: 0.612931\n",
            "Epoch 13 Iteration 3570 - Train Loss: 0.051193 - Dev Loss: 0.599757\n",
            "Epoch 13 Iteration 3580 - Train Loss: 0.048580 - Dev Loss: 0.610936\n",
            "Epoch 14 Iteration 3590 - Train Loss: 0.035427 - Dev Loss: 0.603399\n",
            "Epoch 14 Iteration 3600 - Train Loss: 0.033890 - Dev Loss: 0.609722\n",
            "Epoch 14 Iteration 3610 - Train Loss: 0.040575 - Dev Loss: 0.615719\n",
            "Epoch 14 Iteration 3620 - Train Loss: 0.028336 - Dev Loss: 0.630330\n",
            "Epoch 14 Iteration 3630 - Train Loss: 0.040479 - Dev Loss: 0.618750\n",
            "Epoch 14 Iteration 3640 - Train Loss: 0.033071 - Dev Loss: 0.612854\n",
            "Epoch 14 Iteration 3650 - Train Loss: 0.033835 - Dev Loss: 0.600437\n",
            "Epoch 14 Iteration 3660 - Train Loss: 0.038636 - Dev Loss: 0.612601\n",
            "Epoch 14 Iteration 3670 - Train Loss: 0.031509 - Dev Loss: 0.617439\n",
            "Epoch 14 Iteration 3680 - Train Loss: 0.040234 - Dev Loss: 0.612271\n",
            "Epoch 14 Iteration 3690 - Train Loss: 0.027078 - Dev Loss: 0.613933\n",
            "Epoch 14 Iteration 3700 - Train Loss: 0.036718 - Dev Loss: 0.634095\n",
            "Epoch 14 Iteration 3710 - Train Loss: 0.030761 - Dev Loss: 0.637095\n",
            "Epoch 14 Iteration 3720 - Train Loss: 0.032756 - Dev Loss: 0.615644\n",
            "Epoch 14 Iteration 3730 - Train Loss: 0.030902 - Dev Loss: 0.614711\n",
            "Epoch 14 Iteration 3740 - Train Loss: 0.032502 - Dev Loss: 0.634422\n",
            "Epoch 14 Iteration 3750 - Train Loss: 0.037560 - Dev Loss: 0.626523\n",
            "Epoch 14 Iteration 3760 - Train Loss: 0.036612 - Dev Loss: 0.624745\n",
            "Epoch 14 Iteration 3770 - Train Loss: 0.036506 - Dev Loss: 0.624320\n",
            "Epoch 14 Iteration 3780 - Train Loss: 0.034472 - Dev Loss: 0.635912\n",
            "Epoch 14 Iteration 3790 - Train Loss: 0.039490 - Dev Loss: 0.644486\n",
            "Epoch 14 Iteration 3800 - Train Loss: 0.039546 - Dev Loss: 0.640903\n",
            "Epoch 14 Iteration 3810 - Train Loss: 0.036863 - Dev Loss: 0.629081\n",
            "Epoch 14 Iteration 3820 - Train Loss: 0.038421 - Dev Loss: 0.648014\n",
            "Epoch 14 Iteration 3830 - Train Loss: 0.033824 - Dev Loss: 0.627898\n",
            "Epoch 15 Iteration 3840 - Train Loss: 0.034514 - Dev Loss: 0.613653\n",
            "Epoch 15 Iteration 3850 - Train Loss: 0.020017 - Dev Loss: 0.636714\n",
            "Epoch 15 Iteration 3860 - Train Loss: 0.023659 - Dev Loss: 0.627906\n",
            "Epoch 15 Iteration 3870 - Train Loss: 0.028159 - Dev Loss: 0.627210\n",
            "Epoch 15 Iteration 3880 - Train Loss: 0.024610 - Dev Loss: 0.633696\n",
            "Epoch 15 Iteration 3890 - Train Loss: 0.022860 - Dev Loss: 0.642429\n",
            "Epoch 15 Iteration 3900 - Train Loss: 0.028891 - Dev Loss: 0.649373\n",
            "Epoch 15 Iteration 3910 - Train Loss: 0.026769 - Dev Loss: 0.651619\n",
            "Epoch 15 Iteration 3920 - Train Loss: 0.026390 - Dev Loss: 0.634009\n",
            "Epoch 15 Iteration 3930 - Train Loss: 0.019813 - Dev Loss: 0.645350\n",
            "Epoch 15 Iteration 3940 - Train Loss: 0.024157 - Dev Loss: 0.645515\n",
            "Epoch 15 Iteration 3950 - Train Loss: 0.024805 - Dev Loss: 0.646071\n",
            "Epoch 15 Iteration 3960 - Train Loss: 0.030782 - Dev Loss: 0.654793\n",
            "Epoch 15 Iteration 3970 - Train Loss: 0.030408 - Dev Loss: 0.663272\n",
            "Epoch 15 Iteration 3980 - Train Loss: 0.025282 - Dev Loss: 0.653436\n",
            "Epoch 15 Iteration 3990 - Train Loss: 0.028400 - Dev Loss: 0.645039\n",
            "Epoch 15 Iteration 4000 - Train Loss: 0.022598 - Dev Loss: 0.661303\n",
            "Epoch 15 Iteration 4010 - Train Loss: 0.027241 - Dev Loss: 0.650810\n",
            "Epoch 15 Iteration 4020 - Train Loss: 0.026316 - Dev Loss: 0.646384\n",
            "Epoch 15 Iteration 4030 - Train Loss: 0.028877 - Dev Loss: 0.653222\n",
            "Epoch 15 Iteration 4040 - Train Loss: 0.029354 - Dev Loss: 0.644527\n",
            "Epoch 15 Iteration 4050 - Train Loss: 0.032471 - Dev Loss: 0.642314\n",
            "Epoch 15 Iteration 4060 - Train Loss: 0.030761 - Dev Loss: 0.656640\n",
            "Epoch 15 Iteration 4070 - Train Loss: 0.026923 - Dev Loss: 0.656920\n",
            "Epoch 15 Iteration 4080 - Train Loss: 0.031309 - Dev Loss: 0.648654\n",
            "Epoch 15 Iteration 4090 - Train Loss: 0.024688 - Dev Loss: 0.637273\n",
            "Epoch 16 Iteration 4100 - Train Loss: 0.024717 - Dev Loss: 0.648983\n",
            "Epoch 16 Iteration 4110 - Train Loss: 0.019935 - Dev Loss: 0.656639\n",
            "Epoch 16 Iteration 4120 - Train Loss: 0.021524 - Dev Loss: 0.649079\n",
            "Epoch 16 Iteration 4130 - Train Loss: 0.017360 - Dev Loss: 0.649002\n",
            "Epoch 16 Iteration 4140 - Train Loss: 0.018416 - Dev Loss: 0.655350\n",
            "Epoch 16 Iteration 4150 - Train Loss: 0.020644 - Dev Loss: 0.664812\n",
            "Epoch 16 Iteration 4160 - Train Loss: 0.019632 - Dev Loss: 0.666567\n",
            "Epoch 16 Iteration 4170 - Train Loss: 0.019256 - Dev Loss: 0.662574\n",
            "Epoch 16 Iteration 4180 - Train Loss: 0.014843 - Dev Loss: 0.663720\n",
            "Epoch 16 Iteration 4190 - Train Loss: 0.018819 - Dev Loss: 0.662005\n",
            "Epoch 16 Iteration 4200 - Train Loss: 0.023816 - Dev Loss: 0.661372\n",
            "Epoch 16 Iteration 4210 - Train Loss: 0.018809 - Dev Loss: 0.666637\n",
            "Epoch 16 Iteration 4220 - Train Loss: 0.025281 - Dev Loss: 0.663496\n",
            "Epoch 16 Iteration 4230 - Train Loss: 0.019378 - Dev Loss: 0.664050\n",
            "Epoch 16 Iteration 4240 - Train Loss: 0.020188 - Dev Loss: 0.677931\n",
            "Epoch 16 Iteration 4250 - Train Loss: 0.019505 - Dev Loss: 0.688908\n",
            "Epoch 16 Iteration 4260 - Train Loss: 0.022357 - Dev Loss: 0.686432\n",
            "Epoch 16 Iteration 4270 - Train Loss: 0.016885 - Dev Loss: 0.677129\n",
            "Epoch 16 Iteration 4280 - Train Loss: 0.022901 - Dev Loss: 0.677562\n",
            "Epoch 16 Iteration 4290 - Train Loss: 0.022049 - Dev Loss: 0.679113\n",
            "Epoch 16 Iteration 4300 - Train Loss: 0.025916 - Dev Loss: 0.683792\n",
            "Epoch 16 Iteration 4310 - Train Loss: 0.016985 - Dev Loss: 0.674566\n",
            "Epoch 16 Iteration 4320 - Train Loss: 0.019579 - Dev Loss: 0.676003\n",
            "Epoch 16 Iteration 4330 - Train Loss: 0.017658 - Dev Loss: 0.673192\n",
            "Epoch 16 Iteration 4340 - Train Loss: 0.021308 - Dev Loss: 0.665511\n",
            "Epoch 16 Iteration 4350 - Train Loss: 0.017844 - Dev Loss: 0.677257\n",
            "Epoch 17 Iteration 4360 - Train Loss: 0.014978 - Dev Loss: 0.679960\n",
            "Epoch 17 Iteration 4370 - Train Loss: 0.012282 - Dev Loss: 0.675769\n",
            "Epoch 17 Iteration 4380 - Train Loss: 0.015415 - Dev Loss: 0.672542\n",
            "Epoch 17 Iteration 4390 - Train Loss: 0.012517 - Dev Loss: 0.679913\n",
            "Epoch 17 Iteration 4400 - Train Loss: 0.016350 - Dev Loss: 0.687594\n",
            "Epoch 17 Iteration 4410 - Train Loss: 0.017197 - Dev Loss: 0.681233\n",
            "Epoch 17 Iteration 4420 - Train Loss: 0.015220 - Dev Loss: 0.677597\n",
            "Epoch 17 Iteration 4430 - Train Loss: 0.012959 - Dev Loss: 0.679045\n",
            "Epoch 17 Iteration 4440 - Train Loss: 0.014231 - Dev Loss: 0.679165\n",
            "Epoch 17 Iteration 4450 - Train Loss: 0.012703 - Dev Loss: 0.674893\n",
            "Epoch 17 Iteration 4460 - Train Loss: 0.017876 - Dev Loss: 0.690386\n",
            "Epoch 17 Iteration 4470 - Train Loss: 0.020044 - Dev Loss: 0.702973\n",
            "Epoch 17 Iteration 4480 - Train Loss: 0.013431 - Dev Loss: 0.693292\n",
            "Epoch 17 Iteration 4490 - Train Loss: 0.013016 - Dev Loss: 0.693464\n",
            "Epoch 17 Iteration 4500 - Train Loss: 0.014807 - Dev Loss: 0.692875\n",
            "Epoch 17 Iteration 4510 - Train Loss: 0.018078 - Dev Loss: 0.695167\n",
            "Epoch 17 Iteration 4520 - Train Loss: 0.016791 - Dev Loss: 0.690670\n",
            "Epoch 17 Iteration 4530 - Train Loss: 0.015107 - Dev Loss: 0.689696\n",
            "Epoch 17 Iteration 4540 - Train Loss: 0.015079 - Dev Loss: 0.701819\n",
            "Epoch 17 Iteration 4550 - Train Loss: 0.017614 - Dev Loss: 0.697945\n",
            "Epoch 17 Iteration 4560 - Train Loss: 0.016818 - Dev Loss: 0.689761\n",
            "Epoch 17 Iteration 4570 - Train Loss: 0.017835 - Dev Loss: 0.701469\n",
            "Epoch 17 Iteration 4580 - Train Loss: 0.014851 - Dev Loss: 0.702361\n",
            "Epoch 17 Iteration 4590 - Train Loss: 0.014579 - Dev Loss: 0.712702\n",
            "Epoch 17 Iteration 4600 - Train Loss: 0.017477 - Dev Loss: 0.712458\n",
            "Epoch 18 Iteration 4610 - Train Loss: 0.013530 - Dev Loss: 0.697694\n",
            "Epoch 18 Iteration 4620 - Train Loss: 0.010289 - Dev Loss: 0.694012\n",
            "Epoch 18 Iteration 4630 - Train Loss: 0.009794 - Dev Loss: 0.705979\n",
            "Epoch 18 Iteration 4640 - Train Loss: 0.009890 - Dev Loss: 0.698852\n",
            "Epoch 18 Iteration 4650 - Train Loss: 0.010094 - Dev Loss: 0.694768\n",
            "Epoch 18 Iteration 4660 - Train Loss: 0.014325 - Dev Loss: 0.699867\n",
            "Epoch 18 Iteration 4670 - Train Loss: 0.011374 - Dev Loss: 0.701467\n",
            "Epoch 18 Iteration 4680 - Train Loss: 0.010204 - Dev Loss: 0.702960\n",
            "Epoch 18 Iteration 4690 - Train Loss: 0.013047 - Dev Loss: 0.708591\n",
            "Epoch 18 Iteration 4700 - Train Loss: 0.010771 - Dev Loss: 0.705839\n",
            "Epoch 18 Iteration 4710 - Train Loss: 0.010683 - Dev Loss: 0.698105\n",
            "Epoch 18 Iteration 4720 - Train Loss: 0.009408 - Dev Loss: 0.698418\n",
            "Epoch 18 Iteration 4730 - Train Loss: 0.016096 - Dev Loss: 0.704446\n",
            "Epoch 18 Iteration 4740 - Train Loss: 0.010709 - Dev Loss: 0.701640\n",
            "Epoch 18 Iteration 4750 - Train Loss: 0.015447 - Dev Loss: 0.702572\n",
            "Epoch 18 Iteration 4760 - Train Loss: 0.011261 - Dev Loss: 0.705802\n",
            "Epoch 18 Iteration 4770 - Train Loss: 0.013854 - Dev Loss: 0.708982\n",
            "Epoch 18 Iteration 4780 - Train Loss: 0.013818 - Dev Loss: 0.709473\n",
            "Epoch 18 Iteration 4790 - Train Loss: 0.013045 - Dev Loss: 0.709434\n",
            "Epoch 18 Iteration 4800 - Train Loss: 0.010368 - Dev Loss: 0.707387\n",
            "Epoch 18 Iteration 4810 - Train Loss: 0.009475 - Dev Loss: 0.709773\n",
            "Epoch 18 Iteration 4820 - Train Loss: 0.013081 - Dev Loss: 0.714607\n",
            "Epoch 18 Iteration 4830 - Train Loss: 0.012007 - Dev Loss: 0.715587\n",
            "Epoch 18 Iteration 4840 - Train Loss: 0.009632 - Dev Loss: 0.712803\n",
            "Epoch 18 Iteration 4850 - Train Loss: 0.012093 - Dev Loss: 0.729748\n",
            "Epoch 18 Iteration 4860 - Train Loss: 0.011592 - Dev Loss: 0.726852\n",
            "Epoch 19 Iteration 4870 - Train Loss: 0.011556 - Dev Loss: 0.715001\n",
            "Epoch 19 Iteration 4880 - Train Loss: 0.007754 - Dev Loss: 0.718451\n",
            "Epoch 19 Iteration 4890 - Train Loss: 0.007783 - Dev Loss: 0.725510\n",
            "Epoch 19 Iteration 4900 - Train Loss: 0.009612 - Dev Loss: 0.722821\n",
            "Epoch 19 Iteration 4910 - Train Loss: 0.010480 - Dev Loss: 0.720033\n",
            "Epoch 19 Iteration 4920 - Train Loss: 0.011956 - Dev Loss: 0.726788\n",
            "Epoch 19 Iteration 4930 - Train Loss: 0.007041 - Dev Loss: 0.720053\n",
            "Epoch 19 Iteration 4940 - Train Loss: 0.008191 - Dev Loss: 0.719514\n",
            "Epoch 19 Iteration 4950 - Train Loss: 0.007694 - Dev Loss: 0.720970\n",
            "Epoch 19 Iteration 4960 - Train Loss: 0.009398 - Dev Loss: 0.725719\n",
            "Epoch 19 Iteration 4970 - Train Loss: 0.008236 - Dev Loss: 0.725863\n",
            "Epoch 19 Iteration 4980 - Train Loss: 0.009869 - Dev Loss: 0.715234\n",
            "Epoch 19 Iteration 4990 - Train Loss: 0.008689 - Dev Loss: 0.716710\n",
            "Epoch 19 Iteration 5000 - Train Loss: 0.012195 - Dev Loss: 0.723565\n",
            "Epoch 19 Iteration 5010 - Train Loss: 0.008968 - Dev Loss: 0.724698\n",
            "Epoch 19 Iteration 5020 - Train Loss: 0.008739 - Dev Loss: 0.720208\n",
            "Epoch 19 Iteration 5030 - Train Loss: 0.008889 - Dev Loss: 0.725328\n",
            "Epoch 19 Iteration 5040 - Train Loss: 0.007806 - Dev Loss: 0.732944\n",
            "Epoch 19 Iteration 5050 - Train Loss: 0.008634 - Dev Loss: 0.734290\n",
            "Epoch 19 Iteration 5060 - Train Loss: 0.008311 - Dev Loss: 0.739201\n",
            "Epoch 19 Iteration 5070 - Train Loss: 0.009685 - Dev Loss: 0.741384\n",
            "Epoch 19 Iteration 5080 - Train Loss: 0.008582 - Dev Loss: 0.740631\n",
            "Epoch 19 Iteration 5090 - Train Loss: 0.009371 - Dev Loss: 0.742950\n",
            "Epoch 19 Iteration 5100 - Train Loss: 0.007154 - Dev Loss: 0.751414\n",
            "Epoch 19 Iteration 5110 - Train Loss: 0.010085 - Dev Loss: 0.739664\n",
            "Epoch 20 Iteration 5120 - Train Loss: 0.008252 - Dev Loss: 0.735047\n",
            "Epoch 20 Iteration 5130 - Train Loss: 0.006380 - Dev Loss: 0.739203\n",
            "Epoch 20 Iteration 5140 - Train Loss: 0.005885 - Dev Loss: 0.746799\n",
            "Epoch 20 Iteration 5150 - Train Loss: 0.006937 - Dev Loss: 0.748333\n",
            "Epoch 20 Iteration 5160 - Train Loss: 0.006182 - Dev Loss: 0.743883\n",
            "Epoch 20 Iteration 5170 - Train Loss: 0.006549 - Dev Loss: 0.741953\n",
            "Epoch 20 Iteration 5180 - Train Loss: 0.007027 - Dev Loss: 0.749181\n",
            "Epoch 20 Iteration 5190 - Train Loss: 0.006297 - Dev Loss: 0.745259\n",
            "Epoch 20 Iteration 5200 - Train Loss: 0.008406 - Dev Loss: 0.736280\n",
            "Epoch 20 Iteration 5210 - Train Loss: 0.006133 - Dev Loss: 0.737462\n",
            "Epoch 20 Iteration 5220 - Train Loss: 0.006854 - Dev Loss: 0.737280\n",
            "Epoch 20 Iteration 5230 - Train Loss: 0.005911 - Dev Loss: 0.736643\n",
            "Epoch 20 Iteration 5240 - Train Loss: 0.006472 - Dev Loss: 0.744240\n",
            "Epoch 20 Iteration 5250 - Train Loss: 0.007161 - Dev Loss: 0.753503\n",
            "Epoch 20 Iteration 5260 - Train Loss: 0.007901 - Dev Loss: 0.748907\n",
            "Epoch 20 Iteration 5270 - Train Loss: 0.006851 - Dev Loss: 0.750105\n",
            "Epoch 20 Iteration 5280 - Train Loss: 0.004936 - Dev Loss: 0.753518\n",
            "Epoch 20 Iteration 5290 - Train Loss: 0.007017 - Dev Loss: 0.749718\n",
            "Epoch 20 Iteration 5300 - Train Loss: 0.006198 - Dev Loss: 0.756292\n",
            "Epoch 20 Iteration 5310 - Train Loss: 0.007085 - Dev Loss: 0.760731\n",
            "Epoch 20 Iteration 5320 - Train Loss: 0.006471 - Dev Loss: 0.755124\n",
            "Epoch 20 Iteration 5330 - Train Loss: 0.007596 - Dev Loss: 0.766560\n",
            "Epoch 20 Iteration 5340 - Train Loss: 0.009947 - Dev Loss: 0.765648\n",
            "Epoch 20 Iteration 5350 - Train Loss: 0.007327 - Dev Loss: 0.769164\n",
            "Epoch 20 Iteration 5360 - Train Loss: 0.006935 - Dev Loss: 0.775176\n",
            "Epoch 20 Iteration 5370 - Train Loss: 0.008159 - Dev Loss: 0.776805\n",
            "Epoch 21 Iteration 5380 - Train Loss: 0.006935 - Dev Loss: 0.770776\n",
            "Epoch 21 Iteration 5390 - Train Loss: 0.005782 - Dev Loss: 0.762794\n",
            "Epoch 21 Iteration 5400 - Train Loss: 0.004975 - Dev Loss: 0.763434\n",
            "Epoch 21 Iteration 5410 - Train Loss: 0.006381 - Dev Loss: 0.763162\n",
            "Epoch 21 Iteration 5420 - Train Loss: 0.005027 - Dev Loss: 0.758706\n",
            "Epoch 21 Iteration 5430 - Train Loss: 0.004895 - Dev Loss: 0.761524\n",
            "Epoch 21 Iteration 5440 - Train Loss: 0.004773 - Dev Loss: 0.769198\n",
            "Epoch 21 Iteration 5450 - Train Loss: 0.004881 - Dev Loss: 0.775821\n",
            "Epoch 21 Iteration 5460 - Train Loss: 0.005193 - Dev Loss: 0.771024\n",
            "Epoch 21 Iteration 5470 - Train Loss: 0.007678 - Dev Loss: 0.765051\n",
            "Epoch 21 Iteration 5480 - Train Loss: 0.004596 - Dev Loss: 0.767079\n",
            "Epoch 21 Iteration 5490 - Train Loss: 0.006469 - Dev Loss: 0.766118\n",
            "Epoch 21 Iteration 5500 - Train Loss: 0.006391 - Dev Loss: 0.766476\n",
            "Epoch 21 Iteration 5510 - Train Loss: 0.005233 - Dev Loss: 0.775841\n",
            "Epoch 21 Iteration 5520 - Train Loss: 0.005423 - Dev Loss: 0.775847\n",
            "Epoch 21 Iteration 5530 - Train Loss: 0.005391 - Dev Loss: 0.770484\n",
            "Epoch 21 Iteration 5540 - Train Loss: 0.005903 - Dev Loss: 0.768692\n",
            "Epoch 21 Iteration 5550 - Train Loss: 0.005169 - Dev Loss: 0.766599\n",
            "Epoch 21 Iteration 5560 - Train Loss: 0.004226 - Dev Loss: 0.767123\n",
            "Epoch 21 Iteration 5570 - Train Loss: 0.005042 - Dev Loss: 0.777151\n",
            "Epoch 21 Iteration 5580 - Train Loss: 0.004985 - Dev Loss: 0.780149\n",
            "Epoch 21 Iteration 5590 - Train Loss: 0.004647 - Dev Loss: 0.766325\n",
            "Epoch 21 Iteration 5600 - Train Loss: 0.006236 - Dev Loss: 0.766985\n",
            "Epoch 21 Iteration 5610 - Train Loss: 0.006010 - Dev Loss: 0.778211\n",
            "Epoch 21 Iteration 5620 - Train Loss: 0.004984 - Dev Loss: 0.779135\n",
            "Epoch 21 Iteration 5630 - Train Loss: 0.004764 - Dev Loss: 0.777500\n",
            "Epoch 22 Iteration 5640 - Train Loss: 0.004255 - Dev Loss: 0.778524\n",
            "Epoch 22 Iteration 5650 - Train Loss: 0.003672 - Dev Loss: 0.785177\n",
            "Epoch 22 Iteration 5660 - Train Loss: 0.003770 - Dev Loss: 0.787178\n",
            "Epoch 22 Iteration 5670 - Train Loss: 0.003758 - Dev Loss: 0.783080\n",
            "Epoch 22 Iteration 5680 - Train Loss: 0.003712 - Dev Loss: 0.779570\n",
            "Epoch 22 Iteration 5690 - Train Loss: 0.003971 - Dev Loss: 0.776448\n",
            "Epoch 22 Iteration 5700 - Train Loss: 0.003604 - Dev Loss: 0.781944\n",
            "Epoch 22 Iteration 5710 - Train Loss: 0.004768 - Dev Loss: 0.786632\n",
            "Epoch 22 Iteration 5720 - Train Loss: 0.004283 - Dev Loss: 0.787725\n",
            "Epoch 22 Iteration 5730 - Train Loss: 0.003990 - Dev Loss: 0.788069\n",
            "Epoch 22 Iteration 5740 - Train Loss: 0.003971 - Dev Loss: 0.788247\n",
            "Epoch 22 Iteration 5750 - Train Loss: 0.005584 - Dev Loss: 0.794253\n",
            "Epoch 22 Iteration 5760 - Train Loss: 0.004555 - Dev Loss: 0.782648\n",
            "Epoch 22 Iteration 5770 - Train Loss: 0.003445 - Dev Loss: 0.781884\n",
            "Epoch 22 Iteration 5780 - Train Loss: 0.003492 - Dev Loss: 0.792073\n",
            "Epoch 22 Iteration 5790 - Train Loss: 0.004030 - Dev Loss: 0.793844\n",
            "Epoch 22 Iteration 5800 - Train Loss: 0.004341 - Dev Loss: 0.795999\n",
            "Epoch 22 Iteration 5810 - Train Loss: 0.004212 - Dev Loss: 0.789427\n",
            "Epoch 22 Iteration 5820 - Train Loss: 0.004752 - Dev Loss: 0.783742\n",
            "Epoch 22 Iteration 5830 - Train Loss: 0.004053 - Dev Loss: 0.788591\n",
            "Epoch 22 Iteration 5840 - Train Loss: 0.004069 - Dev Loss: 0.791767\n",
            "Epoch 22 Iteration 5850 - Train Loss: 0.004220 - Dev Loss: 0.786726\n",
            "Epoch 22 Iteration 5860 - Train Loss: 0.004159 - Dev Loss: 0.789979\n",
            "Epoch 22 Iteration 5870 - Train Loss: 0.004049 - Dev Loss: 0.794887\n",
            "Epoch 22 Iteration 5880 - Train Loss: 0.005993 - Dev Loss: 0.797745\n",
            "Epoch 23 Iteration 5890 - Train Loss: 0.003488 - Dev Loss: 0.796429\n",
            "Epoch 23 Iteration 5900 - Train Loss: 0.002707 - Dev Loss: 0.800460\n",
            "Epoch 23 Iteration 5910 - Train Loss: 0.002729 - Dev Loss: 0.800331\n",
            "Epoch 23 Iteration 5920 - Train Loss: 0.003309 - Dev Loss: 0.796628\n",
            "Epoch 23 Iteration 5930 - Train Loss: 0.003698 - Dev Loss: 0.801726\n",
            "Epoch 23 Iteration 5940 - Train Loss: 0.003525 - Dev Loss: 0.811682\n",
            "Epoch 23 Iteration 5950 - Train Loss: 0.003429 - Dev Loss: 0.806560\n",
            "Epoch 23 Iteration 5960 - Train Loss: 0.002894 - Dev Loss: 0.807633\n",
            "Epoch 23 Iteration 5970 - Train Loss: 0.003096 - Dev Loss: 0.810611\n",
            "Epoch 23 Iteration 5980 - Train Loss: 0.002753 - Dev Loss: 0.805728\n",
            "Epoch 23 Iteration 5990 - Train Loss: 0.003419 - Dev Loss: 0.805028\n",
            "Epoch 23 Iteration 6000 - Train Loss: 0.003335 - Dev Loss: 0.808978\n",
            "Epoch 23 Iteration 6010 - Train Loss: 0.002923 - Dev Loss: 0.815764\n",
            "Epoch 23 Iteration 6020 - Train Loss: 0.003123 - Dev Loss: 0.819983\n",
            "Epoch 23 Iteration 6030 - Train Loss: 0.003149 - Dev Loss: 0.812938\n",
            "Epoch 23 Iteration 6040 - Train Loss: 0.005497 - Dev Loss: 0.808039\n",
            "Epoch 23 Iteration 6050 - Train Loss: 0.003090 - Dev Loss: 0.810199\n",
            "Epoch 23 Iteration 6060 - Train Loss: 0.003519 - Dev Loss: 0.816456\n",
            "Epoch 23 Iteration 6070 - Train Loss: 0.003452 - Dev Loss: 0.820116\n",
            "Epoch 23 Iteration 6080 - Train Loss: 0.003309 - Dev Loss: 0.818701\n",
            "Epoch 23 Iteration 6090 - Train Loss: 0.003588 - Dev Loss: 0.814229\n",
            "Epoch 23 Iteration 6100 - Train Loss: 0.003337 - Dev Loss: 0.815386\n",
            "Epoch 23 Iteration 6110 - Train Loss: 0.003244 - Dev Loss: 0.819430\n",
            "Epoch 23 Iteration 6120 - Train Loss: 0.003572 - Dev Loss: 0.820784\n",
            "Epoch 23 Iteration 6130 - Train Loss: 0.002881 - Dev Loss: 0.821085\n",
            "Epoch 23 Iteration 6140 - Train Loss: 0.003689 - Dev Loss: 0.819779\n",
            "Epoch 24 Iteration 6150 - Train Loss: 0.002663 - Dev Loss: 0.814088\n",
            "Epoch 24 Iteration 6160 - Train Loss: 0.002502 - Dev Loss: 0.813017\n",
            "Epoch 24 Iteration 6170 - Train Loss: 0.003180 - Dev Loss: 0.813734\n",
            "Epoch 24 Iteration 6180 - Train Loss: 0.002938 - Dev Loss: 0.814485\n",
            "Epoch 24 Iteration 6190 - Train Loss: 0.002857 - Dev Loss: 0.813918\n",
            "Epoch 24 Iteration 6200 - Train Loss: 0.002592 - Dev Loss: 0.810779\n",
            "Epoch 24 Iteration 6210 - Train Loss: 0.002208 - Dev Loss: 0.813891\n",
            "Epoch 24 Iteration 6220 - Train Loss: 0.002548 - Dev Loss: 0.822246\n",
            "Epoch 24 Iteration 6230 - Train Loss: 0.002714 - Dev Loss: 0.826925\n",
            "Epoch 24 Iteration 6240 - Train Loss: 0.003568 - Dev Loss: 0.826961\n",
            "Epoch 24 Iteration 6250 - Train Loss: 0.002457 - Dev Loss: 0.823204\n",
            "Epoch 24 Iteration 6260 - Train Loss: 0.002443 - Dev Loss: 0.828151\n",
            "Epoch 24 Iteration 6270 - Train Loss: 0.003306 - Dev Loss: 0.829885\n",
            "Epoch 24 Iteration 6280 - Train Loss: 0.002366 - Dev Loss: 0.828798\n",
            "Epoch 24 Iteration 6290 - Train Loss: 0.002939 - Dev Loss: 0.826721\n",
            "Epoch 24 Iteration 6300 - Train Loss: 0.002532 - Dev Loss: 0.828017\n",
            "Epoch 24 Iteration 6310 - Train Loss: 0.002466 - Dev Loss: 0.826584\n",
            "Epoch 24 Iteration 6320 - Train Loss: 0.002819 - Dev Loss: 0.831147\n",
            "Epoch 24 Iteration 6330 - Train Loss: 0.002314 - Dev Loss: 0.830694\n",
            "Epoch 24 Iteration 6340 - Train Loss: 0.002275 - Dev Loss: 0.829576\n",
            "Epoch 24 Iteration 6350 - Train Loss: 0.002221 - Dev Loss: 0.829537\n",
            "Epoch 24 Iteration 6360 - Train Loss: 0.002139 - Dev Loss: 0.829457\n",
            "Epoch 24 Iteration 6370 - Train Loss: 0.002547 - Dev Loss: 0.835232\n",
            "Epoch 24 Iteration 6380 - Train Loss: 0.002799 - Dev Loss: 0.840244\n",
            "Epoch 24 Iteration 6390 - Train Loss: 0.002170 - Dev Loss: 0.837073\n",
            "Epoch 25 Iteration 6400 - Train Loss: 0.002672 - Dev Loss: 0.831711\n",
            "Epoch 25 Iteration 6410 - Train Loss: 0.002076 - Dev Loss: 0.833185\n",
            "Epoch 25 Iteration 6420 - Train Loss: 0.001755 - Dev Loss: 0.834584\n",
            "Epoch 25 Iteration 6430 - Train Loss: 0.002148 - Dev Loss: 0.832695\n",
            "Epoch 25 Iteration 6440 - Train Loss: 0.002140 - Dev Loss: 0.832290\n",
            "Epoch 25 Iteration 6450 - Train Loss: 0.001961 - Dev Loss: 0.833558\n",
            "Epoch 25 Iteration 6460 - Train Loss: 0.002301 - Dev Loss: 0.832467\n",
            "Epoch 25 Iteration 6470 - Train Loss: 0.001983 - Dev Loss: 0.836398\n",
            "Epoch 25 Iteration 6480 - Train Loss: 0.002412 - Dev Loss: 0.830190\n",
            "Epoch 25 Iteration 6490 - Train Loss: 0.001756 - Dev Loss: 0.833568\n",
            "Epoch 25 Iteration 6500 - Train Loss: 0.001947 - Dev Loss: 0.839127\n",
            "Epoch 25 Iteration 6510 - Train Loss: 0.002334 - Dev Loss: 0.841284\n",
            "Epoch 25 Iteration 6520 - Train Loss: 0.002035 - Dev Loss: 0.845892\n",
            "Epoch 25 Iteration 6530 - Train Loss: 0.002379 - Dev Loss: 0.853326\n",
            "Epoch 25 Iteration 6540 - Train Loss: 0.002452 - Dev Loss: 0.855347\n",
            "Epoch 25 Iteration 6550 - Train Loss: 0.002252 - Dev Loss: 0.848552\n",
            "Epoch 25 Iteration 6560 - Train Loss: 0.001762 - Dev Loss: 0.843612\n",
            "Epoch 25 Iteration 6570 - Train Loss: 0.002072 - Dev Loss: 0.845713\n",
            "Epoch 25 Iteration 6580 - Train Loss: 0.002390 - Dev Loss: 0.844213\n",
            "Epoch 25 Iteration 6590 - Train Loss: 0.001776 - Dev Loss: 0.847163\n",
            "Epoch 25 Iteration 6600 - Train Loss: 0.002461 - Dev Loss: 0.851581\n",
            "Epoch 25 Iteration 6610 - Train Loss: 0.002334 - Dev Loss: 0.851240\n",
            "Epoch 25 Iteration 6620 - Train Loss: 0.002061 - Dev Loss: 0.848488\n",
            "Epoch 25 Iteration 6630 - Train Loss: 0.002276 - Dev Loss: 0.846388\n",
            "Epoch 25 Iteration 6640 - Train Loss: 0.002024 - Dev Loss: 0.853963\n",
            "Epoch 25 Iteration 6650 - Train Loss: 0.002053 - Dev Loss: 0.846989\n",
            "Epoch 26 Iteration 6660 - Train Loss: 0.001828 - Dev Loss: 0.838087\n",
            "Epoch 26 Iteration 6670 - Train Loss: 0.001754 - Dev Loss: 0.840860\n",
            "Epoch 26 Iteration 6680 - Train Loss: 0.001638 - Dev Loss: 0.848765\n",
            "Epoch 26 Iteration 6690 - Train Loss: 0.001728 - Dev Loss: 0.848719\n",
            "Epoch 26 Iteration 6700 - Train Loss: 0.001535 - Dev Loss: 0.845737\n",
            "Epoch 26 Iteration 6710 - Train Loss: 0.001608 - Dev Loss: 0.844273\n",
            "Epoch 26 Iteration 6720 - Train Loss: 0.001598 - Dev Loss: 0.844834\n",
            "Epoch 26 Iteration 6730 - Train Loss: 0.001718 - Dev Loss: 0.847153\n",
            "Epoch 26 Iteration 6740 - Train Loss: 0.001724 - Dev Loss: 0.850021\n",
            "Epoch 26 Iteration 6750 - Train Loss: 0.001834 - Dev Loss: 0.853371\n",
            "Epoch 26 Iteration 6760 - Train Loss: 0.001850 - Dev Loss: 0.858257\n",
            "Epoch 26 Iteration 6770 - Train Loss: 0.001605 - Dev Loss: 0.861556\n",
            "Epoch 26 Iteration 6780 - Train Loss: 0.001687 - Dev Loss: 0.862069\n",
            "Epoch 26 Iteration 6790 - Train Loss: 0.001575 - Dev Loss: 0.859630\n",
            "Epoch 26 Iteration 6800 - Train Loss: 0.001689 - Dev Loss: 0.861522\n",
            "Epoch 26 Iteration 6810 - Train Loss: 0.001903 - Dev Loss: 0.863766\n",
            "Epoch 26 Iteration 6820 - Train Loss: 0.001713 - Dev Loss: 0.863289\n",
            "Epoch 26 Iteration 6830 - Train Loss: 0.001623 - Dev Loss: 0.859835\n",
            "Epoch 26 Iteration 6840 - Train Loss: 0.001410 - Dev Loss: 0.858398\n",
            "Epoch 26 Iteration 6850 - Train Loss: 0.001344 - Dev Loss: 0.859367\n",
            "Epoch 26 Iteration 6860 - Train Loss: 0.001849 - Dev Loss: 0.863167\n",
            "Epoch 26 Iteration 6870 - Train Loss: 0.002143 - Dev Loss: 0.859244\n",
            "Epoch 26 Iteration 6880 - Train Loss: 0.002026 - Dev Loss: 0.866401\n",
            "Epoch 26 Iteration 6890 - Train Loss: 0.001801 - Dev Loss: 0.871549\n",
            "Epoch 26 Iteration 6900 - Train Loss: 0.001984 - Dev Loss: 0.874738\n",
            "Epoch 26 Iteration 6910 - Train Loss: 0.001541 - Dev Loss: 0.868330\n",
            "Epoch 27 Iteration 6920 - Train Loss: 0.001486 - Dev Loss: 0.862650\n",
            "Epoch 27 Iteration 6930 - Train Loss: 0.001307 - Dev Loss: 0.864695\n",
            "Epoch 27 Iteration 6940 - Train Loss: 0.001284 - Dev Loss: 0.867587\n",
            "Epoch 27 Iteration 6950 - Train Loss: 0.001489 - Dev Loss: 0.865904\n",
            "Epoch 27 Iteration 6960 - Train Loss: 0.001376 - Dev Loss: 0.868260\n",
            "Epoch 27 Iteration 6970 - Train Loss: 0.001439 - Dev Loss: 0.864450\n",
            "Epoch 27 Iteration 6980 - Train Loss: 0.001340 - Dev Loss: 0.861892\n",
            "Epoch 27 Iteration 6990 - Train Loss: 0.001461 - Dev Loss: 0.865524\n",
            "Epoch 27 Iteration 7000 - Train Loss: 0.001713 - Dev Loss: 0.873748\n",
            "Epoch 27 Iteration 7010 - Train Loss: 0.001305 - Dev Loss: 0.869255\n",
            "Epoch 27 Iteration 7020 - Train Loss: 0.001753 - Dev Loss: 0.871454\n",
            "Epoch 27 Iteration 7030 - Train Loss: 0.001401 - Dev Loss: 0.873801\n",
            "Epoch 27 Iteration 7040 - Train Loss: 0.001590 - Dev Loss: 0.878136\n",
            "Epoch 27 Iteration 7050 - Train Loss: 0.001327 - Dev Loss: 0.881013\n",
            "Epoch 27 Iteration 7060 - Train Loss: 0.001403 - Dev Loss: 0.879134\n",
            "Epoch 27 Iteration 7070 - Train Loss: 0.001186 - Dev Loss: 0.875376\n",
            "Epoch 27 Iteration 7080 - Train Loss: 0.001495 - Dev Loss: 0.876396\n",
            "Epoch 27 Iteration 7090 - Train Loss: 0.001517 - Dev Loss: 0.877087\n",
            "Epoch 27 Iteration 7100 - Train Loss: 0.001353 - Dev Loss: 0.875592\n",
            "Epoch 27 Iteration 7110 - Train Loss: 0.001496 - Dev Loss: 0.881707\n",
            "Epoch 27 Iteration 7120 - Train Loss: 0.001471 - Dev Loss: 0.886855\n",
            "Epoch 27 Iteration 7130 - Train Loss: 0.001439 - Dev Loss: 0.884149\n",
            "Epoch 27 Iteration 7140 - Train Loss: 0.001345 - Dev Loss: 0.882732\n",
            "Epoch 27 Iteration 7150 - Train Loss: 0.001393 - Dev Loss: 0.876905\n",
            "Epoch 27 Iteration 7160 - Train Loss: 0.001416 - Dev Loss: 0.870386\n",
            "Epoch 28 Iteration 7170 - Train Loss: 0.001220 - Dev Loss: 0.876938\n",
            "Epoch 28 Iteration 7180 - Train Loss: 0.001172 - Dev Loss: 0.887445\n",
            "Epoch 28 Iteration 7190 - Train Loss: 0.001118 - Dev Loss: 0.891506\n",
            "Epoch 28 Iteration 7200 - Train Loss: 0.001137 - Dev Loss: 0.889396\n",
            "Epoch 28 Iteration 7210 - Train Loss: 0.001138 - Dev Loss: 0.887971\n",
            "Epoch 28 Iteration 7220 - Train Loss: 0.001049 - Dev Loss: 0.888688\n",
            "Epoch 28 Iteration 7230 - Train Loss: 0.001366 - Dev Loss: 0.886750\n",
            "Epoch 28 Iteration 7240 - Train Loss: 0.001028 - Dev Loss: 0.888463\n",
            "Epoch 28 Iteration 7250 - Train Loss: 0.001075 - Dev Loss: 0.888277\n",
            "Epoch 28 Iteration 7260 - Train Loss: 0.001039 - Dev Loss: 0.885993\n",
            "Epoch 28 Iteration 7270 - Train Loss: 0.001151 - Dev Loss: 0.885388\n",
            "Epoch 28 Iteration 7280 - Train Loss: 0.001084 - Dev Loss: 0.889371\n",
            "Epoch 28 Iteration 7290 - Train Loss: 0.001553 - Dev Loss: 0.890480\n",
            "Epoch 28 Iteration 7300 - Train Loss: 0.002021 - Dev Loss: 0.884317\n",
            "Epoch 28 Iteration 7310 - Train Loss: 0.001470 - Dev Loss: 0.875100\n",
            "Epoch 28 Iteration 7320 - Train Loss: 0.001538 - Dev Loss: 0.882733\n",
            "Epoch 28 Iteration 7330 - Train Loss: 0.001680 - Dev Loss: 0.893195\n",
            "Epoch 28 Iteration 7340 - Train Loss: 0.001523 - Dev Loss: 0.895834\n",
            "Epoch 28 Iteration 7350 - Train Loss: 0.001811 - Dev Loss: 0.900723\n",
            "Epoch 28 Iteration 7360 - Train Loss: 0.001076 - Dev Loss: 0.898659\n",
            "Epoch 28 Iteration 7370 - Train Loss: 0.001703 - Dev Loss: 0.896419\n",
            "Epoch 28 Iteration 7380 - Train Loss: 0.002248 - Dev Loss: 0.887766\n",
            "Epoch 28 Iteration 7390 - Train Loss: 0.002056 - Dev Loss: 0.881595\n",
            "Epoch 28 Iteration 7400 - Train Loss: 0.001728 - Dev Loss: 0.886649\n",
            "Epoch 28 Iteration 7410 - Train Loss: 0.001274 - Dev Loss: 0.893615\n",
            "Epoch 28 Iteration 7420 - Train Loss: 0.001387 - Dev Loss: 0.899030\n",
            "Epoch 29 Iteration 7430 - Train Loss: 0.001072 - Dev Loss: 0.894316\n",
            "Epoch 29 Iteration 7440 - Train Loss: 0.001301 - Dev Loss: 0.898346\n",
            "Epoch 29 Iteration 7450 - Train Loss: 0.000962 - Dev Loss: 0.903039\n",
            "Epoch 29 Iteration 7460 - Train Loss: 0.001079 - Dev Loss: 0.900686\n",
            "Epoch 29 Iteration 7470 - Train Loss: 0.001046 - Dev Loss: 0.901290\n",
            "Epoch 29 Iteration 7480 - Train Loss: 0.000994 - Dev Loss: 0.902503\n",
            "Epoch 29 Iteration 7490 - Train Loss: 0.001058 - Dev Loss: 0.909844\n",
            "Epoch 29 Iteration 7500 - Train Loss: 0.000938 - Dev Loss: 0.910430\n",
            "Epoch 29 Iteration 7510 - Train Loss: 0.001324 - Dev Loss: 0.911408\n",
            "Epoch 29 Iteration 7520 - Train Loss: 0.001033 - Dev Loss: 0.916158\n",
            "Epoch 29 Iteration 7530 - Train Loss: 0.000985 - Dev Loss: 0.913662\n",
            "Epoch 29 Iteration 7540 - Train Loss: 0.001142 - Dev Loss: 0.906921\n",
            "Epoch 29 Iteration 7550 - Train Loss: 0.001039 - Dev Loss: 0.904902\n",
            "Epoch 29 Iteration 7560 - Train Loss: 0.001111 - Dev Loss: 0.910707\n",
            "Epoch 29 Iteration 7570 - Train Loss: 0.001046 - Dev Loss: 0.915928\n",
            "Epoch 29 Iteration 7580 - Train Loss: 0.001134 - Dev Loss: 0.921374\n",
            "Epoch 29 Iteration 7590 - Train Loss: 0.001148 - Dev Loss: 0.923103\n",
            "Epoch 29 Iteration 7600 - Train Loss: 0.000991 - Dev Loss: 0.921014\n",
            "Epoch 29 Iteration 7610 - Train Loss: 0.000899 - Dev Loss: 0.918147\n",
            "Epoch 29 Iteration 7620 - Train Loss: 0.001192 - Dev Loss: 0.916081\n",
            "Epoch 29 Iteration 7630 - Train Loss: 0.000947 - Dev Loss: 0.915772\n",
            "Epoch 29 Iteration 7640 - Train Loss: 0.001100 - Dev Loss: 0.914792\n",
            "Epoch 29 Iteration 7650 - Train Loss: 0.001007 - Dev Loss: 0.911477\n",
            "Epoch 29 Iteration 7660 - Train Loss: 0.001195 - Dev Loss: 0.907705\n",
            "Epoch 29 Iteration 7670 - Train Loss: 0.001490 - Dev Loss: 0.922994\n",
            "Epoch 30 Iteration 7680 - Train Loss: 0.001066 - Dev Loss: 0.928663\n",
            "Epoch 30 Iteration 7690 - Train Loss: 0.000974 - Dev Loss: 0.923245\n",
            "Epoch 30 Iteration 7700 - Train Loss: 0.000805 - Dev Loss: 0.918902\n",
            "Epoch 30 Iteration 7710 - Train Loss: 0.000834 - Dev Loss: 0.916520\n",
            "Epoch 30 Iteration 7720 - Train Loss: 0.000780 - Dev Loss: 0.916777\n",
            "Epoch 30 Iteration 7730 - Train Loss: 0.000682 - Dev Loss: 0.918367\n",
            "Epoch 30 Iteration 7740 - Train Loss: 0.000820 - Dev Loss: 0.920473\n",
            "Epoch 30 Iteration 7750 - Train Loss: 0.000879 - Dev Loss: 0.922653\n",
            "Epoch 30 Iteration 7760 - Train Loss: 0.000953 - Dev Loss: 0.925946\n",
            "Epoch 30 Iteration 7770 - Train Loss: 0.001201 - Dev Loss: 0.927084\n",
            "Epoch 30 Iteration 7780 - Train Loss: 0.000987 - Dev Loss: 0.926730\n",
            "Epoch 30 Iteration 7790 - Train Loss: 0.001095 - Dev Loss: 0.921579\n",
            "Epoch 30 Iteration 7800 - Train Loss: 0.000944 - Dev Loss: 0.917338\n",
            "Epoch 30 Iteration 7810 - Train Loss: 0.000946 - Dev Loss: 0.921562\n",
            "Epoch 30 Iteration 7820 - Train Loss: 0.000930 - Dev Loss: 0.934163\n",
            "Epoch 30 Iteration 7830 - Train Loss: 0.000919 - Dev Loss: 0.938500\n",
            "Epoch 30 Iteration 7840 - Train Loss: 0.000768 - Dev Loss: 0.934105\n",
            "Epoch 30 Iteration 7850 - Train Loss: 0.000878 - Dev Loss: 0.928844\n",
            "Epoch 30 Iteration 7860 - Train Loss: 0.000990 - Dev Loss: 0.928199\n",
            "Epoch 30 Iteration 7870 - Train Loss: 0.000984 - Dev Loss: 0.930416\n",
            "Epoch 30 Iteration 7880 - Train Loss: 0.000888 - Dev Loss: 0.929229\n",
            "Epoch 30 Iteration 7890 - Train Loss: 0.000875 - Dev Loss: 0.928684\n",
            "Epoch 30 Iteration 7900 - Train Loss: 0.000847 - Dev Loss: 0.929180\n",
            "Epoch 30 Iteration 7910 - Train Loss: 0.000904 - Dev Loss: 0.926811\n",
            "Epoch 30 Iteration 7920 - Train Loss: 0.000833 - Dev Loss: 0.926991\n",
            "Epoch 30 Iteration 7930 - Train Loss: 0.000759 - Dev Loss: 0.925701\n",
            "Epoch 31 Iteration 7940 - Train Loss: 0.000731 - Dev Loss: 0.928083\n",
            "Epoch 31 Iteration 7950 - Train Loss: 0.000763 - Dev Loss: 0.935027\n",
            "Epoch 31 Iteration 7960 - Train Loss: 0.000732 - Dev Loss: 0.933926\n",
            "Epoch 31 Iteration 7970 - Train Loss: 0.000567 - Dev Loss: 0.929025\n",
            "Epoch 31 Iteration 7980 - Train Loss: 0.000620 - Dev Loss: 0.927847\n",
            "Epoch 31 Iteration 7990 - Train Loss: 0.000674 - Dev Loss: 0.929354\n",
            "Epoch 31 Iteration 8000 - Train Loss: 0.000670 - Dev Loss: 0.933149\n",
            "Epoch 31 Iteration 8010 - Train Loss: 0.000667 - Dev Loss: 0.931895\n",
            "Epoch 31 Iteration 8020 - Train Loss: 0.000789 - Dev Loss: 0.932331\n",
            "Epoch 31 Iteration 8030 - Train Loss: 0.000725 - Dev Loss: 0.934473\n",
            "Epoch 31 Iteration 8040 - Train Loss: 0.000629 - Dev Loss: 0.936829\n",
            "Epoch 31 Iteration 8050 - Train Loss: 0.000633 - Dev Loss: 0.937260\n",
            "Epoch 31 Iteration 8060 - Train Loss: 0.000624 - Dev Loss: 0.938542\n",
            "Epoch 31 Iteration 8070 - Train Loss: 0.001444 - Dev Loss: 0.943622\n",
            "Epoch 31 Iteration 8080 - Train Loss: 0.001016 - Dev Loss: 0.948964\n",
            "Epoch 31 Iteration 8090 - Train Loss: 0.000747 - Dev Loss: 0.950922\n",
            "Epoch 31 Iteration 8100 - Train Loss: 0.000764 - Dev Loss: 0.942637\n",
            "Epoch 31 Iteration 8110 - Train Loss: 0.000685 - Dev Loss: 0.938537\n",
            "Epoch 31 Iteration 8120 - Train Loss: 0.000908 - Dev Loss: 0.938524\n",
            "Epoch 31 Iteration 8130 - Train Loss: 0.000794 - Dev Loss: 0.938500\n",
            "Epoch 31 Iteration 8140 - Train Loss: 0.000775 - Dev Loss: 0.943181\n",
            "Epoch 31 Iteration 8150 - Train Loss: 0.000670 - Dev Loss: 0.947431\n",
            "Epoch 31 Iteration 8160 - Train Loss: 0.000774 - Dev Loss: 0.947233\n",
            "Epoch 31 Iteration 8170 - Train Loss: 0.000595 - Dev Loss: 0.949229\n",
            "Epoch 31 Iteration 8180 - Train Loss: 0.000719 - Dev Loss: 0.947129\n",
            "Epoch 31 Iteration 8190 - Train Loss: 0.000742 - Dev Loss: 0.941044\n",
            "Epoch 32 Iteration 8200 - Train Loss: 0.000725 - Dev Loss: 0.941040\n",
            "Epoch 32 Iteration 8210 - Train Loss: 0.000539 - Dev Loss: 0.943951\n",
            "Epoch 32 Iteration 8220 - Train Loss: 0.000577 - Dev Loss: 0.943720\n",
            "Epoch 32 Iteration 8230 - Train Loss: 0.000470 - Dev Loss: 0.942508\n",
            "Epoch 32 Iteration 8240 - Train Loss: 0.000693 - Dev Loss: 0.940493\n",
            "Epoch 32 Iteration 8250 - Train Loss: 0.000578 - Dev Loss: 0.938958\n",
            "Epoch 32 Iteration 8260 - Train Loss: 0.000590 - Dev Loss: 0.943490\n",
            "Epoch 32 Iteration 8270 - Train Loss: 0.000584 - Dev Loss: 0.949938\n",
            "Epoch 32 Iteration 8280 - Train Loss: 0.000497 - Dev Loss: 0.951314\n",
            "Epoch 32 Iteration 8290 - Train Loss: 0.000596 - Dev Loss: 0.950169\n",
            "Epoch 32 Iteration 8300 - Train Loss: 0.000611 - Dev Loss: 0.951504\n",
            "Epoch 32 Iteration 8310 - Train Loss: 0.000632 - Dev Loss: 0.953162\n",
            "Epoch 32 Iteration 8320 - Train Loss: 0.000596 - Dev Loss: 0.948373\n",
            "Epoch 32 Iteration 8330 - Train Loss: 0.000551 - Dev Loss: 0.949701\n",
            "Epoch 32 Iteration 8340 - Train Loss: 0.000644 - Dev Loss: 0.953766\n",
            "Epoch 32 Iteration 8350 - Train Loss: 0.000544 - Dev Loss: 0.949013\n",
            "Epoch 32 Iteration 8360 - Train Loss: 0.000664 - Dev Loss: 0.950831\n",
            "Epoch 32 Iteration 8370 - Train Loss: 0.000506 - Dev Loss: 0.955246\n",
            "Epoch 32 Iteration 8380 - Train Loss: 0.000655 - Dev Loss: 0.955908\n",
            "Epoch 32 Iteration 8390 - Train Loss: 0.000532 - Dev Loss: 0.956246\n",
            "Epoch 32 Iteration 8400 - Train Loss: 0.000584 - Dev Loss: 0.957057\n",
            "Epoch 32 Iteration 8410 - Train Loss: 0.000589 - Dev Loss: 0.954335\n",
            "Epoch 32 Iteration 8420 - Train Loss: 0.000509 - Dev Loss: 0.952275\n",
            "Epoch 32 Iteration 8430 - Train Loss: 0.000560 - Dev Loss: 0.956427\n",
            "Epoch 32 Iteration 8440 - Train Loss: 0.000643 - Dev Loss: 0.961003\n",
            "Epoch 33 Iteration 8450 - Train Loss: 0.000568 - Dev Loss: 0.957093\n",
            "Epoch 33 Iteration 8460 - Train Loss: 0.000516 - Dev Loss: 0.953167\n",
            "Epoch 33 Iteration 8470 - Train Loss: 0.000512 - Dev Loss: 0.949567\n",
            "Epoch 33 Iteration 8480 - Train Loss: 0.000445 - Dev Loss: 0.951804\n",
            "Epoch 33 Iteration 8490 - Train Loss: 0.000451 - Dev Loss: 0.955783\n",
            "Epoch 33 Iteration 8500 - Train Loss: 0.000564 - Dev Loss: 0.957306\n",
            "Epoch 33 Iteration 8510 - Train Loss: 0.000495 - Dev Loss: 0.956068\n",
            "Epoch 33 Iteration 8520 - Train Loss: 0.000469 - Dev Loss: 0.957069\n",
            "Epoch 33 Iteration 8530 - Train Loss: 0.000401 - Dev Loss: 0.957455\n",
            "Epoch 33 Iteration 8540 - Train Loss: 0.000450 - Dev Loss: 0.957964\n",
            "Epoch 33 Iteration 8550 - Train Loss: 0.000457 - Dev Loss: 0.957073\n",
            "Epoch 33 Iteration 8560 - Train Loss: 0.000433 - Dev Loss: 0.955513\n",
            "Epoch 33 Iteration 8570 - Train Loss: 0.000464 - Dev Loss: 0.956563\n",
            "Epoch 33 Iteration 8580 - Train Loss: 0.000475 - Dev Loss: 0.960620\n",
            "Epoch 33 Iteration 8590 - Train Loss: 0.000560 - Dev Loss: 0.962699\n",
            "Epoch 33 Iteration 8600 - Train Loss: 0.000494 - Dev Loss: 0.960523\n",
            "Epoch 33 Iteration 8610 - Train Loss: 0.000543 - Dev Loss: 0.960641\n",
            "Epoch 33 Iteration 8620 - Train Loss: 0.000529 - Dev Loss: 0.961748\n",
            "Epoch 33 Iteration 8630 - Train Loss: 0.000426 - Dev Loss: 0.961710\n",
            "Epoch 33 Iteration 8640 - Train Loss: 0.000454 - Dev Loss: 0.962776\n",
            "Epoch 33 Iteration 8650 - Train Loss: 0.000525 - Dev Loss: 0.965572\n",
            "Epoch 33 Iteration 8660 - Train Loss: 0.000476 - Dev Loss: 0.967322\n",
            "Epoch 33 Iteration 8670 - Train Loss: 0.000464 - Dev Loss: 0.968999\n",
            "Epoch 33 Iteration 8680 - Train Loss: 0.000499 - Dev Loss: 0.965881\n",
            "Epoch 33 Iteration 8690 - Train Loss: 0.000532 - Dev Loss: 0.965434\n",
            "Epoch 33 Iteration 8700 - Train Loss: 0.000487 - Dev Loss: 0.974024\n",
            "Epoch 34 Iteration 8710 - Train Loss: 0.000439 - Dev Loss: 0.977455\n",
            "Epoch 34 Iteration 8720 - Train Loss: 0.000403 - Dev Loss: 0.974837\n",
            "Epoch 34 Iteration 8730 - Train Loss: 0.000351 - Dev Loss: 0.971778\n",
            "Epoch 34 Iteration 8740 - Train Loss: 0.000428 - Dev Loss: 0.970316\n",
            "Epoch 34 Iteration 8750 - Train Loss: 0.000398 - Dev Loss: 0.969644\n",
            "Epoch 34 Iteration 8760 - Train Loss: 0.000387 - Dev Loss: 0.971249\n",
            "Epoch 34 Iteration 8770 - Train Loss: 0.000399 - Dev Loss: 0.968913\n",
            "Epoch 34 Iteration 8780 - Train Loss: 0.000373 - Dev Loss: 0.969637\n",
            "Epoch 34 Iteration 8790 - Train Loss: 0.000415 - Dev Loss: 0.971331\n",
            "Epoch 34 Iteration 8800 - Train Loss: 0.000416 - Dev Loss: 0.971834\n",
            "Epoch 34 Iteration 8810 - Train Loss: 0.000404 - Dev Loss: 0.972276\n",
            "Epoch 34 Iteration 8820 - Train Loss: 0.000375 - Dev Loss: 0.975830\n",
            "Epoch 34 Iteration 8830 - Train Loss: 0.000437 - Dev Loss: 0.976585\n",
            "Epoch 34 Iteration 8840 - Train Loss: 0.000470 - Dev Loss: 0.974434\n",
            "Epoch 34 Iteration 8850 - Train Loss: 0.000432 - Dev Loss: 0.975519\n",
            "Epoch 34 Iteration 8860 - Train Loss: 0.000440 - Dev Loss: 0.975414\n",
            "Epoch 34 Iteration 8870 - Train Loss: 0.000402 - Dev Loss: 0.975639\n",
            "Epoch 34 Iteration 8880 - Train Loss: 0.000369 - Dev Loss: 0.977117\n",
            "Epoch 34 Iteration 8890 - Train Loss: 0.000348 - Dev Loss: 0.978051\n",
            "Epoch 34 Iteration 8900 - Train Loss: 0.000428 - Dev Loss: 0.979210\n",
            "Epoch 34 Iteration 8910 - Train Loss: 0.000370 - Dev Loss: 0.977639\n",
            "Epoch 34 Iteration 8920 - Train Loss: 0.000450 - Dev Loss: 0.984199\n",
            "Epoch 34 Iteration 8930 - Train Loss: 0.000390 - Dev Loss: 0.984835\n",
            "Epoch 34 Iteration 8940 - Train Loss: 0.000406 - Dev Loss: 0.981453\n",
            "Epoch 34 Iteration 8950 - Train Loss: 0.000467 - Dev Loss: 0.979569\n",
            "Epoch 35 Iteration 8960 - Train Loss: 0.000404 - Dev Loss: 0.977529\n",
            "Epoch 35 Iteration 8970 - Train Loss: 0.000360 - Dev Loss: 0.977695\n",
            "Epoch 35 Iteration 8980 - Train Loss: 0.000372 - Dev Loss: 0.981333\n",
            "Epoch 35 Iteration 8990 - Train Loss: 0.000348 - Dev Loss: 0.982860\n",
            "Epoch 35 Iteration 9000 - Train Loss: 0.000331 - Dev Loss: 0.983364\n",
            "Epoch 35 Iteration 9010 - Train Loss: 0.000343 - Dev Loss: 0.984256\n",
            "Epoch 35 Iteration 9020 - Train Loss: 0.000373 - Dev Loss: 0.983106\n",
            "Epoch 35 Iteration 9030 - Train Loss: 0.000322 - Dev Loss: 0.982060\n",
            "Epoch 35 Iteration 9040 - Train Loss: 0.000341 - Dev Loss: 0.981937\n",
            "Epoch 35 Iteration 9050 - Train Loss: 0.000349 - Dev Loss: 0.985416\n",
            "Epoch 35 Iteration 9060 - Train Loss: 0.000290 - Dev Loss: 0.987200\n",
            "Epoch 35 Iteration 9070 - Train Loss: 0.000318 - Dev Loss: 0.984808\n",
            "Epoch 35 Iteration 9080 - Train Loss: 0.000318 - Dev Loss: 0.982407\n",
            "Epoch 35 Iteration 9090 - Train Loss: 0.000351 - Dev Loss: 0.983461\n",
            "Epoch 35 Iteration 9100 - Train Loss: 0.000361 - Dev Loss: 0.986789\n",
            "Epoch 35 Iteration 9110 - Train Loss: 0.000367 - Dev Loss: 0.987488\n",
            "Epoch 35 Iteration 9120 - Train Loss: 0.000371 - Dev Loss: 0.986298\n",
            "Epoch 35 Iteration 9130 - Train Loss: 0.000350 - Dev Loss: 0.985909\n",
            "Epoch 35 Iteration 9140 - Train Loss: 0.000323 - Dev Loss: 0.987456\n",
            "Epoch 35 Iteration 9150 - Train Loss: 0.000390 - Dev Loss: 0.990198\n",
            "Epoch 35 Iteration 9160 - Train Loss: 0.000372 - Dev Loss: 0.992084\n",
            "Epoch 35 Iteration 9170 - Train Loss: 0.000307 - Dev Loss: 0.990985\n",
            "Epoch 35 Iteration 9180 - Train Loss: 0.000356 - Dev Loss: 0.991671\n",
            "Epoch 35 Iteration 9190 - Train Loss: 0.000324 - Dev Loss: 0.991567\n",
            "Epoch 35 Iteration 9200 - Train Loss: 0.000395 - Dev Loss: 0.997401\n",
            "Epoch 35 Iteration 9210 - Train Loss: 0.000357 - Dev Loss: 0.998384\n",
            "Epoch 36 Iteration 9220 - Train Loss: 0.000310 - Dev Loss: 0.996260\n",
            "Epoch 36 Iteration 9230 - Train Loss: 0.000299 - Dev Loss: 0.996035\n",
            "Epoch 36 Iteration 9240 - Train Loss: 0.000324 - Dev Loss: 0.997542\n",
            "Epoch 36 Iteration 9250 - Train Loss: 0.000276 - Dev Loss: 0.996855\n",
            "Epoch 36 Iteration 9260 - Train Loss: 0.000287 - Dev Loss: 0.997005\n",
            "Epoch 36 Iteration 9270 - Train Loss: 0.000289 - Dev Loss: 0.995628\n",
            "Epoch 36 Iteration 9280 - Train Loss: 0.000286 - Dev Loss: 0.993865\n",
            "Epoch 36 Iteration 9290 - Train Loss: 0.000322 - Dev Loss: 0.996281\n",
            "Epoch 36 Iteration 9300 - Train Loss: 0.000310 - Dev Loss: 0.995359\n",
            "Epoch 36 Iteration 9310 - Train Loss: 0.000286 - Dev Loss: 0.996582\n",
            "Epoch 36 Iteration 9320 - Train Loss: 0.000250 - Dev Loss: 0.996999\n",
            "Epoch 36 Iteration 9330 - Train Loss: 0.000322 - Dev Loss: 0.997882\n",
            "Epoch 36 Iteration 9340 - Train Loss: 0.000295 - Dev Loss: 0.998640\n",
            "Epoch 36 Iteration 9350 - Train Loss: 0.000326 - Dev Loss: 1.000003\n",
            "Epoch 36 Iteration 9360 - Train Loss: 0.000300 - Dev Loss: 1.000750\n",
            "Epoch 36 Iteration 9370 - Train Loss: 0.000299 - Dev Loss: 0.997617\n",
            "Epoch 36 Iteration 9380 - Train Loss: 0.000312 - Dev Loss: 0.996612\n",
            "Epoch 36 Iteration 9390 - Train Loss: 0.000298 - Dev Loss: 0.997649\n",
            "Epoch 36 Iteration 9400 - Train Loss: 0.000295 - Dev Loss: 1.001275\n",
            "Epoch 36 Iteration 9410 - Train Loss: 0.000298 - Dev Loss: 1.002816\n",
            "Epoch 36 Iteration 9420 - Train Loss: 0.000321 - Dev Loss: 1.000698\n",
            "Epoch 36 Iteration 9430 - Train Loss: 0.000273 - Dev Loss: 1.002386\n",
            "Epoch 36 Iteration 9440 - Train Loss: 0.000292 - Dev Loss: 1.009134\n",
            "Epoch 36 Iteration 9450 - Train Loss: 0.000281 - Dev Loss: 1.011332\n",
            "Epoch 36 Iteration 9460 - Train Loss: 0.000329 - Dev Loss: 1.009238\n",
            "Epoch 36 Iteration 9470 - Train Loss: 0.000281 - Dev Loss: 1.005812\n",
            "Epoch 37 Iteration 9480 - Train Loss: 0.000259 - Dev Loss: 1.007566\n",
            "Epoch 37 Iteration 9490 - Train Loss: 0.000251 - Dev Loss: 1.009784\n",
            "Epoch 37 Iteration 9500 - Train Loss: 0.000242 - Dev Loss: 1.010846\n",
            "Epoch 37 Iteration 9510 - Train Loss: 0.000250 - Dev Loss: 1.010890\n",
            "Epoch 37 Iteration 9520 - Train Loss: 0.000264 - Dev Loss: 1.007512\n",
            "Epoch 37 Iteration 9530 - Train Loss: 0.000276 - Dev Loss: 1.009032\n",
            "Epoch 37 Iteration 9540 - Train Loss: 0.000276 - Dev Loss: 1.012342\n",
            "Epoch 37 Iteration 9550 - Train Loss: 0.000291 - Dev Loss: 1.011748\n",
            "Epoch 37 Iteration 9560 - Train Loss: 0.000239 - Dev Loss: 1.010109\n",
            "Epoch 37 Iteration 9570 - Train Loss: 0.000249 - Dev Loss: 1.007594\n",
            "Epoch 37 Iteration 9580 - Train Loss: 0.000220 - Dev Loss: 1.006334\n",
            "Epoch 37 Iteration 9590 - Train Loss: 0.000236 - Dev Loss: 1.012383\n",
            "Epoch 37 Iteration 9600 - Train Loss: 0.000229 - Dev Loss: 1.015281\n",
            "Epoch 37 Iteration 9610 - Train Loss: 0.000257 - Dev Loss: 1.017104\n",
            "Epoch 37 Iteration 9620 - Train Loss: 0.000286 - Dev Loss: 1.018022\n",
            "Epoch 37 Iteration 9630 - Train Loss: 0.000220 - Dev Loss: 1.016767\n",
            "Epoch 37 Iteration 9640 - Train Loss: 0.000261 - Dev Loss: 1.017049\n",
            "Epoch 37 Iteration 9650 - Train Loss: 0.000272 - Dev Loss: 1.015965\n",
            "Epoch 37 Iteration 9660 - Train Loss: 0.000268 - Dev Loss: 1.014035\n",
            "Epoch 37 Iteration 9670 - Train Loss: 0.000240 - Dev Loss: 1.015666\n",
            "Epoch 37 Iteration 9680 - Train Loss: 0.000251 - Dev Loss: 1.018993\n",
            "Epoch 37 Iteration 9690 - Train Loss: 0.000235 - Dev Loss: 1.019101\n",
            "Epoch 37 Iteration 9700 - Train Loss: 0.000255 - Dev Loss: 1.018982\n",
            "Epoch 37 Iteration 9710 - Train Loss: 0.000266 - Dev Loss: 1.021027\n",
            "Epoch 37 Iteration 9720 - Train Loss: 0.000233 - Dev Loss: 1.021609\n",
            "Epoch 38 Iteration 9730 - Train Loss: 0.000261 - Dev Loss: 1.023419\n",
            "Epoch 38 Iteration 9740 - Train Loss: 0.000224 - Dev Loss: 1.021744\n",
            "Epoch 38 Iteration 9750 - Train Loss: 0.000204 - Dev Loss: 1.020376\n",
            "Epoch 38 Iteration 9760 - Train Loss: 0.000192 - Dev Loss: 1.021048\n",
            "Epoch 38 Iteration 9770 - Train Loss: 0.000195 - Dev Loss: 1.020627\n",
            "Epoch 38 Iteration 9780 - Train Loss: 0.000209 - Dev Loss: 1.019961\n",
            "Epoch 38 Iteration 9790 - Train Loss: 0.000242 - Dev Loss: 1.019326\n",
            "Epoch 38 Iteration 9800 - Train Loss: 0.000195 - Dev Loss: 1.020016\n",
            "Epoch 38 Iteration 9810 - Train Loss: 0.000207 - Dev Loss: 1.021714\n",
            "Epoch 38 Iteration 9820 - Train Loss: 0.000206 - Dev Loss: 1.022533\n",
            "Epoch 38 Iteration 9830 - Train Loss: 0.000247 - Dev Loss: 1.021599\n",
            "Epoch 38 Iteration 9840 - Train Loss: 0.000187 - Dev Loss: 1.023916\n",
            "Epoch 38 Iteration 9850 - Train Loss: 0.000243 - Dev Loss: 1.026281\n",
            "Epoch 38 Iteration 9860 - Train Loss: 0.000255 - Dev Loss: 1.025492\n",
            "Epoch 38 Iteration 9870 - Train Loss: 0.000204 - Dev Loss: 1.025627\n",
            "Epoch 38 Iteration 9880 - Train Loss: 0.000228 - Dev Loss: 1.027047\n",
            "Epoch 38 Iteration 9890 - Train Loss: 0.000232 - Dev Loss: 1.030430\n",
            "Epoch 38 Iteration 9900 - Train Loss: 0.000210 - Dev Loss: 1.029986\n",
            "Epoch 38 Iteration 9910 - Train Loss: 0.000188 - Dev Loss: 1.029961\n",
            "Epoch 38 Iteration 9920 - Train Loss: 0.000230 - Dev Loss: 1.028606\n",
            "Epoch 38 Iteration 9930 - Train Loss: 0.000218 - Dev Loss: 1.028173\n",
            "Epoch 38 Iteration 9940 - Train Loss: 0.000207 - Dev Loss: 1.027790\n",
            "Epoch 38 Iteration 9950 - Train Loss: 0.000228 - Dev Loss: 1.027269\n",
            "Epoch 38 Iteration 9960 - Train Loss: 0.000193 - Dev Loss: 1.028253\n",
            "Epoch 38 Iteration 9970 - Train Loss: 0.000252 - Dev Loss: 1.030629\n",
            "Epoch 38 Iteration 9980 - Train Loss: 0.000228 - Dev Loss: 1.032373\n",
            "Epoch 39 Iteration 9990 - Train Loss: 0.000222 - Dev Loss: 1.033255\n",
            "Epoch 39 Iteration 10000 - Train Loss: 0.000197 - Dev Loss: 1.032828\n",
            "Epoch 39 Iteration 10010 - Train Loss: 0.000175 - Dev Loss: 1.034049\n",
            "Epoch 39 Iteration 10020 - Train Loss: 0.000165 - Dev Loss: 1.036163\n",
            "Epoch 39 Iteration 10030 - Train Loss: 0.000181 - Dev Loss: 1.041000\n",
            "Epoch 39 Iteration 10040 - Train Loss: 0.000185 - Dev Loss: 1.042118\n",
            "Epoch 39 Iteration 10050 - Train Loss: 0.000186 - Dev Loss: 1.040191\n",
            "Epoch 39 Iteration 10060 - Train Loss: 0.000176 - Dev Loss: 1.037863\n",
            "Epoch 39 Iteration 10070 - Train Loss: 0.000225 - Dev Loss: 1.035783\n",
            "Epoch 39 Iteration 10080 - Train Loss: 0.000185 - Dev Loss: 1.036145\n",
            "Epoch 39 Iteration 10090 - Train Loss: 0.000165 - Dev Loss: 1.036149\n",
            "Epoch 39 Iteration 10100 - Train Loss: 0.000199 - Dev Loss: 1.036954\n",
            "Epoch 39 Iteration 10110 - Train Loss: 0.000188 - Dev Loss: 1.037691\n",
            "Epoch 39 Iteration 10120 - Train Loss: 0.000170 - Dev Loss: 1.038007\n",
            "Epoch 39 Iteration 10130 - Train Loss: 0.000212 - Dev Loss: 1.039044\n",
            "Epoch 39 Iteration 10140 - Train Loss: 0.000168 - Dev Loss: 1.042280\n",
            "Epoch 39 Iteration 10150 - Train Loss: 0.000189 - Dev Loss: 1.041454\n",
            "Epoch 39 Iteration 10160 - Train Loss: 0.000167 - Dev Loss: 1.040724\n",
            "Epoch 39 Iteration 10170 - Train Loss: 0.000190 - Dev Loss: 1.039719\n",
            "Epoch 39 Iteration 10180 - Train Loss: 0.000185 - Dev Loss: 1.039351\n",
            "Epoch 39 Iteration 10190 - Train Loss: 0.000173 - Dev Loss: 1.040549\n",
            "Epoch 39 Iteration 10200 - Train Loss: 0.000206 - Dev Loss: 1.043509\n",
            "Epoch 39 Iteration 10210 - Train Loss: 0.000224 - Dev Loss: 1.046755\n",
            "Epoch 39 Iteration 10220 - Train Loss: 0.000202 - Dev Loss: 1.047157\n",
            "Epoch 39 Iteration 10230 - Train Loss: 0.000183 - Dev Loss: 1.045356\n",
            "Epoch 40 Iteration 10240 - Train Loss: 0.000181 - Dev Loss: 1.040911\n",
            "Epoch 40 Iteration 10250 - Train Loss: 0.000174 - Dev Loss: 1.039605\n",
            "Epoch 40 Iteration 10260 - Train Loss: 0.000164 - Dev Loss: 1.043385\n",
            "Epoch 40 Iteration 10270 - Train Loss: 0.000144 - Dev Loss: 1.045211\n",
            "Epoch 40 Iteration 10280 - Train Loss: 0.000174 - Dev Loss: 1.045646\n",
            "Epoch 40 Iteration 10290 - Train Loss: 0.000167 - Dev Loss: 1.044903\n",
            "Epoch 40 Iteration 10300 - Train Loss: 0.000187 - Dev Loss: 1.045600\n",
            "Epoch 40 Iteration 10310 - Train Loss: 0.000180 - Dev Loss: 1.048501\n",
            "Epoch 40 Iteration 10320 - Train Loss: 0.000174 - Dev Loss: 1.048142\n",
            "Epoch 40 Iteration 10330 - Train Loss: 0.000143 - Dev Loss: 1.047681\n",
            "Epoch 40 Iteration 10340 - Train Loss: 0.000151 - Dev Loss: 1.047784\n",
            "Epoch 40 Iteration 10350 - Train Loss: 0.000145 - Dev Loss: 1.046287\n",
            "Epoch 40 Iteration 10360 - Train Loss: 0.000138 - Dev Loss: 1.046009\n",
            "Epoch 40 Iteration 10370 - Train Loss: 0.000177 - Dev Loss: 1.047497\n",
            "Epoch 40 Iteration 10380 - Train Loss: 0.000158 - Dev Loss: 1.047950\n",
            "Epoch 40 Iteration 10390 - Train Loss: 0.000186 - Dev Loss: 1.049733\n",
            "Epoch 40 Iteration 10400 - Train Loss: 0.000136 - Dev Loss: 1.050864\n",
            "Epoch 40 Iteration 10410 - Train Loss: 0.000148 - Dev Loss: 1.049352\n",
            "Epoch 40 Iteration 10420 - Train Loss: 0.000136 - Dev Loss: 1.051506\n",
            "Epoch 40 Iteration 10430 - Train Loss: 0.000155 - Dev Loss: 1.054581\n",
            "Epoch 40 Iteration 10440 - Train Loss: 0.000147 - Dev Loss: 1.056332\n",
            "Epoch 40 Iteration 10450 - Train Loss: 0.000160 - Dev Loss: 1.055355\n",
            "Epoch 40 Iteration 10460 - Train Loss: 0.000166 - Dev Loss: 1.056584\n",
            "Epoch 40 Iteration 10470 - Train Loss: 0.000188 - Dev Loss: 1.055808\n",
            "Epoch 40 Iteration 10480 - Train Loss: 0.000155 - Dev Loss: 1.053534\n",
            "Epoch 40 Iteration 10490 - Train Loss: 0.000160 - Dev Loss: 1.053916\n",
            "Epoch 41 Iteration 10500 - Train Loss: 0.000148 - Dev Loss: 1.056907\n",
            "Epoch 41 Iteration 10510 - Train Loss: 0.000126 - Dev Loss: 1.057792\n",
            "Epoch 41 Iteration 10520 - Train Loss: 0.000118 - Dev Loss: 1.057462\n",
            "Epoch 41 Iteration 10530 - Train Loss: 0.000165 - Dev Loss: 1.059474\n",
            "Epoch 41 Iteration 10540 - Train Loss: 0.000125 - Dev Loss: 1.060698\n",
            "Epoch 41 Iteration 10550 - Train Loss: 0.000132 - Dev Loss: 1.060311\n",
            "Epoch 41 Iteration 10560 - Train Loss: 0.000141 - Dev Loss: 1.060315\n",
            "Epoch 41 Iteration 10570 - Train Loss: 0.000128 - Dev Loss: 1.060633\n",
            "Epoch 41 Iteration 10580 - Train Loss: 0.000147 - Dev Loss: 1.063255\n",
            "Epoch 41 Iteration 10590 - Train Loss: 0.000153 - Dev Loss: 1.065014\n",
            "Epoch 41 Iteration 10600 - Train Loss: 0.000147 - Dev Loss: 1.064376\n",
            "Epoch 41 Iteration 10610 - Train Loss: 0.000132 - Dev Loss: 1.063511\n",
            "Epoch 41 Iteration 10620 - Train Loss: 0.000145 - Dev Loss: 1.064200\n",
            "Epoch 41 Iteration 10630 - Train Loss: 0.000146 - Dev Loss: 1.067367\n",
            "Epoch 41 Iteration 10640 - Train Loss: 0.000138 - Dev Loss: 1.070240\n",
            "Epoch 41 Iteration 10650 - Train Loss: 0.000143 - Dev Loss: 1.070113\n",
            "Epoch 41 Iteration 10660 - Train Loss: 0.000136 - Dev Loss: 1.068228\n",
            "Epoch 41 Iteration 10670 - Train Loss: 0.000149 - Dev Loss: 1.066233\n",
            "Epoch 41 Iteration 10680 - Train Loss: 0.000160 - Dev Loss: 1.065037\n",
            "Epoch 41 Iteration 10690 - Train Loss: 0.000128 - Dev Loss: 1.070922\n",
            "Epoch 41 Iteration 10700 - Train Loss: 0.000150 - Dev Loss: 1.070647\n",
            "Epoch 41 Iteration 10710 - Train Loss: 0.000136 - Dev Loss: 1.068629\n",
            "Epoch 41 Iteration 10720 - Train Loss: 0.000137 - Dev Loss: 1.067784\n",
            "Epoch 41 Iteration 10730 - Train Loss: 0.000124 - Dev Loss: 1.067964\n",
            "Epoch 41 Iteration 10740 - Train Loss: 0.000138 - Dev Loss: 1.068402\n",
            "Epoch 41 Iteration 10750 - Train Loss: 0.000133 - Dev Loss: 1.067443\n",
            "Epoch 42 Iteration 10760 - Train Loss: 0.000128 - Dev Loss: 1.065643\n",
            "Epoch 42 Iteration 10770 - Train Loss: 0.000106 - Dev Loss: 1.066179\n",
            "Epoch 42 Iteration 10780 - Train Loss: 0.000113 - Dev Loss: 1.066354\n",
            "Epoch 42 Iteration 10790 - Train Loss: 0.000112 - Dev Loss: 1.066758\n",
            "Epoch 42 Iteration 10800 - Train Loss: 0.000123 - Dev Loss: 1.070337\n",
            "Epoch 42 Iteration 10810 - Train Loss: 0.000122 - Dev Loss: 1.068059\n",
            "Epoch 42 Iteration 10820 - Train Loss: 0.000113 - Dev Loss: 1.070133\n",
            "Epoch 42 Iteration 10830 - Train Loss: 0.000131 - Dev Loss: 1.072268\n",
            "Epoch 42 Iteration 10840 - Train Loss: 0.000118 - Dev Loss: 1.075315\n",
            "Epoch 42 Iteration 10850 - Train Loss: 0.000119 - Dev Loss: 1.076448\n",
            "Epoch 42 Iteration 10860 - Train Loss: 0.000127 - Dev Loss: 1.073159\n",
            "Epoch 42 Iteration 10870 - Train Loss: 0.000115 - Dev Loss: 1.071181\n",
            "Epoch 42 Iteration 10880 - Train Loss: 0.000124 - Dev Loss: 1.072007\n",
            "Epoch 42 Iteration 10890 - Train Loss: 0.000123 - Dev Loss: 1.076217\n",
            "Epoch 42 Iteration 10900 - Train Loss: 0.000113 - Dev Loss: 1.080001\n",
            "Epoch 42 Iteration 10910 - Train Loss: 0.000120 - Dev Loss: 1.083429\n",
            "Epoch 42 Iteration 10920 - Train Loss: 0.000121 - Dev Loss: 1.083170\n",
            "Epoch 42 Iteration 10930 - Train Loss: 0.000116 - Dev Loss: 1.079756\n",
            "Epoch 42 Iteration 10940 - Train Loss: 0.000137 - Dev Loss: 1.077707\n",
            "Epoch 42 Iteration 10950 - Train Loss: 0.000117 - Dev Loss: 1.076591\n",
            "Epoch 42 Iteration 10960 - Train Loss: 0.000103 - Dev Loss: 1.079710\n",
            "Epoch 42 Iteration 10970 - Train Loss: 0.000103 - Dev Loss: 1.082450\n",
            "Epoch 42 Iteration 10980 - Train Loss: 0.000118 - Dev Loss: 1.081419\n",
            "Epoch 42 Iteration 10990 - Train Loss: 0.000146 - Dev Loss: 1.083026\n",
            "Epoch 42 Iteration 11000 - Train Loss: 0.000108 - Dev Loss: 1.083667\n",
            "Epoch 43 Iteration 11010 - Train Loss: 0.000117 - Dev Loss: 1.084937\n",
            "Epoch 43 Iteration 11020 - Train Loss: 0.000094 - Dev Loss: 1.086027\n",
            "Epoch 43 Iteration 11030 - Train Loss: 0.000098 - Dev Loss: 1.088134\n",
            "Epoch 43 Iteration 11040 - Train Loss: 0.000097 - Dev Loss: 1.088744\n",
            "Epoch 43 Iteration 11050 - Train Loss: 0.000100 - Dev Loss: 1.088976\n",
            "Epoch 43 Iteration 11060 - Train Loss: 0.000101 - Dev Loss: 1.086795\n",
            "Epoch 43 Iteration 11070 - Train Loss: 0.000110 - Dev Loss: 1.086012\n",
            "Epoch 43 Iteration 11080 - Train Loss: 0.000109 - Dev Loss: 1.085006\n",
            "Epoch 43 Iteration 11090 - Train Loss: 0.000109 - Dev Loss: 1.086627\n",
            "Epoch 43 Iteration 11100 - Train Loss: 0.000107 - Dev Loss: 1.089203\n",
            "Epoch 43 Iteration 11110 - Train Loss: 0.000106 - Dev Loss: 1.089565\n",
            "Epoch 43 Iteration 11120 - Train Loss: 0.000106 - Dev Loss: 1.088173\n",
            "Epoch 43 Iteration 11130 - Train Loss: 0.000105 - Dev Loss: 1.087218\n",
            "Epoch 43 Iteration 11140 - Train Loss: 0.000111 - Dev Loss: 1.084969\n",
            "Epoch 43 Iteration 11150 - Train Loss: 0.000102 - Dev Loss: 1.089547\n",
            "Epoch 43 Iteration 11160 - Train Loss: 0.000092 - Dev Loss: 1.092981\n",
            "Epoch 43 Iteration 11170 - Train Loss: 0.000092 - Dev Loss: 1.092701\n",
            "Epoch 43 Iteration 11180 - Train Loss: 0.000102 - Dev Loss: 1.092466\n",
            "Epoch 43 Iteration 11190 - Train Loss: 0.000106 - Dev Loss: 1.092926\n",
            "Epoch 43 Iteration 11200 - Train Loss: 0.000106 - Dev Loss: 1.091343\n",
            "Epoch 43 Iteration 11210 - Train Loss: 0.000096 - Dev Loss: 1.091855\n",
            "Epoch 43 Iteration 11220 - Train Loss: 0.000111 - Dev Loss: 1.090431\n",
            "Epoch 43 Iteration 11230 - Train Loss: 0.000088 - Dev Loss: 1.087445\n",
            "Epoch 43 Iteration 11240 - Train Loss: 0.000120 - Dev Loss: 1.089950\n",
            "Epoch 43 Iteration 11250 - Train Loss: 0.000109 - Dev Loss: 1.092017\n",
            "Epoch 43 Iteration 11260 - Train Loss: 0.000099 - Dev Loss: 1.091906\n",
            "Epoch 44 Iteration 11270 - Train Loss: 0.000102 - Dev Loss: 1.091759\n",
            "Epoch 44 Iteration 11280 - Train Loss: 0.000099 - Dev Loss: 1.093934\n",
            "Epoch 44 Iteration 11290 - Train Loss: 0.000086 - Dev Loss: 1.096095\n",
            "Epoch 44 Iteration 11300 - Train Loss: 0.000097 - Dev Loss: 1.096036\n",
            "Epoch 44 Iteration 11310 - Train Loss: 0.000077 - Dev Loss: 1.095925\n",
            "Epoch 44 Iteration 11320 - Train Loss: 0.000083 - Dev Loss: 1.096580\n",
            "Epoch 44 Iteration 11330 - Train Loss: 0.000084 - Dev Loss: 1.097117\n",
            "Epoch 44 Iteration 11340 - Train Loss: 0.000094 - Dev Loss: 1.097978\n",
            "Epoch 44 Iteration 11350 - Train Loss: 0.000082 - Dev Loss: 1.099500\n",
            "Epoch 44 Iteration 11360 - Train Loss: 0.000099 - Dev Loss: 1.099064\n",
            "Epoch 44 Iteration 11370 - Train Loss: 0.000095 - Dev Loss: 1.098752\n",
            "Epoch 44 Iteration 11380 - Train Loss: 0.000095 - Dev Loss: 1.097788\n",
            "Epoch 44 Iteration 11390 - Train Loss: 0.000077 - Dev Loss: 1.101679\n",
            "Epoch 44 Iteration 11400 - Train Loss: 0.000096 - Dev Loss: 1.103780\n",
            "Epoch 44 Iteration 11410 - Train Loss: 0.000094 - Dev Loss: 1.100751\n",
            "Epoch 44 Iteration 11420 - Train Loss: 0.000090 - Dev Loss: 1.098141\n",
            "Epoch 44 Iteration 11430 - Train Loss: 0.000086 - Dev Loss: 1.096428\n",
            "Epoch 44 Iteration 11440 - Train Loss: 0.000100 - Dev Loss: 1.099586\n",
            "Epoch 44 Iteration 11450 - Train Loss: 0.000088 - Dev Loss: 1.102218\n",
            "Epoch 44 Iteration 11460 - Train Loss: 0.000085 - Dev Loss: 1.100964\n",
            "Epoch 44 Iteration 11470 - Train Loss: 0.000088 - Dev Loss: 1.101687\n",
            "Epoch 44 Iteration 11480 - Train Loss: 0.000081 - Dev Loss: 1.103547\n",
            "Epoch 44 Iteration 11490 - Train Loss: 0.000086 - Dev Loss: 1.104872\n",
            "Epoch 44 Iteration 11500 - Train Loss: 0.000090 - Dev Loss: 1.106218\n",
            "Epoch 44 Iteration 11510 - Train Loss: 0.000081 - Dev Loss: 1.107581\n",
            "Epoch 45 Iteration 11520 - Train Loss: 0.000083 - Dev Loss: 1.109691\n",
            "Epoch 45 Iteration 11530 - Train Loss: 0.000082 - Dev Loss: 1.111645\n",
            "Epoch 45 Iteration 11540 - Train Loss: 0.000080 - Dev Loss: 1.111570\n",
            "Epoch 45 Iteration 11550 - Train Loss: 0.000083 - Dev Loss: 1.111917\n",
            "Epoch 45 Iteration 11560 - Train Loss: 0.000078 - Dev Loss: 1.111825\n",
            "Epoch 45 Iteration 11570 - Train Loss: 0.000068 - Dev Loss: 1.110790\n",
            "Epoch 45 Iteration 11580 - Train Loss: 0.000070 - Dev Loss: 1.108369\n",
            "Epoch 45 Iteration 11590 - Train Loss: 0.000075 - Dev Loss: 1.109432\n",
            "Epoch 45 Iteration 11600 - Train Loss: 0.000079 - Dev Loss: 1.111036\n",
            "Epoch 45 Iteration 11610 - Train Loss: 0.000077 - Dev Loss: 1.109717\n",
            "Epoch 45 Iteration 11620 - Train Loss: 0.000086 - Dev Loss: 1.112162\n",
            "Epoch 45 Iteration 11630 - Train Loss: 0.000078 - Dev Loss: 1.110970\n",
            "Epoch 45 Iteration 11640 - Train Loss: 0.000079 - Dev Loss: 1.107327\n",
            "Epoch 45 Iteration 11650 - Train Loss: 0.000065 - Dev Loss: 1.107621\n",
            "Epoch 45 Iteration 11660 - Train Loss: 0.000079 - Dev Loss: 1.110167\n",
            "Epoch 45 Iteration 11670 - Train Loss: 0.000075 - Dev Loss: 1.113598\n",
            "Epoch 45 Iteration 11680 - Train Loss: 0.000080 - Dev Loss: 1.113109\n",
            "Epoch 45 Iteration 11690 - Train Loss: 0.000082 - Dev Loss: 1.111735\n",
            "Epoch 45 Iteration 11700 - Train Loss: 0.000074 - Dev Loss: 1.112177\n",
            "Epoch 45 Iteration 11710 - Train Loss: 0.000072 - Dev Loss: 1.113935\n",
            "Epoch 45 Iteration 11720 - Train Loss: 0.000078 - Dev Loss: 1.117001\n",
            "Epoch 45 Iteration 11730 - Train Loss: 0.000075 - Dev Loss: 1.116738\n",
            "Epoch 45 Iteration 11740 - Train Loss: 0.000088 - Dev Loss: 1.116368\n",
            "Epoch 45 Iteration 11750 - Train Loss: 0.000084 - Dev Loss: 1.117774\n",
            "Epoch 45 Iteration 11760 - Train Loss: 0.000077 - Dev Loss: 1.117911\n",
            "Epoch 45 Iteration 11770 - Train Loss: 0.000071 - Dev Loss: 1.118242\n",
            "Epoch 46 Iteration 11780 - Train Loss: 0.000076 - Dev Loss: 1.118760\n",
            "Epoch 46 Iteration 11790 - Train Loss: 0.000062 - Dev Loss: 1.120591\n",
            "Epoch 46 Iteration 11800 - Train Loss: 0.000068 - Dev Loss: 1.121929\n",
            "Epoch 46 Iteration 11810 - Train Loss: 0.000060 - Dev Loss: 1.122920\n",
            "Epoch 46 Iteration 11820 - Train Loss: 0.000060 - Dev Loss: 1.124461\n",
            "Epoch 46 Iteration 11830 - Train Loss: 0.000070 - Dev Loss: 1.126803\n",
            "Epoch 46 Iteration 11840 - Train Loss: 0.000060 - Dev Loss: 1.126722\n",
            "Epoch 46 Iteration 11850 - Train Loss: 0.000065 - Dev Loss: 1.125594\n",
            "Epoch 46 Iteration 11860 - Train Loss: 0.000065 - Dev Loss: 1.126972\n",
            "Epoch 46 Iteration 11870 - Train Loss: 0.000065 - Dev Loss: 1.127237\n",
            "Epoch 46 Iteration 11880 - Train Loss: 0.000074 - Dev Loss: 1.126135\n",
            "Epoch 46 Iteration 11890 - Train Loss: 0.000071 - Dev Loss: 1.124056\n",
            "Epoch 46 Iteration 11900 - Train Loss: 0.000067 - Dev Loss: 1.124628\n",
            "Epoch 46 Iteration 11910 - Train Loss: 0.000067 - Dev Loss: 1.124265\n",
            "Epoch 46 Iteration 11920 - Train Loss: 0.000074 - Dev Loss: 1.125516\n",
            "Epoch 46 Iteration 11930 - Train Loss: 0.000057 - Dev Loss: 1.125687\n",
            "Epoch 46 Iteration 11940 - Train Loss: 0.000068 - Dev Loss: 1.128076\n",
            "Epoch 46 Iteration 11950 - Train Loss: 0.000079 - Dev Loss: 1.130552\n",
            "Epoch 46 Iteration 11960 - Train Loss: 0.000065 - Dev Loss: 1.130586\n",
            "Epoch 46 Iteration 11970 - Train Loss: 0.000073 - Dev Loss: 1.130404\n",
            "Epoch 46 Iteration 11980 - Train Loss: 0.000063 - Dev Loss: 1.129379\n",
            "Epoch 46 Iteration 11990 - Train Loss: 0.000060 - Dev Loss: 1.129318\n",
            "Epoch 46 Iteration 12000 - Train Loss: 0.000071 - Dev Loss: 1.129809\n",
            "Epoch 46 Iteration 12010 - Train Loss: 0.000075 - Dev Loss: 1.128196\n",
            "Epoch 46 Iteration 12020 - Train Loss: 0.000066 - Dev Loss: 1.130531\n",
            "Epoch 46 Iteration 12030 - Train Loss: 0.000050 - Dev Loss: 1.134290\n",
            "Epoch 47 Iteration 12040 - Train Loss: 0.000057 - Dev Loss: 1.134542\n",
            "Epoch 47 Iteration 12050 - Train Loss: 0.000070 - Dev Loss: 1.133210\n",
            "Epoch 47 Iteration 12060 - Train Loss: 0.000055 - Dev Loss: 1.133135\n",
            "Epoch 47 Iteration 12070 - Train Loss: 0.000060 - Dev Loss: 1.132225\n",
            "Epoch 47 Iteration 12080 - Train Loss: 0.000050 - Dev Loss: 1.129607\n",
            "Epoch 47 Iteration 12090 - Train Loss: 0.000051 - Dev Loss: 1.130493\n",
            "Epoch 47 Iteration 12100 - Train Loss: 0.000049 - Dev Loss: 1.134264\n",
            "Epoch 47 Iteration 12110 - Train Loss: 0.000052 - Dev Loss: 1.136286\n",
            "Epoch 47 Iteration 12120 - Train Loss: 0.000061 - Dev Loss: 1.135334\n",
            "Epoch 47 Iteration 12130 - Train Loss: 0.000055 - Dev Loss: 1.135792\n",
            "Epoch 47 Iteration 12140 - Train Loss: 0.000053 - Dev Loss: 1.136618\n",
            "Epoch 47 Iteration 12150 - Train Loss: 0.000060 - Dev Loss: 1.137636\n",
            "Epoch 47 Iteration 12160 - Train Loss: 0.000062 - Dev Loss: 1.137624\n",
            "Epoch 47 Iteration 12170 - Train Loss: 0.000055 - Dev Loss: 1.138737\n",
            "Epoch 47 Iteration 12180 - Train Loss: 0.000053 - Dev Loss: 1.138983\n",
            "Epoch 47 Iteration 12190 - Train Loss: 0.000060 - Dev Loss: 1.138348\n",
            "Epoch 47 Iteration 12200 - Train Loss: 0.000056 - Dev Loss: 1.138654\n",
            "Epoch 47 Iteration 12210 - Train Loss: 0.000060 - Dev Loss: 1.140058\n",
            "Epoch 47 Iteration 12220 - Train Loss: 0.000059 - Dev Loss: 1.141083\n",
            "Epoch 47 Iteration 12230 - Train Loss: 0.000058 - Dev Loss: 1.142944\n",
            "Epoch 47 Iteration 12240 - Train Loss: 0.000057 - Dev Loss: 1.142876\n",
            "Epoch 47 Iteration 12250 - Train Loss: 0.000064 - Dev Loss: 1.142382\n",
            "Epoch 47 Iteration 12260 - Train Loss: 0.000062 - Dev Loss: 1.142123\n",
            "Epoch 47 Iteration 12270 - Train Loss: 0.000054 - Dev Loss: 1.145862\n",
            "Epoch 47 Iteration 12280 - Train Loss: 0.000058 - Dev Loss: 1.145338\n",
            "Epoch 48 Iteration 12290 - Train Loss: 0.000054 - Dev Loss: 1.146530\n",
            "Epoch 48 Iteration 12300 - Train Loss: 0.000048 - Dev Loss: 1.146541\n",
            "Epoch 48 Iteration 12310 - Train Loss: 0.000049 - Dev Loss: 1.146741\n",
            "Epoch 48 Iteration 12320 - Train Loss: 0.000049 - Dev Loss: 1.146325\n",
            "Epoch 48 Iteration 12330 - Train Loss: 0.000051 - Dev Loss: 1.146745\n",
            "Epoch 48 Iteration 12340 - Train Loss: 0.000049 - Dev Loss: 1.145547\n",
            "Epoch 48 Iteration 12350 - Train Loss: 0.000045 - Dev Loss: 1.146185\n",
            "Epoch 48 Iteration 12360 - Train Loss: 0.000042 - Dev Loss: 1.148129\n",
            "Epoch 48 Iteration 12370 - Train Loss: 0.000046 - Dev Loss: 1.150262\n",
            "Epoch 48 Iteration 12380 - Train Loss: 0.000050 - Dev Loss: 1.149608\n",
            "Epoch 48 Iteration 12390 - Train Loss: 0.000049 - Dev Loss: 1.150325\n",
            "Epoch 48 Iteration 12400 - Train Loss: 0.000052 - Dev Loss: 1.153136\n",
            "Epoch 48 Iteration 12410 - Train Loss: 0.000047 - Dev Loss: 1.153444\n",
            "Epoch 48 Iteration 12420 - Train Loss: 0.000044 - Dev Loss: 1.152571\n",
            "Epoch 48 Iteration 12430 - Train Loss: 0.000061 - Dev Loss: 1.150684\n",
            "Epoch 48 Iteration 12440 - Train Loss: 0.000058 - Dev Loss: 1.151921\n",
            "Epoch 48 Iteration 12450 - Train Loss: 0.000048 - Dev Loss: 1.154442\n",
            "Epoch 48 Iteration 12460 - Train Loss: 0.000049 - Dev Loss: 1.154325\n",
            "Epoch 48 Iteration 12470 - Train Loss: 0.000066 - Dev Loss: 1.156284\n",
            "Epoch 48 Iteration 12480 - Train Loss: 0.000057 - Dev Loss: 1.156703\n",
            "Epoch 48 Iteration 12490 - Train Loss: 0.000041 - Dev Loss: 1.155023\n",
            "Epoch 48 Iteration 12500 - Train Loss: 0.000050 - Dev Loss: 1.153924\n",
            "Epoch 48 Iteration 12510 - Train Loss: 0.000041 - Dev Loss: 1.153857\n",
            "Epoch 48 Iteration 12520 - Train Loss: 0.000049 - Dev Loss: 1.154915\n",
            "Epoch 48 Iteration 12530 - Train Loss: 0.000049 - Dev Loss: 1.157935\n",
            "Epoch 48 Iteration 12540 - Train Loss: 0.000051 - Dev Loss: 1.155403\n",
            "Epoch 49 Iteration 12550 - Train Loss: 0.000051 - Dev Loss: 1.156610\n",
            "Epoch 49 Iteration 12560 - Train Loss: 0.000041 - Dev Loss: 1.158004\n",
            "Epoch 49 Iteration 12570 - Train Loss: 0.000048 - Dev Loss: 1.158208\n",
            "Epoch 49 Iteration 12580 - Train Loss: 0.000041 - Dev Loss: 1.156860\n",
            "Epoch 49 Iteration 12590 - Train Loss: 0.000039 - Dev Loss: 1.157738\n",
            "Epoch 49 Iteration 12600 - Train Loss: 0.000039 - Dev Loss: 1.157993\n",
            "Epoch 49 Iteration 12610 - Train Loss: 0.000041 - Dev Loss: 1.158402\n",
            "Epoch 49 Iteration 12620 - Train Loss: 0.000048 - Dev Loss: 1.160354\n",
            "Epoch 49 Iteration 12630 - Train Loss: 0.000048 - Dev Loss: 1.160523\n",
            "Epoch 49 Iteration 12640 - Train Loss: 0.000039 - Dev Loss: 1.161487\n",
            "Epoch 49 Iteration 12650 - Train Loss: 0.000035 - Dev Loss: 1.159983\n",
            "Epoch 49 Iteration 12660 - Train Loss: 0.000045 - Dev Loss: 1.159092\n",
            "Epoch 49 Iteration 12670 - Train Loss: 0.000043 - Dev Loss: 1.160683\n",
            "Epoch 49 Iteration 12680 - Train Loss: 0.000047 - Dev Loss: 1.162361\n",
            "Epoch 49 Iteration 12690 - Train Loss: 0.000041 - Dev Loss: 1.163194\n",
            "Epoch 49 Iteration 12700 - Train Loss: 0.000052 - Dev Loss: 1.163805\n",
            "Epoch 49 Iteration 12710 - Train Loss: 0.000045 - Dev Loss: 1.163394\n",
            "Epoch 49 Iteration 12720 - Train Loss: 0.000042 - Dev Loss: 1.163435\n",
            "Epoch 49 Iteration 12730 - Train Loss: 0.000040 - Dev Loss: 1.162269\n",
            "Epoch 49 Iteration 12740 - Train Loss: 0.000037 - Dev Loss: 1.162689\n",
            "Epoch 49 Iteration 12750 - Train Loss: 0.000042 - Dev Loss: 1.165112\n",
            "Epoch 49 Iteration 12760 - Train Loss: 0.000039 - Dev Loss: 1.168129\n",
            "Epoch 49 Iteration 12770 - Train Loss: 0.000043 - Dev Loss: 1.168077\n",
            "Epoch 49 Iteration 12780 - Train Loss: 0.000040 - Dev Loss: 1.166846\n",
            "Epoch 49 Iteration 12790 - Train Loss: 0.000048 - Dev Loss: 1.165544\n",
            "Epoch 50 Iteration 12800 - Train Loss: 0.000045 - Dev Loss: 1.167357\n",
            "Epoch 50 Iteration 12810 - Train Loss: 0.000036 - Dev Loss: 1.170237\n",
            "Epoch 50 Iteration 12820 - Train Loss: 0.000038 - Dev Loss: 1.171699\n",
            "Epoch 50 Iteration 12830 - Train Loss: 0.000039 - Dev Loss: 1.172213\n",
            "Epoch 50 Iteration 12840 - Train Loss: 0.000043 - Dev Loss: 1.171707\n",
            "Epoch 50 Iteration 12850 - Train Loss: 0.000033 - Dev Loss: 1.170905\n",
            "Epoch 50 Iteration 12860 - Train Loss: 0.000040 - Dev Loss: 1.171709\n",
            "Epoch 50 Iteration 12870 - Train Loss: 0.000037 - Dev Loss: 1.173570\n",
            "Epoch 50 Iteration 12880 - Train Loss: 0.000042 - Dev Loss: 1.173701\n",
            "Epoch 50 Iteration 12890 - Train Loss: 0.000039 - Dev Loss: 1.175573\n",
            "Epoch 50 Iteration 12900 - Train Loss: 0.000039 - Dev Loss: 1.174933\n",
            "Epoch 50 Iteration 12910 - Train Loss: 0.000037 - Dev Loss: 1.175050\n",
            "Epoch 50 Iteration 12920 - Train Loss: 0.000046 - Dev Loss: 1.179479\n",
            "Epoch 50 Iteration 12930 - Train Loss: 0.000029 - Dev Loss: 1.178529\n",
            "Epoch 50 Iteration 12940 - Train Loss: 0.000033 - Dev Loss: 1.177026\n",
            "Epoch 50 Iteration 12950 - Train Loss: 0.000036 - Dev Loss: 1.175427\n",
            "Epoch 50 Iteration 12960 - Train Loss: 0.000038 - Dev Loss: 1.175254\n",
            "Epoch 50 Iteration 12970 - Train Loss: 0.000037 - Dev Loss: 1.173735\n",
            "Epoch 50 Iteration 12980 - Train Loss: 0.000042 - Dev Loss: 1.175158\n",
            "Epoch 50 Iteration 12990 - Train Loss: 0.000035 - Dev Loss: 1.176545\n",
            "Epoch 50 Iteration 13000 - Train Loss: 0.000041 - Dev Loss: 1.178193\n",
            "Epoch 50 Iteration 13010 - Train Loss: 0.000035 - Dev Loss: 1.180053\n",
            "Epoch 50 Iteration 13020 - Train Loss: 0.000033 - Dev Loss: 1.179508\n",
            "Epoch 50 Iteration 13030 - Train Loss: 0.000038 - Dev Loss: 1.179123\n",
            "Epoch 50 Iteration 13040 - Train Loss: 0.000035 - Dev Loss: 1.180567\n",
            "Epoch 50 Iteration 13050 - Train Loss: 0.000036 - Dev Loss: 1.181416\n",
            "Epoch 51 Iteration 13060 - Train Loss: 0.000030 - Dev Loss: 1.180732\n",
            "Epoch 51 Iteration 13070 - Train Loss: 0.000032 - Dev Loss: 1.181059\n",
            "Epoch 51 Iteration 13080 - Train Loss: 0.000030 - Dev Loss: 1.178985\n",
            "Epoch 51 Iteration 13090 - Train Loss: 0.000028 - Dev Loss: 1.180645\n",
            "Epoch 51 Iteration 13100 - Train Loss: 0.000038 - Dev Loss: 1.182461\n",
            "Epoch 51 Iteration 13110 - Train Loss: 0.000031 - Dev Loss: 1.183693\n",
            "Epoch 51 Iteration 13120 - Train Loss: 0.000033 - Dev Loss: 1.185711\n",
            "Epoch 51 Iteration 13130 - Train Loss: 0.000029 - Dev Loss: 1.186355\n",
            "Epoch 51 Iteration 13140 - Train Loss: 0.000033 - Dev Loss: 1.184985\n",
            "Epoch 51 Iteration 13150 - Train Loss: 0.000032 - Dev Loss: 1.185216\n",
            "Epoch 51 Iteration 13160 - Train Loss: 0.000037 - Dev Loss: 1.186148\n",
            "Epoch 51 Iteration 13170 - Train Loss: 0.000032 - Dev Loss: 1.186134\n",
            "Epoch 51 Iteration 13180 - Train Loss: 0.000040 - Dev Loss: 1.185529\n",
            "Epoch 51 Iteration 13190 - Train Loss: 0.000032 - Dev Loss: 1.186216\n",
            "Epoch 51 Iteration 13200 - Train Loss: 0.000036 - Dev Loss: 1.190187\n",
            "Epoch 51 Iteration 13210 - Train Loss: 0.000030 - Dev Loss: 1.190552\n",
            "Epoch 51 Iteration 13220 - Train Loss: 0.000030 - Dev Loss: 1.191462\n",
            "Epoch 51 Iteration 13230 - Train Loss: 0.000031 - Dev Loss: 1.189766\n",
            "Epoch 51 Iteration 13240 - Train Loss: 0.000031 - Dev Loss: 1.187729\n",
            "Epoch 51 Iteration 13250 - Train Loss: 0.000031 - Dev Loss: 1.188608\n",
            "Epoch 51 Iteration 13260 - Train Loss: 0.000030 - Dev Loss: 1.189576\n",
            "Epoch 51 Iteration 13270 - Train Loss: 0.000032 - Dev Loss: 1.188681\n",
            "Epoch 51 Iteration 13280 - Train Loss: 0.000033 - Dev Loss: 1.189492\n",
            "Epoch 51 Iteration 13290 - Train Loss: 0.000030 - Dev Loss: 1.194746\n",
            "Epoch 51 Iteration 13300 - Train Loss: 0.000034 - Dev Loss: 1.197369\n",
            "Epoch 51 Iteration 13310 - Train Loss: 0.000035 - Dev Loss: 1.197313\n",
            "Epoch 52 Iteration 13320 - Train Loss: 0.000026 - Dev Loss: 1.195790\n",
            "Epoch 52 Iteration 13330 - Train Loss: 0.000026 - Dev Loss: 1.194532\n",
            "Epoch 52 Iteration 13340 - Train Loss: 0.000029 - Dev Loss: 1.195267\n",
            "Epoch 52 Iteration 13350 - Train Loss: 0.000027 - Dev Loss: 1.194870\n",
            "Epoch 52 Iteration 13360 - Train Loss: 0.000030 - Dev Loss: 1.192317\n",
            "Epoch 52 Iteration 13370 - Train Loss: 0.000026 - Dev Loss: 1.193605\n",
            "Epoch 52 Iteration 13380 - Train Loss: 0.000026 - Dev Loss: 1.195612\n",
            "Epoch 52 Iteration 13390 - Train Loss: 0.000025 - Dev Loss: 1.195423\n",
            "Epoch 52 Iteration 13400 - Train Loss: 0.000029 - Dev Loss: 1.194503\n",
            "Epoch 52 Iteration 13410 - Train Loss: 0.000026 - Dev Loss: 1.195439\n",
            "Epoch 52 Iteration 13420 - Train Loss: 0.000027 - Dev Loss: 1.196345\n",
            "Epoch 52 Iteration 13430 - Train Loss: 0.000025 - Dev Loss: 1.199136\n",
            "Epoch 52 Iteration 13440 - Train Loss: 0.000027 - Dev Loss: 1.198973\n",
            "Epoch 52 Iteration 13450 - Train Loss: 0.000032 - Dev Loss: 1.197249\n",
            "Epoch 52 Iteration 13460 - Train Loss: 0.000028 - Dev Loss: 1.197558\n",
            "Epoch 52 Iteration 13470 - Train Loss: 0.000028 - Dev Loss: 1.199699\n",
            "Epoch 52 Iteration 13480 - Train Loss: 0.000029 - Dev Loss: 1.201613\n",
            "Epoch 52 Iteration 13490 - Train Loss: 0.000027 - Dev Loss: 1.201904\n",
            "Epoch 52 Iteration 13500 - Train Loss: 0.000028 - Dev Loss: 1.201872\n",
            "Epoch 52 Iteration 13510 - Train Loss: 0.000029 - Dev Loss: 1.202599\n",
            "Epoch 52 Iteration 13520 - Train Loss: 0.000033 - Dev Loss: 1.202857\n",
            "Epoch 52 Iteration 13530 - Train Loss: 0.000036 - Dev Loss: 1.204364\n",
            "Epoch 52 Iteration 13540 - Train Loss: 0.000027 - Dev Loss: 1.206085\n",
            "Epoch 52 Iteration 13550 - Train Loss: 0.000027 - Dev Loss: 1.205618\n",
            "Epoch 52 Iteration 13560 - Train Loss: 0.000027 - Dev Loss: 1.205015\n",
            "Epoch 53 Iteration 13570 - Train Loss: 0.000031 - Dev Loss: 1.203370\n",
            "Epoch 53 Iteration 13580 - Train Loss: 0.000023 - Dev Loss: 1.202933\n",
            "Epoch 53 Iteration 13590 - Train Loss: 0.000022 - Dev Loss: 1.205212\n",
            "Epoch 53 Iteration 13600 - Train Loss: 0.000021 - Dev Loss: 1.207220\n",
            "Epoch 53 Iteration 13610 - Train Loss: 0.000028 - Dev Loss: 1.209468\n",
            "Epoch 53 Iteration 13620 - Train Loss: 0.000023 - Dev Loss: 1.210310\n",
            "Epoch 53 Iteration 13630 - Train Loss: 0.000027 - Dev Loss: 1.211589\n",
            "Epoch 53 Iteration 13640 - Train Loss: 0.000022 - Dev Loss: 1.211891\n",
            "Epoch 53 Iteration 13650 - Train Loss: 0.000023 - Dev Loss: 1.213788\n",
            "Epoch 53 Iteration 13660 - Train Loss: 0.000026 - Dev Loss: 1.213181\n",
            "Epoch 53 Iteration 13670 - Train Loss: 0.000025 - Dev Loss: 1.211974\n",
            "Epoch 53 Iteration 13680 - Train Loss: 0.000022 - Dev Loss: 1.209183\n",
            "Epoch 53 Iteration 13690 - Train Loss: 0.000026 - Dev Loss: 1.209206\n",
            "Epoch 53 Iteration 13700 - Train Loss: 0.000024 - Dev Loss: 1.211236\n",
            "Epoch 53 Iteration 13710 - Train Loss: 0.000024 - Dev Loss: 1.212874\n",
            "Epoch 53 Iteration 13720 - Train Loss: 0.000023 - Dev Loss: 1.211210\n",
            "Epoch 53 Iteration 13730 - Train Loss: 0.000024 - Dev Loss: 1.213494\n",
            "Epoch 53 Iteration 13740 - Train Loss: 0.000021 - Dev Loss: 1.213355\n",
            "Epoch 53 Iteration 13750 - Train Loss: 0.000026 - Dev Loss: 1.214875\n",
            "Epoch 53 Iteration 13760 - Train Loss: 0.000020 - Dev Loss: 1.217201\n",
            "Epoch 53 Iteration 13770 - Train Loss: 0.000028 - Dev Loss: 1.214490\n",
            "Epoch 53 Iteration 13780 - Train Loss: 0.000024 - Dev Loss: 1.212331\n",
            "Epoch 53 Iteration 13790 - Train Loss: 0.000020 - Dev Loss: 1.210560\n",
            "Epoch 53 Iteration 13800 - Train Loss: 0.000025 - Dev Loss: 1.212974\n",
            "Epoch 53 Iteration 13810 - Train Loss: 0.000028 - Dev Loss: 1.215576\n",
            "Epoch 53 Iteration 13820 - Train Loss: 0.000027 - Dev Loss: 1.218012\n",
            "Epoch 54 Iteration 13830 - Train Loss: 0.000025 - Dev Loss: 1.217890\n",
            "Epoch 54 Iteration 13840 - Train Loss: 0.000021 - Dev Loss: 1.216533\n",
            "Epoch 54 Iteration 13850 - Train Loss: 0.000019 - Dev Loss: 1.218330\n",
            "Epoch 54 Iteration 13860 - Train Loss: 0.000021 - Dev Loss: 1.220757\n",
            "Epoch 54 Iteration 13870 - Train Loss: 0.000019 - Dev Loss: 1.222095\n",
            "Epoch 54 Iteration 13880 - Train Loss: 0.000019 - Dev Loss: 1.222356\n",
            "Epoch 54 Iteration 13890 - Train Loss: 0.000019 - Dev Loss: 1.221491\n",
            "Epoch 54 Iteration 13900 - Train Loss: 0.000021 - Dev Loss: 1.220528\n",
            "Epoch 54 Iteration 13910 - Train Loss: 0.000021 - Dev Loss: 1.222655\n",
            "Epoch 54 Iteration 13920 - Train Loss: 0.000023 - Dev Loss: 1.223086\n",
            "Epoch 54 Iteration 13930 - Train Loss: 0.000020 - Dev Loss: 1.224278\n",
            "Epoch 54 Iteration 13940 - Train Loss: 0.000021 - Dev Loss: 1.221338\n",
            "Epoch 54 Iteration 13950 - Train Loss: 0.000022 - Dev Loss: 1.219274\n",
            "Epoch 54 Iteration 13960 - Train Loss: 0.000022 - Dev Loss: 1.222224\n",
            "Epoch 54 Iteration 13970 - Train Loss: 0.000021 - Dev Loss: 1.225692\n",
            "Epoch 54 Iteration 13980 - Train Loss: 0.000019 - Dev Loss: 1.226373\n",
            "Epoch 54 Iteration 13990 - Train Loss: 0.000025 - Dev Loss: 1.224848\n",
            "Epoch 54 Iteration 14000 - Train Loss: 0.000019 - Dev Loss: 1.222845\n",
            "Epoch 54 Iteration 14010 - Train Loss: 0.000021 - Dev Loss: 1.220519\n",
            "Epoch 54 Iteration 14020 - Train Loss: 0.000023 - Dev Loss: 1.224238\n",
            "Epoch 54 Iteration 14030 - Train Loss: 0.000024 - Dev Loss: 1.227637\n",
            "Epoch 54 Iteration 14040 - Train Loss: 0.000021 - Dev Loss: 1.227816\n",
            "Epoch 54 Iteration 14050 - Train Loss: 0.000024 - Dev Loss: 1.227781\n",
            "Epoch 54 Iteration 14060 - Train Loss: 0.000025 - Dev Loss: 1.227310\n",
            "Epoch 54 Iteration 14070 - Train Loss: 0.000021 - Dev Loss: 1.226243\n",
            "Epoch 55 Iteration 14080 - Train Loss: 0.000018 - Dev Loss: 1.229180\n",
            "Epoch 55 Iteration 14090 - Train Loss: 0.000017 - Dev Loss: 1.231722\n",
            "Epoch 55 Iteration 14100 - Train Loss: 0.000020 - Dev Loss: 1.232185\n",
            "Epoch 55 Iteration 14110 - Train Loss: 0.000017 - Dev Loss: 1.233492\n",
            "Epoch 55 Iteration 14120 - Train Loss: 0.000019 - Dev Loss: 1.233232\n",
            "Epoch 55 Iteration 14130 - Train Loss: 0.000024 - Dev Loss: 1.231773\n",
            "Epoch 55 Iteration 14140 - Train Loss: 0.000018 - Dev Loss: 1.232850\n",
            "Epoch 55 Iteration 14150 - Train Loss: 0.000019 - Dev Loss: 1.234374\n",
            "Epoch 55 Iteration 14160 - Train Loss: 0.000017 - Dev Loss: 1.234392\n",
            "Epoch 55 Iteration 14170 - Train Loss: 0.000017 - Dev Loss: 1.234567\n",
            "Epoch 55 Iteration 14180 - Train Loss: 0.000017 - Dev Loss: 1.234813\n",
            "Epoch 55 Iteration 14190 - Train Loss: 0.000017 - Dev Loss: 1.234496\n",
            "Epoch 55 Iteration 14200 - Train Loss: 0.000020 - Dev Loss: 1.233770\n",
            "Epoch 55 Iteration 14210 - Train Loss: 0.000019 - Dev Loss: 1.233225\n",
            "Epoch 55 Iteration 14220 - Train Loss: 0.000017 - Dev Loss: 1.235460\n",
            "Epoch 55 Iteration 14230 - Train Loss: 0.000016 - Dev Loss: 1.235649\n",
            "Epoch 55 Iteration 14240 - Train Loss: 0.000017 - Dev Loss: 1.236972\n",
            "Epoch 55 Iteration 14250 - Train Loss: 0.000019 - Dev Loss: 1.238462\n",
            "Epoch 55 Iteration 14260 - Train Loss: 0.000019 - Dev Loss: 1.239516\n",
            "Epoch 55 Iteration 14270 - Train Loss: 0.000014 - Dev Loss: 1.240572\n",
            "Epoch 55 Iteration 14280 - Train Loss: 0.000018 - Dev Loss: 1.239805\n",
            "Epoch 55 Iteration 14290 - Train Loss: 0.000020 - Dev Loss: 1.240053\n",
            "Epoch 55 Iteration 14300 - Train Loss: 0.000019 - Dev Loss: 1.242291\n",
            "Epoch 55 Iteration 14310 - Train Loss: 0.000019 - Dev Loss: 1.244892\n",
            "Epoch 55 Iteration 14320 - Train Loss: 0.000023 - Dev Loss: 1.244626\n",
            "Epoch 55 Iteration 14330 - Train Loss: 0.000016 - Dev Loss: 1.240607\n",
            "Epoch 56 Iteration 14340 - Train Loss: 0.000019 - Dev Loss: 1.240416\n",
            "Epoch 56 Iteration 14350 - Train Loss: 0.000017 - Dev Loss: 1.241938\n",
            "Epoch 56 Iteration 14360 - Train Loss: 0.000016 - Dev Loss: 1.242516\n",
            "Epoch 56 Iteration 14370 - Train Loss: 0.000017 - Dev Loss: 1.243720\n",
            "Epoch 56 Iteration 14380 - Train Loss: 0.000014 - Dev Loss: 1.244853\n",
            "Epoch 56 Iteration 14390 - Train Loss: 0.000017 - Dev Loss: 1.246148\n",
            "Epoch 56 Iteration 14400 - Train Loss: 0.000016 - Dev Loss: 1.247006\n",
            "Epoch 56 Iteration 14410 - Train Loss: 0.000017 - Dev Loss: 1.247620\n",
            "Epoch 56 Iteration 14420 - Train Loss: 0.000015 - Dev Loss: 1.247279\n",
            "Epoch 56 Iteration 14430 - Train Loss: 0.000017 - Dev Loss: 1.245758\n",
            "Epoch 56 Iteration 14440 - Train Loss: 0.000014 - Dev Loss: 1.246517\n",
            "Epoch 56 Iteration 14450 - Train Loss: 0.000016 - Dev Loss: 1.247945\n",
            "Epoch 56 Iteration 14460 - Train Loss: 0.000017 - Dev Loss: 1.248347\n",
            "Epoch 56 Iteration 14470 - Train Loss: 0.000015 - Dev Loss: 1.249142\n",
            "Epoch 56 Iteration 14480 - Train Loss: 0.000015 - Dev Loss: 1.248531\n",
            "Epoch 56 Iteration 14490 - Train Loss: 0.000015 - Dev Loss: 1.249122\n",
            "Epoch 56 Iteration 14500 - Train Loss: 0.000015 - Dev Loss: 1.250272\n",
            "Epoch 56 Iteration 14510 - Train Loss: 0.000015 - Dev Loss: 1.252838\n",
            "Epoch 56 Iteration 14520 - Train Loss: 0.000018 - Dev Loss: 1.254404\n",
            "Epoch 56 Iteration 14530 - Train Loss: 0.000016 - Dev Loss: 1.253209\n",
            "Epoch 56 Iteration 14540 - Train Loss: 0.000015 - Dev Loss: 1.251709\n",
            "Epoch 56 Iteration 14550 - Train Loss: 0.000015 - Dev Loss: 1.250583\n",
            "Epoch 56 Iteration 14560 - Train Loss: 0.000018 - Dev Loss: 1.250627\n",
            "Epoch 56 Iteration 14570 - Train Loss: 0.000014 - Dev Loss: 1.252582\n",
            "Epoch 56 Iteration 14580 - Train Loss: 0.000017 - Dev Loss: 1.256028\n",
            "Epoch 56 Iteration 14590 - Train Loss: 0.000016 - Dev Loss: 1.256003\n",
            "Epoch 57 Iteration 14600 - Train Loss: 0.000013 - Dev Loss: 1.254958\n",
            "Epoch 57 Iteration 14610 - Train Loss: 0.000012 - Dev Loss: 1.255685\n",
            "Epoch 57 Iteration 14620 - Train Loss: 0.000013 - Dev Loss: 1.256636\n",
            "Epoch 57 Iteration 14630 - Train Loss: 0.000013 - Dev Loss: 1.254757\n",
            "Epoch 57 Iteration 14640 - Train Loss: 0.000013 - Dev Loss: 1.254535\n",
            "Epoch 57 Iteration 14650 - Train Loss: 0.000012 - Dev Loss: 1.256512\n",
            "Epoch 57 Iteration 14660 - Train Loss: 0.000016 - Dev Loss: 1.256111\n",
            "Epoch 57 Iteration 14670 - Train Loss: 0.000016 - Dev Loss: 1.258161\n",
            "Epoch 57 Iteration 14680 - Train Loss: 0.000015 - Dev Loss: 1.259646\n",
            "Epoch 57 Iteration 14690 - Train Loss: 0.000014 - Dev Loss: 1.258812\n",
            "Epoch 57 Iteration 14700 - Train Loss: 0.000013 - Dev Loss: 1.256890\n",
            "Epoch 57 Iteration 14710 - Train Loss: 0.000012 - Dev Loss: 1.256615\n",
            "Epoch 57 Iteration 14720 - Train Loss: 0.000014 - Dev Loss: 1.259050\n",
            "Epoch 57 Iteration 14730 - Train Loss: 0.000015 - Dev Loss: 1.261254\n",
            "Epoch 57 Iteration 14740 - Train Loss: 0.000014 - Dev Loss: 1.261134\n",
            "Epoch 57 Iteration 14750 - Train Loss: 0.000014 - Dev Loss: 1.260441\n",
            "Epoch 57 Iteration 14760 - Train Loss: 0.000017 - Dev Loss: 1.260907\n",
            "Epoch 57 Iteration 14770 - Train Loss: 0.000015 - Dev Loss: 1.262784\n",
            "Epoch 57 Iteration 14780 - Train Loss: 0.000012 - Dev Loss: 1.263268\n",
            "Epoch 57 Iteration 14790 - Train Loss: 0.000013 - Dev Loss: 1.264516\n",
            "Epoch 57 Iteration 14800 - Train Loss: 0.000013 - Dev Loss: 1.265673\n",
            "Epoch 57 Iteration 14810 - Train Loss: 0.000016 - Dev Loss: 1.270368\n",
            "Epoch 57 Iteration 14820 - Train Loss: 0.000015 - Dev Loss: 1.268440\n",
            "Epoch 57 Iteration 14830 - Train Loss: 0.000013 - Dev Loss: 1.264753\n",
            "Epoch 57 Iteration 14840 - Train Loss: 0.000013 - Dev Loss: 1.265243\n",
            "Epoch 58 Iteration 14850 - Train Loss: 0.000013 - Dev Loss: 1.264714\n",
            "Epoch 58 Iteration 14860 - Train Loss: 0.000011 - Dev Loss: 1.266026\n",
            "Epoch 58 Iteration 14870 - Train Loss: 0.000011 - Dev Loss: 1.267304\n",
            "Epoch 58 Iteration 14880 - Train Loss: 0.000014 - Dev Loss: 1.265006\n",
            "Epoch 58 Iteration 14890 - Train Loss: 0.000011 - Dev Loss: 1.266468\n",
            "Epoch 58 Iteration 14900 - Train Loss: 0.000013 - Dev Loss: 1.269605\n",
            "Epoch 58 Iteration 14910 - Train Loss: 0.000012 - Dev Loss: 1.268981\n",
            "Epoch 58 Iteration 14920 - Train Loss: 0.000011 - Dev Loss: 1.270278\n",
            "Epoch 58 Iteration 14930 - Train Loss: 0.000012 - Dev Loss: 1.271466\n",
            "Epoch 58 Iteration 14940 - Train Loss: 0.000012 - Dev Loss: 1.270491\n",
            "Epoch 58 Iteration 14950 - Train Loss: 0.000013 - Dev Loss: 1.270878\n",
            "Epoch 58 Iteration 14960 - Train Loss: 0.000012 - Dev Loss: 1.272166\n",
            "Epoch 58 Iteration 14970 - Train Loss: 0.000012 - Dev Loss: 1.272201\n",
            "Epoch 58 Iteration 14980 - Train Loss: 0.000012 - Dev Loss: 1.271099\n",
            "Epoch 58 Iteration 14990 - Train Loss: 0.000011 - Dev Loss: 1.270651\n",
            "Epoch 58 Iteration 15000 - Train Loss: 0.000013 - Dev Loss: 1.272880\n",
            "Epoch 58 Iteration 15010 - Train Loss: 0.000015 - Dev Loss: 1.274602\n",
            "Epoch 58 Iteration 15020 - Train Loss: 0.000011 - Dev Loss: 1.275383\n",
            "Epoch 58 Iteration 15030 - Train Loss: 0.000011 - Dev Loss: 1.275200\n",
            "Epoch 58 Iteration 15040 - Train Loss: 0.000014 - Dev Loss: 1.275796\n",
            "Epoch 58 Iteration 15050 - Train Loss: 0.000011 - Dev Loss: 1.275287\n",
            "Epoch 58 Iteration 15060 - Train Loss: 0.000012 - Dev Loss: 1.276106\n",
            "Epoch 58 Iteration 15070 - Train Loss: 0.000013 - Dev Loss: 1.277403\n",
            "Epoch 58 Iteration 15080 - Train Loss: 0.000011 - Dev Loss: 1.278709\n",
            "Epoch 58 Iteration 15090 - Train Loss: 0.000013 - Dev Loss: 1.280271\n",
            "Epoch 58 Iteration 15100 - Train Loss: 0.000011 - Dev Loss: 1.279651\n",
            "Epoch 59 Iteration 15110 - Train Loss: 0.000012 - Dev Loss: 1.280922\n",
            "Epoch 59 Iteration 15120 - Train Loss: 0.000009 - Dev Loss: 1.282074\n",
            "Epoch 59 Iteration 15130 - Train Loss: 0.000011 - Dev Loss: 1.282151\n",
            "Epoch 59 Iteration 15140 - Train Loss: 0.000011 - Dev Loss: 1.281482\n",
            "Epoch 59 Iteration 15150 - Train Loss: 0.000009 - Dev Loss: 1.280561\n",
            "Epoch 59 Iteration 15160 - Train Loss: 0.000011 - Dev Loss: 1.281466\n",
            "Epoch 59 Iteration 15170 - Train Loss: 0.000013 - Dev Loss: 1.282782\n",
            "Epoch 59 Iteration 15180 - Train Loss: 0.000011 - Dev Loss: 1.285790\n",
            "Epoch 59 Iteration 15190 - Train Loss: 0.000011 - Dev Loss: 1.289104\n",
            "Epoch 59 Iteration 15200 - Train Loss: 0.000009 - Dev Loss: 1.288151\n",
            "Epoch 59 Iteration 15210 - Train Loss: 0.000011 - Dev Loss: 1.288036\n",
            "Epoch 59 Iteration 15220 - Train Loss: 0.000011 - Dev Loss: 1.289489\n",
            "Epoch 59 Iteration 15230 - Train Loss: 0.000010 - Dev Loss: 1.289884\n",
            "Epoch 59 Iteration 15240 - Train Loss: 0.000012 - Dev Loss: 1.288604\n",
            "Epoch 59 Iteration 15250 - Train Loss: 0.000013 - Dev Loss: 1.290047\n",
            "Epoch 59 Iteration 15260 - Train Loss: 0.000011 - Dev Loss: 1.290442\n",
            "Epoch 59 Iteration 15270 - Train Loss: 0.000010 - Dev Loss: 1.291342\n",
            "Epoch 59 Iteration 15280 - Train Loss: 0.000010 - Dev Loss: 1.293113\n",
            "Epoch 59 Iteration 15290 - Train Loss: 0.000009 - Dev Loss: 1.292332\n",
            "Epoch 59 Iteration 15300 - Train Loss: 0.000010 - Dev Loss: 1.290110\n",
            "Epoch 59 Iteration 15310 - Train Loss: 0.000009 - Dev Loss: 1.290337\n",
            "Epoch 59 Iteration 15320 - Train Loss: 0.000010 - Dev Loss: 1.289879\n",
            "Epoch 59 Iteration 15330 - Train Loss: 0.000010 - Dev Loss: 1.290922\n",
            "Epoch 59 Iteration 15340 - Train Loss: 0.000011 - Dev Loss: 1.293495\n",
            "Epoch 59 Iteration 15350 - Train Loss: 0.000010 - Dev Loss: 1.293706\n",
            "Epoch 60 Iteration 15360 - Train Loss: 0.000009 - Dev Loss: 1.292665\n",
            "Epoch 60 Iteration 15370 - Train Loss: 0.000008 - Dev Loss: 1.292308\n",
            "Epoch 60 Iteration 15380 - Train Loss: 0.000009 - Dev Loss: 1.291329\n",
            "Epoch 60 Iteration 15390 - Train Loss: 0.000008 - Dev Loss: 1.290076\n",
            "Epoch 60 Iteration 15400 - Train Loss: 0.000010 - Dev Loss: 1.291353\n",
            "Epoch 60 Iteration 15410 - Train Loss: 0.000009 - Dev Loss: 1.292137\n",
            "Epoch 60 Iteration 15420 - Train Loss: 0.000010 - Dev Loss: 1.293686\n",
            "Epoch 60 Iteration 15430 - Train Loss: 0.000009 - Dev Loss: 1.295309\n",
            "Epoch 60 Iteration 15440 - Train Loss: 0.000010 - Dev Loss: 1.295455\n",
            "Epoch 60 Iteration 15450 - Train Loss: 0.000009 - Dev Loss: 1.294551\n",
            "Epoch 60 Iteration 15460 - Train Loss: 0.000009 - Dev Loss: 1.296460\n",
            "Epoch 60 Iteration 15470 - Train Loss: 0.000009 - Dev Loss: 1.295770\n",
            "Epoch 60 Iteration 15480 - Train Loss: 0.000010 - Dev Loss: 1.294758\n",
            "Epoch 60 Iteration 15490 - Train Loss: 0.000009 - Dev Loss: 1.295332\n",
            "Epoch 60 Iteration 15500 - Train Loss: 0.000009 - Dev Loss: 1.298016\n",
            "Epoch 60 Iteration 15510 - Train Loss: 0.000008 - Dev Loss: 1.298848\n",
            "Epoch 60 Iteration 15520 - Train Loss: 0.000008 - Dev Loss: 1.297559\n",
            "Epoch 60 Iteration 15530 - Train Loss: 0.000008 - Dev Loss: 1.296923\n",
            "Epoch 60 Iteration 15540 - Train Loss: 0.000009 - Dev Loss: 1.297608\n",
            "Epoch 60 Iteration 15550 - Train Loss: 0.000008 - Dev Loss: 1.297677\n",
            "Epoch 60 Iteration 15560 - Train Loss: 0.000010 - Dev Loss: 1.296958\n",
            "Epoch 60 Iteration 15570 - Train Loss: 0.000010 - Dev Loss: 1.299314\n",
            "Epoch 60 Iteration 15580 - Train Loss: 0.000010 - Dev Loss: 1.301933\n",
            "Epoch 60 Iteration 15590 - Train Loss: 0.000009 - Dev Loss: 1.304007\n",
            "Epoch 60 Iteration 15600 - Train Loss: 0.000008 - Dev Loss: 1.303780\n",
            "Epoch 60 Iteration 15610 - Train Loss: 0.000010 - Dev Loss: 1.302622\n",
            "Epoch 61 Iteration 15620 - Train Loss: 0.000009 - Dev Loss: 1.302294\n",
            "Epoch 61 Iteration 15630 - Train Loss: 0.000007 - Dev Loss: 1.303829\n",
            "Epoch 61 Iteration 15640 - Train Loss: 0.000007 - Dev Loss: 1.303504\n",
            "Epoch 61 Iteration 15650 - Train Loss: 0.000008 - Dev Loss: 1.305337\n",
            "Epoch 61 Iteration 15660 - Train Loss: 0.000008 - Dev Loss: 1.305753\n",
            "Epoch 61 Iteration 15670 - Train Loss: 0.000008 - Dev Loss: 1.303800\n",
            "Epoch 61 Iteration 15680 - Train Loss: 0.000009 - Dev Loss: 1.302820\n",
            "Epoch 61 Iteration 15690 - Train Loss: 0.000008 - Dev Loss: 1.304108\n",
            "Epoch 61 Iteration 15700 - Train Loss: 0.000008 - Dev Loss: 1.305577\n",
            "Epoch 61 Iteration 15710 - Train Loss: 0.000008 - Dev Loss: 1.305182\n",
            "Epoch 61 Iteration 15720 - Train Loss: 0.000009 - Dev Loss: 1.305464\n",
            "Epoch 61 Iteration 15730 - Train Loss: 0.000006 - Dev Loss: 1.306323\n",
            "Epoch 61 Iteration 15740 - Train Loss: 0.000009 - Dev Loss: 1.308050\n",
            "Epoch 61 Iteration 15750 - Train Loss: 0.000008 - Dev Loss: 1.307720\n",
            "Epoch 61 Iteration 15760 - Train Loss: 0.000008 - Dev Loss: 1.306748\n",
            "Epoch 61 Iteration 15770 - Train Loss: 0.000008 - Dev Loss: 1.305767\n",
            "Epoch 61 Iteration 15780 - Train Loss: 0.000009 - Dev Loss: 1.306385\n",
            "Epoch 61 Iteration 15790 - Train Loss: 0.000008 - Dev Loss: 1.310204\n",
            "Epoch 61 Iteration 15800 - Train Loss: 0.000008 - Dev Loss: 1.310423\n",
            "Epoch 61 Iteration 15810 - Train Loss: 0.000008 - Dev Loss: 1.310909\n",
            "Epoch 61 Iteration 15820 - Train Loss: 0.000008 - Dev Loss: 1.310764\n",
            "Epoch 61 Iteration 15830 - Train Loss: 0.000007 - Dev Loss: 1.313151\n",
            "Epoch 61 Iteration 15840 - Train Loss: 0.000008 - Dev Loss: 1.313580\n",
            "Epoch 61 Iteration 15850 - Train Loss: 0.000008 - Dev Loss: 1.314976\n",
            "Epoch 61 Iteration 15860 - Train Loss: 0.000008 - Dev Loss: 1.317445\n",
            "Epoch 61 Iteration 15870 - Train Loss: 0.000008 - Dev Loss: 1.317135\n",
            "Epoch 62 Iteration 15880 - Train Loss: 0.000006 - Dev Loss: 1.314773\n",
            "Epoch 62 Iteration 15890 - Train Loss: 0.000007 - Dev Loss: 1.315340\n",
            "Epoch 62 Iteration 15900 - Train Loss: 0.000007 - Dev Loss: 1.316592\n",
            "Epoch 62 Iteration 15910 - Train Loss: 0.000007 - Dev Loss: 1.317417\n",
            "Epoch 62 Iteration 15920 - Train Loss: 0.000007 - Dev Loss: 1.317101\n",
            "Epoch 62 Iteration 15930 - Train Loss: 0.000008 - Dev Loss: 1.319193\n",
            "Epoch 62 Iteration 15940 - Train Loss: 0.000007 - Dev Loss: 1.319417\n",
            "Epoch 62 Iteration 15950 - Train Loss: 0.000007 - Dev Loss: 1.318132\n",
            "Epoch 62 Iteration 15960 - Train Loss: 0.000006 - Dev Loss: 1.317948\n",
            "Epoch 62 Iteration 15970 - Train Loss: 0.000008 - Dev Loss: 1.319510\n",
            "Epoch 62 Iteration 15980 - Train Loss: 0.000007 - Dev Loss: 1.321652\n",
            "Epoch 62 Iteration 15990 - Train Loss: 0.000006 - Dev Loss: 1.323212\n",
            "Epoch 62 Iteration 16000 - Train Loss: 0.000006 - Dev Loss: 1.323500\n",
            "Epoch 62 Iteration 16010 - Train Loss: 0.000006 - Dev Loss: 1.323403\n",
            "Epoch 62 Iteration 16020 - Train Loss: 0.000007 - Dev Loss: 1.324062\n",
            "Epoch 62 Iteration 16030 - Train Loss: 0.000006 - Dev Loss: 1.324808\n",
            "Epoch 62 Iteration 16040 - Train Loss: 0.000008 - Dev Loss: 1.323735\n",
            "Epoch 62 Iteration 16050 - Train Loss: 0.000007 - Dev Loss: 1.321816\n",
            "Epoch 62 Iteration 16060 - Train Loss: 0.000006 - Dev Loss: 1.321483\n",
            "Epoch 62 Iteration 16070 - Train Loss: 0.000008 - Dev Loss: 1.323139\n",
            "Epoch 62 Iteration 16080 - Train Loss: 0.000008 - Dev Loss: 1.326379\n",
            "Epoch 62 Iteration 16090 - Train Loss: 0.000006 - Dev Loss: 1.327518\n",
            "Epoch 62 Iteration 16100 - Train Loss: 0.000006 - Dev Loss: 1.327121\n",
            "Epoch 62 Iteration 16110 - Train Loss: 0.000008 - Dev Loss: 1.326572\n",
            "Epoch 62 Iteration 16120 - Train Loss: 0.000007 - Dev Loss: 1.325088\n",
            "Epoch 63 Iteration 16130 - Train Loss: 0.000007 - Dev Loss: 1.325720\n",
            "Epoch 63 Iteration 16140 - Train Loss: 0.000006 - Dev Loss: 1.327091\n",
            "Epoch 63 Iteration 16150 - Train Loss: 0.000006 - Dev Loss: 1.328855\n",
            "Epoch 63 Iteration 16160 - Train Loss: 0.000006 - Dev Loss: 1.330648\n",
            "Epoch 63 Iteration 16170 - Train Loss: 0.000007 - Dev Loss: 1.331600\n",
            "Epoch 63 Iteration 16180 - Train Loss: 0.000007 - Dev Loss: 1.334095\n",
            "Epoch 63 Iteration 16190 - Train Loss: 0.000006 - Dev Loss: 1.334499\n",
            "Epoch 63 Iteration 16200 - Train Loss: 0.000006 - Dev Loss: 1.333517\n",
            "Epoch 63 Iteration 16210 - Train Loss: 0.000006 - Dev Loss: 1.332556\n",
            "Epoch 63 Iteration 16220 - Train Loss: 0.000006 - Dev Loss: 1.332392\n",
            "Epoch 63 Iteration 16230 - Train Loss: 0.000005 - Dev Loss: 1.332662\n",
            "Epoch 63 Iteration 16240 - Train Loss: 0.000006 - Dev Loss: 1.332465\n",
            "Epoch 63 Iteration 16250 - Train Loss: 0.000006 - Dev Loss: 1.332248\n",
            "Epoch 63 Iteration 16260 - Train Loss: 0.000006 - Dev Loss: 1.333192\n",
            "Epoch 63 Iteration 16270 - Train Loss: 0.000007 - Dev Loss: 1.334369\n",
            "Epoch 63 Iteration 16280 - Train Loss: 0.000006 - Dev Loss: 1.336129\n",
            "Epoch 63 Iteration 16290 - Train Loss: 0.000007 - Dev Loss: 1.337331\n",
            "Epoch 63 Iteration 16300 - Train Loss: 0.000005 - Dev Loss: 1.337578\n",
            "Epoch 63 Iteration 16310 - Train Loss: 0.000006 - Dev Loss: 1.337397\n",
            "Epoch 63 Iteration 16320 - Train Loss: 0.000007 - Dev Loss: 1.336959\n",
            "Epoch 63 Iteration 16330 - Train Loss: 0.000006 - Dev Loss: 1.336823\n",
            "Epoch 63 Iteration 16340 - Train Loss: 0.000006 - Dev Loss: 1.336991\n",
            "Epoch 63 Iteration 16350 - Train Loss: 0.000006 - Dev Loss: 1.336906\n",
            "Epoch 63 Iteration 16360 - Train Loss: 0.000006 - Dev Loss: 1.336610\n",
            "Epoch 63 Iteration 16370 - Train Loss: 0.000007 - Dev Loss: 1.336926\n",
            "Epoch 63 Iteration 16380 - Train Loss: 0.000006 - Dev Loss: 1.336252\n",
            "Epoch 64 Iteration 16390 - Train Loss: 0.000006 - Dev Loss: 1.336361\n",
            "Epoch 64 Iteration 16400 - Train Loss: 0.000004 - Dev Loss: 1.337408\n",
            "Epoch 64 Iteration 16410 - Train Loss: 0.000005 - Dev Loss: 1.338368\n",
            "Epoch 64 Iteration 16420 - Train Loss: 0.000006 - Dev Loss: 1.339479\n",
            "Epoch 64 Iteration 16430 - Train Loss: 0.000006 - Dev Loss: 1.340273\n",
            "Epoch 64 Iteration 16440 - Train Loss: 0.000005 - Dev Loss: 1.340317\n",
            "Epoch 64 Iteration 16450 - Train Loss: 0.000005 - Dev Loss: 1.338887\n",
            "Epoch 64 Iteration 16460 - Train Loss: 0.000006 - Dev Loss: 1.338575\n",
            "Epoch 64 Iteration 16470 - Train Loss: 0.000006 - Dev Loss: 1.341731\n",
            "Epoch 64 Iteration 16480 - Train Loss: 0.000005 - Dev Loss: 1.342342\n",
            "Epoch 64 Iteration 16490 - Train Loss: 0.000005 - Dev Loss: 1.343505\n",
            "Epoch 64 Iteration 16500 - Train Loss: 0.000006 - Dev Loss: 1.343817\n",
            "Epoch 64 Iteration 16510 - Train Loss: 0.000005 - Dev Loss: 1.342400\n",
            "Epoch 64 Iteration 16520 - Train Loss: 0.000006 - Dev Loss: 1.343802\n",
            "Epoch 64 Iteration 16530 - Train Loss: 0.000004 - Dev Loss: 1.343779\n",
            "Epoch 64 Iteration 16540 - Train Loss: 0.000005 - Dev Loss: 1.343570\n",
            "Epoch 64 Iteration 16550 - Train Loss: 0.000005 - Dev Loss: 1.343617\n",
            "Epoch 64 Iteration 16560 - Train Loss: 0.000006 - Dev Loss: 1.347296\n",
            "Epoch 64 Iteration 16570 - Train Loss: 0.000005 - Dev Loss: 1.352774\n",
            "Epoch 64 Iteration 16580 - Train Loss: 0.000005 - Dev Loss: 1.350940\n",
            "Epoch 64 Iteration 16590 - Train Loss: 0.000006 - Dev Loss: 1.350614\n",
            "Epoch 64 Iteration 16600 - Train Loss: 0.000006 - Dev Loss: 1.351470\n",
            "Epoch 64 Iteration 16610 - Train Loss: 0.000006 - Dev Loss: 1.351885\n",
            "Epoch 64 Iteration 16620 - Train Loss: 0.000006 - Dev Loss: 1.352042\n",
            "Epoch 64 Iteration 16630 - Train Loss: 0.000005 - Dev Loss: 1.351856\n",
            "Epoch 65 Iteration 16640 - Train Loss: 0.000005 - Dev Loss: 1.351046\n",
            "Epoch 65 Iteration 16650 - Train Loss: 0.000005 - Dev Loss: 1.352975\n",
            "Epoch 65 Iteration 16660 - Train Loss: 0.000005 - Dev Loss: 1.354539\n",
            "Epoch 65 Iteration 16670 - Train Loss: 0.000004 - Dev Loss: 1.354867\n",
            "Epoch 65 Iteration 16680 - Train Loss: 0.000005 - Dev Loss: 1.355721\n",
            "Epoch 65 Iteration 16690 - Train Loss: 0.000005 - Dev Loss: 1.357177\n",
            "Epoch 65 Iteration 16700 - Train Loss: 0.000005 - Dev Loss: 1.357033\n",
            "Epoch 65 Iteration 16710 - Train Loss: 0.000004 - Dev Loss: 1.356284\n",
            "Epoch 65 Iteration 16720 - Train Loss: 0.000005 - Dev Loss: 1.356870\n",
            "Epoch 65 Iteration 16730 - Train Loss: 0.000005 - Dev Loss: 1.356632\n",
            "Epoch 65 Iteration 16740 - Train Loss: 0.000004 - Dev Loss: 1.355730\n",
            "Epoch 65 Iteration 16750 - Train Loss: 0.000004 - Dev Loss: 1.355782\n",
            "Epoch 65 Iteration 16760 - Train Loss: 0.000005 - Dev Loss: 1.358464\n",
            "Epoch 65 Iteration 16770 - Train Loss: 0.000005 - Dev Loss: 1.360073\n",
            "Epoch 65 Iteration 16780 - Train Loss: 0.000004 - Dev Loss: 1.363728\n",
            "Epoch 65 Iteration 16790 - Train Loss: 0.000005 - Dev Loss: 1.363994\n",
            "Epoch 65 Iteration 16800 - Train Loss: 0.000005 - Dev Loss: 1.363537\n",
            "Epoch 65 Iteration 16810 - Train Loss: 0.000004 - Dev Loss: 1.362166\n",
            "Epoch 65 Iteration 16820 - Train Loss: 0.000005 - Dev Loss: 1.360802\n",
            "Epoch 65 Iteration 16830 - Train Loss: 0.000005 - Dev Loss: 1.360140\n",
            "Epoch 65 Iteration 16840 - Train Loss: 0.000005 - Dev Loss: 1.359651\n",
            "Epoch 65 Iteration 16850 - Train Loss: 0.000005 - Dev Loss: 1.361572\n",
            "Epoch 65 Iteration 16860 - Train Loss: 0.000004 - Dev Loss: 1.363281\n",
            "Epoch 65 Iteration 16870 - Train Loss: 0.000004 - Dev Loss: 1.362526\n",
            "Epoch 65 Iteration 16880 - Train Loss: 0.000004 - Dev Loss: 1.362141\n",
            "Epoch 65 Iteration 16890 - Train Loss: 0.000005 - Dev Loss: 1.362628\n",
            "Epoch 66 Iteration 16900 - Train Loss: 0.000004 - Dev Loss: 1.362387\n",
            "Epoch 66 Iteration 16910 - Train Loss: 0.000004 - Dev Loss: 1.362266\n",
            "Epoch 66 Iteration 16920 - Train Loss: 0.000004 - Dev Loss: 1.362773\n",
            "Epoch 66 Iteration 16930 - Train Loss: 0.000004 - Dev Loss: 1.363759\n",
            "Epoch 66 Iteration 16940 - Train Loss: 0.000005 - Dev Loss: 1.365219\n",
            "Epoch 66 Iteration 16950 - Train Loss: 0.000003 - Dev Loss: 1.366591\n",
            "Epoch 66 Iteration 16960 - Train Loss: 0.000004 - Dev Loss: 1.365166\n",
            "Epoch 66 Iteration 16970 - Train Loss: 0.000005 - Dev Loss: 1.363750\n",
            "Epoch 66 Iteration 16980 - Train Loss: 0.000004 - Dev Loss: 1.365064\n",
            "Epoch 66 Iteration 16990 - Train Loss: 0.000004 - Dev Loss: 1.367861\n",
            "Epoch 66 Iteration 17000 - Train Loss: 0.000004 - Dev Loss: 1.369876\n",
            "Epoch 66 Iteration 17010 - Train Loss: 0.000004 - Dev Loss: 1.370058\n",
            "Epoch 66 Iteration 17020 - Train Loss: 0.000004 - Dev Loss: 1.369905\n",
            "Epoch 66 Iteration 17030 - Train Loss: 0.000003 - Dev Loss: 1.371443\n",
            "Epoch 66 Iteration 17040 - Train Loss: 0.000004 - Dev Loss: 1.371066\n",
            "Epoch 66 Iteration 17050 - Train Loss: 0.000004 - Dev Loss: 1.371401\n",
            "Epoch 66 Iteration 17060 - Train Loss: 0.000004 - Dev Loss: 1.373964\n",
            "Epoch 66 Iteration 17070 - Train Loss: 0.000004 - Dev Loss: 1.375522\n",
            "Epoch 66 Iteration 17080 - Train Loss: 0.000004 - Dev Loss: 1.375803\n",
            "Epoch 66 Iteration 17090 - Train Loss: 0.000005 - Dev Loss: 1.374865\n",
            "Epoch 66 Iteration 17100 - Train Loss: 0.000004 - Dev Loss: 1.373012\n",
            "Epoch 66 Iteration 17110 - Train Loss: 0.000005 - Dev Loss: 1.372408\n",
            "Epoch 66 Iteration 17120 - Train Loss: 0.000005 - Dev Loss: 1.374447\n",
            "Epoch 66 Iteration 17130 - Train Loss: 0.000004 - Dev Loss: 1.375462\n",
            "Epoch 66 Iteration 17140 - Train Loss: 0.000003 - Dev Loss: 1.375641\n",
            "Epoch 66 Iteration 17150 - Train Loss: 0.000003 - Dev Loss: 1.375907\n",
            "Epoch 67 Iteration 17160 - Train Loss: 0.000003 - Dev Loss: 1.375183\n",
            "Epoch 67 Iteration 17170 - Train Loss: 0.000004 - Dev Loss: 1.374399\n",
            "Epoch 67 Iteration 17180 - Train Loss: 0.000003 - Dev Loss: 1.376590\n",
            "Epoch 67 Iteration 17190 - Train Loss: 0.000003 - Dev Loss: 1.379118\n",
            "Epoch 67 Iteration 17200 - Train Loss: 0.000003 - Dev Loss: 1.378733\n",
            "Epoch 67 Iteration 17210 - Train Loss: 0.000004 - Dev Loss: 1.376790\n",
            "Epoch 67 Iteration 17220 - Train Loss: 0.000004 - Dev Loss: 1.377271\n",
            "Epoch 67 Iteration 17230 - Train Loss: 0.000003 - Dev Loss: 1.379561\n",
            "Epoch 67 Iteration 17240 - Train Loss: 0.000003 - Dev Loss: 1.380904\n",
            "Epoch 67 Iteration 17250 - Train Loss: 0.000003 - Dev Loss: 1.382712\n",
            "Epoch 67 Iteration 17260 - Train Loss: 0.000004 - Dev Loss: 1.382495\n",
            "Epoch 67 Iteration 17270 - Train Loss: 0.000003 - Dev Loss: 1.381297\n",
            "Epoch 67 Iteration 17280 - Train Loss: 0.000003 - Dev Loss: 1.380197\n",
            "Epoch 67 Iteration 17290 - Train Loss: 0.000004 - Dev Loss: 1.381245\n",
            "Epoch 67 Iteration 17300 - Train Loss: 0.000003 - Dev Loss: 1.383208\n",
            "Epoch 67 Iteration 17310 - Train Loss: 0.000004 - Dev Loss: 1.384790\n",
            "Epoch 67 Iteration 17320 - Train Loss: 0.000003 - Dev Loss: 1.385365\n",
            "Epoch 67 Iteration 17330 - Train Loss: 0.000004 - Dev Loss: 1.384693\n",
            "Epoch 67 Iteration 17340 - Train Loss: 0.000003 - Dev Loss: 1.382229\n",
            "Epoch 67 Iteration 17350 - Train Loss: 0.000003 - Dev Loss: 1.381396\n",
            "Epoch 67 Iteration 17360 - Train Loss: 0.000004 - Dev Loss: 1.383245\n",
            "Epoch 67 Iteration 17370 - Train Loss: 0.000004 - Dev Loss: 1.386392\n",
            "Epoch 67 Iteration 17380 - Train Loss: 0.000003 - Dev Loss: 1.388526\n",
            "Epoch 67 Iteration 17390 - Train Loss: 0.000003 - Dev Loss: 1.388313\n",
            "Epoch 67 Iteration 17400 - Train Loss: 0.000004 - Dev Loss: 1.388103\n",
            "Epoch 68 Iteration 17410 - Train Loss: 0.000004 - Dev Loss: 1.388164\n",
            "Epoch 68 Iteration 17420 - Train Loss: 0.000003 - Dev Loss: 1.389941\n",
            "Epoch 68 Iteration 17430 - Train Loss: 0.000003 - Dev Loss: 1.390748\n",
            "Epoch 68 Iteration 17440 - Train Loss: 0.000004 - Dev Loss: 1.389139\n",
            "Epoch 68 Iteration 17450 - Train Loss: 0.000003 - Dev Loss: 1.388915\n",
            "Epoch 68 Iteration 17460 - Train Loss: 0.000003 - Dev Loss: 1.388611\n",
            "Epoch 68 Iteration 17470 - Train Loss: 0.000003 - Dev Loss: 1.391233\n",
            "Epoch 68 Iteration 17480 - Train Loss: 0.000003 - Dev Loss: 1.393930\n",
            "Epoch 68 Iteration 17490 - Train Loss: 0.000003 - Dev Loss: 1.395744\n",
            "Epoch 68 Iteration 17500 - Train Loss: 0.000003 - Dev Loss: 1.394768\n",
            "Epoch 68 Iteration 17510 - Train Loss: 0.000003 - Dev Loss: 1.393529\n",
            "Epoch 68 Iteration 17520 - Train Loss: 0.000003 - Dev Loss: 1.392391\n",
            "Epoch 68 Iteration 17530 - Train Loss: 0.000003 - Dev Loss: 1.394237\n",
            "Epoch 68 Iteration 17540 - Train Loss: 0.000003 - Dev Loss: 1.395557\n",
            "Epoch 68 Iteration 17550 - Train Loss: 0.000003 - Dev Loss: 1.395802\n",
            "Epoch 68 Iteration 17560 - Train Loss: 0.000003 - Dev Loss: 1.398330\n",
            "Epoch 68 Iteration 17570 - Train Loss: 0.000003 - Dev Loss: 1.399802\n",
            "Epoch 68 Iteration 17580 - Train Loss: 0.000003 - Dev Loss: 1.397181\n",
            "Epoch 68 Iteration 17590 - Train Loss: 0.000003 - Dev Loss: 1.395624\n",
            "Epoch 68 Iteration 17600 - Train Loss: 0.000003 - Dev Loss: 1.396475\n",
            "Epoch 68 Iteration 17610 - Train Loss: 0.000004 - Dev Loss: 1.399605\n",
            "Epoch 68 Iteration 17620 - Train Loss: 0.000003 - Dev Loss: 1.400328\n",
            "Epoch 68 Iteration 17630 - Train Loss: 0.000003 - Dev Loss: 1.401381\n",
            "Epoch 68 Iteration 17640 - Train Loss: 0.000004 - Dev Loss: 1.402454\n",
            "Epoch 68 Iteration 17650 - Train Loss: 0.000003 - Dev Loss: 1.401862\n",
            "Epoch 68 Iteration 17660 - Train Loss: 0.000003 - Dev Loss: 1.399585\n",
            "Epoch 69 Iteration 17670 - Train Loss: 0.000003 - Dev Loss: 1.397188\n",
            "Epoch 69 Iteration 17680 - Train Loss: 0.000003 - Dev Loss: 1.398808\n",
            "Epoch 69 Iteration 17690 - Train Loss: 0.000003 - Dev Loss: 1.400197\n",
            "Epoch 69 Iteration 17700 - Train Loss: 0.000002 - Dev Loss: 1.400035\n",
            "Epoch 69 Iteration 17710 - Train Loss: 0.000003 - Dev Loss: 1.401265\n",
            "Epoch 69 Iteration 17720 - Train Loss: 0.000003 - Dev Loss: 1.401736\n",
            "Epoch 69 Iteration 17730 - Train Loss: 0.000003 - Dev Loss: 1.404223\n",
            "Epoch 69 Iteration 17740 - Train Loss: 0.000003 - Dev Loss: 1.405988\n",
            "Epoch 69 Iteration 17750 - Train Loss: 0.000003 - Dev Loss: 1.405635\n",
            "Epoch 69 Iteration 17760 - Train Loss: 0.000003 - Dev Loss: 1.405083\n",
            "Epoch 69 Iteration 17770 - Train Loss: 0.000003 - Dev Loss: 1.405075\n",
            "Epoch 69 Iteration 17780 - Train Loss: 0.000002 - Dev Loss: 1.405874\n",
            "Epoch 69 Iteration 17790 - Train Loss: 0.000003 - Dev Loss: 1.408370\n",
            "Epoch 69 Iteration 17800 - Train Loss: 0.000003 - Dev Loss: 1.414592\n",
            "Epoch 69 Iteration 17810 - Train Loss: 0.000003 - Dev Loss: 1.412450\n",
            "Epoch 69 Iteration 17820 - Train Loss: 0.000002 - Dev Loss: 1.409608\n",
            "Epoch 69 Iteration 17830 - Train Loss: 0.000003 - Dev Loss: 1.408801\n",
            "Epoch 69 Iteration 17840 - Train Loss: 0.000003 - Dev Loss: 1.407395\n",
            "Epoch 69 Iteration 17850 - Train Loss: 0.000003 - Dev Loss: 1.407683\n",
            "Epoch 69 Iteration 17860 - Train Loss: 0.000003 - Dev Loss: 1.410441\n",
            "Epoch 69 Iteration 17870 - Train Loss: 0.000003 - Dev Loss: 1.411808\n",
            "Epoch 69 Iteration 17880 - Train Loss: 0.000003 - Dev Loss: 1.413418\n",
            "Epoch 69 Iteration 17890 - Train Loss: 0.000003 - Dev Loss: 1.414577\n",
            "Epoch 69 Iteration 17900 - Train Loss: 0.000003 - Dev Loss: 1.414088\n",
            "Epoch 69 Iteration 17910 - Train Loss: 0.000002 - Dev Loss: 1.414167\n",
            "Epoch 70 Iteration 17920 - Train Loss: 0.000003 - Dev Loss: 1.413533\n",
            "Epoch 70 Iteration 17930 - Train Loss: 0.000002 - Dev Loss: 1.413959\n",
            "Epoch 70 Iteration 17940 - Train Loss: 0.000002 - Dev Loss: 1.414459\n",
            "Epoch 70 Iteration 17950 - Train Loss: 0.000002 - Dev Loss: 1.412246\n",
            "Epoch 70 Iteration 17960 - Train Loss: 0.000002 - Dev Loss: 1.411360\n",
            "Epoch 70 Iteration 17970 - Train Loss: 0.000002 - Dev Loss: 1.411452\n",
            "Epoch 70 Iteration 17980 - Train Loss: 0.000003 - Dev Loss: 1.413521\n",
            "Epoch 70 Iteration 17990 - Train Loss: 0.000002 - Dev Loss: 1.415781\n",
            "Epoch 70 Iteration 18000 - Train Loss: 0.000003 - Dev Loss: 1.416776\n",
            "Epoch 70 Iteration 18010 - Train Loss: 0.000002 - Dev Loss: 1.417416\n",
            "Epoch 70 Iteration 18020 - Train Loss: 0.000003 - Dev Loss: 1.417390\n",
            "Epoch 70 Iteration 18030 - Train Loss: 0.000002 - Dev Loss: 1.417220\n",
            "Epoch 70 Iteration 18040 - Train Loss: 0.000002 - Dev Loss: 1.418508\n",
            "Epoch 70 Iteration 18050 - Train Loss: 0.000002 - Dev Loss: 1.420433\n",
            "Epoch 70 Iteration 18060 - Train Loss: 0.000003 - Dev Loss: 1.420067\n",
            "Epoch 70 Iteration 18070 - Train Loss: 0.000002 - Dev Loss: 1.421132\n",
            "Epoch 70 Iteration 18080 - Train Loss: 0.000003 - Dev Loss: 1.421143\n",
            "Epoch 70 Iteration 18090 - Train Loss: 0.000002 - Dev Loss: 1.421208\n",
            "Epoch 70 Iteration 18100 - Train Loss: 0.000003 - Dev Loss: 1.423630\n",
            "Epoch 70 Iteration 18110 - Train Loss: 0.000002 - Dev Loss: 1.425720\n",
            "Epoch 70 Iteration 18120 - Train Loss: 0.000003 - Dev Loss: 1.425350\n",
            "Epoch 70 Iteration 18130 - Train Loss: 0.000002 - Dev Loss: 1.423781\n",
            "Epoch 70 Iteration 18140 - Train Loss: 0.000002 - Dev Loss: 1.422382\n",
            "Epoch 70 Iteration 18150 - Train Loss: 0.000002 - Dev Loss: 1.424229\n",
            "Epoch 70 Iteration 18160 - Train Loss: 0.000002 - Dev Loss: 1.426547\n",
            "Epoch 70 Iteration 18170 - Train Loss: 0.000002 - Dev Loss: 1.428024\n",
            "Epoch 71 Iteration 18180 - Train Loss: 0.000002 - Dev Loss: 1.425806\n",
            "Epoch 71 Iteration 18190 - Train Loss: 0.000002 - Dev Loss: 1.423186\n",
            "Epoch 71 Iteration 18200 - Train Loss: 0.000002 - Dev Loss: 1.423011\n",
            "Epoch 71 Iteration 18210 - Train Loss: 0.000002 - Dev Loss: 1.423522\n",
            "Epoch 71 Iteration 18220 - Train Loss: 0.000002 - Dev Loss: 1.423561\n",
            "Epoch 71 Iteration 18230 - Train Loss: 0.000002 - Dev Loss: 1.423394\n",
            "Epoch 71 Iteration 18240 - Train Loss: 0.000002 - Dev Loss: 1.423725\n",
            "Epoch 71 Iteration 18250 - Train Loss: 0.000002 - Dev Loss: 1.425070\n",
            "Epoch 71 Iteration 18260 - Train Loss: 0.000002 - Dev Loss: 1.426204\n",
            "Epoch 71 Iteration 18270 - Train Loss: 0.000002 - Dev Loss: 1.427175\n",
            "Epoch 71 Iteration 18280 - Train Loss: 0.000002 - Dev Loss: 1.429403\n",
            "Epoch 71 Iteration 18290 - Train Loss: 0.000002 - Dev Loss: 1.430790\n",
            "Epoch 71 Iteration 18300 - Train Loss: 0.000002 - Dev Loss: 1.430230\n",
            "Epoch 71 Iteration 18310 - Train Loss: 0.000002 - Dev Loss: 1.430999\n",
            "Epoch 71 Iteration 18320 - Train Loss: 0.000002 - Dev Loss: 1.431413\n",
            "Epoch 71 Iteration 18330 - Train Loss: 0.000002 - Dev Loss: 1.431646\n",
            "Epoch 71 Iteration 18340 - Train Loss: 0.000002 - Dev Loss: 1.433467\n",
            "Epoch 71 Iteration 18350 - Train Loss: 0.000002 - Dev Loss: 1.433000\n",
            "Epoch 71 Iteration 18360 - Train Loss: 0.000002 - Dev Loss: 1.431480\n",
            "Epoch 71 Iteration 18370 - Train Loss: 0.000002 - Dev Loss: 1.433210\n",
            "Epoch 71 Iteration 18380 - Train Loss: 0.000002 - Dev Loss: 1.435865\n",
            "Epoch 71 Iteration 18390 - Train Loss: 0.000002 - Dev Loss: 1.436021\n",
            "Epoch 71 Iteration 18400 - Train Loss: 0.000002 - Dev Loss: 1.437534\n",
            "Epoch 71 Iteration 18410 - Train Loss: 0.000002 - Dev Loss: 1.440784\n",
            "Epoch 71 Iteration 18420 - Train Loss: 0.000002 - Dev Loss: 1.441331\n",
            "Epoch 71 Iteration 18430 - Train Loss: 0.000002 - Dev Loss: 1.440689\n",
            "Epoch 72 Iteration 18440 - Train Loss: 0.000002 - Dev Loss: 1.440073\n",
            "Epoch 72 Iteration 18450 - Train Loss: 0.000002 - Dev Loss: 1.440008\n",
            "Epoch 72 Iteration 18460 - Train Loss: 0.000002 - Dev Loss: 1.441402\n",
            "Epoch 72 Iteration 18470 - Train Loss: 0.000002 - Dev Loss: 1.441474\n",
            "Epoch 72 Iteration 18480 - Train Loss: 0.000002 - Dev Loss: 1.439426\n",
            "Epoch 72 Iteration 18490 - Train Loss: 0.000002 - Dev Loss: 1.437786\n",
            "Epoch 72 Iteration 18500 - Train Loss: 0.000002 - Dev Loss: 1.437579\n",
            "Epoch 72 Iteration 18510 - Train Loss: 0.000001 - Dev Loss: 1.439980\n",
            "Epoch 72 Iteration 18520 - Train Loss: 0.000002 - Dev Loss: 1.444033\n",
            "Epoch 72 Iteration 18530 - Train Loss: 0.000002 - Dev Loss: 1.444163\n",
            "Epoch 72 Iteration 18540 - Train Loss: 0.000002 - Dev Loss: 1.441730\n",
            "Epoch 72 Iteration 18550 - Train Loss: 0.000002 - Dev Loss: 1.441787\n",
            "Epoch 72 Iteration 18560 - Train Loss: 0.000002 - Dev Loss: 1.444140\n",
            "Epoch 72 Iteration 18570 - Train Loss: 0.000002 - Dev Loss: 1.444921\n",
            "Epoch 72 Iteration 18580 - Train Loss: 0.000002 - Dev Loss: 1.443711\n",
            "Epoch 72 Iteration 18590 - Train Loss: 0.000002 - Dev Loss: 1.443223\n",
            "Epoch 72 Iteration 18600 - Train Loss: 0.000002 - Dev Loss: 1.443602\n",
            "Epoch 72 Iteration 18610 - Train Loss: 0.000002 - Dev Loss: 1.446904\n",
            "Epoch 72 Iteration 18620 - Train Loss: 0.000002 - Dev Loss: 1.449174\n",
            "Epoch 72 Iteration 18630 - Train Loss: 0.000002 - Dev Loss: 1.447973\n",
            "Epoch 72 Iteration 18640 - Train Loss: 0.000002 - Dev Loss: 1.446194\n",
            "Epoch 72 Iteration 18650 - Train Loss: 0.000002 - Dev Loss: 1.446601\n",
            "Epoch 72 Iteration 18660 - Train Loss: 0.000002 - Dev Loss: 1.446995\n",
            "Epoch 72 Iteration 18670 - Train Loss: 0.000002 - Dev Loss: 1.449324\n",
            "Epoch 72 Iteration 18680 - Train Loss: 0.000002 - Dev Loss: 1.449551\n",
            "Epoch 73 Iteration 18690 - Train Loss: 0.000002 - Dev Loss: 1.449497\n",
            "Epoch 73 Iteration 18700 - Train Loss: 0.000002 - Dev Loss: 1.449335\n",
            "Epoch 73 Iteration 18710 - Train Loss: 0.000002 - Dev Loss: 1.450026\n",
            "Epoch 73 Iteration 18720 - Train Loss: 0.000002 - Dev Loss: 1.450670\n",
            "Epoch 73 Iteration 18730 - Train Loss: 0.000001 - Dev Loss: 1.451202\n",
            "Epoch 73 Iteration 18740 - Train Loss: 0.000002 - Dev Loss: 1.451142\n",
            "Epoch 73 Iteration 18750 - Train Loss: 0.000001 - Dev Loss: 1.452828\n",
            "Epoch 73 Iteration 18760 - Train Loss: 0.000002 - Dev Loss: 1.454258\n",
            "Epoch 73 Iteration 18770 - Train Loss: 0.000001 - Dev Loss: 1.454671\n",
            "Epoch 73 Iteration 18780 - Train Loss: 0.000002 - Dev Loss: 1.453349\n",
            "Epoch 73 Iteration 18790 - Train Loss: 0.000002 - Dev Loss: 1.453651\n",
            "Epoch 73 Iteration 18800 - Train Loss: 0.000001 - Dev Loss: 1.453918\n",
            "Epoch 73 Iteration 18810 - Train Loss: 0.000002 - Dev Loss: 1.454238\n",
            "Epoch 73 Iteration 18820 - Train Loss: 0.000002 - Dev Loss: 1.454877\n",
            "Epoch 73 Iteration 18830 - Train Loss: 0.000002 - Dev Loss: 1.455309\n",
            "Epoch 73 Iteration 18840 - Train Loss: 0.000002 - Dev Loss: 1.456628\n",
            "Epoch 73 Iteration 18850 - Train Loss: 0.000001 - Dev Loss: 1.456341\n",
            "Epoch 73 Iteration 18860 - Train Loss: 0.000002 - Dev Loss: 1.459720\n",
            "Epoch 73 Iteration 18870 - Train Loss: 0.000002 - Dev Loss: 1.459719\n",
            "Epoch 73 Iteration 18880 - Train Loss: 0.000002 - Dev Loss: 1.457554\n",
            "Epoch 73 Iteration 18890 - Train Loss: 0.000001 - Dev Loss: 1.457183\n",
            "Epoch 73 Iteration 18900 - Train Loss: 0.000002 - Dev Loss: 1.459753\n",
            "Epoch 73 Iteration 18910 - Train Loss: 0.000001 - Dev Loss: 1.462077\n",
            "Epoch 73 Iteration 18920 - Train Loss: 0.000002 - Dev Loss: 1.461549\n",
            "Epoch 73 Iteration 18930 - Train Loss: 0.000001 - Dev Loss: 1.458861\n",
            "Epoch 73 Iteration 18940 - Train Loss: 0.000002 - Dev Loss: 1.457878\n",
            "Epoch 74 Iteration 18950 - Train Loss: 0.000002 - Dev Loss: 1.458626\n",
            "Epoch 74 Iteration 18960 - Train Loss: 0.000001 - Dev Loss: 1.459390\n",
            "Epoch 74 Iteration 18970 - Train Loss: 0.000002 - Dev Loss: 1.460528\n",
            "Epoch 74 Iteration 18980 - Train Loss: 0.000001 - Dev Loss: 1.463403\n",
            "Epoch 74 Iteration 18990 - Train Loss: 0.000001 - Dev Loss: 1.464251\n",
            "Epoch 74 Iteration 19000 - Train Loss: 0.000001 - Dev Loss: 1.465379\n",
            "Epoch 74 Iteration 19010 - Train Loss: 0.000001 - Dev Loss: 1.464068\n",
            "Epoch 74 Iteration 19020 - Train Loss: 0.000001 - Dev Loss: 1.464900\n",
            "Epoch 74 Iteration 19030 - Train Loss: 0.000001 - Dev Loss: 1.464927\n",
            "Epoch 74 Iteration 19040 - Train Loss: 0.000001 - Dev Loss: 1.464687\n",
            "Epoch 74 Iteration 19050 - Train Loss: 0.000001 - Dev Loss: 1.464058\n",
            "Epoch 74 Iteration 19060 - Train Loss: 0.000001 - Dev Loss: 1.466035\n",
            "Epoch 74 Iteration 19070 - Train Loss: 0.000001 - Dev Loss: 1.468584\n",
            "Epoch 74 Iteration 19080 - Train Loss: 0.000001 - Dev Loss: 1.467739\n",
            "Epoch 74 Iteration 19090 - Train Loss: 0.000001 - Dev Loss: 1.466924\n",
            "Epoch 74 Iteration 19100 - Train Loss: 0.000001 - Dev Loss: 1.470430\n",
            "Epoch 74 Iteration 19110 - Train Loss: 0.000002 - Dev Loss: 1.470913\n",
            "Epoch 74 Iteration 19120 - Train Loss: 0.000001 - Dev Loss: 1.471111\n",
            "Epoch 74 Iteration 19130 - Train Loss: 0.000001 - Dev Loss: 1.470000\n",
            "Epoch 74 Iteration 19140 - Train Loss: 0.000001 - Dev Loss: 1.470521\n",
            "Epoch 74 Iteration 19150 - Train Loss: 0.000001 - Dev Loss: 1.471558\n",
            "Epoch 74 Iteration 19160 - Train Loss: 0.000002 - Dev Loss: 1.470891\n",
            "Epoch 74 Iteration 19170 - Train Loss: 0.000001 - Dev Loss: 1.470796\n",
            "Epoch 74 Iteration 19180 - Train Loss: 0.000001 - Dev Loss: 1.469364\n",
            "Epoch 74 Iteration 19190 - Train Loss: 0.000001 - Dev Loss: 1.470664\n",
            "Epoch 75 Iteration 19200 - Train Loss: 0.000001 - Dev Loss: 1.473525\n",
            "Epoch 75 Iteration 19210 - Train Loss: 0.000001 - Dev Loss: 1.475529\n",
            "Epoch 75 Iteration 19220 - Train Loss: 0.000001 - Dev Loss: 1.477878\n",
            "Epoch 75 Iteration 19230 - Train Loss: 0.000001 - Dev Loss: 1.477269\n",
            "Epoch 75 Iteration 19240 - Train Loss: 0.000001 - Dev Loss: 1.476144\n",
            "Epoch 75 Iteration 19250 - Train Loss: 0.000001 - Dev Loss: 1.475346\n",
            "Epoch 75 Iteration 19260 - Train Loss: 0.000001 - Dev Loss: 1.475304\n",
            "Epoch 75 Iteration 19270 - Train Loss: 0.000001 - Dev Loss: 1.476454\n",
            "Epoch 75 Iteration 19280 - Train Loss: 0.000001 - Dev Loss: 1.479538\n",
            "Epoch 75 Iteration 19290 - Train Loss: 0.000001 - Dev Loss: 1.483653\n",
            "Epoch 75 Iteration 19300 - Train Loss: 0.000001 - Dev Loss: 1.482221\n",
            "Epoch 75 Iteration 19310 - Train Loss: 0.000001 - Dev Loss: 1.478687\n",
            "Epoch 75 Iteration 19320 - Train Loss: 0.000001 - Dev Loss: 1.477965\n",
            "Epoch 75 Iteration 19330 - Train Loss: 0.000001 - Dev Loss: 1.477478\n",
            "Epoch 75 Iteration 19340 - Train Loss: 0.000001 - Dev Loss: 1.478083\n",
            "Epoch 75 Iteration 19350 - Train Loss: 0.000001 - Dev Loss: 1.479303\n",
            "Epoch 75 Iteration 19360 - Train Loss: 0.000001 - Dev Loss: 1.480898\n",
            "Epoch 75 Iteration 19370 - Train Loss: 0.000001 - Dev Loss: 1.482036\n",
            "Epoch 75 Iteration 19380 - Train Loss: 0.000001 - Dev Loss: 1.482621\n",
            "Epoch 75 Iteration 19390 - Train Loss: 0.000001 - Dev Loss: 1.483343\n",
            "Epoch 75 Iteration 19400 - Train Loss: 0.000001 - Dev Loss: 1.483002\n",
            "Epoch 75 Iteration 19410 - Train Loss: 0.000001 - Dev Loss: 1.482825\n",
            "Epoch 75 Iteration 19420 - Train Loss: 0.000001 - Dev Loss: 1.485493\n",
            "Epoch 75 Iteration 19430 - Train Loss: 0.000001 - Dev Loss: 1.485814\n",
            "Epoch 75 Iteration 19440 - Train Loss: 0.000001 - Dev Loss: 1.485269\n",
            "Epoch 75 Iteration 19450 - Train Loss: 0.000001 - Dev Loss: 1.485857\n",
            "Epoch 76 Iteration 19460 - Train Loss: 0.000001 - Dev Loss: 1.484690\n",
            "Epoch 76 Iteration 19470 - Train Loss: 0.000001 - Dev Loss: 1.483467\n",
            "Epoch 76 Iteration 19480 - Train Loss: 0.000001 - Dev Loss: 1.483920\n",
            "Epoch 76 Iteration 19490 - Train Loss: 0.000001 - Dev Loss: 1.485680\n",
            "Epoch 76 Iteration 19500 - Train Loss: 0.000001 - Dev Loss: 1.488063\n",
            "Epoch 76 Iteration 19510 - Train Loss: 0.000001 - Dev Loss: 1.490385\n",
            "Epoch 76 Iteration 19520 - Train Loss: 0.000001 - Dev Loss: 1.492506\n",
            "Epoch 76 Iteration 19530 - Train Loss: 0.000001 - Dev Loss: 1.492410\n",
            "Epoch 76 Iteration 19540 - Train Loss: 0.000001 - Dev Loss: 1.491013\n",
            "Epoch 76 Iteration 19550 - Train Loss: 0.000001 - Dev Loss: 1.492153\n",
            "Epoch 76 Iteration 19560 - Train Loss: 0.000001 - Dev Loss: 1.492172\n",
            "Epoch 76 Iteration 19570 - Train Loss: 0.000001 - Dev Loss: 1.492068\n",
            "Epoch 76 Iteration 19580 - Train Loss: 0.000001 - Dev Loss: 1.490821\n",
            "Epoch 76 Iteration 19590 - Train Loss: 0.000001 - Dev Loss: 1.491151\n",
            "Epoch 76 Iteration 19600 - Train Loss: 0.000001 - Dev Loss: 1.492497\n",
            "Epoch 76 Iteration 19610 - Train Loss: 0.000001 - Dev Loss: 1.494272\n",
            "Epoch 76 Iteration 19620 - Train Loss: 0.000001 - Dev Loss: 1.496087\n",
            "Epoch 76 Iteration 19630 - Train Loss: 0.000001 - Dev Loss: 1.494663\n",
            "Epoch 76 Iteration 19640 - Train Loss: 0.000001 - Dev Loss: 1.494211\n",
            "Epoch 76 Iteration 19650 - Train Loss: 0.000001 - Dev Loss: 1.494074\n",
            "Epoch 76 Iteration 19660 - Train Loss: 0.000001 - Dev Loss: 1.497086\n",
            "Epoch 76 Iteration 19670 - Train Loss: 0.000001 - Dev Loss: 1.499017\n",
            "Epoch 76 Iteration 19680 - Train Loss: 0.000001 - Dev Loss: 1.498293\n",
            "Epoch 76 Iteration 19690 - Train Loss: 0.000001 - Dev Loss: 1.497465\n",
            "Epoch 76 Iteration 19700 - Train Loss: 0.000001 - Dev Loss: 1.498399\n",
            "Epoch 76 Iteration 19710 - Train Loss: 0.000001 - Dev Loss: 1.501780\n",
            "Epoch 77 Iteration 19720 - Train Loss: 0.000001 - Dev Loss: 1.504016\n",
            "Epoch 77 Iteration 19730 - Train Loss: 0.000001 - Dev Loss: 1.504025\n",
            "Epoch 77 Iteration 19740 - Train Loss: 0.000001 - Dev Loss: 1.502617\n",
            "Epoch 77 Iteration 19750 - Train Loss: 0.000001 - Dev Loss: 1.501384\n",
            "Epoch 77 Iteration 19760 - Train Loss: 0.000001 - Dev Loss: 1.500535\n",
            "Epoch 77 Iteration 19770 - Train Loss: 0.000001 - Dev Loss: 1.500861\n",
            "Epoch 77 Iteration 19780 - Train Loss: 0.000001 - Dev Loss: 1.501400\n",
            "Epoch 77 Iteration 19790 - Train Loss: 0.000001 - Dev Loss: 1.501097\n",
            "Epoch 77 Iteration 19800 - Train Loss: 0.000001 - Dev Loss: 1.501592\n",
            "Epoch 77 Iteration 19810 - Train Loss: 0.000001 - Dev Loss: 1.501138\n",
            "Epoch 77 Iteration 19820 - Train Loss: 0.000001 - Dev Loss: 1.501144\n",
            "Epoch 77 Iteration 19830 - Train Loss: 0.000001 - Dev Loss: 1.502278\n",
            "Epoch 77 Iteration 19840 - Train Loss: 0.000001 - Dev Loss: 1.502129\n",
            "Epoch 77 Iteration 19850 - Train Loss: 0.000001 - Dev Loss: 1.502064\n",
            "Epoch 77 Iteration 19860 - Train Loss: 0.000001 - Dev Loss: 1.500726\n",
            "Epoch 77 Iteration 19870 - Train Loss: 0.000001 - Dev Loss: 1.500730\n",
            "Epoch 77 Iteration 19880 - Train Loss: 0.000001 - Dev Loss: 1.503351\n",
            "Epoch 77 Iteration 19890 - Train Loss: 0.000001 - Dev Loss: 1.506083\n",
            "Epoch 77 Iteration 19900 - Train Loss: 0.000001 - Dev Loss: 1.507529\n",
            "Epoch 77 Iteration 19910 - Train Loss: 0.000001 - Dev Loss: 1.507984\n",
            "Epoch 77 Iteration 19920 - Train Loss: 0.000001 - Dev Loss: 1.506750\n",
            "Epoch 77 Iteration 19930 - Train Loss: 0.000001 - Dev Loss: 1.506702\n",
            "Epoch 77 Iteration 19940 - Train Loss: 0.000001 - Dev Loss: 1.506715\n",
            "Epoch 77 Iteration 19950 - Train Loss: 0.000001 - Dev Loss: 1.507468\n",
            "Epoch 77 Iteration 19960 - Train Loss: 0.000001 - Dev Loss: 1.509200\n",
            "Epoch 78 Iteration 19970 - Train Loss: 0.000001 - Dev Loss: 1.511340\n",
            "Epoch 78 Iteration 19980 - Train Loss: 0.000001 - Dev Loss: 1.513310\n",
            "Epoch 78 Iteration 19990 - Train Loss: 0.000001 - Dev Loss: 1.513578\n",
            "Epoch 78 Iteration 20000 - Train Loss: 0.000001 - Dev Loss: 1.515165\n",
            "Epoch 78 Iteration 20010 - Train Loss: 0.000001 - Dev Loss: 1.515024\n",
            "Epoch 78 Iteration 20020 - Train Loss: 0.000001 - Dev Loss: 1.515093\n",
            "Epoch 78 Iteration 20030 - Train Loss: 0.000001 - Dev Loss: 1.515846\n",
            "Epoch 78 Iteration 20040 - Train Loss: 0.000001 - Dev Loss: 1.515734\n",
            "Epoch 78 Iteration 20050 - Train Loss: 0.000001 - Dev Loss: 1.514608\n",
            "Epoch 78 Iteration 20060 - Train Loss: 0.000001 - Dev Loss: 1.515696\n",
            "Epoch 78 Iteration 20070 - Train Loss: 0.000001 - Dev Loss: 1.517299\n",
            "Epoch 78 Iteration 20080 - Train Loss: 0.000001 - Dev Loss: 1.516961\n",
            "Epoch 78 Iteration 20090 - Train Loss: 0.000001 - Dev Loss: 1.516758\n",
            "Epoch 78 Iteration 20100 - Train Loss: 0.000001 - Dev Loss: 1.515913\n",
            "Epoch 78 Iteration 20110 - Train Loss: 0.000001 - Dev Loss: 1.515931\n",
            "Epoch 78 Iteration 20120 - Train Loss: 0.000001 - Dev Loss: 1.516366\n",
            "Epoch 78 Iteration 20130 - Train Loss: 0.000001 - Dev Loss: 1.516367\n",
            "Epoch 78 Iteration 20140 - Train Loss: 0.000001 - Dev Loss: 1.517235\n",
            "Epoch 78 Iteration 20150 - Train Loss: 0.000001 - Dev Loss: 1.519222\n",
            "Epoch 78 Iteration 20160 - Train Loss: 0.000001 - Dev Loss: 1.518994\n",
            "Epoch 78 Iteration 20170 - Train Loss: 0.000001 - Dev Loss: 1.520208\n",
            "Epoch 78 Iteration 20180 - Train Loss: 0.000001 - Dev Loss: 1.521035\n",
            "Epoch 78 Iteration 20190 - Train Loss: 0.000001 - Dev Loss: 1.523148\n",
            "Epoch 78 Iteration 20200 - Train Loss: 0.000001 - Dev Loss: 1.523203\n",
            "Epoch 78 Iteration 20210 - Train Loss: 0.000001 - Dev Loss: 1.524725\n",
            "Epoch 78 Iteration 20220 - Train Loss: 0.000001 - Dev Loss: 1.525080\n",
            "Epoch 79 Iteration 20230 - Train Loss: 0.000001 - Dev Loss: 1.522117\n",
            "Epoch 79 Iteration 20240 - Train Loss: 0.000001 - Dev Loss: 1.523979\n",
            "Epoch 79 Iteration 20250 - Train Loss: 0.000001 - Dev Loss: 1.527296\n",
            "Epoch 79 Iteration 20260 - Train Loss: 0.000001 - Dev Loss: 1.528589\n",
            "Epoch 79 Iteration 20270 - Train Loss: 0.000001 - Dev Loss: 1.530865\n",
            "Epoch 79 Iteration 20280 - Train Loss: 0.000001 - Dev Loss: 1.529449\n",
            "Epoch 79 Iteration 20290 - Train Loss: 0.000001 - Dev Loss: 1.526760\n",
            "Epoch 79 Iteration 20300 - Train Loss: 0.000001 - Dev Loss: 1.527690\n",
            "Epoch 79 Iteration 20310 - Train Loss: 0.000001 - Dev Loss: 1.529432\n",
            "Epoch 79 Iteration 20320 - Train Loss: 0.000001 - Dev Loss: 1.533550\n",
            "Epoch 79 Iteration 20330 - Train Loss: 0.000001 - Dev Loss: 1.534018\n",
            "Epoch 79 Iteration 20340 - Train Loss: 0.000001 - Dev Loss: 1.532578\n",
            "Epoch 79 Iteration 20350 - Train Loss: 0.000001 - Dev Loss: 1.532306\n",
            "Epoch 79 Iteration 20360 - Train Loss: 0.000001 - Dev Loss: 1.532006\n",
            "Epoch 79 Iteration 20370 - Train Loss: 0.000001 - Dev Loss: 1.532095\n",
            "Epoch 79 Iteration 20380 - Train Loss: 0.000001 - Dev Loss: 1.531726\n",
            "Epoch 79 Iteration 20390 - Train Loss: 0.000001 - Dev Loss: 1.533983\n",
            "Epoch 79 Iteration 20400 - Train Loss: 0.000001 - Dev Loss: 1.534884\n",
            "Epoch 79 Iteration 20410 - Train Loss: 0.000001 - Dev Loss: 1.534321\n",
            "Epoch 79 Iteration 20420 - Train Loss: 0.000001 - Dev Loss: 1.534198\n",
            "Epoch 79 Iteration 20430 - Train Loss: 0.000001 - Dev Loss: 1.536712\n",
            "Epoch 79 Iteration 20440 - Train Loss: 0.000001 - Dev Loss: 1.536141\n",
            "Epoch 79 Iteration 20450 - Train Loss: 0.000001 - Dev Loss: 1.535015\n",
            "Epoch 79 Iteration 20460 - Train Loss: 0.000001 - Dev Loss: 1.532013\n",
            "Epoch 79 Iteration 20470 - Train Loss: 0.000001 - Dev Loss: 1.531130\n",
            "Epoch 80 Iteration 20480 - Train Loss: 0.000001 - Dev Loss: 1.533866\n",
            "Epoch 80 Iteration 20490 - Train Loss: 0.000001 - Dev Loss: 1.535484\n",
            "Epoch 80 Iteration 20500 - Train Loss: 0.000001 - Dev Loss: 1.537671\n",
            "Epoch 80 Iteration 20510 - Train Loss: 0.000001 - Dev Loss: 1.538284\n",
            "Epoch 80 Iteration 20520 - Train Loss: 0.000001 - Dev Loss: 1.537775\n",
            "Epoch 80 Iteration 20530 - Train Loss: 0.000001 - Dev Loss: 1.536643\n",
            "Epoch 80 Iteration 20540 - Train Loss: 0.000001 - Dev Loss: 1.537505\n",
            "Epoch 80 Iteration 20550 - Train Loss: 0.000001 - Dev Loss: 1.538651\n",
            "Epoch 80 Iteration 20560 - Train Loss: 0.000001 - Dev Loss: 1.538355\n",
            "Epoch 80 Iteration 20570 - Train Loss: 0.000001 - Dev Loss: 1.539654\n",
            "Epoch 80 Iteration 20580 - Train Loss: 0.000001 - Dev Loss: 1.540389\n",
            "Epoch 80 Iteration 20590 - Train Loss: 0.000001 - Dev Loss: 1.540902\n",
            "Epoch 80 Iteration 20600 - Train Loss: 0.000001 - Dev Loss: 1.540846\n",
            "Epoch 80 Iteration 20610 - Train Loss: 0.000001 - Dev Loss: 1.540625\n",
            "Epoch 80 Iteration 20620 - Train Loss: 0.000001 - Dev Loss: 1.540454\n",
            "Epoch 80 Iteration 20630 - Train Loss: 0.000001 - Dev Loss: 1.541045\n",
            "Epoch 80 Iteration 20640 - Train Loss: 0.000001 - Dev Loss: 1.542553\n",
            "Epoch 80 Iteration 20650 - Train Loss: 0.000001 - Dev Loss: 1.542905\n",
            "Epoch 80 Iteration 20660 - Train Loss: 0.000001 - Dev Loss: 1.544214\n",
            "Epoch 80 Iteration 20670 - Train Loss: 0.000001 - Dev Loss: 1.545314\n",
            "Epoch 80 Iteration 20680 - Train Loss: 0.000001 - Dev Loss: 1.545608\n",
            "Epoch 80 Iteration 20690 - Train Loss: 0.000001 - Dev Loss: 1.546253\n",
            "Epoch 80 Iteration 20700 - Train Loss: 0.000001 - Dev Loss: 1.548635\n",
            "Epoch 80 Iteration 20710 - Train Loss: 0.000001 - Dev Loss: 1.548805\n",
            "Epoch 80 Iteration 20720 - Train Loss: 0.000001 - Dev Loss: 1.546883\n",
            "Epoch 80 Iteration 20730 - Train Loss: 0.000001 - Dev Loss: 1.546250\n",
            "Epoch 81 Iteration 20740 - Train Loss: 0.000001 - Dev Loss: 1.549203\n",
            "Epoch 81 Iteration 20750 - Train Loss: 0.000001 - Dev Loss: 1.550749\n",
            "Epoch 81 Iteration 20760 - Train Loss: 0.000001 - Dev Loss: 1.551714\n",
            "Epoch 81 Iteration 20770 - Train Loss: 0.000001 - Dev Loss: 1.550738\n",
            "Epoch 81 Iteration 20780 - Train Loss: 0.000001 - Dev Loss: 1.550351\n",
            "Epoch 81 Iteration 20790 - Train Loss: 0.000001 - Dev Loss: 1.550848\n",
            "Epoch 81 Iteration 20800 - Train Loss: 0.000001 - Dev Loss: 1.551806\n",
            "Epoch 81 Iteration 20810 - Train Loss: 0.000001 - Dev Loss: 1.551700\n",
            "Epoch 81 Iteration 20820 - Train Loss: 0.000001 - Dev Loss: 1.551813\n",
            "Epoch 81 Iteration 20830 - Train Loss: 0.000001 - Dev Loss: 1.552576\n",
            "Epoch 81 Iteration 20840 - Train Loss: 0.000001 - Dev Loss: 1.552812\n",
            "Epoch 81 Iteration 20850 - Train Loss: 0.000001 - Dev Loss: 1.553208\n",
            "Epoch 81 Iteration 20860 - Train Loss: 0.000001 - Dev Loss: 1.556079\n",
            "Epoch 81 Iteration 20870 - Train Loss: 0.000000 - Dev Loss: 1.557378\n",
            "Epoch 81 Iteration 20880 - Train Loss: 0.000001 - Dev Loss: 1.557245\n",
            "Epoch 81 Iteration 20890 - Train Loss: 0.000001 - Dev Loss: 1.555739\n",
            "Epoch 81 Iteration 20900 - Train Loss: 0.000000 - Dev Loss: 1.555434\n",
            "Epoch 81 Iteration 20910 - Train Loss: 0.000001 - Dev Loss: 1.558896\n",
            "Epoch 81 Iteration 20920 - Train Loss: 0.000001 - Dev Loss: 1.559218\n",
            "Epoch 81 Iteration 20930 - Train Loss: 0.000001 - Dev Loss: 1.556828\n",
            "Epoch 81 Iteration 20940 - Train Loss: 0.000001 - Dev Loss: 1.556742\n",
            "Epoch 81 Iteration 20950 - Train Loss: 0.000001 - Dev Loss: 1.559718\n",
            "Epoch 81 Iteration 20960 - Train Loss: 0.000001 - Dev Loss: 1.558390\n",
            "Epoch 81 Iteration 20970 - Train Loss: 0.000001 - Dev Loss: 1.560155\n",
            "Epoch 81 Iteration 20980 - Train Loss: 0.000001 - Dev Loss: 1.562095\n",
            "Epoch 81 Iteration 20990 - Train Loss: 0.000001 - Dev Loss: 1.562118\n",
            "Epoch 82 Iteration 21000 - Train Loss: 0.000001 - Dev Loss: 1.564685\n",
            "Epoch 82 Iteration 21010 - Train Loss: 0.000001 - Dev Loss: 1.565830\n",
            "Epoch 82 Iteration 21020 - Train Loss: 0.000000 - Dev Loss: 1.564952\n",
            "Epoch 82 Iteration 21030 - Train Loss: 0.000000 - Dev Loss: 1.563113\n",
            "Epoch 82 Iteration 21040 - Train Loss: 0.000000 - Dev Loss: 1.562417\n",
            "Epoch 82 Iteration 21050 - Train Loss: 0.000000 - Dev Loss: 1.563994\n",
            "Epoch 82 Iteration 21060 - Train Loss: 0.000000 - Dev Loss: 1.566529\n",
            "Epoch 82 Iteration 21070 - Train Loss: 0.000001 - Dev Loss: 1.567909\n",
            "Epoch 82 Iteration 21080 - Train Loss: 0.000001 - Dev Loss: 1.569869\n",
            "Epoch 82 Iteration 21090 - Train Loss: 0.000000 - Dev Loss: 1.568456\n",
            "Epoch 82 Iteration 21100 - Train Loss: 0.000000 - Dev Loss: 1.567695\n",
            "Epoch 82 Iteration 21110 - Train Loss: 0.000001 - Dev Loss: 1.568239\n",
            "Epoch 82 Iteration 21120 - Train Loss: 0.000001 - Dev Loss: 1.566264\n",
            "Epoch 82 Iteration 21130 - Train Loss: 0.000000 - Dev Loss: 1.568508\n",
            "Epoch 82 Iteration 21140 - Train Loss: 0.000000 - Dev Loss: 1.570120\n",
            "Epoch 82 Iteration 21150 - Train Loss: 0.000001 - Dev Loss: 1.572007\n",
            "Epoch 82 Iteration 21160 - Train Loss: 0.000001 - Dev Loss: 1.572628\n",
            "Epoch 82 Iteration 21170 - Train Loss: 0.000000 - Dev Loss: 1.569050\n",
            "Epoch 82 Iteration 21180 - Train Loss: 0.000001 - Dev Loss: 1.569118\n",
            "Epoch 82 Iteration 21190 - Train Loss: 0.000001 - Dev Loss: 1.568819\n",
            "Epoch 82 Iteration 21200 - Train Loss: 0.000000 - Dev Loss: 1.570989\n",
            "Epoch 82 Iteration 21210 - Train Loss: 0.000000 - Dev Loss: 1.572519\n",
            "Epoch 82 Iteration 21220 - Train Loss: 0.000001 - Dev Loss: 1.573241\n",
            "Epoch 82 Iteration 21230 - Train Loss: 0.000000 - Dev Loss: 1.572385\n",
            "Epoch 82 Iteration 21240 - Train Loss: 0.000000 - Dev Loss: 1.572374\n",
            "Epoch 83 Iteration 21250 - Train Loss: 0.000000 - Dev Loss: 1.572919\n",
            "Epoch 83 Iteration 21260 - Train Loss: 0.000000 - Dev Loss: 1.573566\n",
            "Epoch 83 Iteration 21270 - Train Loss: 0.000000 - Dev Loss: 1.573948\n",
            "Epoch 83 Iteration 21280 - Train Loss: 0.000000 - Dev Loss: 1.574012\n",
            "Epoch 83 Iteration 21290 - Train Loss: 0.000000 - Dev Loss: 1.575538\n",
            "Epoch 83 Iteration 21300 - Train Loss: 0.000000 - Dev Loss: 1.576253\n",
            "Epoch 83 Iteration 21310 - Train Loss: 0.000000 - Dev Loss: 1.577865\n",
            "Epoch 83 Iteration 21320 - Train Loss: 0.000000 - Dev Loss: 1.576901\n",
            "Epoch 83 Iteration 21330 - Train Loss: 0.000000 - Dev Loss: 1.579062\n",
            "Epoch 83 Iteration 21340 - Train Loss: 0.000000 - Dev Loss: 1.578935\n",
            "Epoch 83 Iteration 21350 - Train Loss: 0.000000 - Dev Loss: 1.578313\n",
            "Epoch 83 Iteration 21360 - Train Loss: 0.000000 - Dev Loss: 1.580592\n",
            "Epoch 83 Iteration 21370 - Train Loss: 0.000000 - Dev Loss: 1.584011\n",
            "Epoch 83 Iteration 21380 - Train Loss: 0.000000 - Dev Loss: 1.583275\n",
            "Epoch 83 Iteration 21390 - Train Loss: 0.000000 - Dev Loss: 1.583936\n",
            "Epoch 83 Iteration 21400 - Train Loss: 0.000000 - Dev Loss: 1.584227\n",
            "Epoch 83 Iteration 21410 - Train Loss: 0.000000 - Dev Loss: 1.580783\n",
            "Epoch 83 Iteration 21420 - Train Loss: 0.000000 - Dev Loss: 1.581847\n",
            "Epoch 83 Iteration 21430 - Train Loss: 0.000000 - Dev Loss: 1.581454\n",
            "Epoch 83 Iteration 21440 - Train Loss: 0.000000 - Dev Loss: 1.582634\n",
            "Epoch 83 Iteration 21450 - Train Loss: 0.000001 - Dev Loss: 1.586340\n",
            "Epoch 83 Iteration 21460 - Train Loss: 0.000001 - Dev Loss: 1.588728\n",
            "Epoch 83 Iteration 21470 - Train Loss: 0.000000 - Dev Loss: 1.587992\n",
            "Epoch 83 Iteration 21480 - Train Loss: 0.000000 - Dev Loss: 1.584409\n",
            "Epoch 83 Iteration 21490 - Train Loss: 0.000000 - Dev Loss: 1.583236\n",
            "Epoch 83 Iteration 21500 - Train Loss: 0.000000 - Dev Loss: 1.586153\n",
            "Epoch 84 Iteration 21510 - Train Loss: 0.000000 - Dev Loss: 1.586542\n",
            "Epoch 84 Iteration 21520 - Train Loss: 0.000000 - Dev Loss: 1.587750\n",
            "Epoch 84 Iteration 21530 - Train Loss: 0.000000 - Dev Loss: 1.586803\n",
            "Epoch 84 Iteration 21540 - Train Loss: 0.000000 - Dev Loss: 1.587099\n",
            "Epoch 84 Iteration 21550 - Train Loss: 0.000000 - Dev Loss: 1.588674\n",
            "Epoch 84 Iteration 21560 - Train Loss: 0.000000 - Dev Loss: 1.591427\n",
            "Epoch 84 Iteration 21570 - Train Loss: 0.000001 - Dev Loss: 1.587507\n",
            "Epoch 84 Iteration 21580 - Train Loss: 0.000001 - Dev Loss: 1.595082\n",
            "Epoch 84 Iteration 21590 - Train Loss: 0.000001 - Dev Loss: 1.596313\n",
            "Epoch 84 Iteration 21600 - Train Loss: 0.000001 - Dev Loss: 1.588368\n",
            "Epoch 84 Iteration 21610 - Train Loss: 0.000001 - Dev Loss: 1.589494\n",
            "Epoch 84 Iteration 21620 - Train Loss: 0.000024 - Dev Loss: 1.593675\n",
            "Epoch 84 Iteration 21630 - Train Loss: 0.001397 - Dev Loss: 1.608209\n",
            "Epoch 84 Iteration 21640 - Train Loss: 0.009045 - Dev Loss: 1.566512\n",
            "Epoch 84 Iteration 21650 - Train Loss: 0.019601 - Dev Loss: 1.749495\n",
            "Epoch 84 Iteration 21660 - Train Loss: 0.044901 - Dev Loss: 1.652780\n",
            "Epoch 84 Iteration 21670 - Train Loss: 0.014181 - Dev Loss: 1.698054\n",
            "Epoch 84 Iteration 21680 - Train Loss: 0.031192 - Dev Loss: 1.665140\n",
            "Epoch 84 Iteration 21690 - Train Loss: 0.018138 - Dev Loss: 1.687190\n",
            "Epoch 84 Iteration 21700 - Train Loss: 0.018421 - Dev Loss: 1.640891\n",
            "Epoch 84 Iteration 21710 - Train Loss: 0.019214 - Dev Loss: 1.662155\n",
            "Epoch 84 Iteration 21720 - Train Loss: 0.015956 - Dev Loss: 1.653804\n",
            "Epoch 84 Iteration 21730 - Train Loss: 0.022618 - Dev Loss: 1.616481\n",
            "Epoch 84 Iteration 21740 - Train Loss: 0.020344 - Dev Loss: 1.568552\n",
            "Epoch 84 Iteration 21750 - Train Loss: 0.022780 - Dev Loss: 1.560233\n",
            "Epoch 85 Iteration 21760 - Train Loss: 0.017098 - Dev Loss: 1.550125\n",
            "Epoch 85 Iteration 21770 - Train Loss: 0.009135 - Dev Loss: 1.481080\n",
            "Epoch 85 Iteration 21780 - Train Loss: 0.017683 - Dev Loss: 1.408806\n",
            "Epoch 85 Iteration 21790 - Train Loss: 0.013079 - Dev Loss: 1.440675\n",
            "Epoch 85 Iteration 21800 - Train Loss: 0.006540 - Dev Loss: 1.442874\n",
            "Epoch 85 Iteration 21810 - Train Loss: 0.004596 - Dev Loss: 1.457216\n",
            "Epoch 85 Iteration 21820 - Train Loss: 0.013268 - Dev Loss: 1.463463\n",
            "Epoch 85 Iteration 21830 - Train Loss: 0.008615 - Dev Loss: 1.463553\n",
            "Epoch 85 Iteration 21840 - Train Loss: 0.006532 - Dev Loss: 1.478635\n",
            "Epoch 85 Iteration 21850 - Train Loss: 0.009942 - Dev Loss: 1.494191\n",
            "Epoch 85 Iteration 21860 - Train Loss: 0.009857 - Dev Loss: 1.555232\n",
            "Epoch 85 Iteration 21870 - Train Loss: 0.010501 - Dev Loss: 1.505955\n",
            "Epoch 85 Iteration 21880 - Train Loss: 0.006833 - Dev Loss: 1.420511\n",
            "Epoch 85 Iteration 21890 - Train Loss: 0.004247 - Dev Loss: 1.432843\n",
            "Epoch 85 Iteration 21900 - Train Loss: 0.007046 - Dev Loss: 1.497791\n",
            "Epoch 85 Iteration 21910 - Train Loss: 0.005388 - Dev Loss: 1.513864\n",
            "Epoch 85 Iteration 21920 - Train Loss: 0.004243 - Dev Loss: 1.532491\n",
            "Epoch 85 Iteration 21930 - Train Loss: 0.006569 - Dev Loss: 1.548585\n",
            "Epoch 85 Iteration 21940 - Train Loss: 0.009778 - Dev Loss: 1.543388\n",
            "Epoch 85 Iteration 21950 - Train Loss: 0.006331 - Dev Loss: 1.510217\n",
            "Epoch 85 Iteration 21960 - Train Loss: 0.006691 - Dev Loss: 1.493361\n",
            "Epoch 85 Iteration 21970 - Train Loss: 0.006430 - Dev Loss: 1.494590\n",
            "Epoch 85 Iteration 21980 - Train Loss: 0.007830 - Dev Loss: 1.544538\n",
            "Epoch 85 Iteration 21990 - Train Loss: 0.005553 - Dev Loss: 1.523735\n",
            "Epoch 85 Iteration 22000 - Train Loss: 0.003303 - Dev Loss: 1.539923\n",
            "Epoch 85 Iteration 22010 - Train Loss: 0.007546 - Dev Loss: 1.532226\n",
            "Epoch 86 Iteration 22020 - Train Loss: 0.001165 - Dev Loss: 1.507091\n",
            "Epoch 86 Iteration 22030 - Train Loss: 0.000610 - Dev Loss: 1.501392\n",
            "Epoch 86 Iteration 22040 - Train Loss: 0.000623 - Dev Loss: 1.493773\n",
            "Epoch 86 Iteration 22050 - Train Loss: 0.000343 - Dev Loss: 1.488972\n",
            "Epoch 86 Iteration 22060 - Train Loss: 0.000442 - Dev Loss: 1.486531\n",
            "Epoch 86 Iteration 22070 - Train Loss: 0.000368 - Dev Loss: 1.483207\n",
            "Epoch 86 Iteration 22080 - Train Loss: 0.001444 - Dev Loss: 1.490855\n",
            "Epoch 86 Iteration 22090 - Train Loss: 0.000906 - Dev Loss: 1.517821\n",
            "Epoch 86 Iteration 22100 - Train Loss: 0.000225 - Dev Loss: 1.535962\n",
            "Epoch 86 Iteration 22110 - Train Loss: 0.000383 - Dev Loss: 1.536486\n",
            "Epoch 86 Iteration 22120 - Train Loss: 0.001475 - Dev Loss: 1.530790\n",
            "Epoch 86 Iteration 22130 - Train Loss: 0.000616 - Dev Loss: 1.524355\n",
            "Epoch 86 Iteration 22140 - Train Loss: 0.002109 - Dev Loss: 1.521608\n",
            "Epoch 86 Iteration 22150 - Train Loss: 0.000563 - Dev Loss: 1.514444\n",
            "Epoch 86 Iteration 22160 - Train Loss: 0.000263 - Dev Loss: 1.511253\n",
            "Epoch 86 Iteration 22170 - Train Loss: 0.000249 - Dev Loss: 1.508792\n",
            "Epoch 86 Iteration 22180 - Train Loss: 0.000925 - Dev Loss: 1.517975\n",
            "Epoch 86 Iteration 22190 - Train Loss: 0.001229 - Dev Loss: 1.539603\n",
            "Epoch 86 Iteration 22200 - Train Loss: 0.001680 - Dev Loss: 1.534624\n",
            "Epoch 86 Iteration 22210 - Train Loss: 0.003290 - Dev Loss: 1.499298\n",
            "Epoch 86 Iteration 22220 - Train Loss: 0.000654 - Dev Loss: 1.488889\n",
            "Epoch 86 Iteration 22230 - Train Loss: 0.000377 - Dev Loss: 1.483277\n",
            "Epoch 86 Iteration 22240 - Train Loss: 0.000379 - Dev Loss: 1.475373\n",
            "Epoch 86 Iteration 22250 - Train Loss: 0.000418 - Dev Loss: 1.474471\n",
            "Epoch 86 Iteration 22260 - Train Loss: 0.000292 - Dev Loss: 1.473311\n",
            "Epoch 86 Iteration 22270 - Train Loss: 0.000500 - Dev Loss: 1.476585\n",
            "Epoch 87 Iteration 22280 - Train Loss: 0.000189 - Dev Loss: 1.474534\n",
            "Epoch 87 Iteration 22290 - Train Loss: 0.000059 - Dev Loss: 1.472482\n",
            "Epoch 87 Iteration 22300 - Train Loss: 0.000067 - Dev Loss: 1.472091\n",
            "Epoch 87 Iteration 22310 - Train Loss: 0.000127 - Dev Loss: 1.473262\n",
            "Epoch 87 Iteration 22320 - Train Loss: 0.000074 - Dev Loss: 1.474133\n",
            "Epoch 87 Iteration 22330 - Train Loss: 0.000102 - Dev Loss: 1.474661\n",
            "Epoch 87 Iteration 22340 - Train Loss: 0.000141 - Dev Loss: 1.476981\n",
            "Epoch 87 Iteration 22350 - Train Loss: 0.000143 - Dev Loss: 1.479450\n",
            "Epoch 87 Iteration 22360 - Train Loss: 0.000065 - Dev Loss: 1.481079\n",
            "Epoch 87 Iteration 22370 - Train Loss: 0.000071 - Dev Loss: 1.482880\n",
            "Epoch 87 Iteration 22380 - Train Loss: 0.000105 - Dev Loss: 1.484496\n",
            "Epoch 87 Iteration 22390 - Train Loss: 0.000080 - Dev Loss: 1.485716\n",
            "Epoch 87 Iteration 22400 - Train Loss: 0.000078 - Dev Loss: 1.486187\n",
            "Epoch 87 Iteration 22410 - Train Loss: 0.000071 - Dev Loss: 1.485815\n",
            "Epoch 87 Iteration 22420 - Train Loss: 0.000084 - Dev Loss: 1.486365\n",
            "Epoch 87 Iteration 22430 - Train Loss: 0.000107 - Dev Loss: 1.487633\n",
            "Epoch 87 Iteration 22440 - Train Loss: 0.000136 - Dev Loss: 1.488654\n",
            "Epoch 87 Iteration 22450 - Train Loss: 0.000236 - Dev Loss: 1.490280\n",
            "Epoch 87 Iteration 22460 - Train Loss: 0.000215 - Dev Loss: 1.493437\n",
            "Epoch 87 Iteration 22470 - Train Loss: 0.000067 - Dev Loss: 1.505220\n",
            "Epoch 87 Iteration 22480 - Train Loss: 0.000067 - Dev Loss: 1.509349\n",
            "Epoch 87 Iteration 22490 - Train Loss: 0.000102 - Dev Loss: 1.511061\n",
            "Epoch 87 Iteration 22500 - Train Loss: 0.000064 - Dev Loss: 1.511621\n",
            "Epoch 87 Iteration 22510 - Train Loss: 0.000072 - Dev Loss: 1.511651\n",
            "Epoch 87 Iteration 22520 - Train Loss: 0.000073 - Dev Loss: 1.511222\n",
            "Epoch 88 Iteration 22530 - Train Loss: 0.000166 - Dev Loss: 1.510892\n",
            "Epoch 88 Iteration 22540 - Train Loss: 0.000072 - Dev Loss: 1.510424\n",
            "Epoch 88 Iteration 22550 - Train Loss: 0.000043 - Dev Loss: 1.510034\n",
            "Epoch 88 Iteration 22560 - Train Loss: 0.000050 - Dev Loss: 1.509739\n",
            "Epoch 88 Iteration 22570 - Train Loss: 0.000045 - Dev Loss: 1.509379\n",
            "Epoch 88 Iteration 22580 - Train Loss: 0.000060 - Dev Loss: 1.509189\n",
            "Epoch 88 Iteration 22590 - Train Loss: 0.000048 - Dev Loss: 1.508836\n",
            "Epoch 88 Iteration 22600 - Train Loss: 0.000046 - Dev Loss: 1.508618\n",
            "Epoch 88 Iteration 22610 - Train Loss: 0.000052 - Dev Loss: 1.508241\n",
            "Epoch 88 Iteration 22620 - Train Loss: 0.000064 - Dev Loss: 1.507515\n",
            "Epoch 88 Iteration 22630 - Train Loss: 0.000051 - Dev Loss: 1.506748\n",
            "Epoch 88 Iteration 22640 - Train Loss: 0.000044 - Dev Loss: 1.506521\n",
            "Epoch 88 Iteration 22650 - Train Loss: 0.000040 - Dev Loss: 1.506316\n",
            "Epoch 88 Iteration 22660 - Train Loss: 0.000053 - Dev Loss: 1.506073\n",
            "Epoch 88 Iteration 22670 - Train Loss: 0.000069 - Dev Loss: 1.505364\n",
            "Epoch 88 Iteration 22680 - Train Loss: 0.000046 - Dev Loss: 1.504775\n",
            "Epoch 88 Iteration 22690 - Train Loss: 0.000047 - Dev Loss: 1.504680\n",
            "Epoch 88 Iteration 22700 - Train Loss: 0.000033 - Dev Loss: 1.504594\n",
            "Epoch 88 Iteration 22710 - Train Loss: 0.000062 - Dev Loss: 1.504541\n",
            "Epoch 88 Iteration 22720 - Train Loss: 0.000057 - Dev Loss: 1.504575\n",
            "Epoch 88 Iteration 22730 - Train Loss: 0.000055 - Dev Loss: 1.504426\n",
            "Epoch 88 Iteration 22740 - Train Loss: 0.000046 - Dev Loss: 1.504034\n",
            "Epoch 88 Iteration 22750 - Train Loss: 0.000051 - Dev Loss: 1.503996\n",
            "Epoch 88 Iteration 22760 - Train Loss: 0.000053 - Dev Loss: 1.503688\n",
            "Epoch 88 Iteration 22770 - Train Loss: 0.000066 - Dev Loss: 1.503723\n",
            "Epoch 88 Iteration 22780 - Train Loss: 0.000041 - Dev Loss: 1.503616\n",
            "Epoch 89 Iteration 22790 - Train Loss: 0.000032 - Dev Loss: 1.503415\n",
            "Epoch 89 Iteration 22800 - Train Loss: 0.000036 - Dev Loss: 1.503330\n",
            "Epoch 89 Iteration 22810 - Train Loss: 0.000046 - Dev Loss: 1.503380\n",
            "Epoch 89 Iteration 22820 - Train Loss: 0.000036 - Dev Loss: 1.503401\n",
            "Epoch 89 Iteration 22830 - Train Loss: 0.000044 - Dev Loss: 1.503228\n",
            "Epoch 89 Iteration 22840 - Train Loss: 0.000042 - Dev Loss: 1.502944\n",
            "Epoch 89 Iteration 22850 - Train Loss: 0.000036 - Dev Loss: 1.502677\n",
            "Epoch 89 Iteration 22860 - Train Loss: 0.000046 - Dev Loss: 1.502564\n",
            "Epoch 89 Iteration 22870 - Train Loss: 0.000045 - Dev Loss: 1.502584\n",
            "Epoch 89 Iteration 22880 - Train Loss: 0.000049 - Dev Loss: 1.502494\n",
            "Epoch 89 Iteration 22890 - Train Loss: 0.000029 - Dev Loss: 1.502432\n",
            "Epoch 89 Iteration 22900 - Train Loss: 0.000040 - Dev Loss: 1.502243\n",
            "Epoch 89 Iteration 22910 - Train Loss: 0.000036 - Dev Loss: 1.502060\n",
            "Epoch 89 Iteration 22920 - Train Loss: 0.000043 - Dev Loss: 1.502515\n",
            "Epoch 89 Iteration 22930 - Train Loss: 0.000036 - Dev Loss: 1.502732\n",
            "Epoch 89 Iteration 22940 - Train Loss: 0.000035 - Dev Loss: 1.503075\n",
            "Epoch 89 Iteration 22950 - Train Loss: 0.000032 - Dev Loss: 1.503492\n",
            "Epoch 89 Iteration 22960 - Train Loss: 0.000053 - Dev Loss: 1.503532\n",
            "Epoch 89 Iteration 22970 - Train Loss: 0.000041 - Dev Loss: 1.503508\n",
            "Epoch 89 Iteration 22980 - Train Loss: 0.000043 - Dev Loss: 1.503340\n",
            "Epoch 89 Iteration 22990 - Train Loss: 0.000042 - Dev Loss: 1.503326\n",
            "Epoch 89 Iteration 23000 - Train Loss: 0.000038 - Dev Loss: 1.503254\n",
            "Epoch 89 Iteration 23010 - Train Loss: 0.000042 - Dev Loss: 1.503362\n",
            "Epoch 89 Iteration 23020 - Train Loss: 0.000047 - Dev Loss: 1.503252\n",
            "Epoch 89 Iteration 23030 - Train Loss: 0.000036 - Dev Loss: 1.503084\n",
            "Epoch 90 Iteration 23040 - Train Loss: 0.000023 - Dev Loss: 1.503121\n",
            "Epoch 90 Iteration 23050 - Train Loss: 0.000032 - Dev Loss: 1.503027\n",
            "Epoch 90 Iteration 23060 - Train Loss: 0.000039 - Dev Loss: 1.502709\n",
            "Epoch 90 Iteration 23070 - Train Loss: 0.000032 - Dev Loss: 1.502354\n",
            "Epoch 90 Iteration 23080 - Train Loss: 0.000043 - Dev Loss: 1.502273\n",
            "Epoch 90 Iteration 23090 - Train Loss: 0.000033 - Dev Loss: 1.502160\n",
            "Epoch 90 Iteration 23100 - Train Loss: 0.000037 - Dev Loss: 1.501941\n",
            "Epoch 90 Iteration 23110 - Train Loss: 0.000030 - Dev Loss: 1.501925\n",
            "Epoch 90 Iteration 23120 - Train Loss: 0.000032 - Dev Loss: 1.501991\n",
            "Epoch 90 Iteration 23130 - Train Loss: 0.000029 - Dev Loss: 1.502131\n",
            "Epoch 90 Iteration 23140 - Train Loss: 0.000029 - Dev Loss: 1.502029\n",
            "Epoch 90 Iteration 23150 - Train Loss: 0.000036 - Dev Loss: 1.502033\n",
            "Epoch 90 Iteration 23160 - Train Loss: 0.000028 - Dev Loss: 1.502080\n",
            "Epoch 90 Iteration 23170 - Train Loss: 0.000036 - Dev Loss: 1.501999\n",
            "Epoch 90 Iteration 23180 - Train Loss: 0.000032 - Dev Loss: 1.502059\n",
            "Epoch 90 Iteration 23190 - Train Loss: 0.000038 - Dev Loss: 1.502159\n",
            "Epoch 90 Iteration 23200 - Train Loss: 0.000029 - Dev Loss: 1.502355\n",
            "Epoch 90 Iteration 23210 - Train Loss: 0.000037 - Dev Loss: 1.502664\n",
            "Epoch 90 Iteration 23220 - Train Loss: 0.000039 - Dev Loss: 1.502573\n",
            "Epoch 90 Iteration 23230 - Train Loss: 0.000038 - Dev Loss: 1.502539\n",
            "Epoch 90 Iteration 23240 - Train Loss: 0.000043 - Dev Loss: 1.503151\n",
            "Epoch 90 Iteration 23250 - Train Loss: 0.000034 - Dev Loss: 1.503365\n",
            "Epoch 90 Iteration 23260 - Train Loss: 0.000027 - Dev Loss: 1.503633\n",
            "Epoch 90 Iteration 23270 - Train Loss: 0.000029 - Dev Loss: 1.503893\n",
            "Epoch 90 Iteration 23280 - Train Loss: 0.000034 - Dev Loss: 1.503947\n",
            "Epoch 90 Iteration 23290 - Train Loss: 0.000035 - Dev Loss: 1.503822\n",
            "Epoch 91 Iteration 23300 - Train Loss: 0.000030 - Dev Loss: 1.503853\n",
            "Epoch 91 Iteration 23310 - Train Loss: 0.000033 - Dev Loss: 1.503970\n",
            "Epoch 91 Iteration 23320 - Train Loss: 0.000028 - Dev Loss: 1.504286\n",
            "Epoch 91 Iteration 23330 - Train Loss: 0.000033 - Dev Loss: 1.504458\n",
            "Epoch 91 Iteration 23340 - Train Loss: 0.000034 - Dev Loss: 1.504614\n",
            "Epoch 91 Iteration 23350 - Train Loss: 0.000032 - Dev Loss: 1.504550\n",
            "Epoch 91 Iteration 23360 - Train Loss: 0.000032 - Dev Loss: 1.504638\n",
            "Epoch 91 Iteration 23370 - Train Loss: 0.000036 - Dev Loss: 1.504584\n",
            "Epoch 91 Iteration 23380 - Train Loss: 0.000029 - Dev Loss: 1.504513\n",
            "Epoch 91 Iteration 23390 - Train Loss: 0.000023 - Dev Loss: 1.504553\n",
            "Epoch 91 Iteration 23400 - Train Loss: 0.000023 - Dev Loss: 1.504621\n",
            "Epoch 91 Iteration 23410 - Train Loss: 0.000029 - Dev Loss: 1.504501\n",
            "Epoch 91 Iteration 23420 - Train Loss: 0.000029 - Dev Loss: 1.504341\n",
            "Epoch 91 Iteration 23430 - Train Loss: 0.000025 - Dev Loss: 1.504269\n",
            "Epoch 91 Iteration 23440 - Train Loss: 0.000032 - Dev Loss: 1.504127\n",
            "Epoch 91 Iteration 23450 - Train Loss: 0.000029 - Dev Loss: 1.504204\n",
            "Epoch 91 Iteration 23460 - Train Loss: 0.000029 - Dev Loss: 1.504147\n",
            "Epoch 91 Iteration 23470 - Train Loss: 0.000021 - Dev Loss: 1.504150\n",
            "Epoch 91 Iteration 23480 - Train Loss: 0.000035 - Dev Loss: 1.504040\n",
            "Epoch 91 Iteration 23490 - Train Loss: 0.000024 - Dev Loss: 1.503896\n",
            "Epoch 91 Iteration 23500 - Train Loss: 0.000026 - Dev Loss: 1.503781\n",
            "Epoch 91 Iteration 23510 - Train Loss: 0.000033 - Dev Loss: 1.503886\n",
            "Epoch 91 Iteration 23520 - Train Loss: 0.000028 - Dev Loss: 1.503891\n",
            "Epoch 91 Iteration 23530 - Train Loss: 0.000035 - Dev Loss: 1.503856\n",
            "Epoch 91 Iteration 23540 - Train Loss: 0.000029 - Dev Loss: 1.504024\n",
            "Epoch 91 Iteration 23550 - Train Loss: 0.000025 - Dev Loss: 1.503992\n",
            "Epoch 92 Iteration 23560 - Train Loss: 0.000032 - Dev Loss: 1.503955\n",
            "Epoch 92 Iteration 23570 - Train Loss: 0.000032 - Dev Loss: 1.504263\n",
            "Epoch 92 Iteration 23580 - Train Loss: 0.000031 - Dev Loss: 1.504438\n",
            "Epoch 92 Iteration 23590 - Train Loss: 0.000023 - Dev Loss: 1.504698\n",
            "Epoch 92 Iteration 23600 - Train Loss: 0.000029 - Dev Loss: 1.504648\n",
            "Epoch 92 Iteration 23610 - Train Loss: 0.000023 - Dev Loss: 1.504628\n",
            "Epoch 92 Iteration 23620 - Train Loss: 0.000029 - Dev Loss: 1.504777\n",
            "Epoch 92 Iteration 23630 - Train Loss: 0.000030 - Dev Loss: 1.505031\n",
            "Epoch 92 Iteration 23640 - Train Loss: 0.000032 - Dev Loss: 1.505119\n",
            "Epoch 92 Iteration 23650 - Train Loss: 0.000026 - Dev Loss: 1.504908\n",
            "Epoch 92 Iteration 23660 - Train Loss: 0.000021 - Dev Loss: 1.504768\n",
            "Epoch 92 Iteration 23670 - Train Loss: 0.000028 - Dev Loss: 1.504714\n",
            "Epoch 92 Iteration 23680 - Train Loss: 0.000028 - Dev Loss: 1.504859\n",
            "Epoch 92 Iteration 23690 - Train Loss: 0.000022 - Dev Loss: 1.504920\n",
            "Epoch 92 Iteration 23700 - Train Loss: 0.000022 - Dev Loss: 1.504865\n",
            "Epoch 92 Iteration 23710 - Train Loss: 0.000021 - Dev Loss: 1.504740\n",
            "Epoch 92 Iteration 23720 - Train Loss: 0.000025 - Dev Loss: 1.504647\n",
            "Epoch 92 Iteration 23730 - Train Loss: 0.000028 - Dev Loss: 1.504931\n",
            "Epoch 92 Iteration 23740 - Train Loss: 0.000025 - Dev Loss: 1.505132\n",
            "Epoch 92 Iteration 23750 - Train Loss: 0.000018 - Dev Loss: 1.505140\n",
            "Epoch 92 Iteration 23760 - Train Loss: 0.000026 - Dev Loss: 1.505221\n",
            "Epoch 92 Iteration 23770 - Train Loss: 0.000029 - Dev Loss: 1.505398\n",
            "Epoch 92 Iteration 23780 - Train Loss: 0.000018 - Dev Loss: 1.505550\n",
            "Epoch 92 Iteration 23790 - Train Loss: 0.000025 - Dev Loss: 1.505502\n",
            "Epoch 92 Iteration 23800 - Train Loss: 0.000026 - Dev Loss: 1.505306\n",
            "Epoch 93 Iteration 23810 - Train Loss: 0.000020 - Dev Loss: 1.505227\n",
            "Epoch 93 Iteration 23820 - Train Loss: 0.000020 - Dev Loss: 1.505206\n",
            "Epoch 93 Iteration 23830 - Train Loss: 0.000019 - Dev Loss: 1.505070\n",
            "Epoch 93 Iteration 23840 - Train Loss: 0.000025 - Dev Loss: 1.504988\n",
            "Epoch 93 Iteration 23850 - Train Loss: 0.000028 - Dev Loss: 1.505049\n",
            "Epoch 93 Iteration 23860 - Train Loss: 0.000025 - Dev Loss: 1.505320\n",
            "Epoch 93 Iteration 23870 - Train Loss: 0.000021 - Dev Loss: 1.505573\n",
            "Epoch 93 Iteration 23880 - Train Loss: 0.000028 - Dev Loss: 1.505746\n",
            "Epoch 93 Iteration 23890 - Train Loss: 0.000023 - Dev Loss: 1.505991\n",
            "Epoch 93 Iteration 23900 - Train Loss: 0.000019 - Dev Loss: 1.506118\n",
            "Epoch 93 Iteration 23910 - Train Loss: 0.000022 - Dev Loss: 1.506181\n",
            "Epoch 93 Iteration 23920 - Train Loss: 0.000020 - Dev Loss: 1.506136\n",
            "Epoch 93 Iteration 23930 - Train Loss: 0.000019 - Dev Loss: 1.506078\n",
            "Epoch 93 Iteration 23940 - Train Loss: 0.000020 - Dev Loss: 1.506058\n",
            "Epoch 93 Iteration 23950 - Train Loss: 0.000025 - Dev Loss: 1.506085\n",
            "Epoch 93 Iteration 23960 - Train Loss: 0.000020 - Dev Loss: 1.506049\n",
            "Epoch 93 Iteration 23970 - Train Loss: 0.000022 - Dev Loss: 1.505928\n",
            "Epoch 93 Iteration 23980 - Train Loss: 0.000026 - Dev Loss: 1.505874\n",
            "Epoch 93 Iteration 23990 - Train Loss: 0.000021 - Dev Loss: 1.506064\n",
            "Epoch 93 Iteration 24000 - Train Loss: 0.000025 - Dev Loss: 1.506113\n",
            "Epoch 93 Iteration 24010 - Train Loss: 0.000030 - Dev Loss: 1.505971\n",
            "Epoch 93 Iteration 24020 - Train Loss: 0.000019 - Dev Loss: 1.505852\n",
            "Epoch 93 Iteration 24030 - Train Loss: 0.000031 - Dev Loss: 1.505877\n",
            "Epoch 93 Iteration 24040 - Train Loss: 0.000020 - Dev Loss: 1.506029\n",
            "Epoch 93 Iteration 24050 - Train Loss: 0.000022 - Dev Loss: 1.505998\n",
            "Epoch 93 Iteration 24060 - Train Loss: 0.000024 - Dev Loss: 1.505900\n",
            "Epoch 94 Iteration 24070 - Train Loss: 0.000021 - Dev Loss: 1.505649\n",
            "Epoch 94 Iteration 24080 - Train Loss: 0.000019 - Dev Loss: 1.505382\n",
            "Epoch 94 Iteration 24090 - Train Loss: 0.000019 - Dev Loss: 1.505379\n",
            "Epoch 94 Iteration 24100 - Train Loss: 0.000020 - Dev Loss: 1.505343\n",
            "Epoch 94 Iteration 24110 - Train Loss: 0.000019 - Dev Loss: 1.505480\n",
            "Epoch 94 Iteration 24120 - Train Loss: 0.000021 - Dev Loss: 1.505621\n",
            "Epoch 94 Iteration 24130 - Train Loss: 0.000021 - Dev Loss: 1.505869\n",
            "Epoch 94 Iteration 24140 - Train Loss: 0.000022 - Dev Loss: 1.505906\n",
            "Epoch 94 Iteration 24150 - Train Loss: 0.000020 - Dev Loss: 1.505906\n",
            "Epoch 94 Iteration 24160 - Train Loss: 0.000022 - Dev Loss: 1.505658\n",
            "Epoch 94 Iteration 24170 - Train Loss: 0.000020 - Dev Loss: 1.505548\n",
            "Epoch 94 Iteration 24180 - Train Loss: 0.000025 - Dev Loss: 1.505541\n",
            "Epoch 94 Iteration 24190 - Train Loss: 0.000018 - Dev Loss: 1.505789\n",
            "Epoch 94 Iteration 24200 - Train Loss: 0.000018 - Dev Loss: 1.505918\n",
            "Epoch 94 Iteration 24210 - Train Loss: 0.000025 - Dev Loss: 1.506155\n",
            "Epoch 94 Iteration 24220 - Train Loss: 0.000019 - Dev Loss: 1.506361\n",
            "Epoch 94 Iteration 24230 - Train Loss: 0.000017 - Dev Loss: 1.506592\n",
            "Epoch 94 Iteration 24240 - Train Loss: 0.000015 - Dev Loss: 1.506598\n",
            "Epoch 94 Iteration 24250 - Train Loss: 0.000017 - Dev Loss: 1.506504\n",
            "Epoch 94 Iteration 24260 - Train Loss: 0.000021 - Dev Loss: 1.506761\n",
            "Epoch 94 Iteration 24270 - Train Loss: 0.000021 - Dev Loss: 1.507000\n",
            "Epoch 94 Iteration 24280 - Train Loss: 0.000025 - Dev Loss: 1.507298\n",
            "Epoch 94 Iteration 24290 - Train Loss: 0.000019 - Dev Loss: 1.507425\n",
            "Epoch 94 Iteration 24300 - Train Loss: 0.000026 - Dev Loss: 1.507409\n",
            "Epoch 94 Iteration 24310 - Train Loss: 0.000022 - Dev Loss: 1.507441\n",
            "Epoch 95 Iteration 24320 - Train Loss: 0.000023 - Dev Loss: 1.507450\n",
            "Epoch 95 Iteration 24330 - Train Loss: 0.000016 - Dev Loss: 1.507658\n",
            "Epoch 95 Iteration 24340 - Train Loss: 0.000016 - Dev Loss: 1.507801\n",
            "Epoch 95 Iteration 24350 - Train Loss: 0.000022 - Dev Loss: 1.507882\n",
            "Epoch 95 Iteration 24360 - Train Loss: 0.000020 - Dev Loss: 1.507768\n",
            "Epoch 95 Iteration 24370 - Train Loss: 0.000026 - Dev Loss: 1.507784\n",
            "Epoch 95 Iteration 24380 - Train Loss: 0.000014 - Dev Loss: 1.507698\n",
            "Epoch 95 Iteration 24390 - Train Loss: 0.000016 - Dev Loss: 1.507690\n",
            "Epoch 95 Iteration 24400 - Train Loss: 0.000023 - Dev Loss: 1.507691\n",
            "Epoch 95 Iteration 24410 - Train Loss: 0.000018 - Dev Loss: 1.507758\n",
            "Epoch 95 Iteration 24420 - Train Loss: 0.000019 - Dev Loss: 1.507802\n",
            "Epoch 95 Iteration 24430 - Train Loss: 0.000020 - Dev Loss: 1.507796\n",
            "Epoch 95 Iteration 24440 - Train Loss: 0.000020 - Dev Loss: 1.507785\n",
            "Epoch 95 Iteration 24450 - Train Loss: 0.000017 - Dev Loss: 1.507826\n",
            "Epoch 95 Iteration 24460 - Train Loss: 0.000019 - Dev Loss: 1.507937\n",
            "Epoch 95 Iteration 24470 - Train Loss: 0.000021 - Dev Loss: 1.508038\n",
            "Epoch 95 Iteration 24480 - Train Loss: 0.000017 - Dev Loss: 1.508091\n",
            "Epoch 95 Iteration 24490 - Train Loss: 0.000017 - Dev Loss: 1.508155\n",
            "Epoch 95 Iteration 24500 - Train Loss: 0.000019 - Dev Loss: 1.508260\n",
            "Epoch 95 Iteration 24510 - Train Loss: 0.000018 - Dev Loss: 1.508287\n",
            "Epoch 95 Iteration 24520 - Train Loss: 0.000016 - Dev Loss: 1.508218\n",
            "Epoch 95 Iteration 24530 - Train Loss: 0.000017 - Dev Loss: 1.507996\n",
            "Epoch 95 Iteration 24540 - Train Loss: 0.000019 - Dev Loss: 1.508098\n",
            "Epoch 95 Iteration 24550 - Train Loss: 0.000018 - Dev Loss: 1.508126\n",
            "Epoch 95 Iteration 24560 - Train Loss: 0.000019 - Dev Loss: 1.508036\n",
            "Epoch 95 Iteration 24570 - Train Loss: 0.000016 - Dev Loss: 1.508078\n",
            "Epoch 96 Iteration 24580 - Train Loss: 0.000018 - Dev Loss: 1.508105\n",
            "Epoch 96 Iteration 24590 - Train Loss: 0.000018 - Dev Loss: 1.508265\n",
            "Epoch 96 Iteration 24600 - Train Loss: 0.000019 - Dev Loss: 1.508339\n",
            "Epoch 96 Iteration 24610 - Train Loss: 0.000013 - Dev Loss: 1.508346\n",
            "Epoch 96 Iteration 24620 - Train Loss: 0.000011 - Dev Loss: 1.508433\n",
            "Epoch 96 Iteration 24630 - Train Loss: 0.000019 - Dev Loss: 1.508617\n",
            "Epoch 96 Iteration 24640 - Train Loss: 0.000020 - Dev Loss: 1.508868\n",
            "Epoch 96 Iteration 24650 - Train Loss: 0.000020 - Dev Loss: 1.509098\n",
            "Epoch 96 Iteration 24660 - Train Loss: 0.000018 - Dev Loss: 1.509113\n",
            "Epoch 96 Iteration 24670 - Train Loss: 0.000021 - Dev Loss: 1.509086\n",
            "Epoch 96 Iteration 24680 - Train Loss: 0.000017 - Dev Loss: 1.509054\n",
            "Epoch 96 Iteration 24690 - Train Loss: 0.000017 - Dev Loss: 1.508909\n",
            "Epoch 96 Iteration 24700 - Train Loss: 0.000015 - Dev Loss: 1.508945\n",
            "Epoch 96 Iteration 24710 - Train Loss: 0.000021 - Dev Loss: 1.509015\n",
            "Epoch 96 Iteration 24720 - Train Loss: 0.000019 - Dev Loss: 1.508827\n",
            "Epoch 96 Iteration 24730 - Train Loss: 0.000016 - Dev Loss: 1.508473\n",
            "Epoch 96 Iteration 24740 - Train Loss: 0.000014 - Dev Loss: 1.508321\n",
            "Epoch 96 Iteration 24750 - Train Loss: 0.000011 - Dev Loss: 1.508283\n",
            "Epoch 96 Iteration 24760 - Train Loss: 0.000019 - Dev Loss: 1.508157\n",
            "Epoch 96 Iteration 24770 - Train Loss: 0.000013 - Dev Loss: 1.508121\n",
            "Epoch 96 Iteration 24780 - Train Loss: 0.000013 - Dev Loss: 1.508215\n",
            "Epoch 96 Iteration 24790 - Train Loss: 0.000016 - Dev Loss: 1.508361\n",
            "Epoch 96 Iteration 24800 - Train Loss: 0.000021 - Dev Loss: 1.508585\n",
            "Epoch 96 Iteration 24810 - Train Loss: 0.000016 - Dev Loss: 1.508722\n",
            "Epoch 96 Iteration 24820 - Train Loss: 0.000015 - Dev Loss: 1.508777\n",
            "Epoch 96 Iteration 24830 - Train Loss: 0.000015 - Dev Loss: 1.508735\n",
            "Epoch 97 Iteration 24840 - Train Loss: 0.000013 - Dev Loss: 1.508715\n",
            "Epoch 97 Iteration 24850 - Train Loss: 0.000013 - Dev Loss: 1.508690\n",
            "Epoch 97 Iteration 24860 - Train Loss: 0.000015 - Dev Loss: 1.508540\n",
            "Epoch 97 Iteration 24870 - Train Loss: 0.000014 - Dev Loss: 1.508251\n",
            "Epoch 97 Iteration 24880 - Train Loss: 0.000018 - Dev Loss: 1.508092\n",
            "Epoch 97 Iteration 24890 - Train Loss: 0.000017 - Dev Loss: 1.508062\n",
            "Epoch 97 Iteration 24900 - Train Loss: 0.000014 - Dev Loss: 1.508179\n",
            "Epoch 97 Iteration 24910 - Train Loss: 0.000013 - Dev Loss: 1.508230\n",
            "Epoch 97 Iteration 24920 - Train Loss: 0.000015 - Dev Loss: 1.508359\n",
            "Epoch 97 Iteration 24930 - Train Loss: 0.000015 - Dev Loss: 1.508464\n",
            "Epoch 97 Iteration 24940 - Train Loss: 0.000016 - Dev Loss: 1.508674\n",
            "Epoch 97 Iteration 24950 - Train Loss: 0.000017 - Dev Loss: 1.509080\n",
            "Epoch 97 Iteration 24960 - Train Loss: 0.000013 - Dev Loss: 1.509140\n",
            "Epoch 97 Iteration 24970 - Train Loss: 0.000015 - Dev Loss: 1.509107\n",
            "Epoch 97 Iteration 24980 - Train Loss: 0.000014 - Dev Loss: 1.509056\n",
            "Epoch 97 Iteration 24990 - Train Loss: 0.000016 - Dev Loss: 1.509208\n",
            "Epoch 97 Iteration 25000 - Train Loss: 0.000018 - Dev Loss: 1.509353\n",
            "Epoch 97 Iteration 25010 - Train Loss: 0.000014 - Dev Loss: 1.509401\n",
            "Epoch 97 Iteration 25020 - Train Loss: 0.000015 - Dev Loss: 1.509470\n",
            "Epoch 97 Iteration 25030 - Train Loss: 0.000014 - Dev Loss: 1.509592\n",
            "Epoch 97 Iteration 25040 - Train Loss: 0.000017 - Dev Loss: 1.509541\n",
            "Epoch 97 Iteration 25050 - Train Loss: 0.000013 - Dev Loss: 1.509515\n",
            "Epoch 97 Iteration 25060 - Train Loss: 0.000016 - Dev Loss: 1.509639\n",
            "Epoch 97 Iteration 25070 - Train Loss: 0.000014 - Dev Loss: 1.509758\n",
            "Epoch 97 Iteration 25080 - Train Loss: 0.000014 - Dev Loss: 1.509851\n",
            "Epoch 98 Iteration 25090 - Train Loss: 0.000016 - Dev Loss: 1.509798\n",
            "Epoch 98 Iteration 25100 - Train Loss: 0.000017 - Dev Loss: 1.509788\n",
            "Epoch 98 Iteration 25110 - Train Loss: 0.000013 - Dev Loss: 1.509680\n",
            "Epoch 98 Iteration 25120 - Train Loss: 0.000014 - Dev Loss: 1.509676\n",
            "Epoch 98 Iteration 25130 - Train Loss: 0.000013 - Dev Loss: 1.509658\n",
            "Epoch 98 Iteration 25140 - Train Loss: 0.000016 - Dev Loss: 1.509837\n",
            "Epoch 98 Iteration 25150 - Train Loss: 0.000014 - Dev Loss: 1.510038\n",
            "Epoch 98 Iteration 25160 - Train Loss: 0.000010 - Dev Loss: 1.510043\n",
            "Epoch 98 Iteration 25170 - Train Loss: 0.000015 - Dev Loss: 1.510046\n",
            "Epoch 98 Iteration 25180 - Train Loss: 0.000012 - Dev Loss: 1.509956\n",
            "Epoch 98 Iteration 25190 - Train Loss: 0.000013 - Dev Loss: 1.510010\n",
            "Epoch 98 Iteration 25200 - Train Loss: 0.000012 - Dev Loss: 1.510058\n",
            "Epoch 98 Iteration 25210 - Train Loss: 0.000015 - Dev Loss: 1.510134\n",
            "Epoch 98 Iteration 25220 - Train Loss: 0.000017 - Dev Loss: 1.510328\n",
            "Epoch 98 Iteration 25230 - Train Loss: 0.000014 - Dev Loss: 1.510436\n",
            "Epoch 98 Iteration 25240 - Train Loss: 0.000015 - Dev Loss: 1.510288\n",
            "Epoch 98 Iteration 25250 - Train Loss: 0.000013 - Dev Loss: 1.510107\n",
            "Epoch 98 Iteration 25260 - Train Loss: 0.000014 - Dev Loss: 1.510117\n",
            "Epoch 98 Iteration 25270 - Train Loss: 0.000015 - Dev Loss: 1.510300\n",
            "Epoch 98 Iteration 25280 - Train Loss: 0.000011 - Dev Loss: 1.510393\n",
            "Epoch 98 Iteration 25290 - Train Loss: 0.000012 - Dev Loss: 1.510565\n",
            "Epoch 98 Iteration 25300 - Train Loss: 0.000011 - Dev Loss: 1.510549\n",
            "Epoch 98 Iteration 25310 - Train Loss: 0.000014 - Dev Loss: 1.510583\n",
            "Epoch 98 Iteration 25320 - Train Loss: 0.000013 - Dev Loss: 1.510715\n",
            "Epoch 98 Iteration 25330 - Train Loss: 0.000015 - Dev Loss: 1.510701\n",
            "Epoch 98 Iteration 25340 - Train Loss: 0.000015 - Dev Loss: 1.510713\n",
            "Epoch 99 Iteration 25350 - Train Loss: 0.000013 - Dev Loss: 1.510724\n",
            "Epoch 99 Iteration 25360 - Train Loss: 0.000015 - Dev Loss: 1.510898\n",
            "Epoch 99 Iteration 25370 - Train Loss: 0.000010 - Dev Loss: 1.511078\n",
            "Epoch 99 Iteration 25380 - Train Loss: 0.000010 - Dev Loss: 1.511288\n",
            "Epoch 99 Iteration 25390 - Train Loss: 0.000013 - Dev Loss: 1.511454\n",
            "Epoch 99 Iteration 25400 - Train Loss: 0.000014 - Dev Loss: 1.511526\n",
            "Epoch 99 Iteration 25410 - Train Loss: 0.000012 - Dev Loss: 1.511506\n",
            "Epoch 99 Iteration 25420 - Train Loss: 0.000015 - Dev Loss: 1.511352\n",
            "Epoch 99 Iteration 25430 - Train Loss: 0.000011 - Dev Loss: 1.511250\n",
            "Epoch 99 Iteration 25440 - Train Loss: 0.000013 - Dev Loss: 1.511095\n",
            "Epoch 99 Iteration 25450 - Train Loss: 0.000011 - Dev Loss: 1.510997\n",
            "Epoch 99 Iteration 25460 - Train Loss: 0.000012 - Dev Loss: 1.510985\n",
            "Epoch 99 Iteration 25470 - Train Loss: 0.000012 - Dev Loss: 1.510905\n",
            "Epoch 99 Iteration 25480 - Train Loss: 0.000013 - Dev Loss: 1.510865\n",
            "Epoch 99 Iteration 25490 - Train Loss: 0.000010 - Dev Loss: 1.510903\n",
            "Epoch 99 Iteration 25500 - Train Loss: 0.000015 - Dev Loss: 1.510895\n",
            "Epoch 99 Iteration 25510 - Train Loss: 0.000015 - Dev Loss: 1.510936\n",
            "Epoch 99 Iteration 25520 - Train Loss: 0.000014 - Dev Loss: 1.511232\n",
            "Epoch 99 Iteration 25530 - Train Loss: 0.000011 - Dev Loss: 1.511356\n",
            "Epoch 99 Iteration 25540 - Train Loss: 0.000011 - Dev Loss: 1.511463\n",
            "Epoch 99 Iteration 25550 - Train Loss: 0.000014 - Dev Loss: 1.511658\n",
            "Epoch 99 Iteration 25560 - Train Loss: 0.000010 - Dev Loss: 1.511741\n",
            "Epoch 99 Iteration 25570 - Train Loss: 0.000012 - Dev Loss: 1.511849\n",
            "Epoch 99 Iteration 25580 - Train Loss: 0.000013 - Dev Loss: 1.512001\n",
            "Epoch 99 Iteration 25590 - Train Loss: 0.000013 - Dev Loss: 1.512018\n"
          ]
        }
      ],
      "source": [
        "dev_dataset.token_vocab = train_dataset.token_vocab\n",
        "dev_dataset.pos_vocab = train_dataset.pos_vocab\n",
        "\n",
        "# Hyperparameters / constants.\n",
        "input_vocab_size = len(train_dataset.token_vocab)\n",
        "output_vocab_size = len(train_dataset.pos_vocab)\n",
        "batch_size = 16\n",
        "epochs = 100\n",
        "n_layers = 1\n",
        "\n",
        "# Initialize the model.\n",
        "model = Tagger(input_vocab_size, output_vocab_size, n_layers)\n",
        "if torch.cuda.is_available():\n",
        "    model = model.cuda()\n",
        "\n",
        "# Loss function weights.\n",
        "weight = torch.ones(output_vocab_size)\n",
        "weight[0] = 0\n",
        "if torch.cuda.is_available():\n",
        "    weight = weight.cuda()\n",
        "    \n",
        "# Initialize loss function and optimizer.\n",
        "loss_function = torch.nn.NLLLoss(weight)\n",
        "optimizer = torch.optim.Adam(model.parameters())\n",
        "\n",
        "# Main training loop.\n",
        "data_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,\n",
        "                         collate_fn=collate_annotations)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False,\n",
        "                        collate_fn=collate_annotations)\n",
        "\n",
        "losses = []\n",
        "i = 0\n",
        "\n",
        "# For time counting\n",
        "startTime = time.time()\n",
        "for epoch in range(epochs):\n",
        "    for inputs, targets, lengths in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs, _ = model(inputs, lengths=lengths)\n",
        "\n",
        "        outputs = outputs.view(-1, output_vocab_size)\n",
        "        # print('---------------outputs----------------')\n",
        "        # print(outputs.shape)\n",
        "        # print(outputs)\n",
        "        targets = targets.view(-1)\n",
        "        # print('---------------targets----------------')\n",
        "        # print(targets.shape)\n",
        "        # print(targets)\n",
        "\n",
        "        loss = loss_function(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        #losses.append(loss.data[0])\n",
        "        losses.append(loss.item())\n",
        "        if (i % 10) == 0:\n",
        "            # Compute dev loss over entire dev set.\n",
        "            # NOTE: This is expensive. You may want to only use a \n",
        "            # subset of the dev set.\n",
        "            #print('iteration, ', i)\n",
        "            dev_losses = []\n",
        "            for inputs, targets, lengths in dev_loader:\n",
        "                outputs, _ = model(inputs, lengths=lengths)\n",
        "                outputs = outputs.view(-1, output_vocab_size)\n",
        "                targets = targets.view(-1)\n",
        "                loss = loss_function(outputs, targets)\n",
        "                dev_losses.append(loss.item())\n",
        "            avg_train_loss = np.mean(losses)\n",
        "            avg_dev_loss = np.mean(dev_losses)\n",
        "            losses = []\n",
        "            #print('here')\n",
        "            print('Epoch %i Iteration %i - Train Loss: %0.6f - Dev Loss: %0.6f' % (epoch, i, avg_train_loss, avg_dev_loss), end='\\n')\n",
        "            # torch.save(model, 'pos_tagger_gru.pt')\n",
        "        i += 1\n",
        "        \n",
        "# torch.save(model, 'pos_tagger_gru.final.pt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('======================================================================')\n",
        "print('Finished')\n",
        "\n",
        "# For time counting\n",
        "endTime = time.time()\n",
        "elapsedTime = endTime - startTime\n",
        "print( f'Running Time: {elapsedTime / 60:.2} minutes' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkH95ehp9SnL",
        "outputId": "332c635e-35d8-484c-82f3-0f609460f7dd"
      },
      "id": "lkH95ehp9SnL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Finished\n",
            "Running Time: 6.7e+01 minutes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp = 6.7e+01\n",
        "temp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u51ArSOaGICg",
        "outputId": "daf811fb-6b98-4ca0-f39f-1d9c5482b345"
      },
      "id": "u51ArSOaGICg",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "67.0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Collect the predictions and targets\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "for inputs, targets, lengths in dev_loader:\n",
        "    outputs, _ = model(inputs, lengths=lengths)\n",
        "    _, preds = torch.max(outputs, dim=2)\n",
        "    targets = targets.view(-1)\n",
        "    preds = preds.view(-1)\n",
        "    if torch.cuda.is_available():\n",
        "        targets = targets.cpu()\n",
        "        preds = preds.cpu()\n",
        "    y_true.append(targets.data.numpy())\n",
        "    y_pred.append(preds.data.numpy())"
      ],
      "metadata": {
        "id": "nH5MAtmO4-iD"
      },
      "id": "nH5MAtmO4-iD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stack into numpy arrays\n",
        "y_real = np.concatenate(y_true)\n",
        "y_pred = np.concatenate(y_pred)"
      ],
      "metadata": {
        "id": "DSuQYCTY5Ae7"
      },
      "id": "DSuQYCTY5Ae7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_real_temp = []\n",
        "for id in y_real:\n",
        "  y_real_temp.append(dev_dataset.pos_vocab._id2word[ id ])\n",
        "y_real = y_real_temp\n",
        "# print(y_real)"
      ],
      "metadata": {
        "id": "FPx1DSwd5B70"
      },
      "id": "FPx1DSwd5B70",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_temp = []\n",
        "for id in y_pred:\n",
        "  y_pred_temp.append(dev_dataset.pos_vocab._id2word[ id ])\n",
        "y_pred = y_pred_temp\n",
        "# print(y_pred)"
      ],
      "metadata": {
        "id": "sCoVYuR75fqM"
      },
      "id": "sCoVYuR75fqM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print( classification_report( y_real, y_pred ) )\n",
        "f1 = f1_score( y_real, y_pred, average='weighted' )\n",
        "acc = accuracy_score( y_real, y_pred )\n",
        "print( f'F1: {f1:.2}' )\n",
        "print( f'Accuracy: {acc:.2}' )\n",
        "\n",
        "# # Compute accuracy\n",
        "# acc = np.mean(y_real[y_real != 0] == y_pred[y_real != 0])\n",
        "# print('Accuracy - %0.6f\\n' % acc)\n",
        "\n",
        "# # Evaluate f1-score\n",
        "# from sklearn.metrics import f1_score\n",
        "# score = f1_score(y_real, y_pred, average=None)\n",
        "# print('F1-scores:\\n')\n",
        "# for label, score in zip(dev_dataset.pos_vocab._id2word[1:], score[1:]):\n",
        "#     print('%s - %0.6f' % (label, score))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRGM2Dx74Ceu",
        "outputId": "c74a229a-2bef-4d56-8eb3-c63e87743ecb"
      },
      "id": "pRGM2Dx74Ceu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       <pad>       0.00      0.00      0.00     33153\n",
            "         ADJ       0.86      0.54      0.66      1157\n",
            "         ADP       0.96      0.95      0.96      3549\n",
            "         ADV       0.91      0.87      0.89       844\n",
            "         AUX       0.91      0.92      0.92       581\n",
            "       CCONJ       0.99      0.99      0.99       542\n",
            "         DET       0.96      0.96      0.96      3702\n",
            "        INTJ       0.00      0.00      0.00         3\n",
            "        NOUN       0.92      0.74      0.82      4415\n",
            "         NUM       0.90      0.74      0.81       461\n",
            "        PRON       0.90      0.86      0.88       835\n",
            "       PROPN       0.05      0.87      0.10      2143\n",
            "       PUNCT       1.00      1.00      1.00      3267\n",
            "       SCONJ       0.67      0.73      0.70       542\n",
            "         SYM       1.00      1.00      1.00        36\n",
            "        VERB       0.71      0.84      0.77      2166\n",
            "           X       0.00      0.00      0.00        19\n",
            "           _       0.99      0.97      0.98      1753\n",
            "\n",
            "    accuracy                           0.38     59168\n",
            "   macro avg       0.71      0.72      0.69     59168\n",
            "weighted avg       0.37      0.38      0.36     59168\n",
            "\n",
            "F1: 0.36\n",
            "Accuracy: 0.38\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "tagger_gru.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}